{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1c115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb60aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffffc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Set the random seed for the 'random' module\n",
    "random.seed(42)\n",
    "\n",
    "# Set the random seed for 'numpy' (if used)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3548dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('output_Result0.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa98ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401.203</td>\n",
       "      <td>1003.485</td>\n",
       "      <td>949.140</td>\n",
       "      <td>792.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421.250</td>\n",
       "      <td>1021.578</td>\n",
       "      <td>925.547</td>\n",
       "      <td>788.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425.719</td>\n",
       "      <td>1035.750</td>\n",
       "      <td>907.328</td>\n",
       "      <td>704.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431.235</td>\n",
       "      <td>1042.703</td>\n",
       "      <td>900.469</td>\n",
       "      <td>766.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433.390</td>\n",
       "      <td>1044.985</td>\n",
       "      <td>902.468</td>\n",
       "      <td>781.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>209.157</td>\n",
       "      <td>482.406</td>\n",
       "      <td>623.969</td>\n",
       "      <td>714.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>202.657</td>\n",
       "      <td>491.234</td>\n",
       "      <td>627.188</td>\n",
       "      <td>690.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>203.046</td>\n",
       "      <td>492.938</td>\n",
       "      <td>615.297</td>\n",
       "      <td>720.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>107.875</td>\n",
       "      <td>419.500</td>\n",
       "      <td>693.657</td>\n",
       "      <td>744.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>198.750</td>\n",
       "      <td>475.953</td>\n",
       "      <td>606.657</td>\n",
       "      <td>714.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        F2       F3       F4\n",
       "0    401.203  1003.485  949.140  792.094\n",
       "1    421.250  1021.578  925.547  788.015\n",
       "2    425.719  1035.750  907.328  704.781\n",
       "3    431.235  1042.703  900.469  766.844\n",
       "4    433.390  1044.985  902.468  781.000\n",
       "..       ...       ...      ...      ...\n",
       "632  209.157   482.406  623.969  714.625\n",
       "633  202.657   491.234  627.188  690.843\n",
       "634  203.046   492.938  615.297  720.390\n",
       "635  107.875   419.500  693.657  744.625\n",
       "636  198.750   475.953  606.657  714.156\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8875c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa5f8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>186.1922</td>\n",
       "      <td>471.4906</td>\n",
       "      <td>650.2078</td>\n",
       "      <td>736.2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>186.3235</td>\n",
       "      <td>473.4359</td>\n",
       "      <td>651.3828</td>\n",
       "      <td>732.0997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>186.9906</td>\n",
       "      <td>475.8813</td>\n",
       "      <td>652.2797</td>\n",
       "      <td>733.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>192.5687</td>\n",
       "      <td>486.7563</td>\n",
       "      <td>647.7283</td>\n",
       "      <td>724.8138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>189.6234</td>\n",
       "      <td>481.9984</td>\n",
       "      <td>642.6893</td>\n",
       "      <td>723.8966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1        F2        F3        F4\n",
       "0         NaN       NaN       NaN       NaN\n",
       "1         NaN       NaN       NaN       NaN\n",
       "2         NaN       NaN       NaN       NaN\n",
       "3         NaN       NaN       NaN       NaN\n",
       "4         NaN       NaN       NaN       NaN\n",
       "..        ...       ...       ...       ...\n",
       "632  186.1922  471.4906  650.2078  736.2451\n",
       "633  186.3235  473.4359  651.3828  732.0997\n",
       "634  186.9906  475.8813  652.2797  733.2419\n",
       "635  192.5687  486.7563  647.7283  724.8138\n",
       "636  189.6234  481.9984  642.6893  723.8966\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f47a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>434.3110</td>\n",
       "      <td>1037.8001</td>\n",
       "      <td>901.6749</td>\n",
       "      <td>741.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439.2438</td>\n",
       "      <td>1041.3719</td>\n",
       "      <td>895.6578</td>\n",
       "      <td>733.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439.9047</td>\n",
       "      <td>1040.8891</td>\n",
       "      <td>887.2797</td>\n",
       "      <td>722.4185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1         F2        F3        F4\n",
       "0        NaN        NaN       NaN       NaN\n",
       "1        NaN        NaN       NaN       NaN\n",
       "2        NaN        NaN       NaN       NaN\n",
       "3        NaN        NaN       NaN       NaN\n",
       "4        NaN        NaN       NaN       NaN\n",
       "5        NaN        NaN       NaN       NaN\n",
       "6        NaN        NaN       NaN       NaN\n",
       "7        NaN        NaN       NaN       NaN\n",
       "8        NaN        NaN       NaN       NaN\n",
       "9   434.3110  1037.8001  901.6749  741.1248\n",
       "10  439.2438  1041.3719  895.6578  733.3810\n",
       "11  439.9047  1040.8891  887.2797  722.4185"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfa1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93af4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 434.311 , 1037.8001,  901.6749,  741.1248],\n",
       "       [ 439.2438, 1041.3719,  895.6578,  733.381 ],\n",
       "       [ 439.9047, 1040.8891,  887.2797,  722.4185],\n",
       "       ...,\n",
       "       [ 186.9906,  475.8813,  652.2797,  733.2419],\n",
       "       [ 192.5687,  486.7563,  647.7283,  724.8138],\n",
       "       [ 189.6234,  481.9984,  642.6893,  723.8966]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89596b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset_train_scaled = sc.fit_transform(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5180305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19477b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f80fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result = pd.read_csv('SOH_RESULT12.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6e7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.917675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.677398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.670526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.666465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.665487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.664586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0    0.928244\n",
       "1    0.923164\n",
       "2    0.917675\n",
       "3    0.917631\n",
       "4    0.917323\n",
       "..        ...\n",
       "632  0.677398\n",
       "633  0.670526\n",
       "634  0.666465\n",
       "635  0.665487\n",
       "636  0.664586\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c68a1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865ffac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.686977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.683707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.677815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.675764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "..        ...\n",
       "632  0.686977\n",
       "633  0.683707\n",
       "634  0.680679\n",
       "635  0.677815\n",
       "636  0.675764\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ff2375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SOH\n",
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "5       NaN\n",
       "6       NaN\n",
       "7       NaN\n",
       "8       NaN\n",
       "9  0.917701"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eca6fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf70b28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91770118],\n",
       "       [0.91610779],\n",
       "       [0.91450152],\n",
       "       [0.91342167],\n",
       "       [0.91233057],\n",
       "       [0.91072819],\n",
       "       [0.90905045],\n",
       "       [0.90742212],\n",
       "       [0.9062877 ],\n",
       "       [0.90518789],\n",
       "       [0.90630852],\n",
       "       [0.90744841],\n",
       "       [0.90854719],\n",
       "       [0.90914862],\n",
       "       [0.90973227],\n",
       "       [0.91088145],\n",
       "       [0.91147766],\n",
       "       [0.91208714],\n",
       "       [0.9126322 ],\n",
       "       [0.9126316 ],\n",
       "       [0.91048415],\n",
       "       [0.91070341],\n",
       "       [0.91042974],\n",
       "       [0.9096061 ],\n",
       "       [0.90858091],\n",
       "       [0.90727069],\n",
       "       [0.90599129],\n",
       "       [0.90439899],\n",
       "       [0.9023522 ],\n",
       "       [0.90086581],\n",
       "       [0.89905556],\n",
       "       [0.89458119],\n",
       "       [0.89142686],\n",
       "       [0.88909488],\n",
       "       [0.88645091],\n",
       "       [0.88357453],\n",
       "       [0.88095694],\n",
       "       [0.88149199],\n",
       "       [0.88199975],\n",
       "       [0.88171608],\n",
       "       [0.88117336],\n",
       "       [0.88040114],\n",
       "       [0.87910614],\n",
       "       [0.87779384],\n",
       "       [0.8765234 ],\n",
       "       [0.87522125],\n",
       "       [0.87394335],\n",
       "       [0.86956288],\n",
       "       [0.86541898],\n",
       "       [0.86177976],\n",
       "       [0.85817401],\n",
       "       [0.85455419],\n",
       "       [0.85119679],\n",
       "       [0.84756148],\n",
       "       [0.84419609],\n",
       "       [0.84109847],\n",
       "       [0.83770449],\n",
       "       [0.83429666],\n",
       "       [0.83091786],\n",
       "       [0.82757651],\n",
       "       [0.82443764],\n",
       "       [0.82128021],\n",
       "       [0.81787991],\n",
       "       [0.8147698 ],\n",
       "       [0.81133757],\n",
       "       [0.80793431],\n",
       "       [0.80504878],\n",
       "       [0.80293221],\n",
       "       [0.80003196],\n",
       "       [0.79688942],\n",
       "       [0.79377144],\n",
       "       [0.79117924],\n",
       "       [0.78858555],\n",
       "       [0.78595354],\n",
       "       [0.78334691],\n",
       "       [0.78045317],\n",
       "       [0.77763228],\n",
       "       [0.77398833],\n",
       "       [0.77112612],\n",
       "       [0.77317197],\n",
       "       [0.77337613],\n",
       "       [0.77280662],\n",
       "       [0.77169093],\n",
       "       [0.77059487],\n",
       "       [0.76953091],\n",
       "       [0.76873007],\n",
       "       [0.767632  ],\n",
       "       [0.7665769 ],\n",
       "       [0.76524483],\n",
       "       [0.7592473 ],\n",
       "       [0.75507553],\n",
       "       [0.75143143],\n",
       "       [0.74910783],\n",
       "       [0.74756478],\n",
       "       [0.74575695],\n",
       "       [0.74364978],\n",
       "       [0.74101665],\n",
       "       [0.73864669],\n",
       "       [0.73685566],\n",
       "       [0.73501435],\n",
       "       [0.73292721],\n",
       "       [0.730839  ],\n",
       "       [0.72821362],\n",
       "       [0.72481227],\n",
       "       [0.72191826],\n",
       "       [0.71930199],\n",
       "       [0.71722739],\n",
       "       [0.71514902],\n",
       "       [0.71277775],\n",
       "       [0.71199525],\n",
       "       [0.71197445],\n",
       "       [0.71116991],\n",
       "       [0.7098492 ],\n",
       "       [0.70850615],\n",
       "       [0.70719517],\n",
       "       [0.70588796],\n",
       "       [0.70457894],\n",
       "       [0.70297183],\n",
       "       [0.70135373],\n",
       "       [0.69820977],\n",
       "       [0.69482245],\n",
       "       [0.69219149],\n",
       "       [0.69061201],\n",
       "       [0.68985739],\n",
       "       [0.68851485],\n",
       "       [0.68718975],\n",
       "       [0.68559442],\n",
       "       [0.68430467],\n",
       "       [0.68327804],\n",
       "       [0.68221815],\n",
       "       [0.68090219],\n",
       "       [0.67961498],\n",
       "       [0.6777911 ],\n",
       "       [0.67518586],\n",
       "       [0.67312558],\n",
       "       [0.67104499],\n",
       "       [0.66923734],\n",
       "       [0.66742858],\n",
       "       [0.66560804],\n",
       "       [0.66433591],\n",
       "       [0.66513253],\n",
       "       [0.6651595 ],\n",
       "       [0.6646652 ],\n",
       "       [0.66414858],\n",
       "       [0.66364805],\n",
       "       [0.66316326],\n",
       "       [0.66291491],\n",
       "       [0.66238138],\n",
       "       [0.66161838],\n",
       "       [0.66059263],\n",
       "       [0.65775704],\n",
       "       [0.65567486],\n",
       "       [0.65412711],\n",
       "       [0.65261658],\n",
       "       [0.65108506],\n",
       "       [0.64978392],\n",
       "       [0.64957459],\n",
       "       [0.65043876],\n",
       "       [0.65054171],\n",
       "       [0.68514529],\n",
       "       [0.71924637],\n",
       "       [0.75304449],\n",
       "       [0.78683124],\n",
       "       [0.82022317],\n",
       "       [0.85454354],\n",
       "       [0.88885234],\n",
       "       [0.91991088],\n",
       "       [0.95013565],\n",
       "       [0.98082373],\n",
       "       [0.97642479],\n",
       "       [0.97199392],\n",
       "       [0.96757988],\n",
       "       [0.96260955],\n",
       "       [0.95773398],\n",
       "       [0.95162123],\n",
       "       [0.94501228],\n",
       "       [0.94005051],\n",
       "       [0.93512026],\n",
       "       [0.9362181 ],\n",
       "       [0.93680392],\n",
       "       [0.93734629],\n",
       "       [0.93739366],\n",
       "       [0.93906479],\n",
       "       [0.93908152],\n",
       "       [0.9385656 ],\n",
       "       [0.93807676],\n",
       "       [0.93751082],\n",
       "       [0.93641329],\n",
       "       [0.93041341],\n",
       "       [0.92880685],\n",
       "       [0.92569002],\n",
       "       [0.92230917],\n",
       "       [0.91606203],\n",
       "       [0.9117517 ],\n",
       "       [0.90775305],\n",
       "       [0.90347356],\n",
       "       [0.89930634],\n",
       "       [0.89515298],\n",
       "       [0.88991095],\n",
       "       [0.88082842],\n",
       "       [0.87457572],\n",
       "       [0.87019642],\n",
       "       [0.86604197],\n",
       "       [0.8611326 ],\n",
       "       [0.85649073],\n",
       "       [0.8585846 ],\n",
       "       [0.86040398],\n",
       "       [0.86115348],\n",
       "       [0.8608814 ],\n",
       "       [0.86037721],\n",
       "       [0.85809447],\n",
       "       [0.85474429],\n",
       "       [0.85220874],\n",
       "       [0.85015731],\n",
       "       [0.84811571],\n",
       "       [0.839655  ],\n",
       "       [0.83142003],\n",
       "       [0.82423566],\n",
       "       [0.81757432],\n",
       "       [0.81141341],\n",
       "       [0.80606353],\n",
       "       [0.80067294],\n",
       "       [0.79581551],\n",
       "       [0.79070085],\n",
       "       [0.78582759],\n",
       "       [0.78092808],\n",
       "       [0.77605256],\n",
       "       [0.7709601 ],\n",
       "       [0.76710262],\n",
       "       [0.76323655],\n",
       "       [0.75909822],\n",
       "       [0.75526314],\n",
       "       [0.75139183],\n",
       "       [0.74778314],\n",
       "       [0.74416979],\n",
       "       [0.74314608],\n",
       "       [0.74135206],\n",
       "       [0.73956017],\n",
       "       [0.73701708],\n",
       "       [0.73475253],\n",
       "       [0.73272633],\n",
       "       [0.73067364],\n",
       "       [0.72810657],\n",
       "       [0.72606753],\n",
       "       [0.72408303],\n",
       "       [0.71999313],\n",
       "       [0.71693422],\n",
       "       [0.72207281],\n",
       "       [0.72541165],\n",
       "       [0.7271884 ],\n",
       "       [0.72845133],\n",
       "       [0.72921577],\n",
       "       [0.73026171],\n",
       "       [0.73079292],\n",
       "       [0.73102272],\n",
       "       [0.73102337],\n",
       "       [0.73100897],\n",
       "       [0.72304937],\n",
       "       [0.7171491 ],\n",
       "       [0.71253057],\n",
       "       [0.70869341],\n",
       "       [0.7071809 ],\n",
       "       [0.70515106],\n",
       "       [0.70281063],\n",
       "       [0.70074664],\n",
       "       [0.69869028],\n",
       "       [0.69642479],\n",
       "       [0.69462693],\n",
       "       [0.69282754],\n",
       "       [0.69103098],\n",
       "       [0.68872612],\n",
       "       [0.68511583],\n",
       "       [0.68228262],\n",
       "       [0.67999057],\n",
       "       [0.67771466],\n",
       "       [0.67541952],\n",
       "       [0.67336584],\n",
       "       [0.67285732],\n",
       "       [0.67363328],\n",
       "       [0.67338235],\n",
       "       [0.67311688],\n",
       "       [0.67207321],\n",
       "       [0.67103073],\n",
       "       [0.67000876],\n",
       "       [0.6687198 ],\n",
       "       [0.66740307],\n",
       "       [0.66606293],\n",
       "       [0.6629952 ],\n",
       "       [0.65888139],\n",
       "       [0.6557897 ],\n",
       "       [0.65346797],\n",
       "       [0.65298355],\n",
       "       [0.65168548],\n",
       "       [0.64985747],\n",
       "       [0.64829908],\n",
       "       [0.64678785],\n",
       "       [0.6455283 ],\n",
       "       [0.64395614],\n",
       "       [0.64189869],\n",
       "       [0.64011238],\n",
       "       [0.63781504],\n",
       "       [0.63422163],\n",
       "       [0.63117022],\n",
       "       [0.62862211],\n",
       "       [0.62607524],\n",
       "       [0.62376274],\n",
       "       [0.62120646],\n",
       "       [0.61943826],\n",
       "       [0.6199555 ],\n",
       "       [0.61918748],\n",
       "       [0.61791   ],\n",
       "       [0.61585083],\n",
       "       [0.61405425],\n",
       "       [0.61227006],\n",
       "       [0.61020353],\n",
       "       [0.60786944],\n",
       "       [0.60555602],\n",
       "       [0.60247538],\n",
       "       [0.59734667],\n",
       "       [0.59323542],\n",
       "       [0.58963832],\n",
       "       [0.58579999],\n",
       "       [0.58272583],\n",
       "       [0.57964043],\n",
       "       [0.57786945],\n",
       "       [0.57689197],\n",
       "       [0.57612913],\n",
       "       [0.61231947],\n",
       "       [0.6482543 ],\n",
       "       [0.68446044],\n",
       "       [0.72092079],\n",
       "       [0.75833361],\n",
       "       [0.79529015],\n",
       "       [0.83248311],\n",
       "       [0.86896174],\n",
       "       [0.90432495],\n",
       "       [0.93972307],\n",
       "       [0.93867266],\n",
       "       [0.93762341],\n",
       "       [0.93654401],\n",
       "       [0.93545589],\n",
       "       [0.93445145],\n",
       "       [0.93335321],\n",
       "       [0.93174732],\n",
       "       [0.93009814],\n",
       "       [0.92903255],\n",
       "       [0.92956896],\n",
       "       [0.93014035],\n",
       "       [0.93121253],\n",
       "       [0.93180924],\n",
       "       [0.9323688 ],\n",
       "       [0.93293426],\n",
       "       [0.93297811],\n",
       "       [0.93358894],\n",
       "       [0.93412094],\n",
       "       [0.93410898],\n",
       "       [0.93253004],\n",
       "       [0.93262982],\n",
       "       [0.9317161 ],\n",
       "       [0.93051318],\n",
       "       [0.92884462],\n",
       "       [0.92716915],\n",
       "       [0.92577214],\n",
       "       [0.92382779],\n",
       "       [0.92169483],\n",
       "       [0.91985692],\n",
       "       [0.91797712],\n",
       "       [0.91410648],\n",
       "       [0.91162563],\n",
       "       [0.90959132],\n",
       "       [0.90754144],\n",
       "       [0.90497761],\n",
       "       [0.90241034],\n",
       "       [0.90210677],\n",
       "       [0.90206659],\n",
       "       [0.90150967],\n",
       "       [0.90045177],\n",
       "       [0.89916618],\n",
       "       [0.89727241],\n",
       "       [0.89547235],\n",
       "       [0.89368485],\n",
       "       [0.89187297],\n",
       "       [0.89033913],\n",
       "       [0.88683678],\n",
       "       [0.88303394],\n",
       "       [0.87944999],\n",
       "       [0.87612263],\n",
       "       [0.87280442],\n",
       "       [0.86973649],\n",
       "       [0.86640595],\n",
       "       [0.86360258],\n",
       "       [0.86079878],\n",
       "       [0.85769917],\n",
       "       [0.85460145],\n",
       "       [0.85151551],\n",
       "       [0.8487476 ],\n",
       "       [0.84592442],\n",
       "       [0.84333879],\n",
       "       [0.8405115 ],\n",
       "       [0.83795583],\n",
       "       [0.83511601],\n",
       "       [0.83225812],\n",
       "       [0.829688  ],\n",
       "       [0.82759024],\n",
       "       [0.82527239],\n",
       "       [0.82267275],\n",
       "       [0.82012228],\n",
       "       [0.81780015],\n",
       "       [0.81576514],\n",
       "       [0.81368149],\n",
       "       [0.81135363],\n",
       "       [0.80932882],\n",
       "       [0.80732694],\n",
       "       [0.80506131],\n",
       "       [0.80301535],\n",
       "       [0.80639574],\n",
       "       [0.80687406],\n",
       "       [0.80687006],\n",
       "       [0.80631698],\n",
       "       [0.80552244],\n",
       "       [0.80500993],\n",
       "       [0.80448164],\n",
       "       [0.80366943],\n",
       "       [0.80264003],\n",
       "       [0.80159742],\n",
       "       [0.79566919],\n",
       "       [0.79263199],\n",
       "       [0.78982652],\n",
       "       [0.78779249],\n",
       "       [0.78679273],\n",
       "       [0.78553627],\n",
       "       [0.78425646],\n",
       "       [0.78275266],\n",
       "       [0.78118559],\n",
       "       [0.77994661],\n",
       "       [0.77866348],\n",
       "       [0.77711642],\n",
       "       [0.77557274],\n",
       "       [0.77376994],\n",
       "       [0.77147555],\n",
       "       [0.76940679],\n",
       "       [0.76735239],\n",
       "       [0.76553992],\n",
       "       [0.76402631],\n",
       "       [0.76247273],\n",
       "       [0.76194102],\n",
       "       [0.76218245],\n",
       "       [0.76192567],\n",
       "       [0.76115844],\n",
       "       [0.76009311],\n",
       "       [0.75905761],\n",
       "       [0.75801534],\n",
       "       [0.75697536],\n",
       "       [0.75591582],\n",
       "       [0.75459261],\n",
       "       [0.75202137],\n",
       "       [0.74920388],\n",
       "       [0.7468712 ],\n",
       "       [0.74528721],\n",
       "       [0.74480479],\n",
       "       [0.74374886],\n",
       "       [0.74271353],\n",
       "       [0.74167497],\n",
       "       [0.74066665],\n",
       "       [0.73964305],\n",
       "       [0.73860465],\n",
       "       [0.73730004],\n",
       "       [0.73601923],\n",
       "       [0.73450495],\n",
       "       [0.73193893],\n",
       "       [0.73017291],\n",
       "       [0.72838612],\n",
       "       [0.72659453],\n",
       "       [0.7248229 ],\n",
       "       [0.7232871 ],\n",
       "       [0.72229161],\n",
       "       [0.72281716],\n",
       "       [0.72284262],\n",
       "       [0.72261872],\n",
       "       [0.72236744],\n",
       "       [0.72161114],\n",
       "       [0.72113257],\n",
       "       [0.7206331 ],\n",
       "       [0.72009672],\n",
       "       [0.71934516],\n",
       "       [0.71806865],\n",
       "       [0.71553724],\n",
       "       [0.71348605],\n",
       "       [0.7116789 ],\n",
       "       [0.70989794],\n",
       "       [0.70863318],\n",
       "       [0.70706552],\n",
       "       [0.70684204],\n",
       "       [0.70716041],\n",
       "       [0.70764404],\n",
       "       [0.72957791],\n",
       "       [0.75090877],\n",
       "       [0.77234686],\n",
       "       [0.79333079],\n",
       "       [0.81465723],\n",
       "       [0.83576688],\n",
       "       [0.85680418],\n",
       "       [0.87647335],\n",
       "       [0.89506549],\n",
       "       [0.9146737 ],\n",
       "       [0.91252975],\n",
       "       [0.91060455],\n",
       "       [0.90816668],\n",
       "       [0.90580653],\n",
       "       [0.90321845],\n",
       "       [0.90035246],\n",
       "       [0.89772392],\n",
       "       [0.89464694],\n",
       "       [0.89174303],\n",
       "       [0.88747125],\n",
       "       [0.88344082],\n",
       "       [0.87863599],\n",
       "       [0.87466727],\n",
       "       [0.87086884],\n",
       "       [0.86928382],\n",
       "       [0.86736185],\n",
       "       [0.8650419 ],\n",
       "       [0.86295269],\n",
       "       [0.86060509],\n",
       "       [0.85842369],\n",
       "       [0.85594299],\n",
       "       [0.85436209],\n",
       "       [0.85206474],\n",
       "       [0.84954926],\n",
       "       [0.84449856],\n",
       "       [0.83979858],\n",
       "       [0.83506945],\n",
       "       [0.83058482],\n",
       "       [0.82632176],\n",
       "       [0.82542251],\n",
       "       [0.8237924 ],\n",
       "       [0.8215627 ],\n",
       "       [0.81910735],\n",
       "       [0.81679287],\n",
       "       [0.81415486],\n",
       "       [0.81855172],\n",
       "       [0.82196046],\n",
       "       [0.82474169],\n",
       "       [0.8270743 ],\n",
       "       [0.82659226],\n",
       "       [0.82646891],\n",
       "       [0.82613796],\n",
       "       [0.82592505],\n",
       "       [0.82566674],\n",
       "       [0.82957581],\n",
       "       [0.82526219],\n",
       "       [0.82113427],\n",
       "       [0.81657542],\n",
       "       [0.81254631],\n",
       "       [0.80743443],\n",
       "       [0.80287367],\n",
       "       [0.79859569],\n",
       "       [0.79459587],\n",
       "       [0.7908902 ],\n",
       "       [0.78332091],\n",
       "       [0.77662551],\n",
       "       [0.77103334],\n",
       "       [0.76652095],\n",
       "       [0.76418843],\n",
       "       [0.76217202],\n",
       "       [0.75945072],\n",
       "       [0.75706137],\n",
       "       [0.7546195 ],\n",
       "       [0.75207522],\n",
       "       [0.74963763],\n",
       "       [0.74771226],\n",
       "       [0.74554578],\n",
       "       [0.74312141],\n",
       "       [0.73908915],\n",
       "       [0.73502367],\n",
       "       [0.73192763],\n",
       "       [0.72873912],\n",
       "       [0.72581806],\n",
       "       [0.72527175],\n",
       "       [0.72422546],\n",
       "       [0.72296621],\n",
       "       [0.72148039],\n",
       "       [0.71985983],\n",
       "       [0.71994962],\n",
       "       [0.71923873],\n",
       "       [0.7182603 ],\n",
       "       [0.71760596],\n",
       "       [0.71664483],\n",
       "       [0.71357656],\n",
       "       [0.7107902 ],\n",
       "       [0.70832684],\n",
       "       [0.70637626],\n",
       "       [0.70453178],\n",
       "       [0.701048  ],\n",
       "       [0.69814836],\n",
       "       [0.69583055],\n",
       "       [0.69344995],\n",
       "       [0.69100165],\n",
       "       [0.6936009 ],\n",
       "       [0.69626315],\n",
       "       [0.69849184],\n",
       "       [0.70044203],\n",
       "       [0.70225314],\n",
       "       [0.70370254],\n",
       "       [0.70513294],\n",
       "       [0.70623223],\n",
       "       [0.7073371 ],\n",
       "       [0.70880276],\n",
       "       [0.70519197],\n",
       "       [0.70149611],\n",
       "       [0.69782492],\n",
       "       [0.69435578],\n",
       "       [0.69092795],\n",
       "       [0.69157563],\n",
       "       [0.69195138],\n",
       "       [0.69185931],\n",
       "       [0.69176947],\n",
       "       [0.6909775 ],\n",
       "       [0.6905515 ],\n",
       "       [0.6901753 ],\n",
       "       [0.69007631],\n",
       "       [0.69029729],\n",
       "       [0.69057898],\n",
       "       [0.68697669],\n",
       "       [0.68370685],\n",
       "       [0.68067881],\n",
       "       [0.67781505],\n",
       "       [0.67576426]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_setY_scaled = sc.fit_transform(dataset_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc6a260a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84402423],\n",
       "       [0.84008695],\n",
       "       [0.83611787],\n",
       "       [0.83344956],\n",
       "       [0.83075345],\n",
       "       [0.82679398],\n",
       "       [0.82264829],\n",
       "       [0.81862468],\n",
       "       [0.81582152],\n",
       "       [0.81310389],\n",
       "       [0.81587298],\n",
       "       [0.81868964],\n",
       "       [0.82140471],\n",
       "       [0.82289084],\n",
       "       [0.82433306],\n",
       "       [0.82717267],\n",
       "       [0.82864591],\n",
       "       [0.83015195],\n",
       "       [0.83149877],\n",
       "       [0.8314973 ],\n",
       "       [0.82619095],\n",
       "       [0.82673275],\n",
       "       [0.82605649],\n",
       "       [0.82402128],\n",
       "       [0.82148804],\n",
       "       [0.81825049],\n",
       "       [0.8150891 ],\n",
       "       [0.81115451],\n",
       "       [0.80609691],\n",
       "       [0.80242403],\n",
       "       [0.79795091],\n",
       "       [0.78689474],\n",
       "       [0.7791004 ],\n",
       "       [0.77333808],\n",
       "       [0.76680483],\n",
       "       [0.75969731],\n",
       "       [0.75322924],\n",
       "       [0.75455134],\n",
       "       [0.75580603],\n",
       "       [0.75510506],\n",
       "       [0.75376401],\n",
       "       [0.75185585],\n",
       "       [0.7486559 ],\n",
       "       [0.74541323],\n",
       "       [0.74227398],\n",
       "       [0.73905636],\n",
       "       [0.73589867],\n",
       "       [0.72507452],\n",
       "       [0.71483494],\n",
       "       [0.70584244],\n",
       "       [0.69693265],\n",
       "       [0.68798807],\n",
       "       [0.67969194],\n",
       "       [0.6707091 ],\n",
       "       [0.66239322],\n",
       "       [0.65473899],\n",
       "       [0.64635247],\n",
       "       [0.63793172],\n",
       "       [0.62958271],\n",
       "       [0.62132624],\n",
       "       [0.61357009],\n",
       "       [0.6057681 ],\n",
       "       [0.59736595],\n",
       "       [0.58968087],\n",
       "       [0.58119983],\n",
       "       [0.5727904 ],\n",
       "       [0.56566024],\n",
       "       [0.56043019],\n",
       "       [0.55326369],\n",
       "       [0.54549847],\n",
       "       [0.53779395],\n",
       "       [0.53138862],\n",
       "       [0.52497961],\n",
       "       [0.51847593],\n",
       "       [0.51203494],\n",
       "       [0.50488452],\n",
       "       [0.4979141 ],\n",
       "       [0.4889099 ],\n",
       "       [0.48183738],\n",
       "       [0.48689266],\n",
       "       [0.48739714],\n",
       "       [0.4859899 ],\n",
       "       [0.48323304],\n",
       "       [0.48052466],\n",
       "       [0.47789561],\n",
       "       [0.47591675],\n",
       "       [0.47320342],\n",
       "       [0.47059627],\n",
       "       [0.46730471],\n",
       "       [0.45248483],\n",
       "       [0.44217638],\n",
       "       [0.43317182],\n",
       "       [0.42743021],\n",
       "       [0.42361733],\n",
       "       [0.41915017],\n",
       "       [0.41394338],\n",
       "       [0.40743691],\n",
       "       [0.40158074],\n",
       "       [0.3971551 ],\n",
       "       [0.39260523],\n",
       "       [0.38744791],\n",
       "       [0.38228795],\n",
       "       [0.37580063],\n",
       "       [0.3673959 ],\n",
       "       [0.36024479],\n",
       "       [0.35378001],\n",
       "       [0.34865367],\n",
       "       [0.34351802],\n",
       "       [0.33765862],\n",
       "       [0.33572505],\n",
       "       [0.33567366],\n",
       "       [0.33368565],\n",
       "       [0.33042217],\n",
       "       [0.32710349],\n",
       "       [0.32386407],\n",
       "       [0.32063395],\n",
       "       [0.31739936],\n",
       "       [0.3134282 ],\n",
       "       [0.30942988],\n",
       "       [0.30166115],\n",
       "       [0.29329108],\n",
       "       [0.28678998],\n",
       "       [0.28288708],\n",
       "       [0.28102243],\n",
       "       [0.27770501],\n",
       "       [0.27443069],\n",
       "       [0.27048862],\n",
       "       [0.26730165],\n",
       "       [0.26476486],\n",
       "       [0.26214587],\n",
       "       [0.25889412],\n",
       "       [0.25571343],\n",
       "       [0.25120664],\n",
       "       [0.24476909],\n",
       "       [0.23967814],\n",
       "       [0.23453699],\n",
       "       [0.23007031],\n",
       "       [0.22560086],\n",
       "       [0.22110229],\n",
       "       [0.21795886],\n",
       "       [0.21992732],\n",
       "       [0.21999395],\n",
       "       [0.21877255],\n",
       "       [0.21749597],\n",
       "       [0.21625917],\n",
       "       [0.21506126],\n",
       "       [0.21444757],\n",
       "       [0.21312924],\n",
       "       [0.21124385],\n",
       "       [0.20870921],\n",
       "       [0.20170249],\n",
       "       [0.19655743],\n",
       "       [0.19273292],\n",
       "       [0.18900041],\n",
       "       [0.18521602],\n",
       "       [0.18200092],\n",
       "       [0.18148366],\n",
       "       [0.18361901],\n",
       "       [0.18387341],\n",
       "       [0.26937883],\n",
       "       [0.35364257],\n",
       "       [0.43715768],\n",
       "       [0.52064471],\n",
       "       [0.60315615],\n",
       "       [0.68796176],\n",
       "       [0.77273878],\n",
       "       [0.84948439],\n",
       "       [0.92416977],\n",
       "       [1.        ],\n",
       "       [0.98913022],\n",
       "       [0.97818154],\n",
       "       [0.96727445],\n",
       "       [0.95499277],\n",
       "       [0.94294524],\n",
       "       [0.92784064],\n",
       "       [0.91150992],\n",
       "       [0.89924939],\n",
       "       [0.88706677],\n",
       "       [0.88977951],\n",
       "       [0.89122707],\n",
       "       [0.89256729],\n",
       "       [0.89268431],\n",
       "       [0.89681369],\n",
       "       [0.89685502],\n",
       "       [0.89558018],\n",
       "       [0.89437227],\n",
       "       [0.89297382],\n",
       "       [0.89026184],\n",
       "       [0.87543613],\n",
       "       [0.87146632],\n",
       "       [0.86376465],\n",
       "       [0.85541056],\n",
       "       [0.8399739 ],\n",
       "       [0.82932305],\n",
       "       [0.8194424 ],\n",
       "       [0.8088678 ],\n",
       "       [0.79857059],\n",
       "       [0.78830764],\n",
       "       [0.77535458],\n",
       "       [0.75291166],\n",
       "       [0.73746124],\n",
       "       [0.72664001],\n",
       "       [0.71637436],\n",
       "       [0.70424331],\n",
       "       [0.69277327],\n",
       "       [0.6979472 ],\n",
       "       [0.70244289],\n",
       "       [0.70429491],\n",
       "       [0.70362261],\n",
       "       [0.70237675],\n",
       "       [0.69673609],\n",
       "       [0.6884578 ],\n",
       "       [0.68219245],\n",
       "       [0.67712338],\n",
       "       [0.67207859],\n",
       "       [0.65117219],\n",
       "       [0.63082357],\n",
       "       [0.613071  ],\n",
       "       [0.59661083],\n",
       "       [0.58138723],\n",
       "       [0.5681677 ],\n",
       "       [0.55484754],\n",
       "       [0.54284485],\n",
       "       [0.53020651],\n",
       "       [0.51816469],\n",
       "       [0.50605803],\n",
       "       [0.4940106 ],\n",
       "       [0.48142715],\n",
       "       [0.47189532],\n",
       "       [0.46234227],\n",
       "       [0.45211646],\n",
       "       [0.44263996],\n",
       "       [0.43307398],\n",
       "       [0.42415689],\n",
       "       [0.41522831],\n",
       "       [0.41269874],\n",
       "       [0.4082657 ],\n",
       "       [0.40383794],\n",
       "       [0.39755396],\n",
       "       [0.39195828],\n",
       "       [0.38695154],\n",
       "       [0.38187933],\n",
       "       [0.37553611],\n",
       "       [0.37049764],\n",
       "       [0.36559394],\n",
       "       [0.35548782],\n",
       "       [0.34792925],\n",
       "       [0.36062671],\n",
       "       [0.36887697],\n",
       "       [0.37326731],\n",
       "       [0.37638801],\n",
       "       [0.37827694],\n",
       "       [0.38086146],\n",
       "       [0.38217408],\n",
       "       [0.38274192],\n",
       "       [0.38274353],\n",
       "       [0.38270794],\n",
       "       [0.36303977],\n",
       "       [0.34846021],\n",
       "       [0.33704783],\n",
       "       [0.32756622],\n",
       "       [0.3238288 ],\n",
       "       [0.31881306],\n",
       "       [0.31302987],\n",
       "       [0.30792976],\n",
       "       [0.30284849],\n",
       "       [0.29725046],\n",
       "       [0.29280795],\n",
       "       [0.28836165],\n",
       "       [0.28392237],\n",
       "       [0.27822705],\n",
       "       [0.26930604],\n",
       "       [0.26230517],\n",
       "       [0.25664153],\n",
       "       [0.25101774],\n",
       "       [0.24534646],\n",
       "       [0.24027181],\n",
       "       [0.23901525],\n",
       "       [0.24093266],\n",
       "       [0.24031262],\n",
       "       [0.23965664],\n",
       "       [0.23707773],\n",
       "       [0.23450176],\n",
       "       [0.23197648],\n",
       "       [0.22879145],\n",
       "       [0.22553781],\n",
       "       [0.22222634],\n",
       "       [0.21464597],\n",
       "       [0.20448075],\n",
       "       [0.19684118],\n",
       "       [0.1911042 ],\n",
       "       [0.18990719],\n",
       "       [0.18669966],\n",
       "       [0.18218267],\n",
       "       [0.17833187],\n",
       "       [0.17459762],\n",
       "       [0.17148529],\n",
       "       [0.16760048],\n",
       "       [0.16251652],\n",
       "       [0.15810255],\n",
       "       [0.15242582],\n",
       "       [0.14354652],\n",
       "       [0.13600647],\n",
       "       [0.12971011],\n",
       "       [0.12341678],\n",
       "       [0.11770261],\n",
       "       [0.11138603],\n",
       "       [0.10701681],\n",
       "       [0.10829492],\n",
       "       [0.10639715],\n",
       "       [0.10324049],\n",
       "       [0.09815228],\n",
       "       [0.09371294],\n",
       "       [0.08930419],\n",
       "       [0.0841978 ],\n",
       "       [0.07843028],\n",
       "       [0.07271381],\n",
       "       [0.06510155],\n",
       "       [0.05242852],\n",
       "       [0.04226962],\n",
       "       [0.03338119],\n",
       "       [0.02389667],\n",
       "       [0.01630043],\n",
       "       [0.0086764 ],\n",
       "       [0.00430033],\n",
       "       [0.00188496],\n",
       "       [0.        ],\n",
       "       [0.0894263 ],\n",
       "       [0.17822123],\n",
       "       [0.26768657],\n",
       "       [0.35778005],\n",
       "       [0.4502271 ],\n",
       "       [0.54154667],\n",
       "       [0.63345045],\n",
       "       [0.72358912],\n",
       "       [0.81097157],\n",
       "       [0.89844029],\n",
       "       [0.89584474],\n",
       "       [0.89325203],\n",
       "       [0.89058483],\n",
       "       [0.88789609],\n",
       "       [0.88541414],\n",
       "       [0.88270039],\n",
       "       [0.87873221],\n",
       "       [0.8746571 ],\n",
       "       [0.87202403],\n",
       "       [0.87334949],\n",
       "       [0.87476141],\n",
       "       [0.87741076],\n",
       "       [0.87888524],\n",
       "       [0.88026789],\n",
       "       [0.88166516],\n",
       "       [0.8817735 ],\n",
       "       [0.88328286],\n",
       "       [0.88459743],\n",
       "       [0.88456789],\n",
       "       [0.88066633],\n",
       "       [0.88091288],\n",
       "       [0.87865509],\n",
       "       [0.87568266],\n",
       "       [0.87155967],\n",
       "       [0.86741956],\n",
       "       [0.86396755],\n",
       "       [0.85916308],\n",
       "       [0.85389254],\n",
       "       [0.84935106],\n",
       "       [0.84470607],\n",
       "       [0.83514171],\n",
       "       [0.82901154],\n",
       "       [0.82398476],\n",
       "       [0.81891953],\n",
       "       [0.81258429],\n",
       "       [0.80624057],\n",
       "       [0.80549045],\n",
       "       [0.80539117],\n",
       "       [0.80401503],\n",
       "       [0.80140095],\n",
       "       [0.79822425],\n",
       "       [0.79354475],\n",
       "       [0.7890968 ],\n",
       "       [0.78467989],\n",
       "       [0.78020273],\n",
       "       [0.77641262],\n",
       "       [0.76775832],\n",
       "       [0.75836151],\n",
       "       [0.74950557],\n",
       "       [0.74128366],\n",
       "       [0.73308437],\n",
       "       [0.72550352],\n",
       "       [0.71727375],\n",
       "       [0.71034664],\n",
       "       [0.70341845],\n",
       "       [0.6957593 ],\n",
       "       [0.68810485],\n",
       "       [0.6804795 ],\n",
       "       [0.67364   ],\n",
       "       [0.66666393],\n",
       "       [0.66027483],\n",
       "       [0.65328859],\n",
       "       [0.64697353],\n",
       "       [0.63995635],\n",
       "       [0.63289449],\n",
       "       [0.62654374],\n",
       "       [0.62136017],\n",
       "       [0.61563277],\n",
       "       [0.60920907],\n",
       "       [0.60290686],\n",
       "       [0.59716886],\n",
       "       [0.59214036],\n",
       "       [0.58699165],\n",
       "       [0.58123952],\n",
       "       [0.57623621],\n",
       "       [0.57128958],\n",
       "       [0.56569121],\n",
       "       [0.56063563],\n",
       "       [0.56898857],\n",
       "       [0.57017052],\n",
       "       [0.57016062],\n",
       "       [0.56879397],\n",
       "       [0.56683065],\n",
       "       [0.56556425],\n",
       "       [0.56425885],\n",
       "       [0.56225188],\n",
       "       [0.55970824],\n",
       "       [0.55713194],\n",
       "       [0.54248329],\n",
       "       [0.53497837],\n",
       "       [0.52804605],\n",
       "       [0.52301996],\n",
       "       [0.52054956],\n",
       "       [0.51744486],\n",
       "       [0.51428245],\n",
       "       [0.51056655],\n",
       "       [0.50669433],\n",
       "       [0.50363279],\n",
       "       [0.50046219],\n",
       "       [0.4966394 ],\n",
       "       [0.49282498],\n",
       "       [0.48837026],\n",
       "       [0.48270082],\n",
       "       [0.47758892],\n",
       "       [0.4725125 ],\n",
       "       [0.46803388],\n",
       "       [0.46429376],\n",
       "       [0.46045485],\n",
       "       [0.45914101],\n",
       "       [0.45973759],\n",
       "       [0.45910308],\n",
       "       [0.45720724],\n",
       "       [0.45457482],\n",
       "       [0.45201612],\n",
       "       [0.44944066],\n",
       "       [0.44687086],\n",
       "       [0.44425275],\n",
       "       [0.44098309],\n",
       "       [0.43462957],\n",
       "       [0.42766754],\n",
       "       [0.42190349],\n",
       "       [0.41798946],\n",
       "       [0.41679739],\n",
       "       [0.4141882 ],\n",
       "       [0.41162991],\n",
       "       [0.40906362],\n",
       "       [0.40657207],\n",
       "       [0.40404274],\n",
       "       [0.40147686],\n",
       "       [0.39825318],\n",
       "       [0.3950883 ],\n",
       "       [0.39134651],\n",
       "       [0.38500587],\n",
       "       [0.38064202],\n",
       "       [0.37622687],\n",
       "       [0.37179987],\n",
       "       [0.36742217],\n",
       "       [0.36362719],\n",
       "       [0.36116735],\n",
       "       [0.36246599],\n",
       "       [0.36252889],\n",
       "       [0.36197564],\n",
       "       [0.36135473],\n",
       "       [0.3594859 ],\n",
       "       [0.35830336],\n",
       "       [0.35706918],\n",
       "       [0.35574378],\n",
       "       [0.35388668],\n",
       "       [0.35073241],\n",
       "       [0.34447731],\n",
       "       [0.33940881],\n",
       "       [0.33494334],\n",
       "       [0.3305426 ],\n",
       "       [0.32741739],\n",
       "       [0.3235437 ],\n",
       "       [0.32299147],\n",
       "       [0.32377817],\n",
       "       [0.32497323],\n",
       "       [0.37917178],\n",
       "       [0.43188034],\n",
       "       [0.48485382],\n",
       "       [0.5367051 ],\n",
       "       [0.58940271],\n",
       "       [0.64156464],\n",
       "       [0.69354779],\n",
       "       [0.7421503 ],\n",
       "       [0.78809146],\n",
       "       [0.83654333],\n",
       "       [0.83124561],\n",
       "       [0.82648846],\n",
       "       [0.82046447],\n",
       "       [0.81463256],\n",
       "       [0.80823742],\n",
       "       [0.80115555],\n",
       "       [0.79466043],\n",
       "       [0.78705723],\n",
       "       [0.77988165],\n",
       "       [0.7693261 ],\n",
       "       [0.7593669 ],\n",
       "       [0.74749417],\n",
       "       [0.73768746],\n",
       "       [0.72830155],\n",
       "       [0.72438497],\n",
       "       [0.71963579],\n",
       "       [0.71390319],\n",
       "       [0.70874075],\n",
       "       [0.70293985],\n",
       "       [0.6975496 ],\n",
       "       [0.69141979],\n",
       "       [0.6875134 ],\n",
       "       [0.68183665],\n",
       "       [0.67562089],\n",
       "       [0.66314061],\n",
       "       [0.65152697],\n",
       "       [0.63984128],\n",
       "       [0.62875977],\n",
       "       [0.61822575],\n",
       "       [0.6160037 ],\n",
       "       [0.61197572],\n",
       "       [0.60646612],\n",
       "       [0.60039896],\n",
       "       [0.59467988],\n",
       "       [0.58816135],\n",
       "       [0.599026  ],\n",
       "       [0.607449  ],\n",
       "       [0.61432142],\n",
       "       [0.62008528],\n",
       "       [0.61889417],\n",
       "       [0.61858937],\n",
       "       [0.61777159],\n",
       "       [0.61724549],\n",
       "       [0.61660721],\n",
       "       [0.62626652],\n",
       "       [0.61560755],\n",
       "       [0.60540748],\n",
       "       [0.59414255],\n",
       "       [0.58418665],\n",
       "       [0.57155519],\n",
       "       [0.56028554],\n",
       "       [0.54971467],\n",
       "       [0.53983111],\n",
       "       [0.5306744 ],\n",
       "       [0.5119707 ],\n",
       "       [0.49542636],\n",
       "       [0.48160811],\n",
       "       [0.47045801],\n",
       "       [0.46469434],\n",
       "       [0.45971182],\n",
       "       [0.45298747],\n",
       "       [0.4470834 ],\n",
       "       [0.44104954],\n",
       "       [0.43476263],\n",
       "       [0.42873935],\n",
       "       [0.42398175],\n",
       "       [0.41862838],\n",
       "       [0.41263778],\n",
       "       [0.40267405],\n",
       "       [0.39262825],\n",
       "       [0.38497794],\n",
       "       [0.37709914],\n",
       "       [0.36988121],\n",
       "       [0.36853129],\n",
       "       [0.3659459 ],\n",
       "       [0.36283429],\n",
       "       [0.35916284],\n",
       "       [0.35515842],\n",
       "       [0.35538029],\n",
       "       [0.3536237 ],\n",
       "       [0.351206  ],\n",
       "       [0.34958911],\n",
       "       [0.34721416],\n",
       "       [0.33963246],\n",
       "       [0.33274737],\n",
       "       [0.32666041],\n",
       "       [0.32184053],\n",
       "       [0.31728282],\n",
       "       [0.3086744 ],\n",
       "       [0.3015094 ],\n",
       "       [0.29578209],\n",
       "       [0.28989963],\n",
       "       [0.2838499 ],\n",
       "       [0.29027263],\n",
       "       [0.29685106],\n",
       "       [0.30235813],\n",
       "       [0.30717705],\n",
       "       [0.31165231],\n",
       "       [0.31523378],\n",
       "       [0.3187683 ],\n",
       "       [0.32148465],\n",
       "       [0.32421478],\n",
       "       [0.3278364 ],\n",
       "       [0.31891415],\n",
       "       [0.30978168],\n",
       "       [0.30071017],\n",
       "       [0.29213794],\n",
       "       [0.28366778],\n",
       "       [0.2852682 ],\n",
       "       [0.28619667],\n",
       "       [0.28596915],\n",
       "       [0.28574716],\n",
       "       [0.28379022],\n",
       "       [0.28273756],\n",
       "       [0.28180797],\n",
       "       [0.28156337],\n",
       "       [0.28210942],\n",
       "       [0.28280547],\n",
       "       [0.27390421],\n",
       "       [0.26582445],\n",
       "       [0.25834217],\n",
       "       [0.2512658 ],\n",
       "       [0.2461983 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_setY_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5df2b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and remaining data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(dataset_train_scaled, training_setY_scaled, test_size=0.3,shuffle=False, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df4c4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the remaining data into validation and testing sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5,shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f79d9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.46714587, 0.62600255, 0.70547366, 0.35846986],\n",
       "       [0.4637791 , 0.62283866, 0.70320174, 0.36007351],\n",
       "       [0.45968124, 0.61891729, 0.70050831, 0.36243047]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c995b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439, 4)\n",
      "(439, 1)\n",
      "(94, 4)\n",
      "(94, 1)\n",
      "(95, 4)\n",
      "(95, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape),print(X_val.shape), print(y_val.shape),print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3049b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[:, 0:1]  \n",
    "X_train2 = X_train[:, 1:2]  \n",
    "X_train3 = X_train[:, 2:3]  \n",
    "X_train4 = X_train[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "587ba546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test[:, 0:1]  \n",
    "X_test2 = X_test[:, 1:2]  \n",
    "X_test3 = X_test[:, 2:3]  \n",
    "X_test4 = X_test[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val1 = X_val[:, 0:1]  \n",
    "X_val2 = X_val[:, 1:2]  \n",
    "X_val3 = X_val[:, 2:3]  \n",
    "X_val4 = X_val[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f8dc2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3e1f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU,SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70a93138",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_1 =(X_train1.shape[1], 1)\n",
    "input_shape_2 = (X_train2.shape[1], 1)\n",
    "input_shape_3 =(X_train3.shape[1], 1)\n",
    "input_shape_4 = (X_train4.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "227c1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e1985e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=input_shape_1)\n",
    "input_2 = Input(shape=input_shape_2)\n",
    "input_3 = Input(shape=input_shape_3)\n",
    "input_4 = Input(shape=input_shape_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d65e875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "print(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "280d7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92d31ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.01\n",
    "decay_rate = 0.99\n",
    "decay_steps = 10000\n",
    "\n",
    "class LearningRateUpdater(Callback):\n",
    "    def __init__(self, initial_lr, decay_rate, decay_steps):\n",
    "        super(LearningRateUpdater, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.initial_lr * math.pow(self.decay_rate, (epoch + 1) // self.decay_steps)\n",
    "        self.model.optimizer.lr.assign(lr)\n",
    "        print(\"Learning rate updated to:\", lr)\n",
    "\n",
    "\n",
    "# Create the optimizer with the initial learning rate\n",
    "optimizer = Adam(learning_rate=initial_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the learning rate updater callback\n",
    "lr_updater_callback = LearningRateUpdater(initial_lr, decay_rate, decay_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2172067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_scheduler(epoch, lr):\n",
    "#     if epoch % 10000 == 0 and epoch > 0:\n",
    "#         lr *= 0.99\n",
    "#     return lr\n",
    "# def lr_scheduler(epoch, lr):\n",
    "        \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_lr, decay_steps=decay_steps, decay_rate=decay_rate, staircase=False)\n",
    "\n",
    "\n",
    "#lr_scheduler_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dc576e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        print(f'\\nLearning rate after epoch {epoch} is {lr:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "466e2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe5ce23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/18 [>.............................] - ETA: 39s - loss: 0.1043 - mae: 0.2595\n",
      "Learning rate after epoch 0 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 3s 30ms/step - loss: 0.0352 - mae: 0.1387 - val_loss: 0.0471 - val_mae: 0.1779\n",
      "Epoch 2/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0692\n",
      "Learning rate after epoch 1 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0729 - val_loss: 0.0223 - val_mae: 0.1159\n",
      "Epoch 3/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0428\n",
      "Learning rate after epoch 2 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0633 - val_loss: 0.0243 - val_mae: 0.1042\n",
      "Epoch 4/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0406\n",
      "Learning rate after epoch 3 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0608 - val_loss: 0.0349 - val_mae: 0.1288\n",
      "Epoch 5/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0371\n",
      "Learning rate after epoch 4 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0593 - val_loss: 0.0393 - val_mae: 0.1468\n",
      "Epoch 6/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0347\n",
      "Learning rate after epoch 5 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0575 - val_loss: 0.0563 - val_mae: 0.1894\n",
      "Epoch 7/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0414\n",
      "Learning rate after epoch 6 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0588 - val_loss: 0.0538 - val_mae: 0.1899\n",
      "Epoch 8/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0479\n",
      "Learning rate after epoch 7 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0559 - val_loss: 0.0609 - val_mae: 0.2062\n",
      "Epoch 9/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0310\n",
      "Learning rate after epoch 8 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0620 - val_loss: 0.0270 - val_mae: 0.1117\n",
      "Epoch 10/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0308\n",
      "Learning rate after epoch 9 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0592 - val_loss: 0.0313 - val_mae: 0.1411\n",
      "Epoch 11/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0561\n",
      "Learning rate after epoch 10 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0660 - val_loss: 0.0466 - val_mae: 0.1822\n",
      "Epoch 12/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0323\n",
      "Learning rate after epoch 11 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0525 - val_loss: 0.0367 - val_mae: 0.1552\n",
      "Epoch 13/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0444\n",
      "Learning rate after epoch 12 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0627 - val_loss: 0.0445 - val_mae: 0.1828\n",
      "Epoch 14/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0753\n",
      "Learning rate after epoch 13 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0560 - val_loss: 0.0440 - val_mae: 0.1791\n",
      "Epoch 15/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0121 - mae: 0.0817\n",
      "Learning rate after epoch 14 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0526 - val_loss: 0.0386 - val_mae: 0.1686\n",
      "Epoch 16/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0597\n",
      "Learning rate after epoch 15 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0540 - val_loss: 0.0478 - val_mae: 0.1931\n",
      "Epoch 17/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0589\n",
      "Learning rate after epoch 16 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0542 - val_loss: 0.0469 - val_mae: 0.1850\n",
      "Epoch 18/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0344\n",
      "Learning rate after epoch 17 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0491 - val_loss: 0.0470 - val_mae: 0.1890\n",
      "Epoch 19/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0130 - mae: 0.0966\n",
      "Learning rate after epoch 18 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 0.0528 - val_mae: 0.2034\n",
      "Epoch 20/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0955\n",
      "Learning rate after epoch 19 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0530 - val_loss: 0.0539 - val_mae: 0.2109\n",
      "Epoch 21/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0613\n",
      "Learning rate after epoch 20 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0539 - val_loss: 0.0348 - val_mae: 0.1590\n",
      "Epoch 22/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0338\n",
      "Learning rate after epoch 21 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0544 - val_loss: 0.0247 - val_mae: 0.1301\n",
      "Epoch 23/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0581\n",
      "Learning rate after epoch 22 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0483 - val_loss: 0.0291 - val_mae: 0.1460\n",
      "Epoch 24/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0365\n",
      "Learning rate after epoch 23 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0453 - val_loss: 0.0205 - val_mae: 0.1262\n",
      "Epoch 25/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0714\n",
      "Learning rate after epoch 24 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0575 - val_loss: 0.0255 - val_mae: 0.1335\n",
      "Epoch 26/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0423\n",
      "Learning rate after epoch 25 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0468 - val_loss: 0.0278 - val_mae: 0.1408\n",
      "Epoch 27/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0642\n",
      "Learning rate after epoch 26 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0491 - val_loss: 0.0343 - val_mae: 0.1695\n",
      "Epoch 28/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0560\n",
      "Learning rate after epoch 27 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0463 - val_loss: 0.0175 - val_mae: 0.1129\n",
      "Epoch 29/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0483\n",
      "Learning rate after epoch 28 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0429 - val_loss: 0.0238 - val_mae: 0.1278\n",
      "Epoch 30/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0470\n",
      "Learning rate after epoch 29 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0550 - val_loss: 0.0307 - val_mae: 0.1584\n",
      "Epoch 31/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0686\n",
      "Learning rate after epoch 30 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0541 - val_loss: 0.0222 - val_mae: 0.1333\n",
      "Epoch 32/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0103 - mae: 0.0839\n",
      "Learning rate after epoch 31 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0485 - val_loss: 0.0329 - val_mae: 0.1677\n",
      "Epoch 33/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0379\n",
      "Learning rate after epoch 32 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0548 - val_loss: 0.0229 - val_mae: 0.1308\n",
      "Epoch 34/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0468\n",
      "Learning rate after epoch 33 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0462 - val_mae: 0.1890\n",
      "Epoch 35/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0544\n",
      "Learning rate after epoch 34 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0517 - val_loss: 0.0315 - val_mae: 0.1641\n",
      "Epoch 36/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0361\n",
      "Learning rate after epoch 35 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0192 - val_mae: 0.1299\n",
      "Epoch 37/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0462\n",
      "Learning rate after epoch 36 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0602 - val_loss: 0.0198 - val_mae: 0.1331\n",
      "Epoch 38/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0314\n",
      "Learning rate after epoch 37 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0197 - val_mae: 0.1332\n",
      "Epoch 39/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0527\n",
      "Learning rate after epoch 38 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0465 - val_loss: 0.0132 - val_mae: 0.0932\n",
      "Epoch 40/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0606\n",
      "Learning rate after epoch 39 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0549 - val_loss: 0.0166 - val_mae: 0.1182\n",
      "Epoch 41/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0456\n",
      "Learning rate after epoch 40 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0552 - val_loss: 0.0178 - val_mae: 0.1149\n",
      "Epoch 42/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0433\n",
      "Learning rate after epoch 41 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0583 - val_loss: 0.0026 - val_mae: 0.0428\n",
      "Epoch 43/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0409\n",
      "Learning rate after epoch 42 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0507 - val_loss: 0.0046 - val_mae: 0.0608\n",
      "Epoch 44/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0454\n",
      "Learning rate after epoch 43 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0507 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 45/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0755\n",
      "Learning rate after epoch 44 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0697 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 46/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0434\n",
      "Learning rate after epoch 45 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0077 - val_mae: 0.0676\n",
      "Epoch 47/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0608\n",
      "Learning rate after epoch 46 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0088 - val_mae: 0.0856\n",
      "Epoch 48/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0304\n",
      "Learning rate after epoch 47 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0096 - val_mae: 0.0835\n",
      "Epoch 49/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0617\n",
      "Learning rate after epoch 48 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 50/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0659\n",
      "Learning rate after epoch 49 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0021 - val_mae: 0.0329\n",
      "Epoch 51/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0777\n",
      "Learning rate after epoch 50 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0032 - val_mae: 0.0418\n",
      "Epoch 52/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0276\n",
      "Learning rate after epoch 51 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0572 - val_loss: 0.0058 - val_mae: 0.0597\n",
      "Epoch 53/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0228\n",
      "Learning rate after epoch 52 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0475 - val_loss: 0.0066 - val_mae: 0.0667\n",
      "Epoch 54/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0497\n",
      "Learning rate after epoch 53 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0523 - val_loss: 7.4297e-04 - val_mae: 0.0167\n",
      "Epoch 55/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0457\n",
      "Learning rate after epoch 54 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0024 - val_mae: 0.0412\n",
      "Epoch 56/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0403\n",
      "Learning rate after epoch 55 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0512 - val_loss: 0.0035 - val_mae: 0.0486\n",
      "Epoch 57/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0728\n",
      "Learning rate after epoch 56 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0548 - val_loss: 9.8013e-04 - val_mae: 0.0240\n",
      "Epoch 58/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0851\n",
      "Learning rate after epoch 57 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0025 - val_mae: 0.0451\n",
      "Epoch 59/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0655\n",
      "Learning rate after epoch 58 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0562 - val_loss: 0.0025 - val_mae: 0.0361\n",
      "Epoch 60/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0913\n",
      "Learning rate after epoch 59 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0019 - val_mae: 0.0362\n",
      "Epoch 61/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0404\n",
      "Learning rate after epoch 60 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0016 - val_mae: 0.0304\n",
      "Epoch 62/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0321\n",
      "Learning rate after epoch 61 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0032 - val_mae: 0.0466\n",
      "Epoch 63/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0435\n",
      "Learning rate after epoch 62 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0511 - val_loss: 0.0025 - val_mae: 0.0446\n",
      "Epoch 64/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0672\n",
      "Learning rate after epoch 63 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0560 - val_loss: 6.0200e-04 - val_mae: 0.0162\n",
      "Epoch 65/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0379\n",
      "Learning rate after epoch 64 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0021 - val_mae: 0.0376\n",
      "Epoch 66/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0283\n",
      "Learning rate after epoch 65 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0561 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 67/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0378\n",
      "Learning rate after epoch 66 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0047 - val_mae: 0.0503\n",
      "Epoch 68/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0574\n",
      "Learning rate after epoch 67 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0023 - val_mae: 0.0352\n",
      "Epoch 69/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0553\n",
      "Learning rate after epoch 68 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 70/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0450\n",
      "Learning rate after epoch 69 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0502 - val_loss: 8.8280e-04 - val_mae: 0.0234\n",
      "Epoch 71/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0687\n",
      "Learning rate after epoch 70 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0028 - val_mae: 0.0443\n",
      "Epoch 72/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0312\n",
      "Learning rate after epoch 71 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0044 - val_mae: 0.0499\n",
      "Epoch 73/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0300\n",
      "Learning rate after epoch 72 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0545 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 74/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0421\n",
      "Learning rate after epoch 73 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0031 - val_mae: 0.0455\n",
      "Epoch 75/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0473\n",
      "Learning rate after epoch 74 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0558 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 76/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0257 - mae: 0.1560\n",
      "Learning rate after epoch 75 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0629 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 77/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0386\n",
      "Learning rate after epoch 76 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0461 - val_loss: 0.0016 - val_mae: 0.0296\n",
      "Epoch 78/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0242\n",
      "Learning rate after epoch 77 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0569 - val_loss: 0.0025 - val_mae: 0.0366\n",
      "Epoch 79/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0414\n",
      "Learning rate after epoch 78 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0448 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "Epoch 80/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0498\n",
      "Learning rate after epoch 79 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 81/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0303\n",
      "Learning rate after epoch 80 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 4.8893e-04 - val_mae: 0.0130\n",
      "Epoch 82/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0739\n",
      "Learning rate after epoch 81 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0557 - val_loss: 6.8947e-04 - val_mae: 0.0205\n",
      "Epoch 83/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0575\n",
      "Learning rate after epoch 82 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0018 - val_mae: 0.0298\n",
      "Epoch 84/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0528\n",
      "Learning rate after epoch 83 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0011 - val_mae: 0.0274\n",
      "Epoch 85/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0442\n",
      "Learning rate after epoch 84 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0515 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 86/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0309\n",
      "Learning rate after epoch 85 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 0.0021 - val_mae: 0.0365\n",
      "Epoch 87/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0703\n",
      "Learning rate after epoch 86 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 9.8494e-04 - val_mae: 0.0258\n",
      "Epoch 88/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0369\n",
      "Learning rate after epoch 87 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 8.5198e-04 - val_mae: 0.0211\n",
      "Epoch 89/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0628\n",
      "Learning rate after epoch 88 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0543 - val_loss: 0.0024 - val_mae: 0.0404\n",
      "Epoch 90/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0446\n",
      "Learning rate after epoch 89 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0464 - val_loss: 0.0041 - val_mae: 0.0556\n",
      "Epoch 91/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0441\n",
      "Learning rate after epoch 90 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0555 - val_loss: 0.0020 - val_mae: 0.0379\n",
      "Epoch 92/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0363\n",
      "Learning rate after epoch 91 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 0.0035 - val_mae: 0.0435\n",
      "Epoch 93/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0354\n",
      "Learning rate after epoch 92 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0045 - val_mae: 0.0558\n",
      "Epoch 94/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0332\n",
      "Learning rate after epoch 93 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 95/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0475\n",
      "Learning rate after epoch 94 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0035 - val_mae: 0.0537\n",
      "Epoch 96/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0325\n",
      "Learning rate after epoch 95 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0051 - val_mae: 0.0628\n",
      "Epoch 97/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0659\n",
      "Learning rate after epoch 96 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0460 - val_loss: 0.0032 - val_mae: 0.0464\n",
      "Epoch 98/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0416\n",
      "Learning rate after epoch 97 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0024 - val_mae: 0.0404\n",
      "Epoch 99/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0387\n",
      "Learning rate after epoch 98 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0579 - val_loss: 8.9953e-04 - val_mae: 0.0235\n",
      "Epoch 100/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0449\n",
      "Learning rate after epoch 99 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0545 - val_loss: 0.0012 - val_mae: 0.0283\n",
      "Epoch 101/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0502\n",
      "Learning rate after epoch 100 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0540 - val_loss: 0.0039 - val_mae: 0.0562\n",
      "Epoch 102/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0305\n",
      "Learning rate after epoch 101 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0037 - val_mae: 0.0527\n",
      "Epoch 103/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0385\n",
      "Learning rate after epoch 102 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0022 - val_mae: 0.0423\n",
      "Epoch 104/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0794\n",
      "Learning rate after epoch 103 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0454 - val_loss: 0.0012 - val_mae: 0.0298\n",
      "Epoch 105/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0466\n",
      "Learning rate after epoch 104 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0566 - val_loss: 0.0024 - val_mae: 0.0413\n",
      "Epoch 106/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0170 - mae: 0.1239\n",
      "Learning rate after epoch 105 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0561 - val_loss: 0.0018 - val_mae: 0.0382\n",
      "Epoch 107/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0370\n",
      "Learning rate after epoch 106 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0026 - val_mae: 0.0461\n",
      "Epoch 108/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0296\n",
      "Learning rate after epoch 107 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0012 - val_mae: 0.0311\n",
      "Epoch 109/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0355\n",
      "Learning rate after epoch 108 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.0012 - val_mae: 0.0300\n",
      "Epoch 110/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0461\n",
      "Learning rate after epoch 109 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0483 - val_loss: 0.0016 - val_mae: 0.0290\n",
      "Epoch 111/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0253\n",
      "Learning rate after epoch 110 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0504 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 112/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0384\n",
      "Learning rate after epoch 111 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 113/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0280\n",
      "Learning rate after epoch 112 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0590 - val_loss: 0.0021 - val_mae: 0.0414\n",
      "Epoch 114/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0748\n",
      "Learning rate after epoch 113 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0035 - val_mae: 0.0552\n",
      "Epoch 115/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0645\n",
      "Learning rate after epoch 114 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0527 - val_loss: 0.0034 - val_mae: 0.0494\n",
      "Epoch 116/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0352\n",
      "Learning rate after epoch 115 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0453 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 117/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0609\n",
      "Learning rate after epoch 116 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 118/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0307\n",
      "Learning rate after epoch 117 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 119/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0471\n",
      "Learning rate after epoch 118 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0028 - val_mae: 0.0486\n",
      "Epoch 120/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0279\n",
      "Learning rate after epoch 119 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0014 - val_mae: 0.0308\n",
      "Epoch 121/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0623\n",
      "Learning rate after epoch 120 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0016 - val_mae: 0.0340\n",
      "Epoch 122/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0873\n",
      "Learning rate after epoch 121 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0517 - val_loss: 0.0014 - val_mae: 0.0338\n",
      "Epoch 123/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0904\n",
      "Learning rate after epoch 122 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0526 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 124/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0608\n",
      "Learning rate after epoch 123 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0419 - val_loss: 0.0037 - val_mae: 0.0461\n",
      "Epoch 125/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0593\n",
      "Learning rate after epoch 124 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 126/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0310\n",
      "Learning rate after epoch 125 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 6.8631e-04 - val_mae: 0.0207\n",
      "Epoch 127/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0579\n",
      "Learning rate after epoch 126 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0016 - val_mae: 0.0346\n",
      "Epoch 128/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0313\n",
      "Learning rate after epoch 127 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0024 - val_mae: 0.0378\n",
      "Epoch 129/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0293\n",
      "Learning rate after epoch 128 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0017 - val_mae: 0.0364\n",
      "Epoch 130/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0491\n",
      "Learning rate after epoch 129 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 2.8639e-04 - val_mae: 0.0087\n",
      "Epoch 131/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0368\n",
      "Learning rate after epoch 130 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0572 - val_loss: 0.0025 - val_mae: 0.0448\n",
      "Epoch 132/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0315\n",
      "Learning rate after epoch 131 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0571 - val_loss: 0.0035 - val_mae: 0.0482\n",
      "Epoch 133/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0360\n",
      "Learning rate after epoch 132 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0487 - val_loss: 0.0018 - val_mae: 0.0330\n",
      "Epoch 134/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0471\n",
      "Learning rate after epoch 133 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0028 - val_mae: 0.0387\n",
      "Epoch 135/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0237\n",
      "Learning rate after epoch 134 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0539 - val_loss: 9.0690e-04 - val_mae: 0.0244\n",
      "Epoch 136/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4663e-04 - mae: 0.0244\n",
      "Learning rate after epoch 135 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0021 - val_mae: 0.0423\n",
      "Epoch 137/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0504\n",
      "Learning rate after epoch 136 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0506 - val_loss: 0.0034 - val_mae: 0.0464\n",
      "Epoch 138/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0546\n",
      "Learning rate after epoch 137 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0057 - val_mae: 0.0551\n",
      "Epoch 139/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0157 - mae: 0.1193\n",
      "Learning rate after epoch 138 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0582 - val_loss: 8.1906e-04 - val_mae: 0.0225\n",
      "Epoch 140/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0248\n",
      "Learning rate after epoch 139 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0510 - val_loss: 0.0022 - val_mae: 0.0434\n",
      "Epoch 141/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0405\n",
      "Learning rate after epoch 140 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 9.0015e-04 - val_mae: 0.0241\n",
      "Epoch 142/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0477\n",
      "Learning rate after epoch 141 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0482 - val_loss: 0.0027 - val_mae: 0.0422\n",
      "Epoch 143/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0322\n",
      "Learning rate after epoch 142 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0486\n",
      "Epoch 144/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0312\n",
      "Learning rate after epoch 143 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0024 - val_mae: 0.0399\n",
      "Epoch 145/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0276\n",
      "Learning rate after epoch 144 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0544 - val_loss: 4.1694e-04 - val_mae: 0.0128\n",
      "Epoch 146/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0289\n",
      "Learning rate after epoch 145 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 147/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0269\n",
      "Learning rate after epoch 146 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0048 - val_mae: 0.0564\n",
      "Epoch 148/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0454\n",
      "Learning rate after epoch 147 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0017 - val_mae: 0.0334\n",
      "Epoch 149/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0381\n",
      "Learning rate after epoch 148 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0530 - val_loss: 2.6289e-04 - val_mae: 0.0085\n",
      "Epoch 150/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0382\n",
      "Learning rate after epoch 149 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 3.9159e-04 - val_mae: 0.0110\n",
      "Epoch 151/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0247\n",
      "Learning rate after epoch 150 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0521 - val_loss: 4.4692e-04 - val_mae: 0.0136\n",
      "Epoch 152/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0323\n",
      "Learning rate after epoch 151 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0419 - val_loss: 0.0038 - val_mae: 0.0559\n",
      "Epoch 153/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0280\n",
      "Learning rate after epoch 152 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0459 - val_loss: 0.0042 - val_mae: 0.0569\n",
      "Epoch 154/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0253\n",
      "Learning rate after epoch 153 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0463 - val_loss: 0.0037 - val_mae: 0.0570\n",
      "Epoch 155/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0316\n",
      "Learning rate after epoch 154 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0520 - val_loss: 0.0039 - val_mae: 0.0523\n",
      "Epoch 156/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0433\n",
      "Learning rate after epoch 155 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0015 - val_mae: 0.0331\n",
      "Epoch 157/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Learning rate after epoch 156 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0028 - val_mae: 0.0402\n",
      "Epoch 158/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2534e-04 - mae: 0.0234\n",
      "Learning rate after epoch 157 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0651 - val_loss: 6.3721e-04 - val_mae: 0.0184\n",
      "Epoch 159/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0455\n",
      "Learning rate after epoch 158 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0014 - val_mae: 0.0334\n",
      "Epoch 160/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0343\n",
      "Learning rate after epoch 159 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 9.0620e-04 - val_mae: 0.0245\n",
      "Epoch 161/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0169 - mae: 0.1249\n",
      "Learning rate after epoch 160 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0463 - val_loss: 0.0027 - val_mae: 0.0479\n",
      "Epoch 162/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0451\n",
      "Learning rate after epoch 161 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0402 - val_loss: 0.0038 - val_mae: 0.0514\n",
      "Epoch 163/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0417\n",
      "Learning rate after epoch 162 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0034 - val_mae: 0.0515\n",
      "Epoch 164/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0652\n",
      "Learning rate after epoch 163 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 165/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0303\n",
      "Learning rate after epoch 164 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0483 - val_loss: 0.0028 - val_mae: 0.0497\n",
      "Epoch 166/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0481\n",
      "Learning rate after epoch 165 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0018 - val_mae: 0.0344\n",
      "Epoch 167/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0466\n",
      "Learning rate after epoch 166 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0018 - val_mae: 0.0389\n",
      "Epoch 168/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0512\n",
      "Learning rate after epoch 167 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0522 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 169/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0106 - mae: 0.0944\n",
      "Learning rate after epoch 168 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0565 - val_loss: 0.0029 - val_mae: 0.0401\n",
      "Epoch 170/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0407\n",
      "Learning rate after epoch 169 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0016 - val_mae: 0.0328\n",
      "Epoch 171/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0403\n",
      "Learning rate after epoch 170 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0023 - val_mae: 0.0365\n",
      "Epoch 172/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0358\n",
      "Learning rate after epoch 171 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0014 - val_mae: 0.0338\n",
      "Epoch 173/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0294\n",
      "Learning rate after epoch 172 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0044 - val_mae: 0.0593\n",
      "Epoch 174/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0418\n",
      "Learning rate after epoch 173 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 9.1991e-04 - val_mae: 0.0247\n",
      "Epoch 175/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0315\n",
      "Learning rate after epoch 174 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 6.3242e-04 - val_mae: 0.0176\n",
      "Epoch 176/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0298\n",
      "Learning rate after epoch 175 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0022 - val_mae: 0.0369\n",
      "Epoch 177/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0642\n",
      "Learning rate after epoch 176 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0018 - val_mae: 0.0385\n",
      "Epoch 178/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0773\n",
      "Learning rate after epoch 177 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0528 - val_loss: 0.0038 - val_mae: 0.0572\n",
      "Epoch 179/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0267\n",
      "Learning rate after epoch 178 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0032 - val_mae: 0.0509\n",
      "Epoch 180/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0558\n",
      "Learning rate after epoch 179 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0021 - val_mae: 0.0377\n",
      "Epoch 181/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0278\n",
      "Learning rate after epoch 180 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0056 - val_mae: 0.0700\n",
      "Epoch 182/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0756\n",
      "Learning rate after epoch 181 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0069 - val_mae: 0.0793\n",
      "Epoch 183/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0434\n",
      "Learning rate after epoch 182 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0530 - val_loss: 0.0039 - val_mae: 0.0535\n",
      "Epoch 184/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0326\n",
      "Learning rate after epoch 183 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 5.0255e-04 - val_mae: 0.0140\n",
      "Epoch 185/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0368\n",
      "Learning rate after epoch 184 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0482 - val_loss: 0.0016 - val_mae: 0.0309\n",
      "Epoch 186/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0408\n",
      "Learning rate after epoch 185 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0027 - val_mae: 0.0407\n",
      "Epoch 187/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0294\n",
      "Learning rate after epoch 186 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 0.0021 - val_mae: 0.0392\n",
      "Epoch 188/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0351\n",
      "Learning rate after epoch 187 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0016 - val_mae: 0.0345\n",
      "Epoch 189/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0730\n",
      "Learning rate after epoch 188 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 190/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0380\n",
      "Learning rate after epoch 189 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0027 - val_mae: 0.0481\n",
      "Epoch 191/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0314\n",
      "Learning rate after epoch 190 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0430 - val_loss: 0.0027 - val_mae: 0.0453\n",
      "Epoch 192/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0635\n",
      "Learning rate after epoch 191 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0023 - val_mae: 0.0438\n",
      "Epoch 193/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0601\n",
      "Learning rate after epoch 192 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0489 - val_loss: 0.0019 - val_mae: 0.0382\n",
      "Epoch 194/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0363\n",
      "Learning rate after epoch 193 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0483 - val_loss: 0.0037 - val_mae: 0.0562\n",
      "Epoch 195/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0319\n",
      "Learning rate after epoch 194 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0022 - val_mae: 0.0426\n",
      "Epoch 196/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0858\n",
      "Learning rate after epoch 195 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0025 - val_mae: 0.0468\n",
      "Epoch 197/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0370\n",
      "Learning rate after epoch 196 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0542 - val_loss: 9.7199e-04 - val_mae: 0.0261\n",
      "Epoch 198/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0898\n",
      "Learning rate after epoch 197 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0269\n",
      "Epoch 199/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0325\n",
      "Learning rate after epoch 198 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0049 - val_mae: 0.0506\n",
      "Epoch 200/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0671\n",
      "Learning rate after epoch 199 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0463 - val_loss: 5.4588e-04 - val_mae: 0.0167\n",
      "Epoch 201/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0337\n",
      "Learning rate after epoch 200 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 9.2414e-04 - val_mae: 0.0249\n",
      "Epoch 202/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0470\n",
      "Learning rate after epoch 201 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0457 - val_loss: 0.0042 - val_mae: 0.0598\n",
      "Epoch 203/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0330\n",
      "Learning rate after epoch 202 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0021 - val_mae: 0.0404\n",
      "Epoch 204/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0349\n",
      "Learning rate after epoch 203 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0450 - val_loss: 0.0043 - val_mae: 0.0514\n",
      "Epoch 205/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0653\n",
      "Learning rate after epoch 204 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0557 - val_loss: 0.0035 - val_mae: 0.0477\n",
      "Epoch 206/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0423\n",
      "Learning rate after epoch 205 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0034 - val_mae: 0.0484\n",
      "Epoch 207/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0390\n",
      "Learning rate after epoch 206 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0037 - val_mae: 0.0558\n",
      "Epoch 208/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0586\n",
      "Learning rate after epoch 207 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0579 - val_loss: 0.0024 - val_mae: 0.0453\n",
      "Epoch 209/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0498\n",
      "Learning rate after epoch 208 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0523 - val_loss: 0.0039 - val_mae: 0.0578\n",
      "Epoch 210/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0394\n",
      "Learning rate after epoch 209 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 211/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0345\n",
      "Learning rate after epoch 210 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0043 - val_mae: 0.0529\n",
      "Epoch 212/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0308\n",
      "Learning rate after epoch 211 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 7.3171e-04 - val_mae: 0.0220\n",
      "Epoch 213/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0363\n",
      "Learning rate after epoch 212 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0477 - val_loss: 0.0022 - val_mae: 0.0428\n",
      "Epoch 214/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0365\n",
      "Learning rate after epoch 213 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0443 - val_loss: 0.0030 - val_mae: 0.0494\n",
      "Epoch 215/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.1334e-04 - mae: 0.0184\n",
      "Learning rate after epoch 214 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0030 - val_mae: 0.0479\n",
      "Epoch 216/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0347\n",
      "Learning rate after epoch 215 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0026 - val_mae: 0.0455\n",
      "Epoch 217/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0591\n",
      "Learning rate after epoch 216 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0512 - val_loss: 0.0026 - val_mae: 0.0418\n",
      "Epoch 218/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0426\n",
      "Learning rate after epoch 217 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0532 - val_loss: 7.4004e-04 - val_mae: 0.0208\n",
      "Epoch 219/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0320\n",
      "Learning rate after epoch 218 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0475 - val_loss: 0.0034 - val_mae: 0.0536\n",
      "Epoch 220/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0406\n",
      "Learning rate after epoch 219 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 4.6044e-04 - val_mae: 0.0105\n",
      "Epoch 221/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0315\n",
      "Learning rate after epoch 220 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0499 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 222/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0289\n",
      "Learning rate after epoch 221 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0030 - val_mae: 0.0485\n",
      "Epoch 223/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0450\n",
      "Learning rate after epoch 222 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0026 - val_mae: 0.0448\n",
      "Epoch 224/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0349\n",
      "Learning rate after epoch 223 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0020 - val_mae: 0.0402\n",
      "Epoch 225/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0500\n",
      "Learning rate after epoch 224 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0529 - val_loss: 0.0028 - val_mae: 0.0458\n",
      "Epoch 226/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4314e-04 - mae: 0.0215\n",
      "Learning rate after epoch 225 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 227/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0486\n",
      "Learning rate after epoch 226 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0416 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 228/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0623\n",
      "Learning rate after epoch 227 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0017 - val_mae: 0.0368\n",
      "Epoch 229/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.9259e-04 - mae: 0.0243\n",
      "Learning rate after epoch 228 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0478 - val_loss: 7.3512e-04 - val_mae: 0.0233\n",
      "Epoch 230/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0369\n",
      "Learning rate after epoch 229 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0523 - val_loss: 0.0029 - val_mae: 0.0385\n",
      "Epoch 231/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0688\n",
      "Learning rate after epoch 230 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0521 - val_loss: 2.6344e-04 - val_mae: 0.0062\n",
      "Epoch 232/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0843\n",
      "Learning rate after epoch 231 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0024 - val_mae: 0.0442\n",
      "Epoch 233/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0408\n",
      "Learning rate after epoch 232 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0470 - val_loss: 0.0020 - val_mae: 0.0388\n",
      "Epoch 234/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.5762e-04 - mae: 0.0205\n",
      "Learning rate after epoch 233 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0015 - val_mae: 0.0329\n",
      "Epoch 235/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0303\n",
      "Learning rate after epoch 234 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0533 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 236/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0388\n",
      "Learning rate after epoch 235 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 0.0022 - val_mae: 0.0392\n",
      "Epoch 237/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0311\n",
      "Learning rate after epoch 236 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0033 - val_mae: 0.0532\n",
      "Epoch 238/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0233\n",
      "Learning rate after epoch 237 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 239/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0265\n",
      "Learning rate after epoch 238 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0380 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 240/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0270\n",
      "Learning rate after epoch 239 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0043 - val_mae: 0.0495\n",
      "Epoch 241/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0582\n",
      "Learning rate after epoch 240 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0011 - val_mae: 0.0286\n",
      "Epoch 242/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0358\n",
      "Learning rate after epoch 241 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0035 - val_mae: 0.0488\n",
      "Epoch 243/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0555\n",
      "Learning rate after epoch 242 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0491 - val_loss: 0.0017 - val_mae: 0.0337\n",
      "Epoch 244/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0236\n",
      "Learning rate after epoch 243 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0011 - val_mae: 0.0209\n",
      "Epoch 245/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0473\n",
      "Learning rate after epoch 244 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0014 - val_mae: 0.0324\n",
      "Epoch 246/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0289\n",
      "Learning rate after epoch 245 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 247/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0330\n",
      "Learning rate after epoch 246 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0048 - val_mae: 0.0488\n",
      "Epoch 248/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0441\n",
      "Learning rate after epoch 247 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0555 - val_loss: 4.3799e-04 - val_mae: 0.0122\n",
      "Epoch 249/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0358\n",
      "Learning rate after epoch 248 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0022 - val_mae: 0.0417\n",
      "Epoch 250/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0493\n",
      "Learning rate after epoch 249 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0508 - val_loss: 4.1976e-04 - val_mae: 0.0134\n",
      "Epoch 251/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0354\n",
      "Learning rate after epoch 250 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 6.4931e-04 - val_mae: 0.0207\n",
      "Epoch 252/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0291\n",
      "Learning rate after epoch 251 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0019 - val_mae: 0.0381\n",
      "Epoch 253/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0976\n",
      "Learning rate after epoch 252 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0032 - val_mae: 0.0434\n",
      "Epoch 254/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0326\n",
      "Learning rate after epoch 253 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0536 - val_loss: 0.0024 - val_mae: 0.0459\n",
      "Epoch 255/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0265\n",
      "Learning rate after epoch 254 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0050 - val_mae: 0.0663\n",
      "Epoch 256/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0561\n",
      "Learning rate after epoch 255 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0028 - val_mae: 0.0476\n",
      "Epoch 257/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0627\n",
      "Learning rate after epoch 256 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0539 - val_loss: 0.0022 - val_mae: 0.0416\n",
      "Epoch 258/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0410\n",
      "Learning rate after epoch 257 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0588 - val_loss: 8.1026e-04 - val_mae: 0.0232\n",
      "Epoch 259/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0500\n",
      "Learning rate after epoch 258 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 4.1858e-04 - val_mae: 0.0135\n",
      "Epoch 260/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0366\n",
      "Learning rate after epoch 259 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0524 - val_loss: 7.9774e-04 - val_mae: 0.0221\n",
      "Epoch 261/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0488\n",
      "Learning rate after epoch 260 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0021 - val_mae: 0.0410\n",
      "Epoch 262/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0748\n",
      "Learning rate after epoch 261 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0476 - val_loss: 0.0012 - val_mae: 0.0288\n",
      "Epoch 263/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0738\n",
      "Learning rate after epoch 262 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0468 - val_loss: 0.0019 - val_mae: 0.0380\n",
      "Epoch 264/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0332\n",
      "Learning rate after epoch 263 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0038 - val_mae: 0.0417\n",
      "Epoch 265/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0505\n",
      "Learning rate after epoch 264 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0010 - val_mae: 0.0272\n",
      "Epoch 266/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0587\n",
      "Learning rate after epoch 265 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0034 - val_mae: 0.0456\n",
      "Epoch 267/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0650\n",
      "Learning rate after epoch 266 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0017 - val_mae: 0.0353\n",
      "Epoch 268/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0378\n",
      "Learning rate after epoch 267 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "Epoch 269/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0441\n",
      "Learning rate after epoch 268 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0021 - val_mae: 0.0396\n",
      "Epoch 270/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0284\n",
      "Learning rate after epoch 269 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0025 - val_mae: 0.0352\n",
      "Epoch 271/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0329\n",
      "Learning rate after epoch 270 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0607 - val_loss: 8.3880e-04 - val_mae: 0.0251\n",
      "Epoch 272/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0331\n",
      "Learning rate after epoch 271 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.0015 - val_mae: 0.0354\n",
      "Epoch 273/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0238\n",
      "Learning rate after epoch 272 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 7.3820e-04 - val_mae: 0.0234\n",
      "Epoch 274/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0925\n",
      "Learning rate after epoch 273 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0597 - val_loss: 6.3381e-04 - val_mae: 0.0185\n",
      "Epoch 275/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0739\n",
      "Learning rate after epoch 274 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 6.8916e-04 - val_mae: 0.0189\n",
      "Epoch 276/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0349\n",
      "Learning rate after epoch 275 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0543 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 277/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0424\n",
      "Learning rate after epoch 276 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0034 - val_mae: 0.0477\n",
      "Epoch 278/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6175e-04 - mae: 0.0210\n",
      "Learning rate after epoch 277 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0498 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 279/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0516\n",
      "Learning rate after epoch 278 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0023 - val_mae: 0.0354\n",
      "Epoch 280/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0603\n",
      "Learning rate after epoch 279 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0462 - val_loss: 5.2107e-04 - val_mae: 0.0162\n",
      "Epoch 281/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0415\n",
      "Learning rate after epoch 280 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0500 - val_loss: 0.0017 - val_mae: 0.0359\n",
      "Epoch 282/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0455\n",
      "Learning rate after epoch 281 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0025 - val_mae: 0.0458\n",
      "Epoch 283/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0376\n",
      "Learning rate after epoch 282 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0022 - val_mae: 0.0402\n",
      "Epoch 284/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0279\n",
      "Learning rate after epoch 283 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 9.9990e-04 - val_mae: 0.0276\n",
      "Epoch 285/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0785\n",
      "Learning rate after epoch 284 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 4.0528e-04 - val_mae: 0.0149\n",
      "Epoch 286/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0424\n",
      "Learning rate after epoch 285 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0031 - val_mae: 0.0476\n",
      "Epoch 287/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0292\n",
      "Learning rate after epoch 286 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0029 - val_mae: 0.0445\n",
      "Epoch 288/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0485\n",
      "Learning rate after epoch 287 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0641 - val_loss: 0.0018 - val_mae: 0.0390\n",
      "Epoch 289/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0315\n",
      "Learning rate after epoch 288 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0038 - val_mae: 0.0476\n",
      "Epoch 290/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0602\n",
      "Learning rate after epoch 289 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0519 - val_loss: 8.9832e-04 - val_mae: 0.0255\n",
      "Epoch 291/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0445\n",
      "Learning rate after epoch 290 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 7.6368e-04 - val_mae: 0.0235\n",
      "Epoch 292/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0247\n",
      "Learning rate after epoch 291 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0035 - val_mae: 0.0454\n",
      "Epoch 293/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0448\n",
      "Learning rate after epoch 292 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 0.0018 - val_mae: 0.0356\n",
      "Epoch 294/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0369\n",
      "Learning rate after epoch 293 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0012 - val_mae: 0.0296\n",
      "Epoch 295/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0417\n",
      "Learning rate after epoch 294 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0015 - val_mae: 0.0355\n",
      "Epoch 296/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0277\n",
      "Learning rate after epoch 295 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0441 - val_loss: 0.0031 - val_mae: 0.0504\n",
      "Epoch 297/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0646\n",
      "Learning rate after epoch 296 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0487 - val_loss: 0.0041 - val_mae: 0.0453\n",
      "Epoch 298/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0300\n",
      "Learning rate after epoch 297 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0021 - val_mae: 0.0374\n",
      "Epoch 299/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0474\n",
      "Learning rate after epoch 298 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 9.2951e-04 - val_mae: 0.0265\n",
      "Epoch 300/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0382\n",
      "Learning rate after epoch 299 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0603 - val_loss: 0.0025 - val_mae: 0.0472\n",
      "Epoch 301/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0544\n",
      "Learning rate after epoch 300 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0018 - val_mae: 0.0348\n",
      "Epoch 302/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0335\n",
      "Learning rate after epoch 301 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0435 - val_loss: 7.9823e-04 - val_mae: 0.0243\n",
      "Epoch 303/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0771\n",
      "Learning rate after epoch 302 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 304/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0833\n",
      "Learning rate after epoch 303 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0321\n",
      "Epoch 305/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0380\n",
      "Learning rate after epoch 304 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0503 - val_loss: 0.0010 - val_mae: 0.0273\n",
      "Epoch 306/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0238\n",
      "Learning rate after epoch 305 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 8.7653e-04 - val_mae: 0.0250\n",
      "Epoch 307/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0712\n",
      "Learning rate after epoch 306 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0035 - val_mae: 0.0457\n",
      "Epoch 308/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0408\n",
      "Learning rate after epoch 307 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0425 - val_loss: 5.9006e-04 - val_mae: 0.0176\n",
      "Epoch 309/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0362\n",
      "Learning rate after epoch 308 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 9.3401e-04 - val_mae: 0.0246\n",
      "Epoch 310/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0346\n",
      "Learning rate after epoch 309 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0624 - val_loss: 0.0035 - val_mae: 0.0557\n",
      "Epoch 311/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0511\n",
      "Learning rate after epoch 310 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0542 - val_loss: 0.0021 - val_mae: 0.0374\n",
      "Epoch 312/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0328\n",
      "Learning rate after epoch 311 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0011 - val_mae: 0.0301\n",
      "Epoch 313/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0533\n",
      "Learning rate after epoch 312 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 314/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0520\n",
      "Learning rate after epoch 313 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0010 - val_mae: 0.0266\n",
      "Epoch 315/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5367e-04 - mae: 0.0228\n",
      "Learning rate after epoch 314 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 7.9932e-04 - val_mae: 0.0192\n",
      "Epoch 316/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0475\n",
      "Learning rate after epoch 315 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0329\n",
      "Epoch 317/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0573\n",
      "Learning rate after epoch 316 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0550 - val_loss: 0.0018 - val_mae: 0.0367\n",
      "Epoch 318/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0347\n",
      "Learning rate after epoch 317 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0012 - val_mae: 0.0302\n",
      "Epoch 319/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0410\n",
      "Learning rate after epoch 318 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0024 - val_mae: 0.0333\n",
      "Epoch 320/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0792\n",
      "Learning rate after epoch 319 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0021 - val_mae: 0.0379\n",
      "Epoch 321/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0587\n",
      "Learning rate after epoch 320 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 322/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0253\n",
      "Learning rate after epoch 321 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 8.5531e-04 - val_mae: 0.0228\n",
      "Epoch 323/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0575\n",
      "Learning rate after epoch 322 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0513 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 324/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.6979e-04 - mae: 0.0251\n",
      "Learning rate after epoch 323 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0428 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 325/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0390\n",
      "Learning rate after epoch 324 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0548 - val_loss: 4.7944e-04 - val_mae: 0.0161\n",
      "Epoch 326/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0422\n",
      "Learning rate after epoch 325 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0416\n",
      "Epoch 327/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0378\n",
      "Learning rate after epoch 326 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 328/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0334\n",
      "Learning rate after epoch 327 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 329/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0927\n",
      "Learning rate after epoch 328 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0527 - val_loss: 0.0034 - val_mae: 0.0536\n",
      "Epoch 330/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0280\n",
      "Learning rate after epoch 329 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0015 - val_mae: 0.0338\n",
      "Epoch 331/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0325\n",
      "Learning rate after epoch 330 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0013 - val_mae: 0.0244\n",
      "Epoch 332/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0343\n",
      "Learning rate after epoch 331 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0014 - val_mae: 0.0324\n",
      "Epoch 333/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0474\n",
      "Learning rate after epoch 332 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0487 - val_loss: 0.0024 - val_mae: 0.0428\n",
      "Epoch 334/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5131e-04 - mae: 0.0232\n",
      "Learning rate after epoch 333 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0515 - val_loss: 6.9636e-04 - val_mae: 0.0219\n",
      "Epoch 335/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0627\n",
      "Learning rate after epoch 334 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 336/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0360\n",
      "Learning rate after epoch 335 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 9.9286e-04 - val_mae: 0.0233\n",
      "Epoch 337/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0421\n",
      "Learning rate after epoch 336 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 338/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0593\n",
      "Learning rate after epoch 337 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0020 - val_mae: 0.0405\n",
      "Epoch 339/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0499\n",
      "Learning rate after epoch 338 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0322\n",
      "Epoch 340/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0347\n",
      "Learning rate after epoch 339 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 341/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0427\n",
      "Learning rate after epoch 340 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 7.7478e-04 - val_mae: 0.0212\n",
      "Epoch 342/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0507\n",
      "Learning rate after epoch 341 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 343/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0276\n",
      "Learning rate after epoch 342 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0451 - val_loss: 0.0022 - val_mae: 0.0313\n",
      "Epoch 344/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0310\n",
      "Learning rate after epoch 343 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0379 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 345/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0868\n",
      "Learning rate after epoch 344 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 7.7030e-04 - val_mae: 0.0215\n",
      "Epoch 346/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0682\n",
      "Learning rate after epoch 345 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0437 - val_loss: 0.0012 - val_mae: 0.0271\n",
      "Epoch 347/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0788\n",
      "Learning rate after epoch 346 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0017 - val_mae: 0.0354\n",
      "Epoch 348/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0545\n",
      "Learning rate after epoch 347 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0528 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 349/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0478\n",
      "Learning rate after epoch 348 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0500 - val_loss: 9.1358e-04 - val_mae: 0.0223\n",
      "Epoch 350/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0334\n",
      "Learning rate after epoch 349 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0014 - val_mae: 0.0318\n",
      "Epoch 351/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0250\n",
      "Learning rate after epoch 350 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0312\n",
      "Epoch 352/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0409\n",
      "Learning rate after epoch 351 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0012 - val_mae: 0.0312\n",
      "Epoch 353/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0508\n",
      "Learning rate after epoch 352 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0425 - val_loss: 6.0794e-04 - val_mae: 0.0158\n",
      "Epoch 354/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0555\n",
      "Learning rate after epoch 353 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0522 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 355/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0834\n",
      "Learning rate after epoch 354 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0431 - val_loss: 0.0025 - val_mae: 0.0334\n",
      "Epoch 356/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0375\n",
      "Learning rate after epoch 355 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0021 - val_mae: 0.0385\n",
      "Epoch 357/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0315\n",
      "Learning rate after epoch 356 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0051 - val_mae: 0.0565\n",
      "Epoch 358/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0284\n",
      "Learning rate after epoch 357 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 0.0011 - val_mae: 0.0260\n",
      "Epoch 359/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0451\n",
      "Learning rate after epoch 358 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 360/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0345\n",
      "Learning rate after epoch 359 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0539 - val_loss: 0.0011 - val_mae: 0.0301\n",
      "Epoch 361/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0453\n",
      "Learning rate after epoch 360 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0446 - val_loss: 8.7756e-04 - val_mae: 0.0255\n",
      "Epoch 362/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0257\n",
      "Learning rate after epoch 361 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0455 - val_loss: 0.0027 - val_mae: 0.0373\n",
      "Epoch 363/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0135 - mae: 0.1075\n",
      "Learning rate after epoch 362 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 364/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0148 - mae: 0.1094\n",
      "Learning rate after epoch 363 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0552 - val_loss: 0.0032 - val_mae: 0.0396\n",
      "Epoch 365/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0455\n",
      "Learning rate after epoch 364 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 5.1513e-04 - val_mae: 0.0177\n",
      "Epoch 366/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0334\n",
      "Learning rate after epoch 365 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 3.5071e-04 - val_mae: 0.0123\n",
      "Epoch 367/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0450\n",
      "Learning rate after epoch 366 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0506 - val_loss: 0.0035 - val_mae: 0.0412\n",
      "Epoch 368/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0320\n",
      "Learning rate after epoch 367 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0528 - val_loss: 9.5617e-04 - val_mae: 0.0273\n",
      "Epoch 369/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0340\n",
      "Learning rate after epoch 368 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0532 - val_loss: 7.0681e-04 - val_mae: 0.0173\n",
      "Epoch 370/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0816\n",
      "Learning rate after epoch 369 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 6.5130e-04 - val_mae: 0.0208\n",
      "Epoch 371/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0290\n",
      "Learning rate after epoch 370 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 8.2759e-04 - val_mae: 0.0230\n",
      "Epoch 372/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0160 - mae: 0.1163\n",
      "Learning rate after epoch 371 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0452 - val_loss: 8.0564e-04 - val_mae: 0.0237\n",
      "Epoch 373/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0366\n",
      "Learning rate after epoch 372 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 5.7788e-04 - val_mae: 0.0183\n",
      "Epoch 374/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0318\n",
      "Learning rate after epoch 373 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 4.9504e-04 - val_mae: 0.0158\n",
      "Epoch 375/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0393\n",
      "Learning rate after epoch 374 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0033 - val_mae: 0.0419\n",
      "Epoch 376/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0267\n",
      "Learning rate after epoch 375 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0498 - val_loss: 7.1936e-04 - val_mae: 0.0207\n",
      "Epoch 377/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0336\n",
      "Learning rate after epoch 376 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0024 - val_mae: 0.0454\n",
      "Epoch 378/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0406\n",
      "Learning rate after epoch 377 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0021 - val_mae: 0.0395\n",
      "Epoch 379/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0406\n",
      "Learning rate after epoch 378 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0536 - val_loss: 7.7468e-04 - val_mae: 0.0190\n",
      "Epoch 380/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0423\n",
      "Learning rate after epoch 379 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0490 - val_loss: 6.6027e-04 - val_mae: 0.0200\n",
      "Epoch 381/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0373\n",
      "Learning rate after epoch 380 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0011 - val_mae: 0.0304\n",
      "Epoch 382/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0592\n",
      "Learning rate after epoch 381 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 8.5618e-04 - val_mae: 0.0261\n",
      "Epoch 383/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0478\n",
      "Learning rate after epoch 382 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0048 - val_mae: 0.0585\n",
      "Epoch 384/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0685\n",
      "Learning rate after epoch 383 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0465 - val_loss: 0.0016 - val_mae: 0.0337\n",
      "Epoch 385/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0595\n",
      "Learning rate after epoch 384 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0629 - val_loss: 0.0013 - val_mae: 0.0304\n",
      "Epoch 386/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0661\n",
      "Learning rate after epoch 385 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0519 - val_loss: 0.0025 - val_mae: 0.0461\n",
      "Epoch 387/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0302\n",
      "Learning rate after epoch 386 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0473 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 388/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0267\n",
      "Learning rate after epoch 387 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0016 - val_mae: 0.0330\n",
      "Epoch 389/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0135 - mae: 0.1033\n",
      "Learning rate after epoch 388 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0543 - val_loss: 0.0050 - val_mae: 0.0637\n",
      "Epoch 390/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0388\n",
      "Learning rate after epoch 389 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0028 - val_mae: 0.0424\n",
      "Epoch 391/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0319\n",
      "Learning rate after epoch 390 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0020 - val_mae: 0.0389\n",
      "Epoch 392/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0439\n",
      "Learning rate after epoch 391 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0460 - val_loss: 0.0023 - val_mae: 0.0352\n",
      "Epoch 393/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0274\n",
      "Learning rate after epoch 392 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0507 - val_loss: 0.0013 - val_mae: 0.0320\n",
      "Epoch 394/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0274\n",
      "Learning rate after epoch 393 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0453 - val_loss: 8.0358e-04 - val_mae: 0.0239\n",
      "Epoch 395/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0628\n",
      "Learning rate after epoch 394 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0031 - val_mae: 0.0518\n",
      "Epoch 396/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0767\n",
      "Learning rate after epoch 395 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0546 - val_loss: 0.0011 - val_mae: 0.0290\n",
      "Epoch 397/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0782\n",
      "Learning rate after epoch 396 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0489 - val_loss: 0.0018 - val_mae: 0.0366\n",
      "Epoch 398/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0744\n",
      "Learning rate after epoch 397 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 399/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0339\n",
      "Learning rate after epoch 398 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0508 - val_loss: 5.4366e-04 - val_mae: 0.0152\n",
      "Epoch 400/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0526\n",
      "Learning rate after epoch 399 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0027 - val_mae: 0.0387\n",
      "Epoch 401/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0533\n",
      "Learning rate after epoch 400 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0586 - val_loss: 5.0222e-04 - val_mae: 0.0171\n",
      "Epoch 402/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0354\n",
      "Learning rate after epoch 401 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0610 - val_loss: 0.0025 - val_mae: 0.0475\n",
      "Epoch 403/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0423\n",
      "Learning rate after epoch 402 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0522 - val_loss: 8.2263e-04 - val_mae: 0.0191\n",
      "Epoch 404/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0361\n",
      "Learning rate after epoch 403 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0602 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 405/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0375\n",
      "Learning rate after epoch 404 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0518 - val_loss: 0.0023 - val_mae: 0.0431\n",
      "Epoch 406/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0453\n",
      "Learning rate after epoch 405 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0524 - val_loss: 0.0019 - val_mae: 0.0390\n",
      "Epoch 407/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0343\n",
      "Learning rate after epoch 406 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0418 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 408/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0323\n",
      "Learning rate after epoch 407 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0024 - val_mae: 0.0411\n",
      "Epoch 409/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0387\n",
      "Learning rate after epoch 408 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0031 - val_mae: 0.0497\n",
      "Epoch 410/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0930\n",
      "Learning rate after epoch 409 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0532 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 411/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0331\n",
      "Learning rate after epoch 410 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 0.0023 - val_mae: 0.0421\n",
      "Epoch 412/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0556\n",
      "Learning rate after epoch 411 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0538 - val_loss: 0.0027 - val_mae: 0.0423\n",
      "Epoch 413/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0381\n",
      "Learning rate after epoch 412 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0011 - val_mae: 0.0288\n",
      "Epoch 414/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0387\n",
      "Learning rate after epoch 413 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0500 - val_loss: 0.0014 - val_mae: 0.0343\n",
      "Epoch 415/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0666\n",
      "Learning rate after epoch 414 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0514 - val_loss: 0.0027 - val_mae: 0.0418\n",
      "Epoch 416/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0358\n",
      "Learning rate after epoch 415 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 417/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0439\n",
      "Learning rate after epoch 416 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 9.2773e-04 - val_mae: 0.0239\n",
      "Epoch 418/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0489\n",
      "Learning rate after epoch 417 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0014 - val_mae: 0.0322\n",
      "Epoch 419/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0709\n",
      "Learning rate after epoch 418 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0489 - val_loss: 0.0034 - val_mae: 0.0516\n",
      "Epoch 420/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0599\n",
      "Learning rate after epoch 419 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 421/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0386\n",
      "Learning rate after epoch 420 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0511 - val_loss: 4.7583e-04 - val_mae: 0.0176\n",
      "Epoch 422/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0137 - mae: 0.1018\n",
      "Learning rate after epoch 421 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0571 - val_loss: 0.0016 - val_mae: 0.0359\n",
      "Epoch 423/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0535\n",
      "Learning rate after epoch 422 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0539 - val_loss: 8.7042e-04 - val_mae: 0.0261\n",
      "Epoch 424/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0282\n",
      "Learning rate after epoch 423 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 4.3112e-04 - val_mae: 0.0148\n",
      "Epoch 425/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0437\n",
      "Learning rate after epoch 424 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0388 - val_loss: 8.9157e-04 - val_mae: 0.0226\n",
      "Epoch 426/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0414\n",
      "Learning rate after epoch 425 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 427/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0265\n",
      "Learning rate after epoch 426 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0041 - val_mae: 0.0517\n",
      "Epoch 428/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0263\n",
      "Learning rate after epoch 427 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 8.9662e-04 - val_mae: 0.0242\n",
      "Epoch 429/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0346\n",
      "Learning rate after epoch 428 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0412 - val_loss: 0.0022 - val_mae: 0.0326\n",
      "Epoch 430/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0376\n",
      "Learning rate after epoch 429 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0029 - val_mae: 0.0391\n",
      "Epoch 431/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0273\n",
      "Learning rate after epoch 430 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0535 - val_loss: 2.3288e-04 - val_mae: 0.0097\n",
      "Epoch 432/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0533\n",
      "Learning rate after epoch 431 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0460 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 433/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0797\n",
      "Learning rate after epoch 432 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0465 - val_loss: 0.0025 - val_mae: 0.0375\n",
      "Epoch 434/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0466\n",
      "Learning rate after epoch 433 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0015 - val_mae: 0.0351\n",
      "Epoch 435/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0278\n",
      "Learning rate after epoch 434 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0432 - val_loss: 0.0031 - val_mae: 0.0496\n",
      "Epoch 436/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0357\n",
      "Learning rate after epoch 435 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0017 - val_mae: 0.0349\n",
      "Epoch 437/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0401\n",
      "Learning rate after epoch 436 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0013 - val_mae: 0.0311\n",
      "Epoch 438/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0290\n",
      "Learning rate after epoch 437 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0013 - val_mae: 0.0292\n",
      "Epoch 439/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0386\n",
      "Learning rate after epoch 438 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0546 - val_loss: 0.0060 - val_mae: 0.0552\n",
      "Epoch 440/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0430\n",
      "Learning rate after epoch 439 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 4.5755e-04 - val_mae: 0.0177\n",
      "Epoch 441/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.9539e-04 - mae: 0.0245\n",
      "Learning rate after epoch 440 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0013 - val_mae: 0.0334\n",
      "Epoch 442/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0635\n",
      "Learning rate after epoch 441 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0031 - val_mae: 0.0457\n",
      "Epoch 443/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0522\n",
      "Learning rate after epoch 442 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0316\n",
      "Epoch 444/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0592\n",
      "Learning rate after epoch 443 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 8.3629e-04 - val_mae: 0.0238\n",
      "Epoch 445/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.9654e-04 - mae: 0.0227\n",
      "Learning rate after epoch 444 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0546 - val_loss: 0.0021 - val_mae: 0.0434\n",
      "Epoch 446/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0642\n",
      "Learning rate after epoch 445 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0539 - val_loss: 3.3754e-04 - val_mae: 0.0139\n",
      "Epoch 447/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0377\n",
      "Learning rate after epoch 446 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0011 - val_mae: 0.0301\n",
      "Epoch 448/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0736\n",
      "Learning rate after epoch 447 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0416 - val_loss: 7.2730e-04 - val_mae: 0.0185\n",
      "Epoch 449/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0419\n",
      "Learning rate after epoch 448 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0506 - val_loss: 0.0010 - val_mae: 0.0284\n",
      "Epoch 450/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0382\n",
      "Learning rate after epoch 449 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0012 - val_mae: 0.0305\n",
      "Epoch 451/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0276\n",
      "Learning rate after epoch 450 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0520 - val_loss: 0.0011 - val_mae: 0.0303\n",
      "Epoch 452/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0454\n",
      "Learning rate after epoch 451 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0463 - val_loss: 8.6886e-04 - val_mae: 0.0266\n",
      "Epoch 453/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0494\n",
      "Learning rate after epoch 452 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 7.0148e-04 - val_mae: 0.0214\n",
      "Epoch 454/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0258\n",
      "Learning rate after epoch 453 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0427 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 455/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0109 - mae: 0.0969\n",
      "Learning rate after epoch 454 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0530 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 456/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0273\n",
      "Learning rate after epoch 455 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0032 - val_mae: 0.0536\n",
      "Epoch 457/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0695\n",
      "Learning rate after epoch 456 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0555 - val_loss: 0.0018 - val_mae: 0.0384\n",
      "Epoch 458/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0635\n",
      "Learning rate after epoch 457 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 459/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0355\n",
      "Learning rate after epoch 458 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0022 - val_mae: 0.0439\n",
      "Epoch 460/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0305\n",
      "Learning rate after epoch 459 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0027 - val_mae: 0.0435\n",
      "Epoch 461/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0522\n",
      "Learning rate after epoch 460 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0434 - val_loss: 0.0049 - val_mae: 0.0477\n",
      "Epoch 462/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0677\n",
      "Learning rate after epoch 461 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0535 - val_loss: 0.0038 - val_mae: 0.0523\n",
      "Epoch 463/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0366\n",
      "Learning rate after epoch 462 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0482 - val_loss: 0.0010 - val_mae: 0.0278\n",
      "Epoch 464/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0720\n",
      "Learning rate after epoch 463 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0012 - val_mae: 0.0298\n",
      "Epoch 465/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0289\n",
      "Learning rate after epoch 464 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0021 - val_mae: 0.0345\n",
      "Epoch 466/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0315\n",
      "Learning rate after epoch 465 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0030 - val_mae: 0.0386\n",
      "Epoch 467/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0393\n",
      "Learning rate after epoch 466 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0476 - val_loss: 0.0032 - val_mae: 0.0527\n",
      "Epoch 468/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0628\n",
      "Learning rate after epoch 467 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0620 - val_loss: 4.7492e-04 - val_mae: 0.0145\n",
      "Epoch 469/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0305\n",
      "Learning rate after epoch 468 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0504 - val_loss: 0.0019 - val_mae: 0.0409\n",
      "Epoch 470/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0114 - mae: 0.1015\n",
      "Learning rate after epoch 469 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0466 - val_loss: 8.0909e-04 - val_mae: 0.0256\n",
      "Epoch 471/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0452\n",
      "Learning rate after epoch 470 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 8.5222e-04 - val_mae: 0.0223\n",
      "Epoch 472/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0260\n",
      "Learning rate after epoch 471 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0012 - val_mae: 0.0323\n",
      "Epoch 473/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0303\n",
      "Learning rate after epoch 472 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0496 - val_loss: 0.0026 - val_mae: 0.0480\n",
      "Epoch 474/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0794\n",
      "Learning rate after epoch 473 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 5.1759e-04 - val_mae: 0.0191\n",
      "Epoch 475/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0664\n",
      "Learning rate after epoch 474 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0536 - val_loss: 0.0011 - val_mae: 0.0284\n",
      "Epoch 476/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0477\n",
      "Learning rate after epoch 475 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0032 - val_mae: 0.0436\n",
      "Epoch 477/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0471\n",
      "Learning rate after epoch 476 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0514 - val_loss: 0.0027 - val_mae: 0.0450\n",
      "Epoch 478/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0344\n",
      "Learning rate after epoch 477 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0410 - val_loss: 0.0028 - val_mae: 0.0394\n",
      "Epoch 479/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0624\n",
      "Learning rate after epoch 478 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0526\n",
      "Epoch 480/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0325\n",
      "Learning rate after epoch 479 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0511 - val_loss: 0.0018 - val_mae: 0.0400\n",
      "Epoch 481/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0459\n",
      "Learning rate after epoch 480 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0538 - val_loss: 0.0035 - val_mae: 0.0543\n",
      "Epoch 482/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0291\n",
      "Learning rate after epoch 481 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0012 - val_mae: 0.0275\n",
      "Epoch 483/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0400\n",
      "Learning rate after epoch 482 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0012 - val_mae: 0.0306\n",
      "Epoch 484/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0333\n",
      "Learning rate after epoch 483 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0444 - val_loss: 4.5008e-04 - val_mae: 0.0155\n",
      "Epoch 485/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0271\n",
      "Learning rate after epoch 484 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0018 - val_mae: 0.0283\n",
      "Epoch 486/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0264\n",
      "Learning rate after epoch 485 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0029 - val_mae: 0.0385\n",
      "Epoch 487/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0593\n",
      "Learning rate after epoch 486 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0525 - val_loss: 0.0022 - val_mae: 0.0366\n",
      "Epoch 488/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9098e-04 - mae: 0.0208\n",
      "Learning rate after epoch 487 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0505 - val_loss: 0.0021 - val_mae: 0.0367\n",
      "Epoch 489/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0416\n",
      "Learning rate after epoch 488 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0029 - val_mae: 0.0461\n",
      "Epoch 490/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0416\n",
      "Learning rate after epoch 489 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0016 - val_mae: 0.0273\n",
      "Epoch 491/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0231\n",
      "Learning rate after epoch 490 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0551 - val_loss: 0.0019 - val_mae: 0.0370\n",
      "Epoch 492/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0286\n",
      "Learning rate after epoch 491 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0510 - val_loss: 8.7867e-04 - val_mae: 0.0227\n",
      "Epoch 493/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0659\n",
      "Learning rate after epoch 492 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0050 - val_mae: 0.0462\n",
      "Epoch 494/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0352\n",
      "Learning rate after epoch 493 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0521 - val_loss: 0.0018 - val_mae: 0.0394\n",
      "Epoch 495/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0254\n",
      "Learning rate after epoch 494 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0448 - val_loss: 0.0037 - val_mae: 0.0577\n",
      "Epoch 496/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0386\n",
      "Learning rate after epoch 495 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0012 - val_mae: 0.0288\n",
      "Epoch 497/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0410\n",
      "Learning rate after epoch 496 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0536 - val_loss: 0.0048 - val_mae: 0.0618\n",
      "Epoch 498/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0378\n",
      "Learning rate after epoch 497 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0026 - val_mae: 0.0477\n",
      "Epoch 499/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0738\n",
      "Learning rate after epoch 498 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0484 - val_loss: 0.0017 - val_mae: 0.0350\n",
      "Epoch 500/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0255\n",
      "Learning rate after epoch 499 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0018 - val_mae: 0.0393\n",
      "Epoch 501/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0984\n",
      "Learning rate after epoch 500 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0011 - val_mae: 0.0304\n",
      "Epoch 502/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.3304e-04 - mae: 0.0238\n",
      "Learning rate after epoch 501 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0445 - val_loss: 0.0019 - val_mae: 0.0375\n",
      "Epoch 503/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0935\n",
      "Learning rate after epoch 502 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0455 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 504/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0374\n",
      "Learning rate after epoch 503 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 505/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0401\n",
      "Learning rate after epoch 504 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0012 - val_mae: 0.0305\n",
      "Epoch 506/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.5973e-04 - mae: 0.0220\n",
      "Learning rate after epoch 505 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0456 - val_loss: 0.0018 - val_mae: 0.0393\n",
      "Epoch 507/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0279\n",
      "Learning rate after epoch 506 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0545 - val_loss: 0.0045 - val_mae: 0.0444\n",
      "Epoch 508/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0479\n",
      "Learning rate after epoch 507 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 509/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0839\n",
      "Learning rate after epoch 508 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0507 - val_loss: 9.8292e-04 - val_mae: 0.0265\n",
      "Epoch 510/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0238\n",
      "Learning rate after epoch 509 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0513 - val_loss: 0.0044 - val_mae: 0.0491\n",
      "Epoch 511/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0595\n",
      "Learning rate after epoch 510 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 9.0669e-04 - val_mae: 0.0269\n",
      "Epoch 512/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0746\n",
      "Learning rate after epoch 511 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0469 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 513/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0312\n",
      "Learning rate after epoch 512 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0553 - val_loss: 6.6877e-04 - val_mae: 0.0212\n",
      "Epoch 514/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5222e-04 - mae: 0.0220\n",
      "Learning rate after epoch 513 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0022 - val_mae: 0.0425\n",
      "Epoch 515/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0295\n",
      "Learning rate after epoch 514 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0585\n",
      "Epoch 516/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0889\n",
      "Learning rate after epoch 515 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0662 - val_loss: 5.8320e-04 - val_mae: 0.0192\n",
      "Epoch 517/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0774\n",
      "Learning rate after epoch 516 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0554 - val_loss: 0.0038 - val_mae: 0.0458\n",
      "Epoch 518/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0682\n",
      "Learning rate after epoch 517 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0477 - val_loss: 0.0025 - val_mae: 0.0371\n",
      "Epoch 519/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0305\n",
      "Learning rate after epoch 518 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0506 - val_loss: 0.0024 - val_mae: 0.0457\n",
      "Epoch 520/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0263\n",
      "Learning rate after epoch 519 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0015 - val_mae: 0.0347\n",
      "Epoch 521/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0355\n",
      "Learning rate after epoch 520 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0484\n",
      "Epoch 522/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0766\n",
      "Learning rate after epoch 521 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0525 - val_loss: 0.0052 - val_mae: 0.0636\n",
      "Epoch 523/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0691\n",
      "Learning rate after epoch 522 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0461 - val_loss: 0.0025 - val_mae: 0.0464\n",
      "Epoch 524/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0361\n",
      "Learning rate after epoch 523 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0516 - val_loss: 7.5282e-04 - val_mae: 0.0225\n",
      "Epoch 525/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0303\n",
      "Learning rate after epoch 524 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0515 - val_loss: 0.0027 - val_mae: 0.0482\n",
      "Epoch 526/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0339\n",
      "Learning rate after epoch 525 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0021 - val_mae: 0.0426\n",
      "Epoch 527/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0812\n",
      "Learning rate after epoch 526 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0018 - val_mae: 0.0350\n",
      "Epoch 528/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0688\n",
      "Learning rate after epoch 527 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0451 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 529/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0426\n",
      "Learning rate after epoch 528 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0455 - val_loss: 0.0039 - val_mae: 0.0589\n",
      "Epoch 530/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0418\n",
      "Learning rate after epoch 529 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0020 - val_mae: 0.0407\n",
      "Epoch 531/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0359\n",
      "Learning rate after epoch 530 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0463 - val_loss: 0.0031 - val_mae: 0.0464\n",
      "Epoch 532/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0660\n",
      "Learning rate after epoch 531 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0015 - val_mae: 0.0353\n",
      "Epoch 533/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0483\n",
      "Learning rate after epoch 532 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0564 - val_loss: 0.0017 - val_mae: 0.0374\n",
      "Epoch 534/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0577\n",
      "Learning rate after epoch 533 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0024 - val_mae: 0.0449\n",
      "Epoch 535/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0544\n",
      "Learning rate after epoch 534 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0562 - val_loss: 6.8777e-04 - val_mae: 0.0215\n",
      "Epoch 536/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0524\n",
      "Learning rate after epoch 535 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0459 - val_loss: 0.0020 - val_mae: 0.0383\n",
      "Epoch 537/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0284\n",
      "Learning rate after epoch 536 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0021 - val_mae: 0.0379\n",
      "Epoch 538/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0660\n",
      "Learning rate after epoch 537 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0030 - val_mae: 0.0459\n",
      "Epoch 539/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0277\n",
      "Learning rate after epoch 538 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 9.8264e-04 - val_mae: 0.0267\n",
      "Epoch 540/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0249\n",
      "Learning rate after epoch 539 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 541/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0255\n",
      "Learning rate after epoch 540 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0466 - val_loss: 0.0024 - val_mae: 0.0333\n",
      "Epoch 542/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0344\n",
      "Learning rate after epoch 541 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0541 - val_loss: 0.0012 - val_mae: 0.0249\n",
      "Epoch 543/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0376\n",
      "Learning rate after epoch 542 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0325\n",
      "Epoch 544/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0663\n",
      "Learning rate after epoch 543 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0030 - val_mae: 0.0414\n",
      "Epoch 545/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0349\n",
      "Learning rate after epoch 544 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0046 - val_mae: 0.0558\n",
      "Epoch 546/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0505\n",
      "Learning rate after epoch 545 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 547/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0797\n",
      "Learning rate after epoch 546 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0458 - val_loss: 0.0012 - val_mae: 0.0289\n",
      "Epoch 548/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0446\n",
      "Learning rate after epoch 547 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 6.9505e-04 - val_mae: 0.0207\n",
      "Epoch 549/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0627\n",
      "Learning rate after epoch 548 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0544 - val_loss: 5.9471e-04 - val_mae: 0.0158\n",
      "Epoch 550/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0284\n",
      "Learning rate after epoch 549 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0016 - val_mae: 0.0376\n",
      "Epoch 551/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0354\n",
      "Learning rate after epoch 550 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 552/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0424\n",
      "Learning rate after epoch 551 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0018 - val_mae: 0.0270\n",
      "Epoch 553/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0436\n",
      "Learning rate after epoch 552 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0446 - val_loss: 0.0062 - val_mae: 0.0536\n",
      "Epoch 554/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0307\n",
      "Learning rate after epoch 553 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0446 - val_loss: 8.4437e-04 - val_mae: 0.0213\n",
      "Epoch 555/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0563\n",
      "Learning rate after epoch 554 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 2.6766e-04 - val_mae: 0.0100\n",
      "Epoch 556/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.0335e-04 - mae: 0.0235\n",
      "Learning rate after epoch 555 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0016 - val_mae: 0.0286\n",
      "Epoch 557/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0317\n",
      "Learning rate after epoch 556 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0419 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 558/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0276\n",
      "Learning rate after epoch 557 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0448 - val_loss: 0.0030 - val_mae: 0.0448\n",
      "Epoch 559/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0614\n",
      "Learning rate after epoch 558 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0476 - val_loss: 9.4612e-04 - val_mae: 0.0237\n",
      "Epoch 560/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0477\n",
      "Learning rate after epoch 559 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0012 - val_mae: 0.0315\n",
      "Epoch 561/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0256\n",
      "Learning rate after epoch 560 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0537 - val_loss: 0.0022 - val_mae: 0.0395\n",
      "Epoch 562/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0643\n",
      "Learning rate after epoch 561 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0416 - val_loss: 0.0029 - val_mae: 0.0379\n",
      "Epoch 563/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0281\n",
      "Learning rate after epoch 562 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0013 - val_mae: 0.0305\n",
      "Epoch 564/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0324\n",
      "Learning rate after epoch 563 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0013 - val_mae: 0.0298\n",
      "Epoch 565/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0405\n",
      "Learning rate after epoch 564 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0521 - val_loss: 0.0010 - val_mae: 0.0291\n",
      "Epoch 566/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0293\n",
      "Learning rate after epoch 565 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0020 - val_mae: 0.0415\n",
      "Epoch 567/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0370\n",
      "Learning rate after epoch 566 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 7.2860e-04 - val_mae: 0.0193\n",
      "Epoch 568/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0292\n",
      "Learning rate after epoch 567 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 8.3779e-04 - val_mae: 0.0201\n",
      "Epoch 569/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0326\n",
      "Learning rate after epoch 568 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0574\n",
      "Epoch 570/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0407\n",
      "Learning rate after epoch 569 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0534 - val_loss: 0.0020 - val_mae: 0.0373\n",
      "Epoch 571/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0326\n",
      "Learning rate after epoch 570 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 9.2575e-04 - val_mae: 0.0280\n",
      "Epoch 572/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0326\n",
      "Learning rate after epoch 571 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 5.1676e-04 - val_mae: 0.0171\n",
      "Epoch 573/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0321\n",
      "Learning rate after epoch 572 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 8.8713e-04 - val_mae: 0.0260\n",
      "Epoch 574/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0247\n",
      "Learning rate after epoch 573 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0030 - val_mae: 0.0470\n",
      "Epoch 575/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0279\n",
      "Learning rate after epoch 574 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0044 - val_mae: 0.0469\n",
      "Epoch 576/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0959\n",
      "Learning rate after epoch 575 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0536 - val_loss: 5.0242e-04 - val_mae: 0.0173\n",
      "Epoch 577/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0453\n",
      "Learning rate after epoch 576 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0452 - val_loss: 5.1621e-04 - val_mae: 0.0168\n",
      "Epoch 578/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0364\n",
      "Learning rate after epoch 577 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0525 - val_loss: 8.1720e-04 - val_mae: 0.0230\n",
      "Epoch 579/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0370\n",
      "Learning rate after epoch 578 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 8.0400e-04 - val_mae: 0.0218\n",
      "Epoch 580/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0318\n",
      "Learning rate after epoch 579 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 3.6196e-04 - val_mae: 0.0125\n",
      "Epoch 581/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0379\n",
      "Learning rate after epoch 580 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0456 - val_loss: 7.0867e-04 - val_mae: 0.0179\n",
      "Epoch 582/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0451\n",
      "Learning rate after epoch 581 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0556 - val_loss: 0.0015 - val_mae: 0.0352\n",
      "Epoch 583/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0627\n",
      "Learning rate after epoch 582 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 2.2685e-04 - val_mae: 0.0087\n",
      "Epoch 584/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0313\n",
      "Learning rate after epoch 583 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0536 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 585/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0511\n",
      "Learning rate after epoch 584 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0496 - val_loss: 0.0017 - val_mae: 0.0385\n",
      "Epoch 586/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0426\n",
      "Learning rate after epoch 585 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0022 - val_mae: 0.0366\n",
      "Epoch 587/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0823\n",
      "Learning rate after epoch 586 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0015 - val_mae: 0.0338\n",
      "Epoch 588/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0837\n",
      "Learning rate after epoch 587 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0440 - val_loss: 7.0361e-04 - val_mae: 0.0235\n",
      "Epoch 589/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0397\n",
      "Learning rate after epoch 588 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0558 - val_loss: 9.9399e-04 - val_mae: 0.0272\n",
      "Epoch 590/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0571\n",
      "Learning rate after epoch 589 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0534 - val_loss: 4.2039e-04 - val_mae: 0.0143\n",
      "Epoch 591/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0665\n",
      "Learning rate after epoch 590 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 5.9230e-04 - val_mae: 0.0157\n",
      "Epoch 592/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0423\n",
      "Learning rate after epoch 591 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0018 - val_mae: 0.0380\n",
      "Epoch 593/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0473\n",
      "Learning rate after epoch 592 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 594/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.7989e-04 - mae: 0.0235\n",
      "Learning rate after epoch 593 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0246\n",
      "Epoch 595/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0971\n",
      "Learning rate after epoch 594 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0555 - val_loss: 0.0017 - val_mae: 0.0371\n",
      "Epoch 596/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0451\n",
      "Learning rate after epoch 595 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0023 - val_mae: 0.0344\n",
      "Epoch 597/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0252\n",
      "Learning rate after epoch 596 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 4.3184e-04 - val_mae: 0.0164\n",
      "Epoch 598/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0416\n",
      "Learning rate after epoch 597 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0020 - val_mae: 0.0301\n",
      "Epoch 599/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0587\n",
      "Learning rate after epoch 598 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0034 - val_mae: 0.0424\n",
      "Epoch 600/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0397\n",
      "Learning rate after epoch 599 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 9.8151e-04 - val_mae: 0.0207\n",
      "Epoch 601/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0530\n",
      "Learning rate after epoch 600 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0515 - val_loss: 0.0025 - val_mae: 0.0425\n",
      "Epoch 602/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0791\n",
      "Learning rate after epoch 601 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0017 - val_mae: 0.0381\n",
      "Epoch 603/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0547\n",
      "Learning rate after epoch 602 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 604/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0393\n",
      "Learning rate after epoch 603 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0045 - val_mae: 0.0588\n",
      "Epoch 605/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0333\n",
      "Learning rate after epoch 604 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0532 - val_loss: 0.0016 - val_mae: 0.0373\n",
      "Epoch 606/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0256\n",
      "Learning rate after epoch 605 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0489 - val_loss: 0.0022 - val_mae: 0.0433\n",
      "Epoch 607/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0303\n",
      "Learning rate after epoch 606 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 2.3633e-04 - val_mae: 0.0085\n",
      "Epoch 608/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0549\n",
      "Learning rate after epoch 607 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0543 - val_loss: 0.0017 - val_mae: 0.0357\n",
      "Epoch 609/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0251\n",
      "Learning rate after epoch 608 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0494 - val_loss: 0.0022 - val_mae: 0.0307\n",
      "Epoch 610/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0313\n",
      "Learning rate after epoch 609 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 611/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0431\n",
      "Learning rate after epoch 610 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 3.5661e-04 - val_mae: 0.0148\n",
      "Epoch 612/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0810\n",
      "Learning rate after epoch 611 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0555 - val_loss: 0.0015 - val_mae: 0.0358\n",
      "Epoch 613/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0718\n",
      "Learning rate after epoch 612 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0022 - val_mae: 0.0436\n",
      "Epoch 614/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0227\n",
      "Learning rate after epoch 613 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 4.9249e-04 - val_mae: 0.0155\n",
      "Epoch 615/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0311\n",
      "Learning rate after epoch 614 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0506 - val_loss: 0.0013 - val_mae: 0.0308\n",
      "Epoch 616/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0222\n",
      "Learning rate after epoch 615 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0010 - val_mae: 0.0260\n",
      "Epoch 617/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0651\n",
      "Learning rate after epoch 616 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0018 - val_mae: 0.0299\n",
      "Epoch 618/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0772\n",
      "Learning rate after epoch 617 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0019 - val_mae: 0.0299\n",
      "Epoch 619/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0617\n",
      "Learning rate after epoch 618 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0031 - val_mae: 0.0468\n",
      "Epoch 620/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0647\n",
      "Learning rate after epoch 619 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0602\n",
      "Epoch 621/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0352\n",
      "Learning rate after epoch 620 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0048 - val_mae: 0.0523\n",
      "Epoch 622/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0949\n",
      "Learning rate after epoch 621 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0526 - val_loss: 0.0054 - val_mae: 0.0641\n",
      "Epoch 623/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0784\n",
      "Learning rate after epoch 622 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 8.6619e-04 - val_mae: 0.0256\n",
      "Epoch 624/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0432\n",
      "Learning rate after epoch 623 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0500 - val_loss: 8.4774e-04 - val_mae: 0.0231\n",
      "Epoch 625/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0303\n",
      "Learning rate after epoch 624 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0440 - val_loss: 0.0014 - val_mae: 0.0341\n",
      "Epoch 626/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0314\n",
      "Learning rate after epoch 625 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0545 - val_loss: 0.0015 - val_mae: 0.0346\n",
      "Epoch 627/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0269\n",
      "Learning rate after epoch 626 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0026 - val_mae: 0.0445\n",
      "Epoch 628/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0371\n",
      "Learning rate after epoch 627 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0501 - val_loss: 6.3188e-04 - val_mae: 0.0209\n",
      "Epoch 629/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0270\n",
      "Learning rate after epoch 628 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0011 - val_mae: 0.0300\n",
      "Epoch 630/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0328\n",
      "Learning rate after epoch 629 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 631/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0247\n",
      "Learning rate after epoch 630 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 9.1613e-04 - val_mae: 0.0265\n",
      "Epoch 632/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0599\n",
      "Learning rate after epoch 631 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0033 - val_mae: 0.0531\n",
      "Epoch 633/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0661\n",
      "Learning rate after epoch 632 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0452 - val_loss: 0.0026 - val_mae: 0.0457\n",
      "Epoch 634/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0340\n",
      "Learning rate after epoch 633 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0023 - val_mae: 0.0448\n",
      "Epoch 635/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0564\n",
      "Learning rate after epoch 634 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0022 - val_mae: 0.0435\n",
      "Epoch 636/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0400\n",
      "Learning rate after epoch 635 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0020 - val_mae: 0.0414\n",
      "Epoch 637/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0510\n",
      "Learning rate after epoch 636 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0539 - val_loss: 0.0023 - val_mae: 0.0337\n",
      "Epoch 638/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0383\n",
      "Learning rate after epoch 637 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0014 - val_mae: 0.0334\n",
      "Epoch 639/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0865\n",
      "Learning rate after epoch 638 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 7.6614e-04 - val_mae: 0.0250\n",
      "Epoch 640/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0825\n",
      "Learning rate after epoch 639 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 6.9206e-04 - val_mae: 0.0203\n",
      "Epoch 641/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0398\n",
      "Learning rate after epoch 640 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0446 - val_loss: 0.0021 - val_mae: 0.0387\n",
      "Epoch 642/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0289\n",
      "Learning rate after epoch 641 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0010 - val_mae: 0.0250\n",
      "Epoch 643/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0263\n",
      "Learning rate after epoch 642 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0019 - val_mae: 0.0301\n",
      "Epoch 644/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0333\n",
      "Learning rate after epoch 643 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0039 - val_mae: 0.0438\n",
      "Epoch 645/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0295\n",
      "Learning rate after epoch 644 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0057 - val_mae: 0.0616\n",
      "Epoch 646/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0363\n",
      "Learning rate after epoch 645 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 9.3236e-04 - val_mae: 0.0198\n",
      "Epoch 647/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0268\n",
      "Learning rate after epoch 646 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 7.4493e-04 - val_mae: 0.0239\n",
      "Epoch 648/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0521\n",
      "Learning rate after epoch 647 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0027 - val_mae: 0.0353\n",
      "Epoch 649/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0251\n",
      "Learning rate after epoch 648 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0022 - val_mae: 0.0435\n",
      "Epoch 650/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0707\n",
      "Learning rate after epoch 649 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0012 - val_mae: 0.0311\n",
      "Epoch 651/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0276\n",
      "Learning rate after epoch 650 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0448 - val_loss: 7.8527e-04 - val_mae: 0.0243\n",
      "Epoch 652/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0283\n",
      "Learning rate after epoch 651 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0490 - val_loss: 9.4586e-04 - val_mae: 0.0252\n",
      "Epoch 653/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0430\n",
      "Learning rate after epoch 652 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0031 - val_mae: 0.0475\n",
      "Epoch 654/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0533\n",
      "Learning rate after epoch 653 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0473 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 655/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0330\n",
      "Learning rate after epoch 654 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0044 - val_mae: 0.0535\n",
      "Epoch 656/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0308\n",
      "Learning rate after epoch 655 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0499 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 657/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0485\n",
      "Learning rate after epoch 656 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0524 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 658/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0456\n",
      "Learning rate after epoch 657 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 3.3669e-04 - val_mae: 0.0135\n",
      "Epoch 659/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0403\n",
      "Learning rate after epoch 658 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0458 - val_loss: 0.0016 - val_mae: 0.0371\n",
      "Epoch 660/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0496\n",
      "Learning rate after epoch 659 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 661/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0244\n",
      "Learning rate after epoch 660 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0031 - val_mae: 0.0421\n",
      "Epoch 662/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0267\n",
      "Learning rate after epoch 661 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0405 - val_loss: 0.0065 - val_mae: 0.0583\n",
      "Epoch 663/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0251\n",
      "Learning rate after epoch 662 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 7.4008e-04 - val_mae: 0.0218\n",
      "Epoch 664/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0272\n",
      "Learning rate after epoch 663 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0510 - val_loss: 0.0023 - val_mae: 0.0446\n",
      "Epoch 665/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0341\n",
      "Learning rate after epoch 664 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 9.5985e-04 - val_mae: 0.0256\n",
      "Epoch 666/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0248\n",
      "Learning rate after epoch 665 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0028 - val_mae: 0.0402\n",
      "Epoch 667/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0127 - mae: 0.1051\n",
      "Learning rate after epoch 666 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0564 - val_loss: 0.0015 - val_mae: 0.0351\n",
      "Epoch 668/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0416\n",
      "Learning rate after epoch 667 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 2.5980e-04 - val_mae: 0.0105\n",
      "Epoch 669/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0409\n",
      "Learning rate after epoch 668 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0032 - val_mae: 0.0365\n",
      "Epoch 670/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0447\n",
      "Learning rate after epoch 669 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0555 - val_loss: 0.0016 - val_mae: 0.0337\n",
      "Epoch 671/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0316\n",
      "Learning rate after epoch 670 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0444 - val_loss: 0.0012 - val_mae: 0.0286\n",
      "Epoch 672/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0587\n",
      "Learning rate after epoch 671 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0525 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 673/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0283\n",
      "Learning rate after epoch 672 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0034 - val_mae: 0.0412\n",
      "Epoch 674/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.7768e-04 - mae: 0.0238\n",
      "Learning rate after epoch 673 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0504 - val_loss: 0.0021 - val_mae: 0.0361\n",
      "Epoch 675/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0559\n",
      "Learning rate after epoch 674 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 7.1905e-04 - val_mae: 0.0212\n",
      "Epoch 676/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0379\n",
      "Learning rate after epoch 675 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0014 - val_mae: 0.0240\n",
      "Epoch 677/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0318\n",
      "Learning rate after epoch 676 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0016 - val_mae: 0.0274\n",
      "Epoch 678/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0211 - mae: 0.1390\n",
      "Learning rate after epoch 677 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0293\n",
      "Epoch 679/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0377\n",
      "Learning rate after epoch 678 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0464 - val_loss: 0.0050 - val_mae: 0.0592\n",
      "Epoch 680/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0428\n",
      "Learning rate after epoch 679 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0035 - val_mae: 0.0417\n",
      "Epoch 681/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0527\n",
      "Learning rate after epoch 680 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0022 - val_mae: 0.0448\n",
      "Epoch 682/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0511\n",
      "Learning rate after epoch 681 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 683/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0761\n",
      "Learning rate after epoch 682 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0036 - val_mae: 0.0566\n",
      "Epoch 684/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0814\n",
      "Learning rate after epoch 683 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0054 - val_mae: 0.0724\n",
      "Epoch 685/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0792\n",
      "Learning rate after epoch 684 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.0023 - val_mae: 0.0430\n",
      "Epoch 686/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0488\n",
      "Learning rate after epoch 685 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0394 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 687/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0504\n",
      "Learning rate after epoch 686 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0525 - val_loss: 0.0024 - val_mae: 0.0418\n",
      "Epoch 688/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0391\n",
      "Learning rate after epoch 687 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0013 - val_mae: 0.0303\n",
      "Epoch 689/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0595\n",
      "Learning rate after epoch 688 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 690/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0541\n",
      "Learning rate after epoch 689 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0408\n",
      "Epoch 691/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0495\n",
      "Learning rate after epoch 690 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0513 - val_loss: 0.0041 - val_mae: 0.0536\n",
      "Epoch 692/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0435\n",
      "Learning rate after epoch 691 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0035 - val_mae: 0.0565\n",
      "Epoch 693/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0493\n",
      "Learning rate after epoch 692 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0051 - val_mae: 0.0514\n",
      "Epoch 694/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0256\n",
      "Learning rate after epoch 693 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0536 - val_loss: 0.0015 - val_mae: 0.0347\n",
      "Epoch 695/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0353\n",
      "Learning rate after epoch 694 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0532 - val_loss: 0.0035 - val_mae: 0.0420\n",
      "Epoch 696/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0277\n",
      "Learning rate after epoch 695 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 3.8677e-04 - val_mae: 0.0139\n",
      "Epoch 697/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0207\n",
      "Learning rate after epoch 696 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0570 - val_loss: 0.0013 - val_mae: 0.0242\n",
      "Epoch 698/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0665\n",
      "Learning rate after epoch 697 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0464 - val_loss: 8.7730e-04 - val_mae: 0.0221\n",
      "Epoch 699/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0580\n",
      "Learning rate after epoch 698 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0010 - val_mae: 0.0283\n",
      "Epoch 700/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0419\n",
      "Learning rate after epoch 699 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0489 - val_loss: 7.9452e-04 - val_mae: 0.0246\n",
      "Epoch 701/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.3742e-04 - mae: 0.0197\n",
      "Learning rate after epoch 700 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0011 - val_mae: 0.0291\n",
      "Epoch 702/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0381\n",
      "Learning rate after epoch 701 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 703/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.1125e-04 - mae: 0.0211\n",
      "Learning rate after epoch 702 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0468 - val_loss: 4.3130e-04 - val_mae: 0.0154\n",
      "Epoch 704/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2560e-04 - mae: 0.0243\n",
      "Learning rate after epoch 703 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0516 - val_loss: 0.0018 - val_mae: 0.0290\n",
      "Epoch 705/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0467\n",
      "Learning rate after epoch 704 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0025 - val_mae: 0.0327\n",
      "Epoch 706/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0576\n",
      "Learning rate after epoch 705 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 2.6677e-04 - val_mae: 0.0101\n",
      "Epoch 707/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0349\n",
      "Learning rate after epoch 706 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0033 - val_mae: 0.0540\n",
      "Epoch 708/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0275\n",
      "Learning rate after epoch 707 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0306\n",
      "Epoch 709/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0308\n",
      "Learning rate after epoch 708 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0544 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 710/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0625\n",
      "Learning rate after epoch 709 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0473 - val_loss: 0.0061 - val_mae: 0.0548\n",
      "Epoch 711/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0705\n",
      "Learning rate after epoch 710 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0517 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 712/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0838\n",
      "Learning rate after epoch 711 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0014 - val_mae: 0.0322\n",
      "Epoch 713/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0741\n",
      "Learning rate after epoch 712 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0256\n",
      "Epoch 714/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0249\n",
      "Learning rate after epoch 713 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 0.0020 - val_mae: 0.0402\n",
      "Epoch 715/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0403\n",
      "Learning rate after epoch 714 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0016 - val_mae: 0.0371\n",
      "Epoch 716/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0305\n",
      "Learning rate after epoch 715 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0576 - val_loss: 8.4491e-04 - val_mae: 0.0238\n",
      "Epoch 717/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0292\n",
      "Learning rate after epoch 716 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0030 - val_mae: 0.0518\n",
      "Epoch 718/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0396\n",
      "Learning rate after epoch 717 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0557 - val_loss: 0.0012 - val_mae: 0.0311\n",
      "Epoch 719/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0443\n",
      "Learning rate after epoch 718 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0019 - val_mae: 0.0408\n",
      "Epoch 720/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0504\n",
      "Learning rate after epoch 719 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0017 - val_mae: 0.0381\n",
      "Epoch 721/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0394\n",
      "Learning rate after epoch 720 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0305\n",
      "Epoch 722/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0275\n",
      "Learning rate after epoch 721 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0458 - val_loss: 0.0015 - val_mae: 0.0335\n",
      "Epoch 723/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0553\n",
      "Learning rate after epoch 722 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0434 - val_loss: 0.0021 - val_mae: 0.0427\n",
      "Epoch 724/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0653\n",
      "Learning rate after epoch 723 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0450 - val_loss: 0.0026 - val_mae: 0.0473\n",
      "Epoch 725/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0536\n",
      "Learning rate after epoch 724 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0504 - val_loss: 0.0027 - val_mae: 0.0444\n",
      "Epoch 726/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0245\n",
      "Learning rate after epoch 725 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0404 - val_loss: 0.0028 - val_mae: 0.0497\n",
      "Epoch 727/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0737\n",
      "Learning rate after epoch 726 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 728/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0335\n",
      "Learning rate after epoch 727 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0462 - val_loss: 0.0033 - val_mae: 0.0467\n",
      "Epoch 729/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0728\n",
      "Learning rate after epoch 728 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0454 - val_loss: 0.0010 - val_mae: 0.0260\n",
      "Epoch 730/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0364\n",
      "Learning rate after epoch 729 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0018 - val_mae: 0.0402\n",
      "Epoch 731/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0273\n",
      "Learning rate after epoch 730 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0467 - val_loss: 5.7157e-04 - val_mae: 0.0166\n",
      "Epoch 732/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0922\n",
      "Learning rate after epoch 731 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0540 - val_loss: 0.0025 - val_mae: 0.0368\n",
      "Epoch 733/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0297\n",
      "Learning rate after epoch 732 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0545 - val_loss: 4.3076e-04 - val_mae: 0.0162\n",
      "Epoch 734/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0578\n",
      "Learning rate after epoch 733 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0023 - val_mae: 0.0454\n",
      "Epoch 735/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0453\n",
      "Learning rate after epoch 734 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0443 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 736/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0392\n",
      "Learning rate after epoch 735 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0019 - val_mae: 0.0394\n",
      "Epoch 737/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0383\n",
      "Learning rate after epoch 736 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0503 - val_loss: 0.0052 - val_mae: 0.0687\n",
      "Epoch 738/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0274\n",
      "Learning rate after epoch 737 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0021 - val_mae: 0.0434\n",
      "Epoch 739/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2588e-04 - mae: 0.0232\n",
      "Learning rate after epoch 738 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 740/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4054e-04 - mae: 0.0253\n",
      "Learning rate after epoch 739 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0309\n",
      "Epoch 741/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0728\n",
      "Learning rate after epoch 740 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 5.4987e-04 - val_mae: 0.0186\n",
      "Epoch 742/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0277\n",
      "Learning rate after epoch 741 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0023 - val_mae: 0.0434\n",
      "Epoch 743/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0324\n",
      "Learning rate after epoch 742 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0025 - val_mae: 0.0452\n",
      "Epoch 744/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0340\n",
      "Learning rate after epoch 743 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0525 - val_loss: 0.0055 - val_mae: 0.0509\n",
      "Epoch 745/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0519\n",
      "Learning rate after epoch 744 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0046 - val_mae: 0.0435\n",
      "Epoch 746/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0421\n",
      "Learning rate after epoch 745 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0012 - val_mae: 0.0305\n",
      "Epoch 747/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0316\n",
      "Learning rate after epoch 746 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0021 - val_mae: 0.0329\n",
      "Epoch 748/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6860e-04 - mae: 0.0211\n",
      "Learning rate after epoch 747 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0540 - val_loss: 0.0015 - val_mae: 0.0283\n",
      "Epoch 749/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0403\n",
      "Learning rate after epoch 748 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0017 - val_mae: 0.0366\n",
      "Epoch 750/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.4508e-04 - mae: 0.0191\n",
      "Learning rate after epoch 749 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 9.1473e-04 - val_mae: 0.0269\n",
      "Epoch 751/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0275\n",
      "Learning rate after epoch 750 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0445 - val_loss: 0.0020 - val_mae: 0.0408\n",
      "Epoch 752/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0308\n",
      "Learning rate after epoch 751 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.0020 - val_mae: 0.0421\n",
      "Epoch 753/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0563\n",
      "Learning rate after epoch 752 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0465 - val_loss: 0.0031 - val_mae: 0.0471\n",
      "Epoch 754/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0538\n",
      "Learning rate after epoch 753 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0038 - val_mae: 0.0541\n",
      "Epoch 755/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0422\n",
      "Learning rate after epoch 754 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0515 - val_loss: 0.0024 - val_mae: 0.0442\n",
      "Epoch 756/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0404\n",
      "Learning rate after epoch 755 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 7.2004e-04 - val_mae: 0.0214\n",
      "Epoch 757/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0654\n",
      "Learning rate after epoch 756 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0017 - val_mae: 0.0350\n",
      "Epoch 758/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0387\n",
      "Learning rate after epoch 757 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0568 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 759/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0695\n",
      "Learning rate after epoch 758 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 0.0034 - val_mae: 0.0522\n",
      "Epoch 760/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0419\n",
      "Learning rate after epoch 759 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0326\n",
      "Epoch 761/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0487\n",
      "Learning rate after epoch 760 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 762/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0578\n",
      "Learning rate after epoch 761 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0420 - val_loss: 0.0012 - val_mae: 0.0298\n",
      "Epoch 763/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0230\n",
      "Learning rate after epoch 762 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0532 - val_loss: 9.9068e-04 - val_mae: 0.0290\n",
      "Epoch 764/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0572\n",
      "Learning rate after epoch 763 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0523 - val_loss: 6.8181e-04 - val_mae: 0.0210\n",
      "Epoch 765/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0360\n",
      "Learning rate after epoch 764 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0523 - val_loss: 0.0029 - val_mae: 0.0436\n",
      "Epoch 766/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0388\n",
      "Learning rate after epoch 765 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0020 - val_mae: 0.0363\n",
      "Epoch 767/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0356\n",
      "Learning rate after epoch 766 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0531 - val_loss: 0.0013 - val_mae: 0.0293\n",
      "Epoch 768/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0601\n",
      "Learning rate after epoch 767 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0033 - val_mae: 0.0443\n",
      "Epoch 769/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0801\n",
      "Learning rate after epoch 768 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0651 - val_loss: 0.0023 - val_mae: 0.0309\n",
      "Epoch 770/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Learning rate after epoch 769 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0028 - val_mae: 0.0417\n",
      "Epoch 771/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0531\n",
      "Learning rate after epoch 770 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0492 - val_loss: 0.0010 - val_mae: 0.0291\n",
      "Epoch 772/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0344\n",
      "Learning rate after epoch 771 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0045 - val_mae: 0.0484\n",
      "Epoch 773/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0935\n",
      "Learning rate after epoch 772 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0012 - val_mae: 0.0304\n",
      "Epoch 774/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0389\n",
      "Learning rate after epoch 773 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 775/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0301\n",
      "Learning rate after epoch 774 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 776/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0261\n",
      "Learning rate after epoch 775 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 0.0015 - val_mae: 0.0367\n",
      "Epoch 777/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0241\n",
      "Learning rate after epoch 776 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 778/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0494\n",
      "Learning rate after epoch 777 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 6.1332e-04 - val_mae: 0.0213\n",
      "Epoch 779/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0386\n",
      "Learning rate after epoch 778 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0573 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 780/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.3531e-04 - mae: 0.0229\n",
      "Learning rate after epoch 779 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0476 - val_loss: 9.0933e-04 - val_mae: 0.0226\n",
      "Epoch 781/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0675\n",
      "Learning rate after epoch 780 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0609 - val_loss: 6.4197e-04 - val_mae: 0.0202\n",
      "Epoch 782/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0419\n",
      "Learning rate after epoch 781 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0458 - val_loss: 9.4473e-04 - val_mae: 0.0245\n",
      "Epoch 783/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0341\n",
      "Learning rate after epoch 782 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0012 - val_mae: 0.0303\n",
      "Epoch 784/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0291\n",
      "Learning rate after epoch 783 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0491 - val_loss: 4.8018e-04 - val_mae: 0.0156\n",
      "Epoch 785/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0897\n",
      "Learning rate after epoch 784 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0582 - val_loss: 0.0019 - val_mae: 0.0288\n",
      "Epoch 786/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0574\n",
      "Learning rate after epoch 785 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0468 - val_loss: 0.0034 - val_mae: 0.0504\n",
      "Epoch 787/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0528\n",
      "Learning rate after epoch 786 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 7.6709e-04 - val_mae: 0.0244\n",
      "Epoch 788/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0552\n",
      "Learning rate after epoch 787 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 8.6175e-04 - val_mae: 0.0245\n",
      "Epoch 789/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0368\n",
      "Learning rate after epoch 788 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0452 - val_loss: 0.0033 - val_mae: 0.0410\n",
      "Epoch 790/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0342\n",
      "Learning rate after epoch 789 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0506 - val_loss: 9.9333e-04 - val_mae: 0.0225\n",
      "Epoch 791/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0650\n",
      "Learning rate after epoch 790 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0015 - val_mae: 0.0363\n",
      "Epoch 792/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0654\n",
      "Learning rate after epoch 791 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 793/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0338\n",
      "Learning rate after epoch 792 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0039 - val_mae: 0.0409\n",
      "Epoch 794/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0284\n",
      "Learning rate after epoch 793 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0518 - val_loss: 6.4734e-04 - val_mae: 0.0197\n",
      "Epoch 795/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0544\n",
      "Learning rate after epoch 794 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 8.8428e-04 - val_mae: 0.0251\n",
      "Epoch 796/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0295\n",
      "Learning rate after epoch 795 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0025 - val_mae: 0.0327\n",
      "Epoch 797/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0412\n",
      "Learning rate after epoch 796 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0021 - val_mae: 0.0398\n",
      "Epoch 798/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0346\n",
      "Learning rate after epoch 797 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0499 - val_loss: 0.0032 - val_mae: 0.0414\n",
      "Epoch 799/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0389\n",
      "Learning rate after epoch 798 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0460 - val_loss: 4.1482e-04 - val_mae: 0.0135\n",
      "Epoch 800/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0225\n",
      "Learning rate after epoch 799 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0447 - val_loss: 0.0017 - val_mae: 0.0349\n",
      "Epoch 801/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0574\n",
      "Learning rate after epoch 800 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0494 - val_loss: 0.0029 - val_mae: 0.0494\n",
      "Epoch 802/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0391\n",
      "Learning rate after epoch 801 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 0.0045 - val_mae: 0.0630\n",
      "Epoch 803/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0661\n",
      "Learning rate after epoch 802 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0549 - val_loss: 6.0665e-04 - val_mae: 0.0197\n",
      "Epoch 804/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0448\n",
      "Learning rate after epoch 803 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0023 - val_mae: 0.0440\n",
      "Epoch 805/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0293\n",
      "Learning rate after epoch 804 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0016 - val_mae: 0.0351\n",
      "Epoch 806/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0511\n",
      "Learning rate after epoch 805 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 5.9425e-04 - val_mae: 0.0175\n",
      "Epoch 807/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0614\n",
      "Learning rate after epoch 806 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 808/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0337\n",
      "Learning rate after epoch 807 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0033 - val_mae: 0.0548\n",
      "Epoch 809/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0322\n",
      "Learning rate after epoch 808 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0025 - val_mae: 0.0350\n",
      "Epoch 810/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0595\n",
      "Learning rate after epoch 809 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0015 - val_mae: 0.0364\n",
      "Epoch 811/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0423\n",
      "Learning rate after epoch 810 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 9.1360e-04 - val_mae: 0.0203\n",
      "Epoch 812/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0325\n",
      "Learning rate after epoch 811 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0034 - val_mae: 0.0512\n",
      "Epoch 813/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0237\n",
      "Learning rate after epoch 812 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0047 - val_mae: 0.0657\n",
      "Epoch 814/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0334\n",
      "Learning rate after epoch 813 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0559 - val_loss: 0.0043 - val_mae: 0.0547\n",
      "Epoch 815/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0267\n",
      "Learning rate after epoch 814 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0011 - val_mae: 0.0274\n",
      "Epoch 816/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0317\n",
      "Learning rate after epoch 815 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0019 - val_mae: 0.0283\n",
      "Epoch 817/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0394\n",
      "Learning rate after epoch 816 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 4.7415e-04 - val_mae: 0.0186\n",
      "Epoch 818/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0355\n",
      "Learning rate after epoch 817 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0529 - val_loss: 0.0028 - val_mae: 0.0452\n",
      "Epoch 819/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0621\n",
      "Learning rate after epoch 818 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0559 - val_loss: 3.5998e-04 - val_mae: 0.0145\n",
      "Epoch 820/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0818\n",
      "Learning rate after epoch 819 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0404 - val_loss: 0.0020 - val_mae: 0.0422\n",
      "Epoch 821/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0471\n",
      "Learning rate after epoch 820 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0430 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 822/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0307\n",
      "Learning rate after epoch 821 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0046 - val_mae: 0.0577\n",
      "Epoch 823/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0359\n",
      "Learning rate after epoch 822 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0504 - val_loss: 0.0014 - val_mae: 0.0328\n",
      "Epoch 824/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0329\n",
      "Learning rate after epoch 823 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0305\n",
      "Epoch 825/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0316\n",
      "Learning rate after epoch 824 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0020 - val_mae: 0.0337\n",
      "Epoch 826/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0336\n",
      "Learning rate after epoch 825 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 9.0552e-04 - val_mae: 0.0224\n",
      "Epoch 827/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0274\n",
      "Learning rate after epoch 826 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0035 - val_mae: 0.0490\n",
      "Epoch 828/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0356\n",
      "Learning rate after epoch 827 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0469 - val_loss: 0.0021 - val_mae: 0.0387\n",
      "Epoch 829/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0639\n",
      "Learning rate after epoch 828 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0474 - val_loss: 0.0024 - val_mae: 0.0431\n",
      "Epoch 830/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0315\n",
      "Learning rate after epoch 829 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0027 - val_mae: 0.0492\n",
      "Epoch 831/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0785\n",
      "Learning rate after epoch 830 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0569 - val_loss: 0.0013 - val_mae: 0.0287\n",
      "Epoch 832/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0473\n",
      "Learning rate after epoch 831 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0040 - val_mae: 0.0475\n",
      "Epoch 833/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8024e-04 - mae: 0.0199\n",
      "Learning rate after epoch 832 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0382 - val_loss: 3.4353e-04 - val_mae: 0.0137\n",
      "Epoch 834/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.0000e-04 - mae: 0.0218\n",
      "Learning rate after epoch 833 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 8.6909e-04 - val_mae: 0.0222\n",
      "Epoch 835/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0381\n",
      "Learning rate after epoch 834 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0014 - val_mae: 0.0333\n",
      "Epoch 836/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0637\n",
      "Learning rate after epoch 835 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0538 - val_loss: 0.0016 - val_mae: 0.0270\n",
      "Epoch 837/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0650\n",
      "Learning rate after epoch 836 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0028 - val_mae: 0.0442\n",
      "Epoch 838/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0605\n",
      "Learning rate after epoch 837 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0491 - val_loss: 7.0866e-04 - val_mae: 0.0210\n",
      "Epoch 839/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0426\n",
      "Learning rate after epoch 838 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0016 - val_mae: 0.0375\n",
      "Epoch 840/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0312\n",
      "Learning rate after epoch 839 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0450 - val_loss: 0.0023 - val_mae: 0.0426\n",
      "Epoch 841/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0264\n",
      "Learning rate after epoch 840 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0011 - val_mae: 0.0303\n",
      "Epoch 842/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0485\n",
      "Learning rate after epoch 841 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0033 - val_mae: 0.0501\n",
      "Epoch 843/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0417\n",
      "Learning rate after epoch 842 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0615 - val_loss: 4.0951e-04 - val_mae: 0.0157\n",
      "Epoch 844/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0284\n",
      "Learning rate after epoch 843 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 845/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0293\n",
      "Learning rate after epoch 844 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0055 - val_mae: 0.0509\n",
      "Epoch 846/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0556\n",
      "Learning rate after epoch 845 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0475 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 847/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0267\n",
      "Learning rate after epoch 846 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0561 - val_loss: 0.0019 - val_mae: 0.0381\n",
      "Epoch 848/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.7558e-04 - mae: 0.0211\n",
      "Learning rate after epoch 847 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0515 - val_loss: 0.0054 - val_mae: 0.0615\n",
      "Epoch 849/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0913\n",
      "Learning rate after epoch 848 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0047 - val_mae: 0.0658\n",
      "Epoch 850/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0298\n",
      "Learning rate after epoch 849 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 7.8090e-04 - val_mae: 0.0255\n",
      "Epoch 851/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0167 - mae: 0.1212\n",
      "Learning rate after epoch 850 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0534 - val_loss: 0.0028 - val_mae: 0.0451\n",
      "Epoch 852/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0401\n",
      "Learning rate after epoch 851 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0531 - val_loss: 0.0025 - val_mae: 0.0401\n",
      "Epoch 853/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0651\n",
      "Learning rate after epoch 852 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0451 - val_loss: 0.0031 - val_mae: 0.0470\n",
      "Epoch 854/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0729\n",
      "Learning rate after epoch 853 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0447 - val_loss: 7.0168e-04 - val_mae: 0.0178\n",
      "Epoch 855/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0468\n",
      "Learning rate after epoch 854 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0488 - val_loss: 0.0035 - val_mae: 0.0400\n",
      "Epoch 856/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0490\n",
      "Learning rate after epoch 855 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 6.9681e-04 - val_mae: 0.0225\n",
      "Epoch 857/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0413\n",
      "Learning rate after epoch 856 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0018 - val_mae: 0.0388\n",
      "Epoch 858/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0460\n",
      "Learning rate after epoch 857 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0444 - val_loss: 0.0019 - val_mae: 0.0397\n",
      "Epoch 859/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0337\n",
      "Learning rate after epoch 858 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0046 - val_mae: 0.0556\n",
      "Epoch 860/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0294\n",
      "Learning rate after epoch 859 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 9.6644e-04 - val_mae: 0.0286\n",
      "Epoch 861/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0451\n",
      "Learning rate after epoch 860 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0495 - val_loss: 0.0021 - val_mae: 0.0383\n",
      "Epoch 862/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0288\n",
      "Learning rate after epoch 861 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0445 - val_loss: 0.0034 - val_mae: 0.0560\n",
      "Epoch 863/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0484\n",
      "Learning rate after epoch 862 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 2.5084e-04 - val_mae: 0.0108\n",
      "Epoch 864/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0471\n",
      "Learning rate after epoch 863 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0502 - val_loss: 0.0011 - val_mae: 0.0305\n",
      "Epoch 865/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0139 - mae: 0.1068\n",
      "Learning rate after epoch 864 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0034 - val_mae: 0.0406\n",
      "Epoch 866/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0360\n",
      "Learning rate after epoch 865 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 0.0027 - val_mae: 0.0423\n",
      "Epoch 867/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0302\n",
      "Learning rate after epoch 866 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0076 - val_mae: 0.0585\n",
      "Epoch 868/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0506\n",
      "Learning rate after epoch 867 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0517 - val_loss: 0.0026 - val_mae: 0.0447\n",
      "Epoch 869/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0261\n",
      "Learning rate after epoch 868 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0026 - val_mae: 0.0471\n",
      "Epoch 870/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.9449e-04 - mae: 0.0213\n",
      "Learning rate after epoch 869 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0514 - val_loss: 0.0076 - val_mae: 0.0600\n",
      "Epoch 871/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0542\n",
      "Learning rate after epoch 870 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0045 - val_mae: 0.0548\n",
      "Epoch 872/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0339\n",
      "Learning rate after epoch 871 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0014 - val_mae: 0.0324\n",
      "Epoch 873/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0343\n",
      "Learning rate after epoch 872 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 8.9807e-04 - val_mae: 0.0242\n",
      "Epoch 874/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0298\n",
      "Learning rate after epoch 873 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 7.7422e-04 - val_mae: 0.0243\n",
      "Epoch 875/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0474\n",
      "Learning rate after epoch 874 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 9.7151e-04 - val_mae: 0.0280\n",
      "Epoch 876/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5181e-04 - mae: 0.0239\n",
      "Learning rate after epoch 875 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0017 - val_mae: 0.0369\n",
      "Epoch 877/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0638\n",
      "Learning rate after epoch 876 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0454 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 878/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0370\n",
      "Learning rate after epoch 877 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0519 - val_loss: 8.9975e-04 - val_mae: 0.0273\n",
      "Epoch 879/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0543\n",
      "Learning rate after epoch 878 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0468 - val_loss: 0.0011 - val_mae: 0.0300\n",
      "Epoch 880/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0395\n",
      "Learning rate after epoch 879 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 8.6895e-04 - val_mae: 0.0228\n",
      "Epoch 881/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0372\n",
      "Learning rate after epoch 880 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0402 - val_loss: 0.0031 - val_mae: 0.0414\n",
      "Epoch 882/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0288\n",
      "Learning rate after epoch 881 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 883/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5128e-04 - mae: 0.0232\n",
      "Learning rate after epoch 882 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0453 - val_loss: 0.0039 - val_mae: 0.0417\n",
      "Epoch 884/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0428\n",
      "Learning rate after epoch 883 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 4.3345e-04 - val_mae: 0.0152\n",
      "Epoch 885/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0439\n",
      "Learning rate after epoch 884 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 0.0036 - val_mae: 0.0584\n",
      "Epoch 886/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0636\n",
      "Learning rate after epoch 885 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0454 - val_loss: 9.9062e-04 - val_mae: 0.0261\n",
      "Epoch 887/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0762\n",
      "Learning rate after epoch 886 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0025 - val_mae: 0.0464\n",
      "Epoch 888/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0587\n",
      "Learning rate after epoch 887 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0495 - val_loss: 0.0032 - val_mae: 0.0543\n",
      "Epoch 889/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7676e-04 - mae: 0.0213\n",
      "Learning rate after epoch 888 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0458 - val_loss: 8.6661e-04 - val_mae: 0.0222\n",
      "Epoch 890/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0833\n",
      "Learning rate after epoch 889 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0538 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 891/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0292\n",
      "Learning rate after epoch 890 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0533 - val_loss: 0.0039 - val_mae: 0.0511\n",
      "Epoch 892/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0391\n",
      "Learning rate after epoch 891 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0479 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 893/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.0281e-04 - mae: 0.0180\n",
      "Learning rate after epoch 892 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0018 - val_mae: 0.0351\n",
      "Epoch 894/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0318\n",
      "Learning rate after epoch 893 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 3.6017e-04 - val_mae: 0.0123\n",
      "Epoch 895/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0252\n",
      "Learning rate after epoch 894 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0412 - val_loss: 8.1286e-04 - val_mae: 0.0206\n",
      "Epoch 896/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0365\n",
      "Learning rate after epoch 895 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0482 - val_loss: 0.0032 - val_mae: 0.0369\n",
      "Epoch 897/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0458\n",
      "Learning rate after epoch 896 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0595 - val_loss: 0.0046 - val_mae: 0.0452\n",
      "Epoch 898/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0270\n",
      "Learning rate after epoch 897 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0526 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 899/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0332\n",
      "Learning rate after epoch 898 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 900/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0683\n",
      "Learning rate after epoch 899 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0064 - val_mae: 0.0524\n",
      "Epoch 901/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.7624e-04 - mae: 0.0198\n",
      "Learning rate after epoch 900 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0016 - val_mae: 0.0383\n",
      "Epoch 902/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0260\n",
      "Learning rate after epoch 901 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0516 - val_loss: 9.3043e-04 - val_mae: 0.0237\n",
      "Epoch 903/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0843\n",
      "Learning rate after epoch 902 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0591 - val_loss: 0.0045 - val_mae: 0.0433\n",
      "Epoch 904/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0538\n",
      "Learning rate after epoch 903 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0015 - val_mae: 0.0367\n",
      "Epoch 905/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0341\n",
      "Learning rate after epoch 904 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0037 - val_mae: 0.0419\n",
      "Epoch 906/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0354\n",
      "Learning rate after epoch 905 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0052 - val_mae: 0.0657\n",
      "Epoch 907/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0350\n",
      "Learning rate after epoch 906 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0022 - val_mae: 0.0441\n",
      "Epoch 908/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0518\n",
      "Learning rate after epoch 907 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0427 - val_loss: 0.0021 - val_mae: 0.0436\n",
      "Epoch 909/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0374\n",
      "Learning rate after epoch 908 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 5.3830e-04 - val_mae: 0.0187\n",
      "Epoch 910/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0339\n",
      "Learning rate after epoch 909 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0547 - val_loss: 0.0023 - val_mae: 0.0422\n",
      "Epoch 911/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0419\n",
      "Learning rate after epoch 910 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0505 - val_loss: 5.7613e-04 - val_mae: 0.0202\n",
      "Epoch 912/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0447\n",
      "Learning rate after epoch 911 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0486 - val_loss: 0.0011 - val_mae: 0.0281\n",
      "Epoch 913/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0144 - mae: 0.1117\n",
      "Learning rate after epoch 912 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0601 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 914/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0733\n",
      "Learning rate after epoch 913 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0533 - val_loss: 0.0012 - val_mae: 0.0295\n",
      "Epoch 915/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.0742e-04 - mae: 0.0192\n",
      "Learning rate after epoch 914 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0014 - val_mae: 0.0252\n",
      "Epoch 916/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0282\n",
      "Learning rate after epoch 915 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0052 - val_mae: 0.0510\n",
      "Epoch 917/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0506\n",
      "Learning rate after epoch 916 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0030 - val_mae: 0.0456\n",
      "Epoch 918/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0807\n",
      "Learning rate after epoch 917 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0620 - val_loss: 0.0024 - val_mae: 0.0428\n",
      "Epoch 919/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0460\n",
      "Learning rate after epoch 918 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 9.8620e-04 - val_mae: 0.0276\n",
      "Epoch 920/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0635\n",
      "Learning rate after epoch 919 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0458 - val_loss: 0.0022 - val_mae: 0.0445\n",
      "Epoch 921/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0918\n",
      "Learning rate after epoch 920 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0519 - val_loss: 0.0061 - val_mae: 0.0605\n",
      "Epoch 922/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0329\n",
      "Learning rate after epoch 921 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 3.8460e-04 - val_mae: 0.0141\n",
      "Epoch 923/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0399\n",
      "Learning rate after epoch 922 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0375 - val_loss: 4.5968e-04 - val_mae: 0.0171\n",
      "Epoch 924/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0432\n",
      "Learning rate after epoch 923 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 9.3108e-04 - val_mae: 0.0276\n",
      "Epoch 925/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0362\n",
      "Learning rate after epoch 924 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0026 - val_mae: 0.0436\n",
      "Epoch 926/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0360\n",
      "Learning rate after epoch 925 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0021 - val_mae: 0.0426\n",
      "Epoch 927/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0577\n",
      "Learning rate after epoch 926 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 928/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0177 - mae: 0.1275\n",
      "Learning rate after epoch 927 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 0.0016 - val_mae: 0.0376\n",
      "Epoch 929/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0281\n",
      "Learning rate after epoch 928 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 5.2684e-04 - val_mae: 0.0169\n",
      "Epoch 930/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0286\n",
      "Learning rate after epoch 929 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0021 - val_mae: 0.0408\n",
      "Epoch 931/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0682\n",
      "Learning rate after epoch 930 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0515 - val_loss: 0.0019 - val_mae: 0.0397\n",
      "Epoch 932/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0359\n",
      "Learning rate after epoch 931 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0607 - val_loss: 0.0015 - val_mae: 0.0362\n",
      "Epoch 933/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0679\n",
      "Learning rate after epoch 932 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0484 - val_loss: 6.0649e-04 - val_mae: 0.0203\n",
      "Epoch 934/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0405\n",
      "Learning rate after epoch 933 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 935/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0426\n",
      "Learning rate after epoch 934 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 4.4116e-04 - val_mae: 0.0144\n",
      "Epoch 936/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0551\n",
      "Learning rate after epoch 935 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0011 - val_mae: 0.0289\n",
      "Epoch 937/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0300\n",
      "Learning rate after epoch 936 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0483 - val_loss: 0.0032 - val_mae: 0.0493\n",
      "Epoch 938/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0344\n",
      "Learning rate after epoch 937 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0498\n",
      "Epoch 939/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0425\n",
      "Learning rate after epoch 938 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0501 - val_loss: 2.1675e-04 - val_mae: 0.0091\n",
      "Epoch 940/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0559\n",
      "Learning rate after epoch 939 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0454 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 941/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.8610e-04 - mae: 0.0154\n",
      "Learning rate after epoch 940 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0028 - val_mae: 0.0338\n",
      "Epoch 942/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0586\n",
      "Learning rate after epoch 941 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0022 - val_mae: 0.0392\n",
      "Epoch 943/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0146 - mae: 0.1167\n",
      "Learning rate after epoch 942 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0518 - val_loss: 0.0020 - val_mae: 0.0299\n",
      "Epoch 944/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0411\n",
      "Learning rate after epoch 943 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0010 - val_mae: 0.0276\n",
      "Epoch 945/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0562\n",
      "Learning rate after epoch 944 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0018 - val_mae: 0.0394\n",
      "Epoch 946/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0257\n",
      "Learning rate after epoch 945 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 947/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0485\n",
      "Learning rate after epoch 946 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0010 - val_mae: 0.0296\n",
      "Epoch 948/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0440\n",
      "Learning rate after epoch 947 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0021 - val_mae: 0.0434\n",
      "Epoch 949/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0686\n",
      "Learning rate after epoch 948 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0479 - val_loss: 0.0044 - val_mae: 0.0497\n",
      "Epoch 950/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0294\n",
      "Learning rate after epoch 949 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0495 - val_loss: 5.8166e-04 - val_mae: 0.0197\n",
      "Epoch 951/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0596\n",
      "Learning rate after epoch 950 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0578 - val_loss: 0.0030 - val_mae: 0.0506\n",
      "Epoch 952/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0494\n",
      "Learning rate after epoch 951 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0440 - val_loss: 7.0401e-04 - val_mae: 0.0226\n",
      "Epoch 953/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0243\n",
      "Learning rate after epoch 952 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 4.7615e-04 - val_mae: 0.0175\n",
      "Epoch 954/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0301\n",
      "Learning rate after epoch 953 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0020 - val_mae: 0.0401\n",
      "Epoch 955/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0471\n",
      "Learning rate after epoch 954 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0427 - val_loss: 0.0025 - val_mae: 0.0472\n",
      "Epoch 956/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0354\n",
      "Learning rate after epoch 955 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "Epoch 957/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0150 - mae: 0.1109\n",
      "Learning rate after epoch 956 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0576 - val_loss: 7.3436e-04 - val_mae: 0.0218\n",
      "Epoch 958/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0535\n",
      "Learning rate after epoch 957 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0032 - val_mae: 0.0477\n",
      "Epoch 959/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0341\n",
      "Learning rate after epoch 958 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0012 - val_mae: 0.0302\n",
      "Epoch 960/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0533\n",
      "Learning rate after epoch 959 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0047 - val_mae: 0.0450\n",
      "Epoch 961/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0340\n",
      "Learning rate after epoch 960 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0042 - val_mae: 0.0418\n",
      "Epoch 962/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0697\n",
      "Learning rate after epoch 961 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 963/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0364\n",
      "Learning rate after epoch 962 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 964/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Learning rate after epoch 963 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0011 - val_mae: 0.0311\n",
      "Epoch 965/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0401\n",
      "Learning rate after epoch 964 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0454 - val_loss: 0.0031 - val_mae: 0.0488\n",
      "Epoch 966/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0661\n",
      "Learning rate after epoch 965 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0056 - val_mae: 0.0642\n",
      "Epoch 967/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0157 - mae: 0.1182\n",
      "Learning rate after epoch 966 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0030 - val_mae: 0.0519\n",
      "Epoch 968/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0409\n",
      "Learning rate after epoch 967 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 6.2133e-04 - val_mae: 0.0204\n",
      "Epoch 969/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0322\n",
      "Learning rate after epoch 968 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0022 - val_mae: 0.0419\n",
      "Epoch 970/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0406\n",
      "Learning rate after epoch 969 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.0026 - val_mae: 0.0465\n",
      "Epoch 971/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0949\n",
      "Learning rate after epoch 970 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0026 - val_mae: 0.0482\n",
      "Epoch 972/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0490\n",
      "Learning rate after epoch 971 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0521 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 973/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0463\n",
      "Learning rate after epoch 972 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0028 - val_mae: 0.0344\n",
      "Epoch 974/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0262\n",
      "Learning rate after epoch 973 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0031 - val_mae: 0.0483\n",
      "Epoch 975/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0250\n",
      "Learning rate after epoch 974 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 8.0336e-04 - val_mae: 0.0253\n",
      "Epoch 976/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0376\n",
      "Learning rate after epoch 975 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0020 - val_mae: 0.0410\n",
      "Epoch 977/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0508\n",
      "Learning rate after epoch 976 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0040 - val_mae: 0.0429\n",
      "Epoch 978/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.6538e-04 - mae: 0.0239\n",
      "Learning rate after epoch 977 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0526 - val_loss: 0.0015 - val_mae: 0.0318\n",
      "Epoch 979/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0500\n",
      "Learning rate after epoch 978 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0569 - val_loss: 4.5695e-04 - val_mae: 0.0144\n",
      "Epoch 980/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0557\n",
      "Learning rate after epoch 979 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 3.5071e-04 - val_mae: 0.0120\n",
      "Epoch 981/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0305\n",
      "Learning rate after epoch 980 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0462 - val_loss: 8.8944e-04 - val_mae: 0.0257\n",
      "Epoch 982/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0676\n",
      "Learning rate after epoch 981 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0482 - val_loss: 0.0023 - val_mae: 0.0460\n",
      "Epoch 983/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0663\n",
      "Learning rate after epoch 982 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0516 - val_loss: 0.0017 - val_mae: 0.0396\n",
      "Epoch 984/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0686\n",
      "Learning rate after epoch 983 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0416 - val_loss: 8.3773e-04 - val_mae: 0.0231\n",
      "Epoch 985/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0374\n",
      "Learning rate after epoch 984 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 986/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0776\n",
      "Learning rate after epoch 985 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0010 - val_mae: 0.0291\n",
      "Epoch 987/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0684\n",
      "Learning rate after epoch 986 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 3.3471e-04 - val_mae: 0.0126\n",
      "Epoch 988/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0428\n",
      "Learning rate after epoch 987 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0028 - val_mae: 0.0435\n",
      "Epoch 989/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0254\n",
      "Learning rate after epoch 988 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0476 - val_loss: 0.0013 - val_mae: 0.0304\n",
      "Epoch 990/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0530\n",
      "Learning rate after epoch 989 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 991/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0395\n",
      "Learning rate after epoch 990 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0022 - val_mae: 0.0431\n",
      "Epoch 992/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0993\n",
      "Learning rate after epoch 991 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 6.3395e-04 - val_mae: 0.0202\n",
      "Epoch 993/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0138 - mae: 0.1046\n",
      "Learning rate after epoch 992 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 6.7185e-04 - val_mae: 0.0209\n",
      "Epoch 994/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0333\n",
      "Learning rate after epoch 993 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0541 - val_loss: 0.0012 - val_mae: 0.0306\n",
      "Epoch 995/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0680\n",
      "Learning rate after epoch 994 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0507 - val_loss: 0.0015 - val_mae: 0.0316\n",
      "Epoch 996/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0416\n",
      "Learning rate after epoch 995 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0455 - val_loss: 0.0022 - val_mae: 0.0309\n",
      "Epoch 997/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0429\n",
      "Learning rate after epoch 996 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0018 - val_mae: 0.0344\n",
      "Epoch 998/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0689\n",
      "Learning rate after epoch 997 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0471 - val_loss: 0.0017 - val_mae: 0.0271\n",
      "Epoch 999/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0265\n",
      "Learning rate after epoch 998 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0521 - val_loss: 0.0026 - val_mae: 0.0470\n",
      "Epoch 1000/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0656\n",
      "Learning rate after epoch 999 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0016 - val_mae: 0.0314\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add,Lambda,Flatten\n",
    "\n",
    "# Define the first parallel recurrent layer with return_sequences=True\n",
    "rnn_1 = SimpleRNN(units=11)(input_1)\n",
    "dropout1 = Dropout(rate=0.1)(rnn_1)\n",
    "\n",
    "# Define the second parallel recurrent layer\n",
    "rnn_2 = SimpleRNN(units=11)(input_2)\n",
    "dropout2 = Dropout(rate=0.1)(rnn_2)\n",
    "\n",
    "# Define the third parallel recurrent layer\n",
    "rnn_3 = SimpleRNN(units=11)(input_3)\n",
    "dropout3 = Dropout(rate=0.1)(rnn_3)\n",
    "\n",
    "# Define the fourth parallel recurrent layer\n",
    "rnn_4 = SimpleRNN(units=11)(input_4)\n",
    "dropout4 = Dropout(rate=0.1)(rnn_4)\n",
    "\n",
    "# Concatenate the outputs of the recurrent layers\n",
    "merged = concatenate([dropout1, dropout2, dropout3, dropout4], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the merged output\n",
    "flatten = Flatten()(merged)\n",
    "\n",
    "# ...\n",
    "activation_layer = Activation('tanh')(flatten)\n",
    "dense1 = Dense(units=50, activation='tanh', kernel_regularizer=regularizers.l2(0.0001))(activation_layer)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "# dense2 = Dense(units=25, activation='relu', kernel_regularizer=regularizers.l1(0.001))(dense1)\n",
    "# dense2 = BatchNormalization()(dense2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the output layer\n",
    "output = Dense(units=1, activation='sigmoid')(dense1)\n",
    "\n",
    "\n",
    "# Create the model with the inputs and output\n",
    "regressor = Model(inputs=[input_1, input_2,input_3, input_4], outputs=output)\n",
    "\n",
    "# Compile the model with the desired optimizer, loss function, and metrics\n",
    "regressor.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model with the training data\n",
    "result=regressor.fit([X_train1, X_train2,X_train3, X_train4], y_train, epochs=1000, batch_size=25,validation_data=([X_val1, X_val2,X_val3, X_val4], y_val),callbacks=[LearningRateLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "852f54fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 11)           143         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_1 (SimpleRNN)       (None, 11)           143         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_2 (SimpleRNN)       (None, 11)           143         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_3 (SimpleRNN)       (None, 11)           143         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 11)           0           ['simple_rnn[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 11)           0           ['simple_rnn_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 11)           0           ['simple_rnn_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 11)           0           ['simple_rnn_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 44)           0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 44)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 44)           0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           2250        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50)          200         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            51          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,073\n",
      "Trainable params: 2,973\n",
      "Non-trainable params: 100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e751d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 846us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data\n",
    "trainPredict = regressor.predict([X_train1, X_train2, X_train3, X_train4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bb6ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8d54155",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83618635],\n",
       "       [0.8353705 ],\n",
       "       [0.82564956],\n",
       "       [0.82474715],\n",
       "       [0.8233608 ],\n",
       "       [0.82210135],\n",
       "       [0.81929123],\n",
       "       [0.8164937 ],\n",
       "       [0.81544036],\n",
       "       [0.81418705],\n",
       "       [0.81793845],\n",
       "       [0.82040113],\n",
       "       [0.83194596],\n",
       "       [0.8358269 ],\n",
       "       [0.8389309 ],\n",
       "       [0.8414162 ],\n",
       "       [0.843505  ],\n",
       "       [0.84492   ],\n",
       "       [0.84587157],\n",
       "       [0.84715706],\n",
       "       [0.8428359 ],\n",
       "       [0.841416  ],\n",
       "       [0.8366117 ],\n",
       "       [0.83414704],\n",
       "       [0.83167696],\n",
       "       [0.8275349 ],\n",
       "       [0.82399315],\n",
       "       [0.82077944],\n",
       "       [0.81696564],\n",
       "       [0.81212753],\n",
       "       [0.80641687],\n",
       "       [0.79642713],\n",
       "       [0.79020834],\n",
       "       [0.7811092 ],\n",
       "       [0.7718161 ],\n",
       "       [0.7665398 ],\n",
       "       [0.7598859 ],\n",
       "       [0.75253475],\n",
       "       [0.74376494],\n",
       "       [0.74000657],\n",
       "       [0.74328476],\n",
       "       [0.74523336],\n",
       "       [0.745184  ],\n",
       "       [0.743986  ],\n",
       "       [0.74226123],\n",
       "       [0.7377545 ],\n",
       "       [0.73469985],\n",
       "       [0.7305297 ],\n",
       "       [0.7276045 ],\n",
       "       [0.71885985],\n",
       "       [0.70433885],\n",
       "       [0.69126946],\n",
       "       [0.6802992 ],\n",
       "       [0.66879934],\n",
       "       [0.65785575],\n",
       "       [0.6484677 ],\n",
       "       [0.6391739 ],\n",
       "       [0.62882966],\n",
       "       [0.61971676],\n",
       "       [0.6109128 ],\n",
       "       [0.6020536 ],\n",
       "       [0.59349155],\n",
       "       [0.5849558 ],\n",
       "       [0.5784521 ],\n",
       "       [0.5711404 ],\n",
       "       [0.5620738 ],\n",
       "       [0.55448556],\n",
       "       [0.5479355 ],\n",
       "       [0.5404666 ],\n",
       "       [0.5331022 ],\n",
       "       [0.528514  ],\n",
       "       [0.52285606],\n",
       "       [0.51628655],\n",
       "       [0.508485  ],\n",
       "       [0.5034153 ],\n",
       "       [0.49756795],\n",
       "       [0.49190333],\n",
       "       [0.48530725],\n",
       "       [0.47914362],\n",
       "       [0.47548637],\n",
       "       [0.46763203],\n",
       "       [0.46258226],\n",
       "       [0.46421972],\n",
       "       [0.46463567],\n",
       "       [0.46219844],\n",
       "       [0.46005118],\n",
       "       [0.4564368 ],\n",
       "       [0.45421705],\n",
       "       [0.45249143],\n",
       "       [0.45033416],\n",
       "       [0.4474089 ],\n",
       "       [0.44277835],\n",
       "       [0.4314354 ],\n",
       "       [0.4195966 ],\n",
       "       [0.40841633],\n",
       "       [0.40540293],\n",
       "       [0.40178618],\n",
       "       [0.3969416 ],\n",
       "       [0.39072496],\n",
       "       [0.38351226],\n",
       "       [0.37864682],\n",
       "       [0.37494832],\n",
       "       [0.3701213 ],\n",
       "       [0.37103269],\n",
       "       [0.36779344],\n",
       "       [0.35824004],\n",
       "       [0.3512758 ],\n",
       "       [0.34388584],\n",
       "       [0.33869302],\n",
       "       [0.33364376],\n",
       "       [0.3279285 ],\n",
       "       [0.32599485],\n",
       "       [0.3263153 ],\n",
       "       [0.31822985],\n",
       "       [0.31742838],\n",
       "       [0.31426683],\n",
       "       [0.31046706],\n",
       "       [0.3075882 ],\n",
       "       [0.3038999 ],\n",
       "       [0.30041805],\n",
       "       [0.29579803],\n",
       "       [0.28837526],\n",
       "       [0.28064117],\n",
       "       [0.27453634],\n",
       "       [0.2681641 ],\n",
       "       [0.26846597],\n",
       "       [0.2652158 ],\n",
       "       [0.26285478],\n",
       "       [0.26112455],\n",
       "       [0.25766328],\n",
       "       [0.25562426],\n",
       "       [0.2530567 ],\n",
       "       [0.2501898 ],\n",
       "       [0.24847761],\n",
       "       [0.24570918],\n",
       "       [0.23994263],\n",
       "       [0.23649041],\n",
       "       [0.23616813],\n",
       "       [0.22983848],\n",
       "       [0.22933581],\n",
       "       [0.2272508 ],\n",
       "       [0.2311618 ],\n",
       "       [0.2341022 ],\n",
       "       [0.23359692],\n",
       "       [0.23346084],\n",
       "       [0.2300368 ],\n",
       "       [0.22864784],\n",
       "       [0.2254125 ],\n",
       "       [0.2274562 ],\n",
       "       [0.22633417],\n",
       "       [0.2258001 ],\n",
       "       [0.22056425],\n",
       "       [0.21544081],\n",
       "       [0.21144311],\n",
       "       [0.20811468],\n",
       "       [0.20693766],\n",
       "       [0.20474987],\n",
       "       [0.20169187],\n",
       "       [0.20643769],\n",
       "       [0.26501048],\n",
       "       [0.34127885],\n",
       "       [0.42223728],\n",
       "       [0.48672402],\n",
       "       [0.53945506],\n",
       "       [0.5980138 ],\n",
       "       [0.6758796 ],\n",
       "       [0.77210325],\n",
       "       [0.86698955],\n",
       "       [0.93372995],\n",
       "       [0.9301298 ],\n",
       "       [0.9027244 ],\n",
       "       [0.89801264],\n",
       "       [0.8914783 ],\n",
       "       [0.8855408 ],\n",
       "       [0.8787142 ],\n",
       "       [0.87190694],\n",
       "       [0.8642451 ],\n",
       "       [0.8574752 ],\n",
       "       [0.8543955 ],\n",
       "       [0.8573153 ],\n",
       "       [0.889204  ],\n",
       "       [0.8911888 ],\n",
       "       [0.891637  ],\n",
       "       [0.8911554 ],\n",
       "       [0.8904317 ],\n",
       "       [0.8887172 ],\n",
       "       [0.8878396 ],\n",
       "       [0.8852786 ],\n",
       "       [0.8814249 ],\n",
       "       [0.868066  ],\n",
       "       [0.85516274],\n",
       "       [0.84930485],\n",
       "       [0.8425592 ],\n",
       "       [0.83475214],\n",
       "       [0.826229  ],\n",
       "       [0.8159748 ],\n",
       "       [0.8049505 ],\n",
       "       [0.79399693],\n",
       "       [0.78166956],\n",
       "       [0.76885486],\n",
       "       [0.7562104 ],\n",
       "       [0.7360931 ],\n",
       "       [0.7182496 ],\n",
       "       [0.7033393 ],\n",
       "       [0.6926984 ],\n",
       "       [0.6806455 ],\n",
       "       [0.66749346],\n",
       "       [0.65716517],\n",
       "       [0.66380113],\n",
       "       [0.66832453],\n",
       "       [0.6707539 ],\n",
       "       [0.6719106 ],\n",
       "       [0.67030203],\n",
       "       [0.66596067],\n",
       "       [0.65907717],\n",
       "       [0.65286756],\n",
       "       [0.64714104],\n",
       "       [0.639817  ],\n",
       "       [0.61757296],\n",
       "       [0.59986275],\n",
       "       [0.5831639 ],\n",
       "       [0.5667234 ],\n",
       "       [0.55405223],\n",
       "       [0.54230595],\n",
       "       [0.5274284 ],\n",
       "       [0.5168747 ],\n",
       "       [0.50865316],\n",
       "       [0.49632117],\n",
       "       [0.48607975],\n",
       "       [0.47081116],\n",
       "       [0.464042  ],\n",
       "       [0.4573785 ],\n",
       "       [0.4489928 ],\n",
       "       [0.4357293 ],\n",
       "       [0.4264076 ],\n",
       "       [0.41852838],\n",
       "       [0.40153885],\n",
       "       [0.39219403],\n",
       "       [0.38111734],\n",
       "       [0.37289438],\n",
       "       [0.35616353],\n",
       "       [0.3488636 ],\n",
       "       [0.34696624],\n",
       "       [0.3412064 ],\n",
       "       [0.33594373],\n",
       "       [0.32588133],\n",
       "       [0.3192793 ],\n",
       "       [0.31234112],\n",
       "       [0.3100288 ],\n",
       "       [0.31560966],\n",
       "       [0.32005918],\n",
       "       [0.31631604],\n",
       "       [0.30609334],\n",
       "       [0.30910674],\n",
       "       [0.31469908],\n",
       "       [0.31261167],\n",
       "       [0.32338217],\n",
       "       [0.3273604 ],\n",
       "       [0.31720436],\n",
       "       [0.30679736],\n",
       "       [0.29537058],\n",
       "       [0.28672877],\n",
       "       [0.2811767 ],\n",
       "       [0.27524045],\n",
       "       [0.2688955 ],\n",
       "       [0.26301277],\n",
       "       [0.25648478],\n",
       "       [0.2503849 ],\n",
       "       [0.25629053],\n",
       "       [0.25067958],\n",
       "       [0.25124928],\n",
       "       [0.25241196],\n",
       "       [0.24485578],\n",
       "       [0.23469934],\n",
       "       [0.22535746],\n",
       "       [0.21921977],\n",
       "       [0.2072562 ],\n",
       "       [0.20338142],\n",
       "       [0.19345163],\n",
       "       [0.19335638],\n",
       "       [0.19555794],\n",
       "       [0.18802327],\n",
       "       [0.18140338],\n",
       "       [0.18781403],\n",
       "       [0.1835095 ],\n",
       "       [0.19087909],\n",
       "       [0.18422519],\n",
       "       [0.17420286],\n",
       "       [0.16626643],\n",
       "       [0.15504542],\n",
       "       [0.13680032],\n",
       "       [0.12918477],\n",
       "       [0.1310724 ],\n",
       "       [0.11904181],\n",
       "       [0.11810295],\n",
       "       [0.11791664],\n",
       "       [0.11607482],\n",
       "       [0.11535911],\n",
       "       [0.11804754],\n",
       "       [0.12940097],\n",
       "       [0.13813706],\n",
       "       [0.13584326],\n",
       "       [0.12896866],\n",
       "       [0.124126  ],\n",
       "       [0.11362702],\n",
       "       [0.09504947],\n",
       "       [0.09055119],\n",
       "       [0.08627877],\n",
       "       [0.08261791],\n",
       "       [0.07367674],\n",
       "       [0.07581354],\n",
       "       [0.07819574],\n",
       "       [0.07462602],\n",
       "       [0.07369649],\n",
       "       [0.07341085],\n",
       "       [0.07208277],\n",
       "       [0.07290108],\n",
       "       [0.06790937],\n",
       "       [0.06512747],\n",
       "       [0.06695684],\n",
       "       [0.06196678],\n",
       "       [0.05626822],\n",
       "       [0.05184416],\n",
       "       [0.05393114],\n",
       "       [0.05602936],\n",
       "       [0.05886076],\n",
       "       [0.06174734],\n",
       "       [0.0889222 ],\n",
       "       [0.12737824],\n",
       "       [0.19890977],\n",
       "       [0.3048209 ],\n",
       "       [0.3981455 ],\n",
       "       [0.46454287],\n",
       "       [0.52613306],\n",
       "       [0.6109916 ],\n",
       "       [0.7330063 ],\n",
       "       [0.86229396],\n",
       "       [0.86367506],\n",
       "       [0.84323364],\n",
       "       [0.8419294 ],\n",
       "       [0.8419752 ],\n",
       "       [0.84088415],\n",
       "       [0.8397937 ],\n",
       "       [0.8379464 ],\n",
       "       [0.8376279 ],\n",
       "       [0.8356073 ],\n",
       "       [0.84045   ],\n",
       "       [0.8420914 ],\n",
       "       [0.8620793 ],\n",
       "       [0.8643678 ],\n",
       "       [0.8663087 ],\n",
       "       [0.8675046 ],\n",
       "       [0.8684279 ],\n",
       "       [0.8700133 ],\n",
       "       [0.8700261 ],\n",
       "       [0.8713201 ],\n",
       "       [0.8683414 ],\n",
       "       [0.8680261 ],\n",
       "       [0.8662199 ],\n",
       "       [0.8645192 ],\n",
       "       [0.8613276 ],\n",
       "       [0.85908914],\n",
       "       [0.85548615],\n",
       "       [0.851666  ],\n",
       "       [0.84907943],\n",
       "       [0.84541935],\n",
       "       [0.8404673 ],\n",
       "       [0.83381903],\n",
       "       [0.8298807 ],\n",
       "       [0.8242372 ],\n",
       "       [0.8197901 ],\n",
       "       [0.8166399 ],\n",
       "       [0.81244266],\n",
       "       [0.80795354],\n",
       "       [0.80217886],\n",
       "       [0.80057937],\n",
       "       [0.80060565],\n",
       "       [0.8009537 ],\n",
       "       [0.7995952 ],\n",
       "       [0.7969874 ],\n",
       "       [0.79393005],\n",
       "       [0.7894833 ],\n",
       "       [0.7870219 ],\n",
       "       [0.78386444],\n",
       "       [0.7805486 ],\n",
       "       [0.77309453],\n",
       "       [0.7637804 ],\n",
       "       [0.7539438 ],\n",
       "       [0.7460448 ],\n",
       "       [0.73834735],\n",
       "       [0.7298539 ],\n",
       "       [0.72186136],\n",
       "       [0.7130944 ],\n",
       "       [0.7050701 ],\n",
       "       [0.6953761 ],\n",
       "       [0.6867993 ],\n",
       "       [0.67835766],\n",
       "       [0.66977024],\n",
       "       [0.6607494 ],\n",
       "       [0.6521155 ],\n",
       "       [0.6441399 ],\n",
       "       [0.636401  ],\n",
       "       [0.62869483],\n",
       "       [0.62064266],\n",
       "       [0.6140982 ],\n",
       "       [0.60716575],\n",
       "       [0.6017779 ],\n",
       "       [0.59573495],\n",
       "       [0.5898799 ],\n",
       "       [0.5847607 ],\n",
       "       [0.58008033],\n",
       "       [0.57601583],\n",
       "       [0.57148856],\n",
       "       [0.56690115],\n",
       "       [0.5627097 ],\n",
       "       [0.55891055],\n",
       "       [0.5537247 ],\n",
       "       [0.55356115],\n",
       "       [0.55424345],\n",
       "       [0.5545046 ],\n",
       "       [0.55388004],\n",
       "       [0.55211765],\n",
       "       [0.55081993],\n",
       "       [0.5499951 ],\n",
       "       [0.5489964 ],\n",
       "       [0.54737145],\n",
       "       [0.54584366],\n",
       "       [0.54081154],\n",
       "       [0.5348132 ],\n",
       "       [0.5290679 ],\n",
       "       [0.52460337],\n",
       "       [0.52265185],\n",
       "       [0.5200912 ],\n",
       "       [0.517184  ],\n",
       "       [0.5146275 ],\n",
       "       [0.51116425],\n",
       "       [0.5086728 ],\n",
       "       [0.50625545],\n",
       "       [0.50335485]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76b50669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "testPredict = regressor.predict([X_test1, X_test2, X_test3, X_test4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a8bdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "valPredict = regressor.predict([X_val1, X_val2,X_val3, X_val4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b6f7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bb9e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.04\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_val,valPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3056cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.18\n"
     ]
    }
   ],
   "source": [
    "MAE = math.sqrt(mean_absolute_error(y_val,valPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d80b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c58d15c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.572074 0.618226]\n",
      " [0.571132 0.616004]\n",
      " [0.568872 0.611976]\n",
      " [0.564554 0.606466]\n",
      " [0.559859 0.600399]\n",
      " [0.554531 0.59468 ]\n",
      " [0.544329 0.588161]\n",
      " [0.544929 0.599026]\n",
      " [0.553753 0.607449]\n",
      " [0.56167  0.614321]\n",
      " [0.567878 0.620085]\n",
      " [0.568282 0.618894]\n",
      " [0.570371 0.618589]\n",
      " [0.573565 0.617772]\n",
      " [0.578066 0.617245]\n",
      " [0.584528 0.616607]\n",
      " [0.592557 0.626267]\n",
      " [0.588167 0.615608]\n",
      " [0.575335 0.605407]\n",
      " [0.570509 0.594143]\n",
      " [0.565401 0.584187]\n",
      " [0.559872 0.571555]\n",
      " [0.553507 0.560286]\n",
      " [0.545907 0.549715]\n",
      " [0.539256 0.539831]\n",
      " [0.532605 0.530674]\n",
      " [0.526999 0.511971]\n",
      " [0.52142  0.495426]\n",
      " [0.517838 0.481608]\n",
      " [0.507818 0.470458]\n",
      " [0.497942 0.464694]\n",
      " [0.490619 0.459712]\n",
      " [0.482272 0.452987]\n",
      " [0.476967 0.447083]\n",
      " [0.473699 0.44105 ]\n",
      " [0.469725 0.434763]\n",
      " [0.465519 0.428739]\n",
      " [0.460968 0.423982]\n",
      " [0.456693 0.418628]\n",
      " [0.452659 0.412638]\n",
      " [0.449133 0.402674]\n",
      " [0.443948 0.392628]\n",
      " [0.440104 0.384978]\n",
      " [0.432745 0.377099]\n",
      " [0.425002 0.369881]\n",
      " [0.417267 0.368531]\n",
      " [0.410944 0.365946]\n",
      " [0.404837 0.362834]\n",
      " [0.396437 0.359163]\n",
      " [0.395534 0.355158]\n",
      " [0.392639 0.35538 ]\n",
      " [0.389679 0.353624]\n",
      " [0.386863 0.351206]\n",
      " [0.381406 0.349589]\n",
      " [0.380407 0.347214]\n",
      " [0.380722 0.339632]\n",
      " [0.379118 0.332747]\n",
      " [0.376453 0.32666 ]\n",
      " [0.377472 0.321841]\n",
      " [0.369347 0.317283]\n",
      " [0.363941 0.308674]\n",
      " [0.357966 0.301509]\n",
      " [0.351799 0.295782]\n",
      " [0.351291 0.2899  ]\n",
      " [0.342947 0.28385 ]\n",
      " [0.334742 0.290273]\n",
      " [0.327911 0.296851]\n",
      " [0.322516 0.302358]\n",
      " [0.314521 0.307177]\n",
      " [0.322441 0.311652]\n",
      " [0.330756 0.315234]\n",
      " [0.338784 0.318768]\n",
      " [0.345779 0.321485]\n",
      " [0.351504 0.324215]\n",
      " [0.35557  0.327836]\n",
      " [0.360265 0.318914]\n",
      " [0.36413  0.309782]\n",
      " [0.367142 0.30071 ]\n",
      " [0.370798 0.292138]\n",
      " [0.363485 0.283668]\n",
      " [0.35328  0.285268]\n",
      " [0.34401  0.286197]\n",
      " [0.333567 0.285969]\n",
      " [0.322008 0.285747]\n",
      " [0.324942 0.28379 ]\n",
      " [0.326265 0.282738]\n",
      " [0.325416 0.281808]\n",
      " [0.324483 0.281563]\n",
      " [0.323814 0.282109]\n",
      " [0.323649 0.282805]\n",
      " [0.325149 0.273904]\n",
      " [0.325326 0.265824]\n",
      " [0.327532 0.258342]\n",
      " [0.331316 0.251266]\n",
      " [0.322018 0.246198]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "print(np.concatenate((testPredict.reshape(len(testPredict),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c431e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.03\n",
      "Test RMSE: 0.04\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_train,trainPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n",
    "\n",
    "RMSE = math.sqrt(mean_squared_error(y_test,testPredict))\n",
    "print('Test RMSE: %.2f' % (RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca612703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007333655738380121\n",
      "0.0019402030252778518\n",
      "0.0015489637863609197\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(y_train,trainPredict)\n",
    "print(mse)\n",
    "\n",
    "mse2=mean_squared_error(y_test,testPredict)\n",
    "print(mse2)\n",
    "\n",
    "mse3 = mean_squared_error(y_val,valPredict)\n",
    "print(mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1ddd352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_train,trainPredict))\n",
    "print('Train MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0f7067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_test,testPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77df0e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889341061039572"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, trainPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd26b337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9454155112862854"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, valPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e65e48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799482180548619"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f0bba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = np.arange(439, 628)\n",
    "                   \n",
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(trainPredict,color = 'blue', label = 'Predicted SOH(Training)')\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "plt.plot( X_data,z,color = 'darkgreen', label = 'Predicted SOH(Testing )')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ab62268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testPredict, color = 'darkgreen', label = 'Predicted SOH(Testing)')\n",
    "plt.plot(y_test, color = 'blue', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60c43329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train-trainPredict, color = 'blue', label = 'Training Error')\n",
    "#plt.plot(combined_data-combined_datap, color = 'blue', label = 'Error')\n",
    "X_data = np.arange(439, 628)\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "p=np.concatenate((y_val,y_test), axis=0)\n",
    "plt.plot(X_data,p-z, color = 'darkgreen', label = 'Testing Error')\n",
    "yticks_positions = [-0.3, -0.2,-0.1,0.0 ,0.1,0.2,0.3]\n",
    "#yticks_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "\n",
    "# Apply the yticks\n",
    "#plt.yticks(yticks_positions, yticks_labels)\n",
    "plt.yticks(yticks_positions)\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9f382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00c860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c16b02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(combined_datap, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f582902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_train, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c97df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4911dcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_val, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8517e995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_test, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5691222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810968759039028"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(combined_data, combined_datap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9979038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ddb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
