{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1c115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb60aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3548dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('output_Result0.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa98ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401.203</td>\n",
       "      <td>1003.485</td>\n",
       "      <td>949.140</td>\n",
       "      <td>792.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421.250</td>\n",
       "      <td>1021.578</td>\n",
       "      <td>925.547</td>\n",
       "      <td>788.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425.719</td>\n",
       "      <td>1035.750</td>\n",
       "      <td>907.328</td>\n",
       "      <td>704.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431.235</td>\n",
       "      <td>1042.703</td>\n",
       "      <td>900.469</td>\n",
       "      <td>766.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433.390</td>\n",
       "      <td>1044.985</td>\n",
       "      <td>902.468</td>\n",
       "      <td>781.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>209.157</td>\n",
       "      <td>482.406</td>\n",
       "      <td>623.969</td>\n",
       "      <td>714.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>202.657</td>\n",
       "      <td>491.234</td>\n",
       "      <td>627.188</td>\n",
       "      <td>690.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>203.046</td>\n",
       "      <td>492.938</td>\n",
       "      <td>615.297</td>\n",
       "      <td>720.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>107.875</td>\n",
       "      <td>419.500</td>\n",
       "      <td>693.657</td>\n",
       "      <td>744.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>198.750</td>\n",
       "      <td>475.953</td>\n",
       "      <td>606.657</td>\n",
       "      <td>714.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        F2       F3       F4\n",
       "0    401.203  1003.485  949.140  792.094\n",
       "1    421.250  1021.578  925.547  788.015\n",
       "2    425.719  1035.750  907.328  704.781\n",
       "3    431.235  1042.703  900.469  766.844\n",
       "4    433.390  1044.985  902.468  781.000\n",
       "..       ...       ...      ...      ...\n",
       "632  209.157   482.406  623.969  714.625\n",
       "633  202.657   491.234  627.188  690.843\n",
       "634  203.046   492.938  615.297  720.390\n",
       "635  107.875   419.500  693.657  744.625\n",
       "636  198.750   475.953  606.657  714.156\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8875c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa5f8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>186.1922</td>\n",
       "      <td>471.4906</td>\n",
       "      <td>650.2078</td>\n",
       "      <td>736.2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>186.3235</td>\n",
       "      <td>473.4359</td>\n",
       "      <td>651.3828</td>\n",
       "      <td>732.0997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>186.9906</td>\n",
       "      <td>475.8813</td>\n",
       "      <td>652.2797</td>\n",
       "      <td>733.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>192.5687</td>\n",
       "      <td>486.7563</td>\n",
       "      <td>647.7283</td>\n",
       "      <td>724.8138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>189.6234</td>\n",
       "      <td>481.9984</td>\n",
       "      <td>642.6893</td>\n",
       "      <td>723.8966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1        F2        F3        F4\n",
       "0         NaN       NaN       NaN       NaN\n",
       "1         NaN       NaN       NaN       NaN\n",
       "2         NaN       NaN       NaN       NaN\n",
       "3         NaN       NaN       NaN       NaN\n",
       "4         NaN       NaN       NaN       NaN\n",
       "..        ...       ...       ...       ...\n",
       "632  186.1922  471.4906  650.2078  736.2451\n",
       "633  186.3235  473.4359  651.3828  732.0997\n",
       "634  186.9906  475.8813  652.2797  733.2419\n",
       "635  192.5687  486.7563  647.7283  724.8138\n",
       "636  189.6234  481.9984  642.6893  723.8966\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f47a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>434.3110</td>\n",
       "      <td>1037.8001</td>\n",
       "      <td>901.6749</td>\n",
       "      <td>741.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439.2438</td>\n",
       "      <td>1041.3719</td>\n",
       "      <td>895.6578</td>\n",
       "      <td>733.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439.9047</td>\n",
       "      <td>1040.8891</td>\n",
       "      <td>887.2797</td>\n",
       "      <td>722.4185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1         F2        F3        F4\n",
       "0        NaN        NaN       NaN       NaN\n",
       "1        NaN        NaN       NaN       NaN\n",
       "2        NaN        NaN       NaN       NaN\n",
       "3        NaN        NaN       NaN       NaN\n",
       "4        NaN        NaN       NaN       NaN\n",
       "5        NaN        NaN       NaN       NaN\n",
       "6        NaN        NaN       NaN       NaN\n",
       "7        NaN        NaN       NaN       NaN\n",
       "8        NaN        NaN       NaN       NaN\n",
       "9   434.3110  1037.8001  901.6749  741.1248\n",
       "10  439.2438  1041.3719  895.6578  733.3810\n",
       "11  439.9047  1040.8891  887.2797  722.4185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfa1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93af4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 434.311 , 1037.8001,  901.6749,  741.1248],\n",
       "       [ 439.2438, 1041.3719,  895.6578,  733.381 ],\n",
       "       [ 439.9047, 1040.8891,  887.2797,  722.4185],\n",
       "       ...,\n",
       "       [ 186.9906,  475.8813,  652.2797,  733.2419],\n",
       "       [ 192.5687,  486.7563,  647.7283,  724.8138],\n",
       "       [ 189.6234,  481.9984,  642.6893,  723.8966]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89596b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset_train_scaled = sc.fit_transform(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5180305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19477b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f80fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result = pd.read_csv('SOH_RESULT12.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6e7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.917675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.677398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.670526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.666465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.665487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.664586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0    0.928244\n",
       "1    0.923164\n",
       "2    0.917675\n",
       "3    0.917631\n",
       "4    0.917323\n",
       "..        ...\n",
       "632  0.677398\n",
       "633  0.670526\n",
       "634  0.666465\n",
       "635  0.665487\n",
       "636  0.664586\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68a1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865ffac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.686977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.683707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.677815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.675764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "..        ...\n",
       "632  0.686977\n",
       "633  0.683707\n",
       "634  0.680679\n",
       "635  0.677815\n",
       "636  0.675764\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ff2375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SOH\n",
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "5       NaN\n",
       "6       NaN\n",
       "7       NaN\n",
       "8       NaN\n",
       "9  0.917701"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca6fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf70b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91770118],\n",
       "       [0.91610779],\n",
       "       [0.91450152],\n",
       "       [0.91342167],\n",
       "       [0.91233057],\n",
       "       [0.91072819],\n",
       "       [0.90905045],\n",
       "       [0.90742212],\n",
       "       [0.9062877 ],\n",
       "       [0.90518789],\n",
       "       [0.90630852],\n",
       "       [0.90744841],\n",
       "       [0.90854719],\n",
       "       [0.90914862],\n",
       "       [0.90973227],\n",
       "       [0.91088145],\n",
       "       [0.91147766],\n",
       "       [0.91208714],\n",
       "       [0.9126322 ],\n",
       "       [0.9126316 ],\n",
       "       [0.91048415],\n",
       "       [0.91070341],\n",
       "       [0.91042974],\n",
       "       [0.9096061 ],\n",
       "       [0.90858091],\n",
       "       [0.90727069],\n",
       "       [0.90599129],\n",
       "       [0.90439899],\n",
       "       [0.9023522 ],\n",
       "       [0.90086581],\n",
       "       [0.89905556],\n",
       "       [0.89458119],\n",
       "       [0.89142686],\n",
       "       [0.88909488],\n",
       "       [0.88645091],\n",
       "       [0.88357453],\n",
       "       [0.88095694],\n",
       "       [0.88149199],\n",
       "       [0.88199975],\n",
       "       [0.88171608],\n",
       "       [0.88117336],\n",
       "       [0.88040114],\n",
       "       [0.87910614],\n",
       "       [0.87779384],\n",
       "       [0.8765234 ],\n",
       "       [0.87522125],\n",
       "       [0.87394335],\n",
       "       [0.86956288],\n",
       "       [0.86541898],\n",
       "       [0.86177976],\n",
       "       [0.85817401],\n",
       "       [0.85455419],\n",
       "       [0.85119679],\n",
       "       [0.84756148],\n",
       "       [0.84419609],\n",
       "       [0.84109847],\n",
       "       [0.83770449],\n",
       "       [0.83429666],\n",
       "       [0.83091786],\n",
       "       [0.82757651],\n",
       "       [0.82443764],\n",
       "       [0.82128021],\n",
       "       [0.81787991],\n",
       "       [0.8147698 ],\n",
       "       [0.81133757],\n",
       "       [0.80793431],\n",
       "       [0.80504878],\n",
       "       [0.80293221],\n",
       "       [0.80003196],\n",
       "       [0.79688942],\n",
       "       [0.79377144],\n",
       "       [0.79117924],\n",
       "       [0.78858555],\n",
       "       [0.78595354],\n",
       "       [0.78334691],\n",
       "       [0.78045317],\n",
       "       [0.77763228],\n",
       "       [0.77398833],\n",
       "       [0.77112612],\n",
       "       [0.77317197],\n",
       "       [0.77337613],\n",
       "       [0.77280662],\n",
       "       [0.77169093],\n",
       "       [0.77059487],\n",
       "       [0.76953091],\n",
       "       [0.76873007],\n",
       "       [0.767632  ],\n",
       "       [0.7665769 ],\n",
       "       [0.76524483],\n",
       "       [0.7592473 ],\n",
       "       [0.75507553],\n",
       "       [0.75143143],\n",
       "       [0.74910783],\n",
       "       [0.74756478],\n",
       "       [0.74575695],\n",
       "       [0.74364978],\n",
       "       [0.74101665],\n",
       "       [0.73864669],\n",
       "       [0.73685566],\n",
       "       [0.73501435],\n",
       "       [0.73292721],\n",
       "       [0.730839  ],\n",
       "       [0.72821362],\n",
       "       [0.72481227],\n",
       "       [0.72191826],\n",
       "       [0.71930199],\n",
       "       [0.71722739],\n",
       "       [0.71514902],\n",
       "       [0.71277775],\n",
       "       [0.71199525],\n",
       "       [0.71197445],\n",
       "       [0.71116991],\n",
       "       [0.7098492 ],\n",
       "       [0.70850615],\n",
       "       [0.70719517],\n",
       "       [0.70588796],\n",
       "       [0.70457894],\n",
       "       [0.70297183],\n",
       "       [0.70135373],\n",
       "       [0.69820977],\n",
       "       [0.69482245],\n",
       "       [0.69219149],\n",
       "       [0.69061201],\n",
       "       [0.68985739],\n",
       "       [0.68851485],\n",
       "       [0.68718975],\n",
       "       [0.68559442],\n",
       "       [0.68430467],\n",
       "       [0.68327804],\n",
       "       [0.68221815],\n",
       "       [0.68090219],\n",
       "       [0.67961498],\n",
       "       [0.6777911 ],\n",
       "       [0.67518586],\n",
       "       [0.67312558],\n",
       "       [0.67104499],\n",
       "       [0.66923734],\n",
       "       [0.66742858],\n",
       "       [0.66560804],\n",
       "       [0.66433591],\n",
       "       [0.66513253],\n",
       "       [0.6651595 ],\n",
       "       [0.6646652 ],\n",
       "       [0.66414858],\n",
       "       [0.66364805],\n",
       "       [0.66316326],\n",
       "       [0.66291491],\n",
       "       [0.66238138],\n",
       "       [0.66161838],\n",
       "       [0.66059263],\n",
       "       [0.65775704],\n",
       "       [0.65567486],\n",
       "       [0.65412711],\n",
       "       [0.65261658],\n",
       "       [0.65108506],\n",
       "       [0.64978392],\n",
       "       [0.64957459],\n",
       "       [0.65043876],\n",
       "       [0.65054171],\n",
       "       [0.68514529],\n",
       "       [0.71924637],\n",
       "       [0.75304449],\n",
       "       [0.78683124],\n",
       "       [0.82022317],\n",
       "       [0.85454354],\n",
       "       [0.88885234],\n",
       "       [0.91991088],\n",
       "       [0.95013565],\n",
       "       [0.98082373],\n",
       "       [0.97642479],\n",
       "       [0.97199392],\n",
       "       [0.96757988],\n",
       "       [0.96260955],\n",
       "       [0.95773398],\n",
       "       [0.95162123],\n",
       "       [0.94501228],\n",
       "       [0.94005051],\n",
       "       [0.93512026],\n",
       "       [0.9362181 ],\n",
       "       [0.93680392],\n",
       "       [0.93734629],\n",
       "       [0.93739366],\n",
       "       [0.93906479],\n",
       "       [0.93908152],\n",
       "       [0.9385656 ],\n",
       "       [0.93807676],\n",
       "       [0.93751082],\n",
       "       [0.93641329],\n",
       "       [0.93041341],\n",
       "       [0.92880685],\n",
       "       [0.92569002],\n",
       "       [0.92230917],\n",
       "       [0.91606203],\n",
       "       [0.9117517 ],\n",
       "       [0.90775305],\n",
       "       [0.90347356],\n",
       "       [0.89930634],\n",
       "       [0.89515298],\n",
       "       [0.88991095],\n",
       "       [0.88082842],\n",
       "       [0.87457572],\n",
       "       [0.87019642],\n",
       "       [0.86604197],\n",
       "       [0.8611326 ],\n",
       "       [0.85649073],\n",
       "       [0.8585846 ],\n",
       "       [0.86040398],\n",
       "       [0.86115348],\n",
       "       [0.8608814 ],\n",
       "       [0.86037721],\n",
       "       [0.85809447],\n",
       "       [0.85474429],\n",
       "       [0.85220874],\n",
       "       [0.85015731],\n",
       "       [0.84811571],\n",
       "       [0.839655  ],\n",
       "       [0.83142003],\n",
       "       [0.82423566],\n",
       "       [0.81757432],\n",
       "       [0.81141341],\n",
       "       [0.80606353],\n",
       "       [0.80067294],\n",
       "       [0.79581551],\n",
       "       [0.79070085],\n",
       "       [0.78582759],\n",
       "       [0.78092808],\n",
       "       [0.77605256],\n",
       "       [0.7709601 ],\n",
       "       [0.76710262],\n",
       "       [0.76323655],\n",
       "       [0.75909822],\n",
       "       [0.75526314],\n",
       "       [0.75139183],\n",
       "       [0.74778314],\n",
       "       [0.74416979],\n",
       "       [0.74314608],\n",
       "       [0.74135206],\n",
       "       [0.73956017],\n",
       "       [0.73701708],\n",
       "       [0.73475253],\n",
       "       [0.73272633],\n",
       "       [0.73067364],\n",
       "       [0.72810657],\n",
       "       [0.72606753],\n",
       "       [0.72408303],\n",
       "       [0.71999313],\n",
       "       [0.71693422],\n",
       "       [0.72207281],\n",
       "       [0.72541165],\n",
       "       [0.7271884 ],\n",
       "       [0.72845133],\n",
       "       [0.72921577],\n",
       "       [0.73026171],\n",
       "       [0.73079292],\n",
       "       [0.73102272],\n",
       "       [0.73102337],\n",
       "       [0.73100897],\n",
       "       [0.72304937],\n",
       "       [0.7171491 ],\n",
       "       [0.71253057],\n",
       "       [0.70869341],\n",
       "       [0.7071809 ],\n",
       "       [0.70515106],\n",
       "       [0.70281063],\n",
       "       [0.70074664],\n",
       "       [0.69869028],\n",
       "       [0.69642479],\n",
       "       [0.69462693],\n",
       "       [0.69282754],\n",
       "       [0.69103098],\n",
       "       [0.68872612],\n",
       "       [0.68511583],\n",
       "       [0.68228262],\n",
       "       [0.67999057],\n",
       "       [0.67771466],\n",
       "       [0.67541952],\n",
       "       [0.67336584],\n",
       "       [0.67285732],\n",
       "       [0.67363328],\n",
       "       [0.67338235],\n",
       "       [0.67311688],\n",
       "       [0.67207321],\n",
       "       [0.67103073],\n",
       "       [0.67000876],\n",
       "       [0.6687198 ],\n",
       "       [0.66740307],\n",
       "       [0.66606293],\n",
       "       [0.6629952 ],\n",
       "       [0.65888139],\n",
       "       [0.6557897 ],\n",
       "       [0.65346797],\n",
       "       [0.65298355],\n",
       "       [0.65168548],\n",
       "       [0.64985747],\n",
       "       [0.64829908],\n",
       "       [0.64678785],\n",
       "       [0.6455283 ],\n",
       "       [0.64395614],\n",
       "       [0.64189869],\n",
       "       [0.64011238],\n",
       "       [0.63781504],\n",
       "       [0.63422163],\n",
       "       [0.63117022],\n",
       "       [0.62862211],\n",
       "       [0.62607524],\n",
       "       [0.62376274],\n",
       "       [0.62120646],\n",
       "       [0.61943826],\n",
       "       [0.6199555 ],\n",
       "       [0.61918748],\n",
       "       [0.61791   ],\n",
       "       [0.61585083],\n",
       "       [0.61405425],\n",
       "       [0.61227006],\n",
       "       [0.61020353],\n",
       "       [0.60786944],\n",
       "       [0.60555602],\n",
       "       [0.60247538],\n",
       "       [0.59734667],\n",
       "       [0.59323542],\n",
       "       [0.58963832],\n",
       "       [0.58579999],\n",
       "       [0.58272583],\n",
       "       [0.57964043],\n",
       "       [0.57786945],\n",
       "       [0.57689197],\n",
       "       [0.57612913],\n",
       "       [0.61231947],\n",
       "       [0.6482543 ],\n",
       "       [0.68446044],\n",
       "       [0.72092079],\n",
       "       [0.75833361],\n",
       "       [0.79529015],\n",
       "       [0.83248311],\n",
       "       [0.86896174],\n",
       "       [0.90432495],\n",
       "       [0.93972307],\n",
       "       [0.93867266],\n",
       "       [0.93762341],\n",
       "       [0.93654401],\n",
       "       [0.93545589],\n",
       "       [0.93445145],\n",
       "       [0.93335321],\n",
       "       [0.93174732],\n",
       "       [0.93009814],\n",
       "       [0.92903255],\n",
       "       [0.92956896],\n",
       "       [0.93014035],\n",
       "       [0.93121253],\n",
       "       [0.93180924],\n",
       "       [0.9323688 ],\n",
       "       [0.93293426],\n",
       "       [0.93297811],\n",
       "       [0.93358894],\n",
       "       [0.93412094],\n",
       "       [0.93410898],\n",
       "       [0.93253004],\n",
       "       [0.93262982],\n",
       "       [0.9317161 ],\n",
       "       [0.93051318],\n",
       "       [0.92884462],\n",
       "       [0.92716915],\n",
       "       [0.92577214],\n",
       "       [0.92382779],\n",
       "       [0.92169483],\n",
       "       [0.91985692],\n",
       "       [0.91797712],\n",
       "       [0.91410648],\n",
       "       [0.91162563],\n",
       "       [0.90959132],\n",
       "       [0.90754144],\n",
       "       [0.90497761],\n",
       "       [0.90241034],\n",
       "       [0.90210677],\n",
       "       [0.90206659],\n",
       "       [0.90150967],\n",
       "       [0.90045177],\n",
       "       [0.89916618],\n",
       "       [0.89727241],\n",
       "       [0.89547235],\n",
       "       [0.89368485],\n",
       "       [0.89187297],\n",
       "       [0.89033913],\n",
       "       [0.88683678],\n",
       "       [0.88303394],\n",
       "       [0.87944999],\n",
       "       [0.87612263],\n",
       "       [0.87280442],\n",
       "       [0.86973649],\n",
       "       [0.86640595],\n",
       "       [0.86360258],\n",
       "       [0.86079878],\n",
       "       [0.85769917],\n",
       "       [0.85460145],\n",
       "       [0.85151551],\n",
       "       [0.8487476 ],\n",
       "       [0.84592442],\n",
       "       [0.84333879],\n",
       "       [0.8405115 ],\n",
       "       [0.83795583],\n",
       "       [0.83511601],\n",
       "       [0.83225812],\n",
       "       [0.829688  ],\n",
       "       [0.82759024],\n",
       "       [0.82527239],\n",
       "       [0.82267275],\n",
       "       [0.82012228],\n",
       "       [0.81780015],\n",
       "       [0.81576514],\n",
       "       [0.81368149],\n",
       "       [0.81135363],\n",
       "       [0.80932882],\n",
       "       [0.80732694],\n",
       "       [0.80506131],\n",
       "       [0.80301535],\n",
       "       [0.80639574],\n",
       "       [0.80687406],\n",
       "       [0.80687006],\n",
       "       [0.80631698],\n",
       "       [0.80552244],\n",
       "       [0.80500993],\n",
       "       [0.80448164],\n",
       "       [0.80366943],\n",
       "       [0.80264003],\n",
       "       [0.80159742],\n",
       "       [0.79566919],\n",
       "       [0.79263199],\n",
       "       [0.78982652],\n",
       "       [0.78779249],\n",
       "       [0.78679273],\n",
       "       [0.78553627],\n",
       "       [0.78425646],\n",
       "       [0.78275266],\n",
       "       [0.78118559],\n",
       "       [0.77994661],\n",
       "       [0.77866348],\n",
       "       [0.77711642],\n",
       "       [0.77557274],\n",
       "       [0.77376994],\n",
       "       [0.77147555],\n",
       "       [0.76940679],\n",
       "       [0.76735239],\n",
       "       [0.76553992],\n",
       "       [0.76402631],\n",
       "       [0.76247273],\n",
       "       [0.76194102],\n",
       "       [0.76218245],\n",
       "       [0.76192567],\n",
       "       [0.76115844],\n",
       "       [0.76009311],\n",
       "       [0.75905761],\n",
       "       [0.75801534],\n",
       "       [0.75697536],\n",
       "       [0.75591582],\n",
       "       [0.75459261],\n",
       "       [0.75202137],\n",
       "       [0.74920388],\n",
       "       [0.7468712 ],\n",
       "       [0.74528721],\n",
       "       [0.74480479],\n",
       "       [0.74374886],\n",
       "       [0.74271353],\n",
       "       [0.74167497],\n",
       "       [0.74066665],\n",
       "       [0.73964305],\n",
       "       [0.73860465],\n",
       "       [0.73730004],\n",
       "       [0.73601923],\n",
       "       [0.73450495],\n",
       "       [0.73193893],\n",
       "       [0.73017291],\n",
       "       [0.72838612],\n",
       "       [0.72659453],\n",
       "       [0.7248229 ],\n",
       "       [0.7232871 ],\n",
       "       [0.72229161],\n",
       "       [0.72281716],\n",
       "       [0.72284262],\n",
       "       [0.72261872],\n",
       "       [0.72236744],\n",
       "       [0.72161114],\n",
       "       [0.72113257],\n",
       "       [0.7206331 ],\n",
       "       [0.72009672],\n",
       "       [0.71934516],\n",
       "       [0.71806865],\n",
       "       [0.71553724],\n",
       "       [0.71348605],\n",
       "       [0.7116789 ],\n",
       "       [0.70989794],\n",
       "       [0.70863318],\n",
       "       [0.70706552],\n",
       "       [0.70684204],\n",
       "       [0.70716041],\n",
       "       [0.70764404],\n",
       "       [0.72957791],\n",
       "       [0.75090877],\n",
       "       [0.77234686],\n",
       "       [0.79333079],\n",
       "       [0.81465723],\n",
       "       [0.83576688],\n",
       "       [0.85680418],\n",
       "       [0.87647335],\n",
       "       [0.89506549],\n",
       "       [0.9146737 ],\n",
       "       [0.91252975],\n",
       "       [0.91060455],\n",
       "       [0.90816668],\n",
       "       [0.90580653],\n",
       "       [0.90321845],\n",
       "       [0.90035246],\n",
       "       [0.89772392],\n",
       "       [0.89464694],\n",
       "       [0.89174303],\n",
       "       [0.88747125],\n",
       "       [0.88344082],\n",
       "       [0.87863599],\n",
       "       [0.87466727],\n",
       "       [0.87086884],\n",
       "       [0.86928382],\n",
       "       [0.86736185],\n",
       "       [0.8650419 ],\n",
       "       [0.86295269],\n",
       "       [0.86060509],\n",
       "       [0.85842369],\n",
       "       [0.85594299],\n",
       "       [0.85436209],\n",
       "       [0.85206474],\n",
       "       [0.84954926],\n",
       "       [0.84449856],\n",
       "       [0.83979858],\n",
       "       [0.83506945],\n",
       "       [0.83058482],\n",
       "       [0.82632176],\n",
       "       [0.82542251],\n",
       "       [0.8237924 ],\n",
       "       [0.8215627 ],\n",
       "       [0.81910735],\n",
       "       [0.81679287],\n",
       "       [0.81415486],\n",
       "       [0.81855172],\n",
       "       [0.82196046],\n",
       "       [0.82474169],\n",
       "       [0.8270743 ],\n",
       "       [0.82659226],\n",
       "       [0.82646891],\n",
       "       [0.82613796],\n",
       "       [0.82592505],\n",
       "       [0.82566674],\n",
       "       [0.82957581],\n",
       "       [0.82526219],\n",
       "       [0.82113427],\n",
       "       [0.81657542],\n",
       "       [0.81254631],\n",
       "       [0.80743443],\n",
       "       [0.80287367],\n",
       "       [0.79859569],\n",
       "       [0.79459587],\n",
       "       [0.7908902 ],\n",
       "       [0.78332091],\n",
       "       [0.77662551],\n",
       "       [0.77103334],\n",
       "       [0.76652095],\n",
       "       [0.76418843],\n",
       "       [0.76217202],\n",
       "       [0.75945072],\n",
       "       [0.75706137],\n",
       "       [0.7546195 ],\n",
       "       [0.75207522],\n",
       "       [0.74963763],\n",
       "       [0.74771226],\n",
       "       [0.74554578],\n",
       "       [0.74312141],\n",
       "       [0.73908915],\n",
       "       [0.73502367],\n",
       "       [0.73192763],\n",
       "       [0.72873912],\n",
       "       [0.72581806],\n",
       "       [0.72527175],\n",
       "       [0.72422546],\n",
       "       [0.72296621],\n",
       "       [0.72148039],\n",
       "       [0.71985983],\n",
       "       [0.71994962],\n",
       "       [0.71923873],\n",
       "       [0.7182603 ],\n",
       "       [0.71760596],\n",
       "       [0.71664483],\n",
       "       [0.71357656],\n",
       "       [0.7107902 ],\n",
       "       [0.70832684],\n",
       "       [0.70637626],\n",
       "       [0.70453178],\n",
       "       [0.701048  ],\n",
       "       [0.69814836],\n",
       "       [0.69583055],\n",
       "       [0.69344995],\n",
       "       [0.69100165],\n",
       "       [0.6936009 ],\n",
       "       [0.69626315],\n",
       "       [0.69849184],\n",
       "       [0.70044203],\n",
       "       [0.70225314],\n",
       "       [0.70370254],\n",
       "       [0.70513294],\n",
       "       [0.70623223],\n",
       "       [0.7073371 ],\n",
       "       [0.70880276],\n",
       "       [0.70519197],\n",
       "       [0.70149611],\n",
       "       [0.69782492],\n",
       "       [0.69435578],\n",
       "       [0.69092795],\n",
       "       [0.69157563],\n",
       "       [0.69195138],\n",
       "       [0.69185931],\n",
       "       [0.69176947],\n",
       "       [0.6909775 ],\n",
       "       [0.6905515 ],\n",
       "       [0.6901753 ],\n",
       "       [0.69007631],\n",
       "       [0.69029729],\n",
       "       [0.69057898],\n",
       "       [0.68697669],\n",
       "       [0.68370685],\n",
       "       [0.68067881],\n",
       "       [0.67781505],\n",
       "       [0.67576426]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_setY_scaled = sc.fit_transform(dataset_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc6a260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84402423],\n",
       "       [0.84008695],\n",
       "       [0.83611787],\n",
       "       [0.83344956],\n",
       "       [0.83075345],\n",
       "       [0.82679398],\n",
       "       [0.82264829],\n",
       "       [0.81862468],\n",
       "       [0.81582152],\n",
       "       [0.81310389],\n",
       "       [0.81587298],\n",
       "       [0.81868964],\n",
       "       [0.82140471],\n",
       "       [0.82289084],\n",
       "       [0.82433306],\n",
       "       [0.82717267],\n",
       "       [0.82864591],\n",
       "       [0.83015195],\n",
       "       [0.83149877],\n",
       "       [0.8314973 ],\n",
       "       [0.82619095],\n",
       "       [0.82673275],\n",
       "       [0.82605649],\n",
       "       [0.82402128],\n",
       "       [0.82148804],\n",
       "       [0.81825049],\n",
       "       [0.8150891 ],\n",
       "       [0.81115451],\n",
       "       [0.80609691],\n",
       "       [0.80242403],\n",
       "       [0.79795091],\n",
       "       [0.78689474],\n",
       "       [0.7791004 ],\n",
       "       [0.77333808],\n",
       "       [0.76680483],\n",
       "       [0.75969731],\n",
       "       [0.75322924],\n",
       "       [0.75455134],\n",
       "       [0.75580603],\n",
       "       [0.75510506],\n",
       "       [0.75376401],\n",
       "       [0.75185585],\n",
       "       [0.7486559 ],\n",
       "       [0.74541323],\n",
       "       [0.74227398],\n",
       "       [0.73905636],\n",
       "       [0.73589867],\n",
       "       [0.72507452],\n",
       "       [0.71483494],\n",
       "       [0.70584244],\n",
       "       [0.69693265],\n",
       "       [0.68798807],\n",
       "       [0.67969194],\n",
       "       [0.6707091 ],\n",
       "       [0.66239322],\n",
       "       [0.65473899],\n",
       "       [0.64635247],\n",
       "       [0.63793172],\n",
       "       [0.62958271],\n",
       "       [0.62132624],\n",
       "       [0.61357009],\n",
       "       [0.6057681 ],\n",
       "       [0.59736595],\n",
       "       [0.58968087],\n",
       "       [0.58119983],\n",
       "       [0.5727904 ],\n",
       "       [0.56566024],\n",
       "       [0.56043019],\n",
       "       [0.55326369],\n",
       "       [0.54549847],\n",
       "       [0.53779395],\n",
       "       [0.53138862],\n",
       "       [0.52497961],\n",
       "       [0.51847593],\n",
       "       [0.51203494],\n",
       "       [0.50488452],\n",
       "       [0.4979141 ],\n",
       "       [0.4889099 ],\n",
       "       [0.48183738],\n",
       "       [0.48689266],\n",
       "       [0.48739714],\n",
       "       [0.4859899 ],\n",
       "       [0.48323304],\n",
       "       [0.48052466],\n",
       "       [0.47789561],\n",
       "       [0.47591675],\n",
       "       [0.47320342],\n",
       "       [0.47059627],\n",
       "       [0.46730471],\n",
       "       [0.45248483],\n",
       "       [0.44217638],\n",
       "       [0.43317182],\n",
       "       [0.42743021],\n",
       "       [0.42361733],\n",
       "       [0.41915017],\n",
       "       [0.41394338],\n",
       "       [0.40743691],\n",
       "       [0.40158074],\n",
       "       [0.3971551 ],\n",
       "       [0.39260523],\n",
       "       [0.38744791],\n",
       "       [0.38228795],\n",
       "       [0.37580063],\n",
       "       [0.3673959 ],\n",
       "       [0.36024479],\n",
       "       [0.35378001],\n",
       "       [0.34865367],\n",
       "       [0.34351802],\n",
       "       [0.33765862],\n",
       "       [0.33572505],\n",
       "       [0.33567366],\n",
       "       [0.33368565],\n",
       "       [0.33042217],\n",
       "       [0.32710349],\n",
       "       [0.32386407],\n",
       "       [0.32063395],\n",
       "       [0.31739936],\n",
       "       [0.3134282 ],\n",
       "       [0.30942988],\n",
       "       [0.30166115],\n",
       "       [0.29329108],\n",
       "       [0.28678998],\n",
       "       [0.28288708],\n",
       "       [0.28102243],\n",
       "       [0.27770501],\n",
       "       [0.27443069],\n",
       "       [0.27048862],\n",
       "       [0.26730165],\n",
       "       [0.26476486],\n",
       "       [0.26214587],\n",
       "       [0.25889412],\n",
       "       [0.25571343],\n",
       "       [0.25120664],\n",
       "       [0.24476909],\n",
       "       [0.23967814],\n",
       "       [0.23453699],\n",
       "       [0.23007031],\n",
       "       [0.22560086],\n",
       "       [0.22110229],\n",
       "       [0.21795886],\n",
       "       [0.21992732],\n",
       "       [0.21999395],\n",
       "       [0.21877255],\n",
       "       [0.21749597],\n",
       "       [0.21625917],\n",
       "       [0.21506126],\n",
       "       [0.21444757],\n",
       "       [0.21312924],\n",
       "       [0.21124385],\n",
       "       [0.20870921],\n",
       "       [0.20170249],\n",
       "       [0.19655743],\n",
       "       [0.19273292],\n",
       "       [0.18900041],\n",
       "       [0.18521602],\n",
       "       [0.18200092],\n",
       "       [0.18148366],\n",
       "       [0.18361901],\n",
       "       [0.18387341],\n",
       "       [0.26937883],\n",
       "       [0.35364257],\n",
       "       [0.43715768],\n",
       "       [0.52064471],\n",
       "       [0.60315615],\n",
       "       [0.68796176],\n",
       "       [0.77273878],\n",
       "       [0.84948439],\n",
       "       [0.92416977],\n",
       "       [1.        ],\n",
       "       [0.98913022],\n",
       "       [0.97818154],\n",
       "       [0.96727445],\n",
       "       [0.95499277],\n",
       "       [0.94294524],\n",
       "       [0.92784064],\n",
       "       [0.91150992],\n",
       "       [0.89924939],\n",
       "       [0.88706677],\n",
       "       [0.88977951],\n",
       "       [0.89122707],\n",
       "       [0.89256729],\n",
       "       [0.89268431],\n",
       "       [0.89681369],\n",
       "       [0.89685502],\n",
       "       [0.89558018],\n",
       "       [0.89437227],\n",
       "       [0.89297382],\n",
       "       [0.89026184],\n",
       "       [0.87543613],\n",
       "       [0.87146632],\n",
       "       [0.86376465],\n",
       "       [0.85541056],\n",
       "       [0.8399739 ],\n",
       "       [0.82932305],\n",
       "       [0.8194424 ],\n",
       "       [0.8088678 ],\n",
       "       [0.79857059],\n",
       "       [0.78830764],\n",
       "       [0.77535458],\n",
       "       [0.75291166],\n",
       "       [0.73746124],\n",
       "       [0.72664001],\n",
       "       [0.71637436],\n",
       "       [0.70424331],\n",
       "       [0.69277327],\n",
       "       [0.6979472 ],\n",
       "       [0.70244289],\n",
       "       [0.70429491],\n",
       "       [0.70362261],\n",
       "       [0.70237675],\n",
       "       [0.69673609],\n",
       "       [0.6884578 ],\n",
       "       [0.68219245],\n",
       "       [0.67712338],\n",
       "       [0.67207859],\n",
       "       [0.65117219],\n",
       "       [0.63082357],\n",
       "       [0.613071  ],\n",
       "       [0.59661083],\n",
       "       [0.58138723],\n",
       "       [0.5681677 ],\n",
       "       [0.55484754],\n",
       "       [0.54284485],\n",
       "       [0.53020651],\n",
       "       [0.51816469],\n",
       "       [0.50605803],\n",
       "       [0.4940106 ],\n",
       "       [0.48142715],\n",
       "       [0.47189532],\n",
       "       [0.46234227],\n",
       "       [0.45211646],\n",
       "       [0.44263996],\n",
       "       [0.43307398],\n",
       "       [0.42415689],\n",
       "       [0.41522831],\n",
       "       [0.41269874],\n",
       "       [0.4082657 ],\n",
       "       [0.40383794],\n",
       "       [0.39755396],\n",
       "       [0.39195828],\n",
       "       [0.38695154],\n",
       "       [0.38187933],\n",
       "       [0.37553611],\n",
       "       [0.37049764],\n",
       "       [0.36559394],\n",
       "       [0.35548782],\n",
       "       [0.34792925],\n",
       "       [0.36062671],\n",
       "       [0.36887697],\n",
       "       [0.37326731],\n",
       "       [0.37638801],\n",
       "       [0.37827694],\n",
       "       [0.38086146],\n",
       "       [0.38217408],\n",
       "       [0.38274192],\n",
       "       [0.38274353],\n",
       "       [0.38270794],\n",
       "       [0.36303977],\n",
       "       [0.34846021],\n",
       "       [0.33704783],\n",
       "       [0.32756622],\n",
       "       [0.3238288 ],\n",
       "       [0.31881306],\n",
       "       [0.31302987],\n",
       "       [0.30792976],\n",
       "       [0.30284849],\n",
       "       [0.29725046],\n",
       "       [0.29280795],\n",
       "       [0.28836165],\n",
       "       [0.28392237],\n",
       "       [0.27822705],\n",
       "       [0.26930604],\n",
       "       [0.26230517],\n",
       "       [0.25664153],\n",
       "       [0.25101774],\n",
       "       [0.24534646],\n",
       "       [0.24027181],\n",
       "       [0.23901525],\n",
       "       [0.24093266],\n",
       "       [0.24031262],\n",
       "       [0.23965664],\n",
       "       [0.23707773],\n",
       "       [0.23450176],\n",
       "       [0.23197648],\n",
       "       [0.22879145],\n",
       "       [0.22553781],\n",
       "       [0.22222634],\n",
       "       [0.21464597],\n",
       "       [0.20448075],\n",
       "       [0.19684118],\n",
       "       [0.1911042 ],\n",
       "       [0.18990719],\n",
       "       [0.18669966],\n",
       "       [0.18218267],\n",
       "       [0.17833187],\n",
       "       [0.17459762],\n",
       "       [0.17148529],\n",
       "       [0.16760048],\n",
       "       [0.16251652],\n",
       "       [0.15810255],\n",
       "       [0.15242582],\n",
       "       [0.14354652],\n",
       "       [0.13600647],\n",
       "       [0.12971011],\n",
       "       [0.12341678],\n",
       "       [0.11770261],\n",
       "       [0.11138603],\n",
       "       [0.10701681],\n",
       "       [0.10829492],\n",
       "       [0.10639715],\n",
       "       [0.10324049],\n",
       "       [0.09815228],\n",
       "       [0.09371294],\n",
       "       [0.08930419],\n",
       "       [0.0841978 ],\n",
       "       [0.07843028],\n",
       "       [0.07271381],\n",
       "       [0.06510155],\n",
       "       [0.05242852],\n",
       "       [0.04226962],\n",
       "       [0.03338119],\n",
       "       [0.02389667],\n",
       "       [0.01630043],\n",
       "       [0.0086764 ],\n",
       "       [0.00430033],\n",
       "       [0.00188496],\n",
       "       [0.        ],\n",
       "       [0.0894263 ],\n",
       "       [0.17822123],\n",
       "       [0.26768657],\n",
       "       [0.35778005],\n",
       "       [0.4502271 ],\n",
       "       [0.54154667],\n",
       "       [0.63345045],\n",
       "       [0.72358912],\n",
       "       [0.81097157],\n",
       "       [0.89844029],\n",
       "       [0.89584474],\n",
       "       [0.89325203],\n",
       "       [0.89058483],\n",
       "       [0.88789609],\n",
       "       [0.88541414],\n",
       "       [0.88270039],\n",
       "       [0.87873221],\n",
       "       [0.8746571 ],\n",
       "       [0.87202403],\n",
       "       [0.87334949],\n",
       "       [0.87476141],\n",
       "       [0.87741076],\n",
       "       [0.87888524],\n",
       "       [0.88026789],\n",
       "       [0.88166516],\n",
       "       [0.8817735 ],\n",
       "       [0.88328286],\n",
       "       [0.88459743],\n",
       "       [0.88456789],\n",
       "       [0.88066633],\n",
       "       [0.88091288],\n",
       "       [0.87865509],\n",
       "       [0.87568266],\n",
       "       [0.87155967],\n",
       "       [0.86741956],\n",
       "       [0.86396755],\n",
       "       [0.85916308],\n",
       "       [0.85389254],\n",
       "       [0.84935106],\n",
       "       [0.84470607],\n",
       "       [0.83514171],\n",
       "       [0.82901154],\n",
       "       [0.82398476],\n",
       "       [0.81891953],\n",
       "       [0.81258429],\n",
       "       [0.80624057],\n",
       "       [0.80549045],\n",
       "       [0.80539117],\n",
       "       [0.80401503],\n",
       "       [0.80140095],\n",
       "       [0.79822425],\n",
       "       [0.79354475],\n",
       "       [0.7890968 ],\n",
       "       [0.78467989],\n",
       "       [0.78020273],\n",
       "       [0.77641262],\n",
       "       [0.76775832],\n",
       "       [0.75836151],\n",
       "       [0.74950557],\n",
       "       [0.74128366],\n",
       "       [0.73308437],\n",
       "       [0.72550352],\n",
       "       [0.71727375],\n",
       "       [0.71034664],\n",
       "       [0.70341845],\n",
       "       [0.6957593 ],\n",
       "       [0.68810485],\n",
       "       [0.6804795 ],\n",
       "       [0.67364   ],\n",
       "       [0.66666393],\n",
       "       [0.66027483],\n",
       "       [0.65328859],\n",
       "       [0.64697353],\n",
       "       [0.63995635],\n",
       "       [0.63289449],\n",
       "       [0.62654374],\n",
       "       [0.62136017],\n",
       "       [0.61563277],\n",
       "       [0.60920907],\n",
       "       [0.60290686],\n",
       "       [0.59716886],\n",
       "       [0.59214036],\n",
       "       [0.58699165],\n",
       "       [0.58123952],\n",
       "       [0.57623621],\n",
       "       [0.57128958],\n",
       "       [0.56569121],\n",
       "       [0.56063563],\n",
       "       [0.56898857],\n",
       "       [0.57017052],\n",
       "       [0.57016062],\n",
       "       [0.56879397],\n",
       "       [0.56683065],\n",
       "       [0.56556425],\n",
       "       [0.56425885],\n",
       "       [0.56225188],\n",
       "       [0.55970824],\n",
       "       [0.55713194],\n",
       "       [0.54248329],\n",
       "       [0.53497837],\n",
       "       [0.52804605],\n",
       "       [0.52301996],\n",
       "       [0.52054956],\n",
       "       [0.51744486],\n",
       "       [0.51428245],\n",
       "       [0.51056655],\n",
       "       [0.50669433],\n",
       "       [0.50363279],\n",
       "       [0.50046219],\n",
       "       [0.4966394 ],\n",
       "       [0.49282498],\n",
       "       [0.48837026],\n",
       "       [0.48270082],\n",
       "       [0.47758892],\n",
       "       [0.4725125 ],\n",
       "       [0.46803388],\n",
       "       [0.46429376],\n",
       "       [0.46045485],\n",
       "       [0.45914101],\n",
       "       [0.45973759],\n",
       "       [0.45910308],\n",
       "       [0.45720724],\n",
       "       [0.45457482],\n",
       "       [0.45201612],\n",
       "       [0.44944066],\n",
       "       [0.44687086],\n",
       "       [0.44425275],\n",
       "       [0.44098309],\n",
       "       [0.43462957],\n",
       "       [0.42766754],\n",
       "       [0.42190349],\n",
       "       [0.41798946],\n",
       "       [0.41679739],\n",
       "       [0.4141882 ],\n",
       "       [0.41162991],\n",
       "       [0.40906362],\n",
       "       [0.40657207],\n",
       "       [0.40404274],\n",
       "       [0.40147686],\n",
       "       [0.39825318],\n",
       "       [0.3950883 ],\n",
       "       [0.39134651],\n",
       "       [0.38500587],\n",
       "       [0.38064202],\n",
       "       [0.37622687],\n",
       "       [0.37179987],\n",
       "       [0.36742217],\n",
       "       [0.36362719],\n",
       "       [0.36116735],\n",
       "       [0.36246599],\n",
       "       [0.36252889],\n",
       "       [0.36197564],\n",
       "       [0.36135473],\n",
       "       [0.3594859 ],\n",
       "       [0.35830336],\n",
       "       [0.35706918],\n",
       "       [0.35574378],\n",
       "       [0.35388668],\n",
       "       [0.35073241],\n",
       "       [0.34447731],\n",
       "       [0.33940881],\n",
       "       [0.33494334],\n",
       "       [0.3305426 ],\n",
       "       [0.32741739],\n",
       "       [0.3235437 ],\n",
       "       [0.32299147],\n",
       "       [0.32377817],\n",
       "       [0.32497323],\n",
       "       [0.37917178],\n",
       "       [0.43188034],\n",
       "       [0.48485382],\n",
       "       [0.5367051 ],\n",
       "       [0.58940271],\n",
       "       [0.64156464],\n",
       "       [0.69354779],\n",
       "       [0.7421503 ],\n",
       "       [0.78809146],\n",
       "       [0.83654333],\n",
       "       [0.83124561],\n",
       "       [0.82648846],\n",
       "       [0.82046447],\n",
       "       [0.81463256],\n",
       "       [0.80823742],\n",
       "       [0.80115555],\n",
       "       [0.79466043],\n",
       "       [0.78705723],\n",
       "       [0.77988165],\n",
       "       [0.7693261 ],\n",
       "       [0.7593669 ],\n",
       "       [0.74749417],\n",
       "       [0.73768746],\n",
       "       [0.72830155],\n",
       "       [0.72438497],\n",
       "       [0.71963579],\n",
       "       [0.71390319],\n",
       "       [0.70874075],\n",
       "       [0.70293985],\n",
       "       [0.6975496 ],\n",
       "       [0.69141979],\n",
       "       [0.6875134 ],\n",
       "       [0.68183665],\n",
       "       [0.67562089],\n",
       "       [0.66314061],\n",
       "       [0.65152697],\n",
       "       [0.63984128],\n",
       "       [0.62875977],\n",
       "       [0.61822575],\n",
       "       [0.6160037 ],\n",
       "       [0.61197572],\n",
       "       [0.60646612],\n",
       "       [0.60039896],\n",
       "       [0.59467988],\n",
       "       [0.58816135],\n",
       "       [0.599026  ],\n",
       "       [0.607449  ],\n",
       "       [0.61432142],\n",
       "       [0.62008528],\n",
       "       [0.61889417],\n",
       "       [0.61858937],\n",
       "       [0.61777159],\n",
       "       [0.61724549],\n",
       "       [0.61660721],\n",
       "       [0.62626652],\n",
       "       [0.61560755],\n",
       "       [0.60540748],\n",
       "       [0.59414255],\n",
       "       [0.58418665],\n",
       "       [0.57155519],\n",
       "       [0.56028554],\n",
       "       [0.54971467],\n",
       "       [0.53983111],\n",
       "       [0.5306744 ],\n",
       "       [0.5119707 ],\n",
       "       [0.49542636],\n",
       "       [0.48160811],\n",
       "       [0.47045801],\n",
       "       [0.46469434],\n",
       "       [0.45971182],\n",
       "       [0.45298747],\n",
       "       [0.4470834 ],\n",
       "       [0.44104954],\n",
       "       [0.43476263],\n",
       "       [0.42873935],\n",
       "       [0.42398175],\n",
       "       [0.41862838],\n",
       "       [0.41263778],\n",
       "       [0.40267405],\n",
       "       [0.39262825],\n",
       "       [0.38497794],\n",
       "       [0.37709914],\n",
       "       [0.36988121],\n",
       "       [0.36853129],\n",
       "       [0.3659459 ],\n",
       "       [0.36283429],\n",
       "       [0.35916284],\n",
       "       [0.35515842],\n",
       "       [0.35538029],\n",
       "       [0.3536237 ],\n",
       "       [0.351206  ],\n",
       "       [0.34958911],\n",
       "       [0.34721416],\n",
       "       [0.33963246],\n",
       "       [0.33274737],\n",
       "       [0.32666041],\n",
       "       [0.32184053],\n",
       "       [0.31728282],\n",
       "       [0.3086744 ],\n",
       "       [0.3015094 ],\n",
       "       [0.29578209],\n",
       "       [0.28989963],\n",
       "       [0.2838499 ],\n",
       "       [0.29027263],\n",
       "       [0.29685106],\n",
       "       [0.30235813],\n",
       "       [0.30717705],\n",
       "       [0.31165231],\n",
       "       [0.31523378],\n",
       "       [0.3187683 ],\n",
       "       [0.32148465],\n",
       "       [0.32421478],\n",
       "       [0.3278364 ],\n",
       "       [0.31891415],\n",
       "       [0.30978168],\n",
       "       [0.30071017],\n",
       "       [0.29213794],\n",
       "       [0.28366778],\n",
       "       [0.2852682 ],\n",
       "       [0.28619667],\n",
       "       [0.28596915],\n",
       "       [0.28574716],\n",
       "       [0.28379022],\n",
       "       [0.28273756],\n",
       "       [0.28180797],\n",
       "       [0.28156337],\n",
       "       [0.28210942],\n",
       "       [0.28280547],\n",
       "       [0.27390421],\n",
       "       [0.26582445],\n",
       "       [0.25834217],\n",
       "       [0.2512658 ],\n",
       "       [0.2461983 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_setY_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5df2b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and remaining data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(dataset_train_scaled, training_setY_scaled, test_size=0.3,shuffle=False, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4c4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the remaining data into validation and testing sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5,shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79d9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.46714587, 0.62600255, 0.70547366, 0.35846986],\n",
       "       [0.4637791 , 0.62283866, 0.70320174, 0.36007351],\n",
       "       [0.45968124, 0.61891729, 0.70050831, 0.36243047]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c995b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439, 4)\n",
      "(439, 1)\n",
      "(94, 4)\n",
      "(94, 1)\n",
      "(95, 4)\n",
      "(95, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape),print(X_val.shape), print(y_val.shape),print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3049b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[:, 0:1]  \n",
    "X_train2 = X_train[:, 1:2]  \n",
    "X_train3 = X_train[:, 2:3]  \n",
    "X_train4 = X_train[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587ba546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test[:, 0:1]  \n",
    "X_test2 = X_test[:, 1:2]  \n",
    "X_test3 = X_test[:, 2:3]  \n",
    "X_test4 = X_test[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val1 = X_val[:, 0:1]  \n",
    "X_val2 = X_val[:, 1:2]  \n",
    "X_val3 = X_val[:, 2:3]  \n",
    "X_val4 = X_val[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8dc2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e1f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70a93138",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_1 =(X_train1.shape[1], 1)\n",
    "input_shape_2 = (X_train2.shape[1], 1)\n",
    "input_shape_3 =(X_train3.shape[1], 1)\n",
    "input_shape_4 = (X_train4.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "227c1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e1985e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=input_shape_1)\n",
    "input_2 = Input(shape=input_shape_2)\n",
    "input_3 = Input(shape=input_shape_3)\n",
    "input_4 = Input(shape=input_shape_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d65e875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "print(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "280d7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92d31ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.01\n",
    "decay_rate = 0.99\n",
    "decay_steps = 10000\n",
    "\n",
    "class LearningRateUpdater(Callback):\n",
    "    def __init__(self, initial_lr, decay_rate, decay_steps):\n",
    "        super(LearningRateUpdater, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.initial_lr * math.pow(self.decay_rate, (epoch + 1) // self.decay_steps)\n",
    "        self.model.optimizer.lr.assign(lr)\n",
    "        print(\"Learning rate updated to:\", lr)\n",
    "\n",
    "\n",
    "# Create the optimizer with the initial learning rate\n",
    "optimizer = Adam(learning_rate=initial_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the learning rate updater callback\n",
    "lr_updater_callback = LearningRateUpdater(initial_lr, decay_rate, decay_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2172067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_scheduler(epoch, lr):\n",
    "#     if epoch % 10000 == 0 and epoch > 0:\n",
    "#         lr *= 0.99\n",
    "#     return lr\n",
    "# def lr_scheduler(epoch, lr):\n",
    "        \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_lr, decay_steps=decay_steps, decay_rate=decay_rate, staircase=False)\n",
    "\n",
    "\n",
    "#lr_scheduler_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "173facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dc576e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        print(f'\\nLearning rate after epoch {epoch} is {lr:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "466e2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5ce23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/18 [>.............................] - ETA: 48s - loss: 0.6074 - mae: 0.3540\n",
      "Learning rate after epoch 0 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 4s 51ms/step - loss: 0.4256 - mae: 0.1636 - val_loss: 0.3373 - val_mae: 0.1474\n",
      "Epoch 2/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.3203 - mae: 0.1056\n",
      "Learning rate after epoch 1 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2602 - mae: 0.0752 - val_loss: 0.2246 - val_mae: 0.1455\n",
      "Epoch 3/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.1960 - mae: 0.0428\n",
      "Learning rate after epoch 2 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1613 - mae: 0.0721 - val_loss: 0.1419 - val_mae: 0.1476\n",
      "Epoch 4/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.1221 - mae: 0.0803\n",
      "Learning rate after epoch 3 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0960 - mae: 0.0618 - val_loss: 0.0963 - val_mae: 0.1525\n",
      "Epoch 5/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0725 - mae: 0.0514\n",
      "Learning rate after epoch 4 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0646 - mae: 0.0675 - val_loss: 0.0770 - val_mae: 0.1612\n",
      "Epoch 6/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0553 - mae: 0.0763\n",
      "Learning rate after epoch 5 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 0.0730 - val_loss: 0.0616 - val_mae: 0.1573\n",
      "Epoch 7/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0362 - mae: 0.0411\n",
      "Learning rate after epoch 6 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.0620 - val_loss: 0.0484 - val_mae: 0.1507\n",
      "Epoch 8/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0250 - mae: 0.0563\n",
      "Learning rate after epoch 7 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.0592 - val_loss: 0.0433 - val_mae: 0.1511\n",
      "Epoch 9/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0202 - mae: 0.0543\n",
      "Learning rate after epoch 8 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0668 - val_loss: 0.0390 - val_mae: 0.1502\n",
      "Epoch 10/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0154 - mae: 0.0537\n",
      "Learning rate after epoch 9 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0659 - val_loss: 0.0362 - val_mae: 0.1448\n",
      "Epoch 11/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0149 - mae: 0.0697\n",
      "Learning rate after epoch 10 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0594 - val_loss: 0.0351 - val_mae: 0.1480\n",
      "Epoch 12/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0134 - mae: 0.0693\n",
      "Learning rate after epoch 11 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0567 - val_loss: 0.0341 - val_mae: 0.1490\n",
      "Epoch 13/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0146 - mae: 0.0691\n",
      "Learning rate after epoch 12 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0644 - val_loss: 0.0338 - val_mae: 0.1442\n",
      "Epoch 14/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0398\n",
      "Learning rate after epoch 13 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0605 - val_loss: 0.0336 - val_mae: 0.1453\n",
      "Epoch 15/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0265\n",
      "Learning rate after epoch 14 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0451 - val_loss: 0.0323 - val_mae: 0.1500\n",
      "Epoch 16/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0555\n",
      "Learning rate after epoch 15 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0592 - val_loss: 0.0326 - val_mae: 0.1450\n",
      "Epoch 17/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0103 - mae: 0.0638\n",
      "Learning rate after epoch 16 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0581 - val_loss: 0.0317 - val_mae: 0.1495\n",
      "Epoch 18/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0465\n",
      "Learning rate after epoch 17 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0495 - val_loss: 0.0311 - val_mae: 0.1401\n",
      "Epoch 19/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0114 - mae: 0.0699\n",
      "Learning rate after epoch 18 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0551 - val_loss: 0.0321 - val_mae: 0.1367\n",
      "Epoch 20/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0131 - mae: 0.0758\n",
      "Learning rate after epoch 19 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0565 - val_loss: 0.0315 - val_mae: 0.1474\n",
      "Epoch 21/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0407\n",
      "Learning rate after epoch 20 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0488 - val_loss: 0.0311 - val_mae: 0.1471\n",
      "Epoch 22/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0368\n",
      "Learning rate after epoch 21 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0525 - val_loss: 0.0297 - val_mae: 0.1471\n",
      "Epoch 23/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0414\n",
      "Learning rate after epoch 22 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0544 - val_loss: 0.0298 - val_mae: 0.1471\n",
      "Epoch 24/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0492\n",
      "Learning rate after epoch 23 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0463 - val_loss: 0.0297 - val_mae: 0.1468\n",
      "Epoch 25/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0138 - mae: 0.0879\n",
      "Learning rate after epoch 24 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0564 - val_loss: 0.0281 - val_mae: 0.1432\n",
      "Epoch 26/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0165 - mae: 0.0991\n",
      "Learning rate after epoch 25 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0607 - val_loss: 0.0278 - val_mae: 0.1413\n",
      "Epoch 27/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0629\n",
      "Learning rate after epoch 26 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0609 - val_loss: 0.0233 - val_mae: 0.1281\n",
      "Epoch 28/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0445\n",
      "Learning rate after epoch 27 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0563 - val_loss: 0.0271 - val_mae: 0.1168\n",
      "Epoch 29/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0473\n",
      "Learning rate after epoch 28 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0504 - val_loss: 0.0268 - val_mae: 0.1378\n",
      "Epoch 30/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0413\n",
      "Learning rate after epoch 29 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0563 - val_loss: 0.0279 - val_mae: 0.1421\n",
      "Epoch 31/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0301\n",
      "Learning rate after epoch 30 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0439 - val_loss: 0.0155 - val_mae: 0.0993\n",
      "Epoch 32/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0321\n",
      "Learning rate after epoch 31 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0503 - val_loss: 0.0136 - val_mae: 0.0861\n",
      "Epoch 33/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0532\n",
      "Learning rate after epoch 32 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0520 - val_loss: 0.0263 - val_mae: 0.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0545\n",
      "Learning rate after epoch 33 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0518 - val_loss: 0.0246 - val_mae: 0.1343\n",
      "Epoch 35/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0390\n",
      "Learning rate after epoch 34 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0462 - val_loss: 0.0363 - val_mae: 0.1508\n",
      "Epoch 36/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0585\n",
      "Learning rate after epoch 35 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0592 - val_loss: 0.0272 - val_mae: 0.1351\n",
      "Epoch 37/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0326\n",
      "Learning rate after epoch 36 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0408 - val_loss: 0.0174 - val_mae: 0.1077\n",
      "Epoch 38/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0299\n",
      "Learning rate after epoch 37 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0595 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 39/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0459\n",
      "Learning rate after epoch 38 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0500 - val_loss: 0.0206 - val_mae: 0.1072\n",
      "Epoch 40/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0513\n",
      "Learning rate after epoch 39 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0561 - val_loss: 0.0652 - val_mae: 0.2396\n",
      "Epoch 41/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0518\n",
      "Learning rate after epoch 40 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0502 - val_loss: 0.0506 - val_mae: 0.1903\n",
      "Epoch 42/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0725\n",
      "Learning rate after epoch 41 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0585 - val_loss: 0.1227 - val_mae: 0.3333\n",
      "Epoch 43/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0444\n",
      "Learning rate after epoch 42 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0443 - val_loss: 0.1678 - val_mae: 0.3840\n",
      "Epoch 44/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0358\n",
      "Learning rate after epoch 43 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0567 - val_loss: 0.2012 - val_mae: 0.4201\n",
      "Epoch 45/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0633\n",
      "Learning rate after epoch 44 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0479 - val_loss: 0.1430 - val_mae: 0.3569\n",
      "Epoch 46/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0379\n",
      "Learning rate after epoch 45 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0551 - val_loss: 0.0446 - val_mae: 0.1905\n",
      "Epoch 47/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0560\n",
      "Learning rate after epoch 46 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0531 - val_loss: 0.0101 - val_mae: 0.0725\n",
      "Epoch 48/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0353\n",
      "Learning rate after epoch 47 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0453 - val_loss: 0.0248 - val_mae: 0.1299\n",
      "Epoch 49/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0265\n",
      "Learning rate after epoch 48 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0482 - val_loss: 0.0064 - val_mae: 0.0404\n",
      "Epoch 50/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0285\n",
      "Learning rate after epoch 49 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0545 - val_loss: 0.0535 - val_mae: 0.2198\n",
      "Epoch 51/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0450\n",
      "Learning rate after epoch 50 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0563 - val_loss: 0.0458 - val_mae: 0.1867\n",
      "Epoch 52/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0630\n",
      "Learning rate after epoch 51 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0461 - val_loss: 0.0503 - val_mae: 0.2077\n",
      "Epoch 53/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0550\n",
      "Learning rate after epoch 52 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0412 - val_loss: 0.0205 - val_mae: 0.1088\n",
      "Epoch 54/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0591\n",
      "Learning rate after epoch 53 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0487 - val_loss: 0.0256 - val_mae: 0.1064\n",
      "Epoch 55/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0392\n",
      "Learning rate after epoch 54 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.0739 - val_loss: 0.2228 - val_mae: 0.3600\n",
      "Epoch 56/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0806 - mae: 0.0386\n",
      "Learning rate after epoch 55 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1246 - mae: 0.0601 - val_loss: 0.3679 - val_mae: 0.4778\n",
      "Epoch 57/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.1270 - mae: 0.0286\n",
      "Learning rate after epoch 56 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1131 - mae: 0.0469 - val_loss: 0.2002 - val_mae: 0.3317\n",
      "Epoch 58/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.1077 - mae: 0.1194\n",
      "Learning rate after epoch 57 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0799 - mae: 0.0591 - val_loss: 0.0652 - val_mae: 0.0756\n",
      "Epoch 59/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0607 - mae: 0.0380\n",
      "Learning rate after epoch 58 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0534 - mae: 0.0515 - val_loss: 0.0549 - val_mae: 0.0824\n",
      "Epoch 60/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0465 - mae: 0.0699\n",
      "Learning rate after epoch 59 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0408 - mae: 0.0635 - val_loss: 0.0501 - val_mae: 0.1242\n",
      "Epoch 61/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0406 - mae: 0.0959\n",
      "Learning rate after epoch 60 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.0564 - val_loss: 0.0401 - val_mae: 0.1287\n",
      "Epoch 62/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0247 - mae: 0.0436\n",
      "Learning rate after epoch 61 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.0547 - val_loss: 0.0394 - val_mae: 0.1425\n",
      "Epoch 63/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0186 - mae: 0.0372\n",
      "Learning rate after epoch 62 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0499 - val_loss: 0.0422 - val_mae: 0.1548\n",
      "Epoch 64/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0251 - mae: 0.0933\n",
      "Learning rate after epoch 63 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0566 - val_loss: 0.0377 - val_mae: 0.1375\n",
      "Epoch 65/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0147 - mae: 0.0332\n",
      "Learning rate after epoch 64 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0502 - val_loss: 0.0347 - val_mae: 0.1482\n",
      "Epoch 66/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.0385\n",
      "Learning rate after epoch 65 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0515 - val_loss: 0.0319 - val_mae: 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0182 - mae: 0.0791\n",
      "Learning rate after epoch 66 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0575 - val_loss: 0.0299 - val_mae: 0.1304\n",
      "Epoch 68/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0144 - mae: 0.0684\n",
      "Learning rate after epoch 67 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0591 - val_loss: 0.0346 - val_mae: 0.1241\n",
      "Epoch 69/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0137 - mae: 0.0661\n",
      "Learning rate after epoch 68 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0520 - val_loss: 0.0478 - val_mae: 0.1473\n",
      "Epoch 70/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0398\n",
      "Learning rate after epoch 69 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0446 - val_loss: 0.0617 - val_mae: 0.1889\n",
      "Epoch 71/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0552\n",
      "Learning rate after epoch 70 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0517 - val_loss: 0.0674 - val_mae: 0.2095\n",
      "Epoch 72/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0161 - mae: 0.0836\n",
      "Learning rate after epoch 71 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0541 - val_loss: 0.0491 - val_mae: 0.1663\n",
      "Epoch 73/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0439\n",
      "Learning rate after epoch 72 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0485 - val_loss: 0.0655 - val_mae: 0.2044\n",
      "Epoch 74/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0440\n",
      "Learning rate after epoch 73 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0475 - val_loss: 0.0820 - val_mae: 0.2432\n",
      "Epoch 75/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0652\n",
      "Learning rate after epoch 74 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0544 - val_loss: 0.0994 - val_mae: 0.2774\n",
      "Epoch 76/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0281\n",
      "Learning rate after epoch 75 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0571 - val_loss: 0.1209 - val_mae: 0.3132\n",
      "Epoch 77/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0512\n",
      "Learning rate after epoch 76 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0561 - val_loss: 0.1665 - val_mae: 0.3719\n",
      "Epoch 78/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0162 - mae: 0.0861\n",
      "Learning rate after epoch 77 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0627 - val_loss: 0.1614 - val_mae: 0.3759\n",
      "Epoch 79/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0600\n",
      "Learning rate after epoch 78 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0462 - val_loss: 0.2460 - val_mae: 0.4686\n",
      "Epoch 80/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0441\n",
      "Learning rate after epoch 79 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0485 - val_loss: 0.2571 - val_mae: 0.4770\n",
      "Epoch 81/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0431\n",
      "Learning rate after epoch 80 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0473 - val_loss: 0.2114 - val_mae: 0.4302\n",
      "Epoch 82/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0523\n",
      "Learning rate after epoch 81 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0621 - val_loss: 0.0815 - val_mae: 0.2574\n",
      "Epoch 83/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0453\n",
      "Learning rate after epoch 82 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0560 - val_loss: 0.0413 - val_mae: 0.1595\n",
      "Epoch 84/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0680\n",
      "Learning rate after epoch 83 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0541 - val_loss: 0.0133 - val_mae: 0.0872\n",
      "Epoch 85/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0528\n",
      "Learning rate after epoch 84 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0488 - val_loss: 0.0107 - val_mae: 0.0708\n",
      "Epoch 86/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0327\n",
      "Learning rate after epoch 85 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0530 - val_loss: 0.0172 - val_mae: 0.0873\n",
      "Epoch 87/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0502\n",
      "Learning rate after epoch 86 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0468 - val_loss: 0.0354 - val_mae: 0.1326\n",
      "Epoch 88/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0415\n",
      "Learning rate after epoch 87 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0527 - val_loss: 0.0231 - val_mae: 0.0987\n",
      "Epoch 89/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0326\n",
      "Learning rate after epoch 88 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0488 - val_loss: 0.0125 - val_mae: 0.0762\n",
      "Epoch 90/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0424\n",
      "Learning rate after epoch 89 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0592 - val_loss: 0.0343 - val_mae: 0.1343\n",
      "Epoch 91/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0360\n",
      "Learning rate after epoch 90 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0520 - val_loss: 0.0933 - val_mae: 0.2844\n",
      "Epoch 92/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0273\n",
      "Learning rate after epoch 91 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0515 - val_loss: 0.0625 - val_mae: 0.2284\n",
      "Epoch 93/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0505\n",
      "Learning rate after epoch 92 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0458 - val_loss: 0.0066 - val_mae: 0.0371\n",
      "Epoch 94/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0313\n",
      "Learning rate after epoch 93 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0523 - val_loss: 0.0745 - val_mae: 0.2597\n",
      "Epoch 95/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0139 - mae: 0.0870\n",
      "Learning rate after epoch 94 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0545 - val_loss: 0.1640 - val_mae: 0.3855\n",
      "Epoch 96/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0164 - mae: 0.0967\n",
      "Learning rate after epoch 95 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0525 - val_loss: 0.0324 - val_mae: 0.1491\n",
      "Epoch 97/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0372\n",
      "Learning rate after epoch 96 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0457 - val_loss: 0.0371 - val_mae: 0.1716\n",
      "Epoch 98/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0373\n",
      "Learning rate after epoch 97 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0528 - val_loss: 0.0180 - val_mae: 0.1054\n",
      "Epoch 99/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0514\n",
      "Learning rate after epoch 98 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0501 - val_loss: 0.0123 - val_mae: 0.0846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0153 - mae: 0.0970\n",
      "Learning rate after epoch 99 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0519 - val_loss: 0.0463 - val_mae: 0.1977\n",
      "Epoch 101/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0523\n",
      "Learning rate after epoch 100 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0513 - val_loss: 0.0254 - val_mae: 0.1221\n",
      "Epoch 102/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0603\n",
      "Learning rate after epoch 101 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0593 - val_loss: 0.0456 - val_mae: 0.2012\n",
      "Epoch 103/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0134 - mae: 0.0864\n",
      "Learning rate after epoch 102 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0620 - val_loss: 0.0308 - val_mae: 0.1570\n",
      "Epoch 104/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0390\n",
      "Learning rate after epoch 103 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0528 - val_loss: 0.0050 - val_mae: 0.0075\n",
      "Epoch 105/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0336\n",
      "Learning rate after epoch 104 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0477 - val_loss: 0.0068 - val_mae: 0.0464\n",
      "Epoch 106/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0417\n",
      "Learning rate after epoch 105 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0496 - val_loss: 0.0096 - val_mae: 0.0665\n",
      "Epoch 107/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0650\n",
      "Learning rate after epoch 106 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0551 - val_loss: 0.0077 - val_mae: 0.0486\n",
      "Epoch 108/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0708\n",
      "Learning rate after epoch 107 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0679 - val_loss: 0.0532 - val_mae: 0.2181\n",
      "Epoch 109/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0119 - mae: 0.0749\n",
      "Learning rate after epoch 108 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0571 - val_loss: 0.1255 - val_mae: 0.3265\n",
      "Epoch 110/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0313\n",
      "Learning rate after epoch 109 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0498 - val_loss: 0.1315 - val_mae: 0.3450\n",
      "Epoch 111/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0414\n",
      "Learning rate after epoch 110 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0483 - val_loss: 0.0413 - val_mae: 0.1727\n",
      "Epoch 112/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0443\n",
      "Learning rate after epoch 111 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0516 - val_loss: 0.0639 - val_mae: 0.2400\n",
      "Epoch 113/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0874\n",
      "Learning rate after epoch 112 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0501 - val_loss: 0.0302 - val_mae: 0.1531\n",
      "Epoch 114/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0654\n",
      "Learning rate after epoch 113 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0564 - val_loss: 0.0219 - val_mae: 0.1195\n",
      "Epoch 115/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0560\n",
      "Learning rate after epoch 114 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0524 - val_loss: 0.0082 - val_mae: 0.0577\n",
      "Epoch 116/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0374\n",
      "Learning rate after epoch 115 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0570 - val_loss: 0.0099 - val_mae: 0.0740\n",
      "Epoch 117/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0431\n",
      "Learning rate after epoch 116 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0534 - val_loss: 0.0071 - val_mae: 0.0489\n",
      "Epoch 118/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0574\n",
      "Learning rate after epoch 117 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0568 - val_loss: 0.0128 - val_mae: 0.0745\n",
      "Epoch 119/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0685\n",
      "Learning rate after epoch 118 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0496 - val_loss: 0.0144 - val_mae: 0.0779\n",
      "Epoch 120/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0298\n",
      "Learning rate after epoch 119 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0461 - val_loss: 0.0073 - val_mae: 0.0521\n",
      "Epoch 121/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0400\n",
      "Learning rate after epoch 120 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0573 - val_loss: 0.0224 - val_mae: 0.1240\n",
      "Epoch 122/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0132 - mae: 0.0865\n",
      "Learning rate after epoch 121 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0525 - val_loss: 0.0299 - val_mae: 0.1299\n",
      "Epoch 123/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0298\n",
      "Learning rate after epoch 122 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0524 - val_loss: 0.0089 - val_mae: 0.0655\n",
      "Epoch 124/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0374\n",
      "Learning rate after epoch 123 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0518 - val_loss: 0.0191 - val_mae: 0.1091\n",
      "Epoch 125/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0601\n",
      "Learning rate after epoch 124 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0520 - val_loss: 0.0152 - val_mae: 0.0920\n",
      "Epoch 126/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0692\n",
      "Learning rate after epoch 125 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0586 - val_loss: 0.0193 - val_mae: 0.1153\n",
      "Epoch 127/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0140 - mae: 0.0770\n",
      "Learning rate after epoch 126 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0479 - val_loss: 0.0446 - val_mae: 0.1974\n",
      "Epoch 128/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0317\n",
      "Learning rate after epoch 127 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0597 - val_loss: 0.0648 - val_mae: 0.2245\n",
      "Epoch 129/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0496\n",
      "Learning rate after epoch 128 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0466 - val_loss: 0.0255 - val_mae: 0.1121\n",
      "Epoch 130/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0277\n",
      "Learning rate after epoch 129 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0477 - val_loss: 0.0111 - val_mae: 0.0645\n",
      "Epoch 131/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0444\n",
      "Learning rate after epoch 130 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0515 - val_loss: 0.0138 - val_mae: 0.0678\n",
      "Epoch 132/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0381\n",
      "Learning rate after epoch 131 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0461 - val_loss: 0.0126 - val_mae: 0.0823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0541\n",
      "Learning rate after epoch 132 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0486 - val_loss: 0.0178 - val_mae: 0.1050\n",
      "Epoch 134/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0142 - mae: 0.0935\n",
      "Learning rate after epoch 133 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0548 - val_loss: 0.0240 - val_mae: 0.1214\n",
      "Epoch 135/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0319\n",
      "Learning rate after epoch 134 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0441 - val_loss: 0.0207 - val_mae: 0.1121\n",
      "Epoch 136/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0293\n",
      "Learning rate after epoch 135 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0498 - val_loss: 0.0221 - val_mae: 0.1325\n",
      "Epoch 137/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0353\n",
      "Learning rate after epoch 136 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0604 - val_loss: 0.0116 - val_mae: 0.0631\n",
      "Epoch 138/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0519\n",
      "Learning rate after epoch 137 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0482 - val_loss: 0.0162 - val_mae: 0.0774\n",
      "Epoch 139/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0379\n",
      "Learning rate after epoch 138 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0546 - val_loss: 0.0181 - val_mae: 0.0907\n",
      "Epoch 140/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0439\n",
      "Learning rate after epoch 139 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0539 - val_loss: 0.1110 - val_mae: 0.3183\n",
      "Epoch 141/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0495\n",
      "Learning rate after epoch 140 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0415 - val_loss: 0.1503 - val_mae: 0.3640\n",
      "Epoch 142/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0129 - mae: 0.0796\n",
      "Learning rate after epoch 141 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0509 - val_loss: 0.1011 - val_mae: 0.2912\n",
      "Epoch 143/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0772\n",
      "Learning rate after epoch 142 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0561 - val_loss: 0.0569 - val_mae: 0.2197\n",
      "Epoch 144/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0606\n",
      "Learning rate after epoch 143 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0524 - val_loss: 0.2357 - val_mae: 0.4588\n",
      "Epoch 145/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0437\n",
      "Learning rate after epoch 144 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0482 - val_loss: 0.2055 - val_mae: 0.4216\n",
      "Epoch 146/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0484\n",
      "Learning rate after epoch 145 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0429 - val_loss: 0.1987 - val_mae: 0.4091\n",
      "Epoch 147/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0267\n",
      "Learning rate after epoch 146 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0545 - val_loss: 0.1334 - val_mae: 0.3432\n",
      "Epoch 148/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0467\n",
      "Learning rate after epoch 147 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0426 - val_loss: 0.0182 - val_mae: 0.0854\n",
      "Epoch 149/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0699\n",
      "Learning rate after epoch 148 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0093 - val_mae: 0.0669\n",
      "Epoch 150/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0466\n",
      "Learning rate after epoch 149 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0503 - val_loss: 0.0073 - val_mae: 0.0445\n",
      "Epoch 151/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0674\n",
      "Learning rate after epoch 150 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0477 - val_loss: 0.0077 - val_mae: 0.0533\n",
      "Epoch 152/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0502\n",
      "Learning rate after epoch 151 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0921\n",
      "Epoch 153/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0161 - mae: 0.0999\n",
      "Learning rate after epoch 152 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0536 - val_loss: 0.0101 - val_mae: 0.0716\n",
      "Epoch 154/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0499\n",
      "Learning rate after epoch 153 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0484 - val_loss: 0.0081 - val_mae: 0.0464\n",
      "Epoch 155/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0655\n",
      "Learning rate after epoch 154 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0500 - val_loss: 0.0058 - val_mae: 0.0302\n",
      "Epoch 156/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0168 - mae: 0.1057\n",
      "Learning rate after epoch 155 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0518 - val_loss: 0.0064 - val_mae: 0.0328\n",
      "Epoch 157/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0339\n",
      "Learning rate after epoch 156 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0562 - val_loss: 0.1047 - val_mae: 0.3104\n",
      "Epoch 158/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0361\n",
      "Learning rate after epoch 157 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0537 - val_loss: 0.0984 - val_mae: 0.3018\n",
      "Epoch 159/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0502\n",
      "Learning rate after epoch 158 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0546 - val_loss: 0.0964 - val_mae: 0.2922\n",
      "Epoch 160/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0488\n",
      "Learning rate after epoch 159 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0508 - val_loss: 0.0810 - val_mae: 0.2602\n",
      "Epoch 161/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0438\n",
      "Learning rate after epoch 160 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0558 - val_loss: 0.1254 - val_mae: 0.3366\n",
      "Epoch 162/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0543\n",
      "Learning rate after epoch 161 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0376 - val_loss: 0.0157 - val_mae: 0.0759\n",
      "Epoch 163/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0309\n",
      "Learning rate after epoch 162 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0466 - val_loss: 0.0229 - val_mae: 0.1182\n",
      "Epoch 164/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0620\n",
      "Learning rate after epoch 163 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0454 - val_loss: 0.0390 - val_mae: 0.1543\n",
      "Epoch 165/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0186 - mae: 0.1105\n",
      "Learning rate after epoch 164 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0529 - val_loss: 0.0572 - val_mae: 0.2268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0233\n",
      "Learning rate after epoch 165 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0460 - val_loss: 0.0462 - val_mae: 0.1977\n",
      "Epoch 167/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0413\n",
      "Learning rate after epoch 166 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0545 - val_loss: 0.0399 - val_mae: 0.1796\n",
      "Epoch 168/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0583\n",
      "Learning rate after epoch 167 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0488 - val_loss: 0.2749 - val_mae: 0.4946\n",
      "Epoch 169/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0540\n",
      "Learning rate after epoch 168 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0507 - val_loss: 0.1862 - val_mae: 0.3978\n",
      "Epoch 170/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0452\n",
      "Learning rate after epoch 169 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0428 - val_loss: 0.2756 - val_mae: 0.4953\n",
      "Epoch 171/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0437\n",
      "Learning rate after epoch 170 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0429 - val_loss: 0.1384 - val_mae: 0.3376\n",
      "Epoch 172/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0338\n",
      "Learning rate after epoch 171 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0483 - val_loss: 0.2617 - val_mae: 0.4735\n",
      "Epoch 173/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0264\n",
      "Learning rate after epoch 172 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0638 - val_loss: 0.2279 - val_mae: 0.4411\n",
      "Epoch 174/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0349\n",
      "Learning rate after epoch 173 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0501 - val_loss: 0.2319 - val_mae: 0.4476\n",
      "Epoch 175/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0301\n",
      "Learning rate after epoch 174 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0481 - val_loss: 0.0368 - val_mae: 0.1714\n",
      "Epoch 176/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0544\n",
      "Learning rate after epoch 175 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0524 - val_loss: 0.0164 - val_mae: 0.1020\n",
      "Epoch 177/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0199\n",
      "Learning rate after epoch 176 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0471 - val_loss: 0.0075 - val_mae: 0.0519\n",
      "Epoch 178/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0373\n",
      "Learning rate after epoch 177 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0544 - val_loss: 0.0060 - val_mae: 0.0338\n",
      "Epoch 179/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0692\n",
      "Learning rate after epoch 178 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0498 - val_loss: 0.0183 - val_mae: 0.1091\n",
      "Epoch 180/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0419\n",
      "Learning rate after epoch 179 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0483 - val_loss: 0.0291 - val_mae: 0.1155\n",
      "Epoch 181/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0360\n",
      "Learning rate after epoch 180 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0519 - val_loss: 0.0534 - val_mae: 0.2152\n",
      "Epoch 182/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0469\n",
      "Learning rate after epoch 181 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0474 - val_loss: 0.0101 - val_mae: 0.0733\n",
      "Epoch 183/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0433\n",
      "Learning rate after epoch 182 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0433 - val_loss: 0.0145 - val_mae: 0.0746\n",
      "Epoch 184/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0357\n",
      "Learning rate after epoch 183 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0466 - val_loss: 0.0173 - val_mae: 0.0943\n",
      "Epoch 185/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0485\n",
      "Learning rate after epoch 184 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0518 - val_loss: 0.0491 - val_mae: 0.1881\n",
      "Epoch 186/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0446\n",
      "Learning rate after epoch 185 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0475 - val_loss: 0.0554 - val_mae: 0.2038\n",
      "Epoch 187/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0717\n",
      "Learning rate after epoch 186 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0545 - val_loss: 0.0529 - val_mae: 0.1993\n",
      "Epoch 188/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0376\n",
      "Learning rate after epoch 187 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0500 - val_loss: 0.0779 - val_mae: 0.2542\n",
      "Epoch 189/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0417\n",
      "Learning rate after epoch 188 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0498 - val_loss: 0.1046 - val_mae: 0.3007\n",
      "Epoch 190/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0405\n",
      "Learning rate after epoch 189 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0480 - val_loss: 0.0524 - val_mae: 0.2043\n",
      "Epoch 191/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0336\n",
      "Learning rate after epoch 190 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0434 - val_loss: 0.0612 - val_mae: 0.2120\n",
      "Epoch 192/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0460\n",
      "Learning rate after epoch 191 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0561 - val_loss: 0.0232 - val_mae: 0.1044\n",
      "Epoch 193/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0353\n",
      "Learning rate after epoch 192 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0527 - val_loss: 0.0344 - val_mae: 0.1527\n",
      "Epoch 194/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0114 - mae: 0.0656\n",
      "Learning rate after epoch 193 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0566 - val_loss: 0.0446 - val_mae: 0.1809\n",
      "Epoch 195/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0501\n",
      "Learning rate after epoch 194 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0489 - val_loss: 0.0460 - val_mae: 0.1937\n",
      "Epoch 196/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0375\n",
      "Learning rate after epoch 195 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0551 - val_loss: 0.0539 - val_mae: 0.2019\n",
      "Epoch 197/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0437\n",
      "Learning rate after epoch 196 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0536 - val_loss: 0.0246 - val_mae: 0.1096\n",
      "Epoch 198/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0347\n",
      "Learning rate after epoch 197 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0438 - val_loss: 0.0131 - val_mae: 0.0655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0448\n",
      "Learning rate after epoch 198 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0746\n",
      "Epoch 200/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0438\n",
      "Learning rate after epoch 199 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0460 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 201/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0339\n",
      "Learning rate after epoch 200 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0492 - val_loss: 0.0793 - val_mae: 0.2479\n",
      "Epoch 202/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0545\n",
      "Learning rate after epoch 201 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0439 - val_loss: 0.1276 - val_mae: 0.3234\n",
      "Epoch 203/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0482\n",
      "Learning rate after epoch 202 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0551 - val_loss: 0.0098 - val_mae: 0.0629\n",
      "Epoch 204/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0326\n",
      "Learning rate after epoch 203 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0511 - val_loss: 0.0228 - val_mae: 0.1282\n",
      "Epoch 205/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0235\n",
      "Learning rate after epoch 204 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0553 - val_loss: 0.0138 - val_mae: 0.0731\n",
      "Epoch 206/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0736\n",
      "Learning rate after epoch 205 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0439 - val_loss: 0.0191 - val_mae: 0.0880\n",
      "Epoch 207/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0119 - mae: 0.0811\n",
      "Learning rate after epoch 206 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0526 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 208/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0448\n",
      "Learning rate after epoch 207 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0480 - val_loss: 0.0136 - val_mae: 0.0714\n",
      "Epoch 209/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0354\n",
      "Learning rate after epoch 208 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0451 - val_loss: 0.0092 - val_mae: 0.0606\n",
      "Epoch 210/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0131 - mae: 0.0806\n",
      "Learning rate after epoch 209 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0552 - val_loss: 0.0183 - val_mae: 0.1048\n",
      "Epoch 211/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0447\n",
      "Learning rate after epoch 210 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0543 - val_loss: 0.1433 - val_mae: 0.3564\n",
      "Epoch 212/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0497\n",
      "Learning rate after epoch 211 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0595 - val_loss: 0.0837 - val_mae: 0.2755\n",
      "Epoch 213/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0401\n",
      "Learning rate after epoch 212 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0525 - val_loss: 0.0361 - val_mae: 0.1707\n",
      "Epoch 214/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0605\n",
      "Learning rate after epoch 213 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0495 - val_loss: 0.0448 - val_mae: 0.1937\n",
      "Epoch 215/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0350\n",
      "Learning rate after epoch 214 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0461 - val_loss: 0.0108 - val_mae: 0.0705\n",
      "Epoch 216/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0339\n",
      "Learning rate after epoch 215 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0482 - val_loss: 0.0440 - val_mae: 0.1963\n",
      "Epoch 217/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0135 - mae: 0.0832\n",
      "Learning rate after epoch 216 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0544 - val_loss: 0.0118 - val_mae: 0.0773\n",
      "Epoch 218/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0539\n",
      "Learning rate after epoch 217 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0491 - val_loss: 0.0077 - val_mae: 0.0490\n",
      "Epoch 219/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0364\n",
      "Learning rate after epoch 218 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0419 - val_loss: 0.0154 - val_mae: 0.0873\n",
      "Epoch 220/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0155 - mae: 0.0944\n",
      "Learning rate after epoch 219 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0569 - val_loss: 0.0150 - val_mae: 0.0915\n",
      "Epoch 221/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0466\n",
      "Learning rate after epoch 220 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0551 - val_loss: 0.2456 - val_mae: 0.4680\n",
      "Epoch 222/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0289\n",
      "Learning rate after epoch 221 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0543 - val_loss: 0.0221 - val_mae: 0.1163\n",
      "Epoch 223/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0421\n",
      "Learning rate after epoch 222 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0686 - val_loss: 0.1708 - val_mae: 0.4005\n",
      "Epoch 224/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0502\n",
      "Learning rate after epoch 223 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0491 - val_loss: 0.0843 - val_mae: 0.2724\n",
      "Epoch 225/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0447\n",
      "Learning rate after epoch 224 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0503 - val_loss: 0.1142 - val_mae: 0.3180\n",
      "Epoch 226/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0433\n",
      "Learning rate after epoch 225 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0582 - val_loss: 0.2906 - val_mae: 0.5089\n",
      "Epoch 227/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0352\n",
      "Learning rate after epoch 226 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0440 - val_loss: 0.0058 - val_mae: 0.0298\n",
      "Epoch 228/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0376\n",
      "Learning rate after epoch 227 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0562 - val_loss: 0.0111 - val_mae: 0.0683\n",
      "Epoch 229/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0592\n",
      "Learning rate after epoch 228 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0573 - val_loss: 0.0301 - val_mae: 0.1374\n",
      "Epoch 230/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0231\n",
      "Learning rate after epoch 229 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0453 - val_loss: 0.0240 - val_mae: 0.0987\n",
      "Epoch 231/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0510\n",
      "Learning rate after epoch 230 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0570 - val_loss: 0.0300 - val_mae: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0637\n",
      "Learning rate after epoch 231 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0557 - val_loss: 0.1378 - val_mae: 0.3580\n",
      "Epoch 233/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0457\n",
      "Learning rate after epoch 232 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0491 - val_loss: 0.0829 - val_mae: 0.2742\n",
      "Epoch 234/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0361\n",
      "Learning rate after epoch 233 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0424 - val_loss: 0.1628 - val_mae: 0.3825\n",
      "Epoch 235/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0700\n",
      "Learning rate after epoch 234 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0641 - val_loss: 0.3044 - val_mae: 0.5205\n",
      "Epoch 236/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0383\n",
      "Learning rate after epoch 235 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0592 - val_loss: 0.1981 - val_mae: 0.4177\n",
      "Epoch 237/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0298\n",
      "Learning rate after epoch 236 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0541 - val_loss: 0.1718 - val_mae: 0.3963\n",
      "Epoch 238/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0504\n",
      "Learning rate after epoch 237 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0614 - val_loss: 0.1809 - val_mae: 0.4056\n",
      "Epoch 239/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0385\n",
      "Learning rate after epoch 238 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0528 - val_loss: 0.1062 - val_mae: 0.3058\n",
      "Epoch 240/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0306\n",
      "Learning rate after epoch 239 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0473 - val_loss: 0.0777 - val_mae: 0.2586\n",
      "Epoch 241/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0384\n",
      "Learning rate after epoch 240 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0593 - val_loss: 0.1133 - val_mae: 0.3247\n",
      "Epoch 242/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0413\n",
      "Learning rate after epoch 241 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0591 - val_loss: 0.0837 - val_mae: 0.2662\n",
      "Epoch 243/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0369\n",
      "Learning rate after epoch 242 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0644 - val_loss: 0.1423 - val_mae: 0.3667\n",
      "Epoch 244/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0467\n",
      "Learning rate after epoch 243 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0613 - val_loss: 0.1000 - val_mae: 0.3033\n",
      "Epoch 245/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0172 - mae: 0.0970\n",
      "Learning rate after epoch 244 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0483 - val_loss: 0.2440 - val_mae: 0.4625\n",
      "Epoch 246/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0466\n",
      "Learning rate after epoch 245 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0519 - val_loss: 0.2078 - val_mae: 0.4368\n",
      "Epoch 247/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0762\n",
      "Learning rate after epoch 246 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0585 - val_loss: 0.0151 - val_mae: 0.1009\n",
      "Epoch 248/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0130 - mae: 0.0797\n",
      "Learning rate after epoch 247 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0605 - val_loss: 0.0237 - val_mae: 0.1367\n",
      "Epoch 249/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0462\n",
      "Learning rate after epoch 248 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0501 - val_loss: 0.0487 - val_mae: 0.2073\n",
      "Epoch 250/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0362\n",
      "Learning rate after epoch 249 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0445 - val_loss: 0.0498 - val_mae: 0.2029\n",
      "Epoch 251/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0567\n",
      "Learning rate after epoch 250 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0508 - val_loss: 0.0429 - val_mae: 0.1735\n",
      "Epoch 252/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0567\n",
      "Learning rate after epoch 251 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0561 - val_loss: 0.0248 - val_mae: 0.1263\n",
      "Epoch 253/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0409\n",
      "Learning rate after epoch 252 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0528 - val_loss: 0.0240 - val_mae: 0.1247\n",
      "Epoch 254/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0227 - mae: 0.1136\n",
      "Learning rate after epoch 253 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0506 - val_loss: 0.0419 - val_mae: 0.1696\n",
      "Epoch 255/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0350\n",
      "Learning rate after epoch 254 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0592 - val_loss: 0.0097 - val_mae: 0.0637\n",
      "Epoch 256/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0520\n",
      "Learning rate after epoch 255 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0509 - val_loss: 0.0413 - val_mae: 0.1907\n",
      "Epoch 257/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0309\n",
      "Learning rate after epoch 256 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0695 - val_loss: 0.0646 - val_mae: 0.2358\n",
      "Epoch 258/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0293\n",
      "Learning rate after epoch 257 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0463 - val_loss: 0.1453 - val_mae: 0.3646\n",
      "Epoch 259/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0409\n",
      "Learning rate after epoch 258 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0502 - val_loss: 0.0115 - val_mae: 0.0798\n",
      "Epoch 260/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0428\n",
      "Learning rate after epoch 259 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0531 - val_loss: 0.0169 - val_mae: 0.1101\n",
      "Epoch 261/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0111 - mae: 0.0659\n",
      "Learning rate after epoch 260 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0495 - val_loss: 0.0318 - val_mae: 0.1521\n",
      "Epoch 262/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0430\n",
      "Learning rate after epoch 261 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0507 - val_loss: 0.0293 - val_mae: 0.1273\n",
      "Epoch 263/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0369\n",
      "Learning rate after epoch 262 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0491 - val_loss: 0.0267 - val_mae: 0.1182\n",
      "Epoch 264/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0458\n",
      "Learning rate after epoch 263 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0556 - val_loss: 0.0208 - val_mae: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0390\n",
      "Learning rate after epoch 264 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0478 - val_loss: 0.0501 - val_mae: 0.2118\n",
      "Epoch 266/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0502\n",
      "Learning rate after epoch 265 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0473 - val_loss: 0.0594 - val_mae: 0.2235\n",
      "Epoch 267/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0643\n",
      "Learning rate after epoch 266 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0531 - val_loss: 0.0534 - val_mae: 0.2194\n",
      "Epoch 268/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0367\n",
      "Learning rate after epoch 267 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0543 - val_loss: 0.0435 - val_mae: 0.1902\n",
      "Epoch 269/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0370\n",
      "Learning rate after epoch 268 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0486 - val_loss: 0.0410 - val_mae: 0.1787\n",
      "Epoch 270/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0465\n",
      "Learning rate after epoch 269 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0512 - val_loss: 0.0340 - val_mae: 0.1353\n",
      "Epoch 271/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0164 - mae: 0.1041\n",
      "Learning rate after epoch 270 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0566 - val_loss: 0.0139 - val_mae: 0.0702\n",
      "Epoch 272/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0330\n",
      "Learning rate after epoch 271 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0526 - val_loss: 0.0449 - val_mae: 0.1983\n",
      "Epoch 273/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0312\n",
      "Learning rate after epoch 272 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0547 - val_loss: 0.0094 - val_mae: 0.0654\n",
      "Epoch 274/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0583\n",
      "Learning rate after epoch 273 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0506 - val_loss: 0.0107 - val_mae: 0.0674\n",
      "Epoch 275/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0446\n",
      "Learning rate after epoch 274 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0514 - val_loss: 0.0089 - val_mae: 0.0647\n",
      "Epoch 276/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0469\n",
      "Learning rate after epoch 275 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0494 - val_loss: 0.0107 - val_mae: 0.0707\n",
      "Epoch 277/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0409\n",
      "Learning rate after epoch 276 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0512 - val_loss: 0.0076 - val_mae: 0.0446\n",
      "Epoch 278/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0482\n",
      "Learning rate after epoch 277 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0480 - val_loss: 0.0141 - val_mae: 0.0901\n",
      "Epoch 279/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0492\n",
      "Learning rate after epoch 278 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0508 - val_loss: 0.0416 - val_mae: 0.1900\n",
      "Epoch 280/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0451\n",
      "Learning rate after epoch 279 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.2382 - val_mae: 0.4671\n",
      "Epoch 281/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0320\n",
      "Learning rate after epoch 280 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0457 - val_loss: 0.1541 - val_mae: 0.3696\n",
      "Epoch 282/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0735\n",
      "Learning rate after epoch 281 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0491 - val_loss: 0.0103 - val_mae: 0.0559\n",
      "Epoch 283/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0456\n",
      "Learning rate after epoch 282 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0566 - val_loss: 0.0088 - val_mae: 0.0481\n",
      "Epoch 284/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0357\n",
      "Learning rate after epoch 283 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0571 - val_loss: 0.0256 - val_mae: 0.1321\n",
      "Epoch 285/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0447\n",
      "Learning rate after epoch 284 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0453 - val_loss: 0.0245 - val_mae: 0.1153\n",
      "Epoch 286/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0450\n",
      "Learning rate after epoch 285 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0584 - val_loss: 0.0316 - val_mae: 0.1386\n",
      "Epoch 287/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0444\n",
      "Learning rate after epoch 286 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0484 - val_loss: 0.1711 - val_mae: 0.3900\n",
      "Epoch 288/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0394\n",
      "Learning rate after epoch 287 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0467 - val_loss: 0.0894 - val_mae: 0.2567\n",
      "Epoch 289/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0164 - mae: 0.0748\n",
      "Learning rate after epoch 288 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0543 - val_loss: 0.1246 - val_mae: 0.3132\n",
      "Epoch 290/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0478\n",
      "Learning rate after epoch 289 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0418 - val_loss: 0.1851 - val_mae: 0.4183\n",
      "Epoch 291/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0155 - mae: 0.0892\n",
      "Learning rate after epoch 290 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0574 - val_loss: 0.0561 - val_mae: 0.2238\n",
      "Epoch 292/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0432\n",
      "Learning rate after epoch 291 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0588 - val_loss: 0.0593 - val_mae: 0.2252\n",
      "Epoch 293/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0481\n",
      "Learning rate after epoch 292 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0542 - val_loss: 0.0804 - val_mae: 0.2526\n",
      "Epoch 294/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0552\n",
      "Learning rate after epoch 293 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0486 - val_loss: 0.0513 - val_mae: 0.2030\n",
      "Epoch 295/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0362\n",
      "Learning rate after epoch 294 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0556 - val_loss: 0.0335 - val_mae: 0.1585\n",
      "Epoch 296/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0480\n",
      "Learning rate after epoch 295 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0532 - val_loss: 0.0312 - val_mae: 0.1442\n",
      "Epoch 297/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0338\n",
      "Learning rate after epoch 296 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0457 - val_loss: 0.0267 - val_mae: 0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0572\n",
      "Learning rate after epoch 297 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0532 - val_loss: 0.0135 - val_mae: 0.0916\n",
      "Epoch 299/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0766\n",
      "Learning rate after epoch 298 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0564 - val_loss: 0.0170 - val_mae: 0.1043\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0081 - mae: 0.0490\n",
      "Learning rate after epoch 299 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0490 - val_loss: 0.0258 - val_mae: 0.1264\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0093 - mae: 0.0539\n",
      "Learning rate after epoch 300 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0539 - val_loss: 0.0249 - val_mae: 0.1350\n",
      "Epoch 302/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0106 - mae: 0.0640\n",
      "Learning rate after epoch 301 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0577 - val_loss: 0.0116 - val_mae: 0.0604\n",
      "Epoch 303/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0370\n",
      "Learning rate after epoch 302 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0589 - val_loss: 0.0092 - val_mae: 0.0523\n",
      "Epoch 304/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0572\n",
      "Learning rate after epoch 303 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0495 - val_loss: 0.0103 - val_mae: 0.0632\n",
      "Epoch 305/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0355\n",
      "Learning rate after epoch 304 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0469 - val_loss: 0.0106 - val_mae: 0.0636\n",
      "Epoch 306/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0335\n",
      "Learning rate after epoch 305 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0432 - val_loss: 0.0129 - val_mae: 0.0731\n",
      "Epoch 307/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0125 - mae: 0.0805\n",
      "Learning rate after epoch 306 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0616 - val_loss: 0.0136 - val_mae: 0.0729\n",
      "Epoch 308/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0497\n",
      "Learning rate after epoch 307 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0495 - val_loss: 0.0124 - val_mae: 0.0693\n",
      "Epoch 309/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0106 - mae: 0.0640\n",
      "Learning rate after epoch 308 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0612 - val_loss: 0.0206 - val_mae: 0.0932\n",
      "Epoch 310/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0483\n",
      "Learning rate after epoch 309 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0562 - val_loss: 0.0243 - val_mae: 0.1025\n",
      "Epoch 311/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0494\n",
      "Learning rate after epoch 310 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0540 - val_loss: 0.0386 - val_mae: 0.1388\n",
      "Epoch 312/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0386\n",
      "Learning rate after epoch 311 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0456 - val_loss: 0.0261 - val_mae: 0.1057\n",
      "Epoch 313/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0477\n",
      "Learning rate after epoch 312 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0549 - val_loss: 0.0273 - val_mae: 0.1174\n",
      "Epoch 314/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0375\n",
      "Learning rate after epoch 313 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0531 - val_loss: 0.1424 - val_mae: 0.3533\n",
      "Epoch 315/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.0667\n",
      "Learning rate after epoch 314 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0542 - val_loss: 0.0303 - val_mae: 0.1463\n",
      "Epoch 316/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0452\n",
      "Learning rate after epoch 315 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0519 - val_loss: 0.0204 - val_mae: 0.1160\n",
      "Epoch 317/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0337\n",
      "Learning rate after epoch 316 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0514 - val_loss: 0.0071 - val_mae: 0.0419\n",
      "Epoch 318/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0352\n",
      "Learning rate after epoch 317 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0442 - val_loss: 0.0139 - val_mae: 0.0831\n",
      "Epoch 319/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0144 - mae: 0.0864\n",
      "Learning rate after epoch 318 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0506 - val_loss: 0.0118 - val_mae: 0.0798\n",
      "Epoch 320/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0464\n",
      "Learning rate after epoch 319 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0563 - val_loss: 0.0134 - val_mae: 0.0820\n",
      "Epoch 321/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0449\n",
      "Learning rate after epoch 320 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0510 - val_loss: 0.0195 - val_mae: 0.1110\n",
      "Epoch 322/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0485\n",
      "Learning rate after epoch 321 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0367 - val_loss: 0.1533 - val_mae: 0.3682\n",
      "Epoch 323/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0365\n",
      "Learning rate after epoch 322 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0448 - val_loss: 0.0911 - val_mae: 0.2793\n",
      "Epoch 324/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0356\n",
      "Learning rate after epoch 323 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0515 - val_loss: 0.2556 - val_mae: 0.4727\n",
      "Epoch 325/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0156 - mae: 0.0797\n",
      "Learning rate after epoch 324 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0589 - val_loss: 0.1346 - val_mae: 0.3502\n",
      "Epoch 326/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0346\n",
      "Learning rate after epoch 325 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0582 - val_loss: 0.0177 - val_mae: 0.1095\n",
      "Epoch 327/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0575\n",
      "Learning rate after epoch 326 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0542 - val_loss: 0.1890 - val_mae: 0.4057\n",
      "Epoch 328/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0352\n",
      "Learning rate after epoch 327 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0564 - val_loss: 0.0207 - val_mae: 0.1000\n",
      "Epoch 329/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0639\n",
      "Learning rate after epoch 328 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0544 - val_loss: 0.1885 - val_mae: 0.4146\n",
      "Epoch 330/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0368\n",
      "Learning rate after epoch 329 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0496 - val_loss: 0.0075 - val_mae: 0.0506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0155 - mae: 0.0964\n",
      "Learning rate after epoch 330 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0594 - val_loss: 0.0547 - val_mae: 0.2136\n",
      "Epoch 332/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0133 - mae: 0.0760\n",
      "Learning rate after epoch 331 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0531 - val_loss: 0.0340 - val_mae: 0.1593\n",
      "Epoch 333/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0487\n",
      "Learning rate after epoch 332 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0444 - val_loss: 0.0367 - val_mae: 0.1766\n",
      "Epoch 334/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0408\n",
      "Learning rate after epoch 333 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0528 - val_loss: 0.0156 - val_mae: 0.1030\n",
      "Epoch 335/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0653\n",
      "Learning rate after epoch 334 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0495 - val_loss: 0.0356 - val_mae: 0.1694\n",
      "Epoch 336/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0395\n",
      "Learning rate after epoch 335 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0466 - val_loss: 0.0254 - val_mae: 0.1318\n",
      "Epoch 337/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0378\n",
      "Learning rate after epoch 336 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0445 - val_loss: 0.0493 - val_mae: 0.1875\n",
      "Epoch 338/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0430\n",
      "Learning rate after epoch 337 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0506 - val_loss: 0.0103 - val_mae: 0.0732\n",
      "Epoch 339/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0524\n",
      "Learning rate after epoch 338 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0562 - val_loss: 0.0073 - val_mae: 0.0457\n",
      "Epoch 340/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0333\n",
      "Learning rate after epoch 339 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0544 - val_loss: 0.0130 - val_mae: 0.0904\n",
      "Epoch 341/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0269\n",
      "Learning rate after epoch 340 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0513 - val_loss: 0.0056 - val_mae: 0.0281\n",
      "Epoch 342/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0803\n",
      "Learning rate after epoch 341 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0488 - val_loss: 0.0110 - val_mae: 0.0611\n",
      "Epoch 343/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0337\n",
      "Learning rate after epoch 342 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0477 - val_loss: 0.0151 - val_mae: 0.0979\n",
      "Epoch 344/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0480\n",
      "Learning rate after epoch 343 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0611 - val_loss: 0.2111 - val_mae: 0.4332\n",
      "Epoch 345/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0429\n",
      "Learning rate after epoch 344 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0494 - val_loss: 0.2566 - val_mae: 0.4737\n",
      "Epoch 346/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0709\n",
      "Learning rate after epoch 345 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0604 - val_loss: 0.1677 - val_mae: 0.3870\n",
      "Epoch 347/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0498\n",
      "Learning rate after epoch 346 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0488 - val_loss: 0.1432 - val_mae: 0.3542\n",
      "Epoch 348/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0463\n",
      "Learning rate after epoch 347 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0495 - val_loss: 0.0697 - val_mae: 0.2436\n",
      "Epoch 349/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0494\n",
      "Learning rate after epoch 348 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0571 - val_loss: 0.0201 - val_mae: 0.1230\n",
      "Epoch 350/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0432\n",
      "Learning rate after epoch 349 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0468 - val_loss: 0.0235 - val_mae: 0.1284\n",
      "Epoch 351/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0402\n",
      "Learning rate after epoch 350 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0498 - val_loss: 0.0148 - val_mae: 0.0937\n",
      "Epoch 352/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0346\n",
      "Learning rate after epoch 351 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0463 - val_loss: 0.0262 - val_mae: 0.1253\n",
      "Epoch 353/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0513\n",
      "Learning rate after epoch 352 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0620 - val_loss: 0.0155 - val_mae: 0.0896\n",
      "Epoch 354/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0529\n",
      "Learning rate after epoch 353 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0569 - val_loss: 0.0112 - val_mae: 0.0767\n",
      "Epoch 355/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0216 - mae: 0.1211\n",
      "Learning rate after epoch 354 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0496 - val_loss: 0.0110 - val_mae: 0.0645\n",
      "Epoch 356/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0342\n",
      "Learning rate after epoch 355 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0532 - val_loss: 0.0155 - val_mae: 0.0853\n",
      "Epoch 357/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0148 - mae: 0.0923\n",
      "Learning rate after epoch 356 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0597 - val_loss: 0.0356 - val_mae: 0.1476\n",
      "Epoch 358/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.0669\n",
      "Learning rate after epoch 357 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0553 - val_loss: 0.0301 - val_mae: 0.1446\n",
      "Epoch 359/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0103 - mae: 0.0678\n",
      "Learning rate after epoch 358 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0493 - val_loss: 0.0370 - val_mae: 0.1559\n",
      "Epoch 360/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0359\n",
      "Learning rate after epoch 359 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0560 - val_loss: 0.0111 - val_mae: 0.0750\n",
      "Epoch 361/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0428\n",
      "Learning rate after epoch 360 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0544 - val_loss: 0.0056 - val_mae: 0.0274\n",
      "Epoch 362/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0468\n",
      "Learning rate after epoch 361 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0490 - val_loss: 0.0080 - val_mae: 0.0501\n",
      "Epoch 363/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0328\n",
      "Learning rate after epoch 362 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0536 - val_loss: 0.0110 - val_mae: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0468\n",
      "Learning rate after epoch 363 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0500 - val_loss: 0.0200 - val_mae: 0.0943\n",
      "Epoch 365/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0385\n",
      "Learning rate after epoch 364 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0423 - val_loss: 0.0278 - val_mae: 0.1337\n",
      "Epoch 366/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0380\n",
      "Learning rate after epoch 365 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0480 - val_loss: 0.0047 - val_mae: 0.0088\n",
      "Epoch 367/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0353\n",
      "Learning rate after epoch 366 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.1093\n",
      "Epoch 368/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0563\n",
      "Learning rate after epoch 367 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0485 - val_loss: 0.0114 - val_mae: 0.0821\n",
      "Epoch 369/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0436\n",
      "Learning rate after epoch 368 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0500 - val_loss: 0.0063 - val_mae: 0.0398\n",
      "Epoch 370/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0663\n",
      "Learning rate after epoch 369 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0523 - val_loss: 0.0145 - val_mae: 0.0914\n",
      "Epoch 371/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0488\n",
      "Learning rate after epoch 370 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0509 - val_loss: 0.0133 - val_mae: 0.0801\n",
      "Epoch 372/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0565\n",
      "Learning rate after epoch 371 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0543 - val_loss: 0.0138 - val_mae: 0.0880\n",
      "Epoch 373/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0383\n",
      "Learning rate after epoch 372 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0573 - val_loss: 0.0157 - val_mae: 0.0887\n",
      "Epoch 374/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0375\n",
      "Learning rate after epoch 373 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0491 - val_loss: 0.0115 - val_mae: 0.0669\n",
      "Epoch 375/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0383\n",
      "Learning rate after epoch 374 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0561 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 376/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0180 - mae: 0.1026\n",
      "Learning rate after epoch 375 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0536 - val_loss: 0.1847 - val_mae: 0.4006\n",
      "Epoch 377/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0363\n",
      "Learning rate after epoch 376 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0550 - val_loss: 0.1884 - val_mae: 0.4056\n",
      "Epoch 378/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0390\n",
      "Learning rate after epoch 377 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0581 - val_loss: 0.0056 - val_mae: 0.0180\n",
      "Epoch 379/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0705\n",
      "Learning rate after epoch 378 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0581 - val_loss: 0.1597 - val_mae: 0.3759\n",
      "Epoch 380/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0532\n",
      "Learning rate after epoch 379 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0548 - val_loss: 0.0121 - val_mae: 0.0762\n",
      "Epoch 381/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0401\n",
      "Learning rate after epoch 380 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0512 - val_loss: 0.0281 - val_mae: 0.1317\n",
      "Epoch 382/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0390\n",
      "Learning rate after epoch 381 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0430 - val_loss: 0.0304 - val_mae: 0.1539\n",
      "Epoch 383/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0410\n",
      "Learning rate after epoch 382 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0465 - val_loss: 0.0116 - val_mae: 0.0794\n",
      "Epoch 384/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0408\n",
      "Learning rate after epoch 383 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0578 - val_loss: 0.0341 - val_mae: 0.1662\n",
      "Epoch 385/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0629\n",
      "Learning rate after epoch 384 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0476 - val_loss: 0.0054 - val_mae: 0.0222\n",
      "Epoch 386/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0437\n",
      "Learning rate after epoch 385 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0460 - val_loss: 0.0088 - val_mae: 0.0557\n",
      "Epoch 387/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0423\n",
      "Learning rate after epoch 386 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0531 - val_loss: 0.0243 - val_mae: 0.1169\n",
      "Epoch 388/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0347\n",
      "Learning rate after epoch 387 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0479 - val_loss: 0.0567 - val_mae: 0.2059\n",
      "Epoch 389/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0228\n",
      "Learning rate after epoch 388 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0563 - val_loss: 0.1142 - val_mae: 0.3265\n",
      "Epoch 390/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0118 - mae: 0.0717\n",
      "Learning rate after epoch 389 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0516 - val_loss: 0.1683 - val_mae: 0.3906\n",
      "Epoch 391/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0373\n",
      "Learning rate after epoch 390 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0644 - val_loss: 0.0194 - val_mae: 0.1029\n",
      "Epoch 392/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0124 - mae: 0.0751\n",
      "Learning rate after epoch 391 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0509 - val_loss: 0.0277 - val_mae: 0.1391\n",
      "Epoch 393/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0124 - mae: 0.0736\n",
      "Learning rate after epoch 392 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0546 - val_loss: 0.0683 - val_mae: 0.2510\n",
      "Epoch 394/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0429\n",
      "Learning rate after epoch 393 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0472 - val_loss: 0.0188 - val_mae: 0.1094\n",
      "Epoch 395/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0541\n",
      "Learning rate after epoch 394 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0511 - val_loss: 0.0456 - val_mae: 0.1880\n",
      "Epoch 396/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0579\n",
      "Learning rate after epoch 395 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0497 - val_loss: 0.0275 - val_mae: 0.1361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0455\n",
      "Learning rate after epoch 396 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0526 - val_loss: 0.0581 - val_mae: 0.2290\n",
      "Epoch 398/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0448\n",
      "Learning rate after epoch 397 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0540 - val_loss: 0.0506 - val_mae: 0.2132\n",
      "Epoch 399/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0150 - mae: 0.0935\n",
      "Learning rate after epoch 398 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0600 - val_loss: 0.0328 - val_mae: 0.1625\n",
      "Epoch 400/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0158 - mae: 0.0924\n",
      "Learning rate after epoch 399 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0587 - val_loss: 0.0079 - val_mae: 0.0378\n",
      "Epoch 401/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0353\n",
      "Learning rate after epoch 400 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0584 - val_loss: 0.0058 - val_mae: 0.0313\n",
      "Epoch 402/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0305\n",
      "Learning rate after epoch 401 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0479 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 403/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0501\n",
      "Learning rate after epoch 402 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0503 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 404/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0508\n",
      "Learning rate after epoch 403 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0484 - val_loss: 0.0126 - val_mae: 0.0766\n",
      "Epoch 405/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0360\n",
      "Learning rate after epoch 404 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0508 - val_loss: 0.0147 - val_mae: 0.0817\n",
      "Epoch 406/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0511\n",
      "Learning rate after epoch 405 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0481 - val_loss: 0.0077 - val_mae: 0.0489\n",
      "Epoch 407/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0682\n",
      "Learning rate after epoch 406 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0512 - val_loss: 0.0095 - val_mae: 0.0665\n",
      "Epoch 408/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0583\n",
      "Learning rate after epoch 407 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0596 - val_loss: 0.0121 - val_mae: 0.0777\n",
      "Epoch 409/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0566\n",
      "Learning rate after epoch 408 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0546 - val_loss: 0.0206 - val_mae: 0.0924\n",
      "Epoch 410/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0295\n",
      "Learning rate after epoch 409 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0575 - val_loss: 0.0240 - val_mae: 0.1186\n",
      "Epoch 411/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0586\n",
      "Learning rate after epoch 410 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0524 - val_loss: 0.1383 - val_mae: 0.3533\n",
      "Epoch 412/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0757\n",
      "Learning rate after epoch 411 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0566 - val_loss: 0.0292 - val_mae: 0.1471\n",
      "Epoch 413/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0568\n",
      "Learning rate after epoch 412 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0497 - val_loss: 0.0431 - val_mae: 0.1880\n",
      "Epoch 414/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0276\n",
      "Learning rate after epoch 413 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0496 - val_loss: 0.1862 - val_mae: 0.4026\n",
      "Epoch 415/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0395\n",
      "Learning rate after epoch 414 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0513 - val_loss: 0.0180 - val_mae: 0.1076\n",
      "Epoch 416/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0689\n",
      "Learning rate after epoch 415 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0517 - val_loss: 0.0113 - val_mae: 0.0772\n",
      "Epoch 417/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0444\n",
      "Learning rate after epoch 416 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0501 - val_loss: 0.0156 - val_mae: 0.1013\n",
      "Epoch 418/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0599\n",
      "Learning rate after epoch 417 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0517 - val_loss: 0.0070 - val_mae: 0.0433\n",
      "Epoch 419/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0420\n",
      "Learning rate after epoch 418 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0493 - val_loss: 0.0108 - val_mae: 0.0673\n",
      "Epoch 420/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0151 - mae: 0.0852\n",
      "Learning rate after epoch 419 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0505 - val_loss: 0.0103 - val_mae: 0.0604\n",
      "Epoch 421/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0354\n",
      "Learning rate after epoch 420 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0481 - val_loss: 0.0180 - val_mae: 0.1019\n",
      "Epoch 422/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0333\n",
      "Learning rate after epoch 421 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0509 - val_loss: 0.1217 - val_mae: 0.3354\n",
      "Epoch 423/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0410\n",
      "Learning rate after epoch 422 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0573 - val_loss: 0.0052 - val_mae: 0.0193\n",
      "Epoch 424/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0384\n",
      "Learning rate after epoch 423 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0508 - val_loss: 0.0285 - val_mae: 0.1391\n",
      "Epoch 425/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0557\n",
      "Learning rate after epoch 424 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0605 - val_loss: 0.0085 - val_mae: 0.0575\n",
      "Epoch 426/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0405\n",
      "Learning rate after epoch 425 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0477 - val_loss: 0.0061 - val_mae: 0.0334\n",
      "Epoch 427/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0324\n",
      "Learning rate after epoch 426 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0467 - val_loss: 0.0094 - val_mae: 0.0659\n",
      "Epoch 428/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0142 - mae: 0.0894\n",
      "Learning rate after epoch 427 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0520 - val_loss: 0.0125 - val_mae: 0.0832\n",
      "Epoch 429/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0145 - mae: 0.0857\n",
      "Learning rate after epoch 428 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0618 - val_loss: 0.2860 - val_mae: 0.5046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0726\n",
      "Learning rate after epoch 429 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0426 - val_loss: 0.1362 - val_mae: 0.3492\n",
      "Epoch 431/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0420\n",
      "Learning rate after epoch 430 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0540 - val_loss: 0.1290 - val_mae: 0.3366\n",
      "Epoch 432/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0332\n",
      "Learning rate after epoch 431 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0463 - val_loss: 0.1118 - val_mae: 0.3117\n",
      "Epoch 433/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0425\n",
      "Learning rate after epoch 432 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0582 - val_loss: 0.0557 - val_mae: 0.2191\n",
      "Epoch 434/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0498\n",
      "Learning rate after epoch 433 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0497 - val_loss: 0.0091 - val_mae: 0.0618\n",
      "Epoch 435/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0416\n",
      "Learning rate after epoch 434 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0458 - val_loss: 0.0090 - val_mae: 0.0630\n",
      "Epoch 436/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0419\n",
      "Learning rate after epoch 435 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0509 - val_loss: 0.0141 - val_mae: 0.0848\n",
      "Epoch 437/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0788\n",
      "Learning rate after epoch 436 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0531 - val_loss: 0.0051 - val_mae: 0.0203\n",
      "Epoch 438/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0144 - mae: 0.0863\n",
      "Learning rate after epoch 437 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0572 - val_loss: 0.0355 - val_mae: 0.1579\n",
      "Epoch 439/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0218 - mae: 0.1262\n",
      "Learning rate after epoch 438 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0536 - val_loss: 0.0159 - val_mae: 0.0882\n",
      "Epoch 440/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0640\n",
      "Learning rate after epoch 439 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0641 - val_loss: 0.0299 - val_mae: 0.1575\n",
      "Epoch 441/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0081 - mae: 0.0441\n",
      "Learning rate after epoch 440 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0476 - val_loss: 0.0325 - val_mae: 0.1646\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0093 - mae: 0.0532\n",
      "Learning rate after epoch 441 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0532 - val_loss: 0.0263 - val_mae: 0.1457\n",
      "Epoch 443/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0374\n",
      "Learning rate after epoch 442 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0451 - val_loss: 0.0257 - val_mae: 0.1389\n",
      "Epoch 444/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0473\n",
      "Learning rate after epoch 443 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0585 - val_loss: 0.0334 - val_mae: 0.1613\n",
      "Epoch 445/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0287\n",
      "Learning rate after epoch 444 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0533 - val_loss: 0.0389 - val_mae: 0.1730\n",
      "Epoch 446/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0339\n",
      "Learning rate after epoch 445 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0555 - val_loss: 0.0507 - val_mae: 0.2112\n",
      "Epoch 447/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0309\n",
      "Learning rate after epoch 446 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0527 - val_loss: 0.0566 - val_mae: 0.2122\n",
      "Epoch 448/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0771\n",
      "Learning rate after epoch 447 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0578 - val_loss: 0.0532 - val_mae: 0.1949\n",
      "Epoch 449/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0300\n",
      "Learning rate after epoch 448 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0632 - val_loss: 0.0325 - val_mae: 0.1602\n",
      "Epoch 450/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0542\n",
      "Learning rate after epoch 449 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0528 - val_loss: 0.0225 - val_mae: 0.1152\n",
      "Epoch 451/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0404\n",
      "Learning rate after epoch 450 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0458 - val_loss: 0.0225 - val_mae: 0.1042\n",
      "Epoch 452/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0446\n",
      "Learning rate after epoch 451 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0424 - val_loss: 0.0658 - val_mae: 0.2428\n",
      "Epoch 453/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0167 - mae: 0.0849\n",
      "Learning rate after epoch 452 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0570 - val_loss: 0.0305 - val_mae: 0.1440\n",
      "Epoch 454/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0400\n",
      "Learning rate after epoch 453 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0530 - val_loss: 0.0064 - val_mae: 0.0351\n",
      "Epoch 455/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0452\n",
      "Learning rate after epoch 454 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0514 - val_loss: 0.0391 - val_mae: 0.1837\n",
      "Epoch 456/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0313\n",
      "Learning rate after epoch 455 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0409 - val_loss: 0.0224 - val_mae: 0.1201\n",
      "Epoch 457/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0400\n",
      "Learning rate after epoch 456 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0521 - val_loss: 0.0407 - val_mae: 0.1823\n",
      "Epoch 458/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0331\n",
      "Learning rate after epoch 457 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0513 - val_loss: 0.0254 - val_mae: 0.1238\n",
      "Epoch 459/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0345\n",
      "Learning rate after epoch 458 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0508 - val_loss: 0.0429 - val_mae: 0.1789\n",
      "Epoch 460/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0499\n",
      "Learning rate after epoch 459 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0503 - val_loss: 0.0172 - val_mae: 0.1041\n",
      "Epoch 461/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0402\n",
      "Learning rate after epoch 460 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0522 - val_loss: 0.0080 - val_mae: 0.0521\n",
      "Epoch 462/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0491\n",
      "Learning rate after epoch 461 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0407 - val_loss: 0.0063 - val_mae: 0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0582\n",
      "Learning rate after epoch 462 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0482 - val_loss: 0.0109 - val_mae: 0.0702\n",
      "Epoch 464/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0366\n",
      "Learning rate after epoch 463 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0464 - val_loss: 0.0079 - val_mae: 0.0460\n",
      "Epoch 465/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0143 - mae: 0.0848\n",
      "Learning rate after epoch 464 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0493 - val_loss: 0.0065 - val_mae: 0.0428\n",
      "Epoch 466/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0420\n",
      "Learning rate after epoch 465 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0467 - val_loss: 0.0312 - val_mae: 0.1507\n",
      "Epoch 467/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0455\n",
      "Learning rate after epoch 466 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0584 - val_loss: 0.0539 - val_mae: 0.2172\n",
      "Epoch 468/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0516\n",
      "Learning rate after epoch 467 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0546 - val_loss: 0.0585 - val_mae: 0.2218\n",
      "Epoch 469/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0326\n",
      "Learning rate after epoch 468 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0475 - val_loss: 0.0436 - val_mae: 0.1911\n",
      "Epoch 470/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0128 - mae: 0.0844\n",
      "Learning rate after epoch 469 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0511 - val_loss: 0.0792 - val_mae: 0.2693\n",
      "Epoch 471/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0510\n",
      "Learning rate after epoch 470 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0537 - val_loss: 0.0819 - val_mae: 0.2743\n",
      "Epoch 472/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0515\n",
      "Learning rate after epoch 471 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0648 - val_loss: 0.2801 - val_mae: 0.5029\n",
      "Epoch 473/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0509\n",
      "Learning rate after epoch 472 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0546 - val_loss: 0.0070 - val_mae: 0.0313\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0091 - mae: 0.0515\n",
      "Learning rate after epoch 473 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0515 - val_loss: 0.0077 - val_mae: 0.0507\n",
      "Epoch 475/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0102 - mae: 0.0596\n",
      "Learning rate after epoch 474 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0598 - val_loss: 0.0127 - val_mae: 0.0852\n",
      "Epoch 476/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0109 - mae: 0.0656\n",
      "Learning rate after epoch 475 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0573 - val_loss: 0.0121 - val_mae: 0.0795\n",
      "Epoch 477/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0187 - mae: 0.1017\n",
      "Learning rate after epoch 476 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0510 - val_loss: 0.0227 - val_mae: 0.1027\n",
      "Epoch 478/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0257\n",
      "Learning rate after epoch 477 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0511 - val_loss: 0.0156 - val_mae: 0.0892\n",
      "Epoch 479/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0685\n",
      "Learning rate after epoch 478 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0660 - val_loss: 0.0390 - val_mae: 0.1623\n",
      "Epoch 480/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0167 - mae: 0.1043\n",
      "Learning rate after epoch 479 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0559 - val_loss: 0.0060 - val_mae: 0.0343\n",
      "Epoch 481/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0233 - mae: 0.1291\n",
      "Learning rate after epoch 480 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0597 - val_loss: 0.0055 - val_mae: 0.0272\n",
      "Epoch 482/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0721\n",
      "Learning rate after epoch 481 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0593 - val_loss: 0.0111 - val_mae: 0.0721\n",
      "Epoch 483/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0109 - mae: 0.0682\n",
      "Learning rate after epoch 482 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0526 - val_loss: 0.0210 - val_mae: 0.1093\n",
      "Epoch 484/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0298\n",
      "Learning rate after epoch 483 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0569 - val_loss: 0.0100 - val_mae: 0.0698\n",
      "Epoch 485/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0476\n",
      "Learning rate after epoch 484 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0556 - val_loss: 0.0061 - val_mae: 0.0284\n",
      "Epoch 486/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0414\n",
      "Learning rate after epoch 485 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0519 - val_loss: 0.0223 - val_mae: 0.1138\n",
      "Epoch 487/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0611\n",
      "Learning rate after epoch 486 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0511 - val_loss: 0.0546 - val_mae: 0.2032\n",
      "Epoch 488/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0876\n",
      "Learning rate after epoch 487 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0535 - val_loss: 0.0675 - val_mae: 0.2313\n",
      "Epoch 489/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0581\n",
      "Learning rate after epoch 488 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0604 - val_loss: 0.2247 - val_mae: 0.4428\n",
      "Epoch 490/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0307\n",
      "Learning rate after epoch 489 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0484 - val_loss: 0.2462 - val_mae: 0.4645\n",
      "Epoch 491/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0550\n",
      "Learning rate after epoch 490 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0508 - val_loss: 0.2609 - val_mae: 0.4774\n",
      "Epoch 492/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0419\n",
      "Learning rate after epoch 491 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0590 - val_loss: 0.2292 - val_mae: 0.4484\n",
      "Epoch 493/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0525\n",
      "Learning rate after epoch 492 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0442 - val_loss: 0.0957 - val_mae: 0.2924\n",
      "Epoch 494/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0632\n",
      "Learning rate after epoch 493 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0481 - val_loss: 0.1924 - val_mae: 0.4094\n",
      "Epoch 495/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0739\n",
      "Learning rate after epoch 494 is 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0534 - val_loss: 0.1207 - val_mae: 0.3248\n",
      "Epoch 496/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0273\n",
      "Learning rate after epoch 495 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0462 - val_loss: 0.0672 - val_mae: 0.2348\n",
      "Epoch 497/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0766\n",
      "Learning rate after epoch 496 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0536 - val_loss: 0.0264 - val_mae: 0.1262\n",
      "Epoch 498/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0333\n",
      "Learning rate after epoch 497 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0455 - val_loss: 0.0296 - val_mae: 0.1413\n",
      "Epoch 499/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0368\n",
      "Learning rate after epoch 498 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0524 - val_loss: 0.1143 - val_mae: 0.3200\n",
      "Epoch 500/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0499\n",
      "Learning rate after epoch 499 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0582 - val_loss: 0.0737 - val_mae: 0.2542\n",
      "Epoch 501/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0539\n",
      "Learning rate after epoch 500 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0485 - val_loss: 0.0221 - val_mae: 0.1191\n",
      "Epoch 502/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0518\n",
      "Learning rate after epoch 501 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0492 - val_loss: 0.0156 - val_mae: 0.0964\n",
      "Epoch 503/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0390\n",
      "Learning rate after epoch 502 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0512 - val_loss: 0.0071 - val_mae: 0.0444\n",
      "Epoch 504/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0335\n",
      "Learning rate after epoch 503 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0456 - val_loss: 0.0152 - val_mae: 0.0977\n",
      "Epoch 505/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0690\n",
      "Learning rate after epoch 504 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0481 - val_loss: 0.0123 - val_mae: 0.0793\n",
      "Epoch 506/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0305\n",
      "Learning rate after epoch 505 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0443 - val_loss: 0.0073 - val_mae: 0.0500\n",
      "Epoch 507/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0417\n",
      "Learning rate after epoch 506 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0587 - val_loss: 0.0081 - val_mae: 0.0468\n",
      "Epoch 508/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0480\n",
      "Learning rate after epoch 507 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0563 - val_loss: 0.0115 - val_mae: 0.0668\n",
      "Epoch 509/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0610\n",
      "Learning rate after epoch 508 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0513 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 510/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0311\n",
      "Learning rate after epoch 509 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0530 - val_loss: 0.0144 - val_mae: 0.0978\n",
      "Epoch 511/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0093 - mae: 0.0561\n",
      "Learning rate after epoch 510 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0559 - val_loss: 0.0054 - val_mae: 0.0226\n",
      "Epoch 512/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0121 - mae: 0.0725\n",
      "Learning rate after epoch 511 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0528 - val_loss: 0.0054 - val_mae: 0.0284\n",
      "Epoch 513/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0392\n",
      "Learning rate after epoch 512 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0566 - val_loss: 0.0092 - val_mae: 0.0506\n",
      "Epoch 514/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0470\n",
      "Learning rate after epoch 513 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0535 - val_loss: 0.0067 - val_mae: 0.0382\n",
      "Epoch 515/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0510\n",
      "Learning rate after epoch 514 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0449 - val_loss: 0.0137 - val_mae: 0.0709\n",
      "Epoch 516/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0731\n",
      "Learning rate after epoch 515 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0578 - val_loss: 0.0131 - val_mae: 0.0878\n",
      "Epoch 517/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0361\n",
      "Learning rate after epoch 516 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0096 - val_mae: 0.0567\n",
      "Epoch 518/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0717\n",
      "Learning rate after epoch 517 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0505 - val_loss: 0.0456 - val_mae: 0.1943\n",
      "Epoch 519/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0403\n",
      "Learning rate after epoch 518 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0592 - val_loss: 0.0589 - val_mae: 0.2280\n",
      "Epoch 520/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0403\n",
      "Learning rate after epoch 519 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0478 - val_loss: 0.0819 - val_mae: 0.2707\n",
      "Epoch 521/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0133 - mae: 0.0825\n",
      "Learning rate after epoch 520 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0461 - val_loss: 0.0786 - val_mae: 0.2668\n",
      "Epoch 522/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0408\n",
      "Learning rate after epoch 521 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0483 - val_loss: 0.0955 - val_mae: 0.2942\n",
      "Epoch 523/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0632\n",
      "Learning rate after epoch 522 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0445 - val_loss: 0.0250 - val_mae: 0.1246\n",
      "Epoch 524/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0538\n",
      "Learning rate after epoch 523 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0515 - val_loss: 0.0245 - val_mae: 0.1384\n",
      "Epoch 525/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0388\n",
      "Learning rate after epoch 524 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0545 - val_loss: 0.0221 - val_mae: 0.1076\n",
      "Epoch 526/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0585\n",
      "Learning rate after epoch 525 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0514 - val_loss: 0.2186 - val_mae: 0.4449\n",
      "Epoch 527/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0299\n",
      "Learning rate after epoch 526 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0467 - val_loss: 0.0380 - val_mae: 0.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0481\n",
      "Learning rate after epoch 527 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0458 - val_loss: 0.0485 - val_mae: 0.1938\n",
      "Epoch 529/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0376\n",
      "Learning rate after epoch 528 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0529 - val_loss: 0.0133 - val_mae: 0.0887\n",
      "Epoch 530/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0294\n",
      "Learning rate after epoch 529 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0521 - val_loss: 0.0115 - val_mae: 0.0811\n",
      "Epoch 531/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.0729\n",
      "Learning rate after epoch 530 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0535 - val_loss: 0.0094 - val_mae: 0.0646\n",
      "Epoch 532/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0632\n",
      "Learning rate after epoch 531 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0527 - val_loss: 0.0117 - val_mae: 0.0822\n",
      "Epoch 533/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0682\n",
      "Learning rate after epoch 532 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0623 - val_loss: 0.0124 - val_mae: 0.0872\n",
      "Epoch 534/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0321\n",
      "Learning rate after epoch 533 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0497 - val_loss: 0.0293 - val_mae: 0.1544\n",
      "Epoch 535/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0563\n",
      "Learning rate after epoch 534 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0533 - val_loss: 0.0083 - val_mae: 0.0552\n",
      "Epoch 536/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0288\n",
      "Learning rate after epoch 535 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0461 - val_loss: 0.0065 - val_mae: 0.0464\n",
      "Epoch 537/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0672\n",
      "Learning rate after epoch 536 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0615 - val_loss: 0.0102 - val_mae: 0.0565\n",
      "Epoch 538/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0106 - mae: 0.0635\n",
      "Learning rate after epoch 537 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0607 - val_loss: 0.0066 - val_mae: 0.0394\n",
      "Epoch 539/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0354\n",
      "Learning rate after epoch 538 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0590 - val_loss: 0.0070 - val_mae: 0.0462\n",
      "Epoch 540/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0266\n",
      "Learning rate after epoch 539 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0547 - val_loss: 0.0182 - val_mae: 0.1054\n",
      "Epoch 541/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0869\n",
      "Learning rate after epoch 540 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0620 - val_loss: 0.0318 - val_mae: 0.1575\n",
      "Epoch 542/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0401\n",
      "Learning rate after epoch 541 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0360\n",
      "Epoch 543/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0478\n",
      "Learning rate after epoch 542 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0577 - val_loss: 0.0300 - val_mae: 0.1584\n",
      "Epoch 544/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0326\n",
      "Learning rate after epoch 543 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0420 - val_loss: 0.0465 - val_mae: 0.1915\n",
      "Epoch 545/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0357\n",
      "Learning rate after epoch 544 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0478 - val_loss: 0.0221 - val_mae: 0.1302\n",
      "Epoch 546/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0496\n",
      "Learning rate after epoch 545 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0495 - val_loss: 0.0060 - val_mae: 0.0380\n",
      "Epoch 547/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0715\n",
      "Learning rate after epoch 546 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0535 - val_loss: 0.0231 - val_mae: 0.1049\n",
      "Epoch 548/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0604\n",
      "Learning rate after epoch 547 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0484 - val_loss: 0.0076 - val_mae: 0.0437\n",
      "Epoch 549/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0484\n",
      "Learning rate after epoch 548 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0499 - val_loss: 0.0095 - val_mae: 0.0552\n",
      "Epoch 550/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0702\n",
      "Learning rate after epoch 549 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0520 - val_loss: 0.0138 - val_mae: 0.0733\n",
      "Epoch 551/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0132 - mae: 0.0835\n",
      "Learning rate after epoch 550 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0586 - val_loss: 0.0059 - val_mae: 0.0289\n",
      "Epoch 552/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0149 - mae: 0.0917\n",
      "Learning rate after epoch 551 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0490 - val_loss: 0.0206 - val_mae: 0.0935\n",
      "Epoch 553/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0447\n",
      "Learning rate after epoch 552 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0457 - val_loss: 0.0084 - val_mae: 0.0495\n",
      "Epoch 554/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0339\n",
      "Learning rate after epoch 553 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0484 - val_loss: 0.0138 - val_mae: 0.0832\n",
      "Epoch 555/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0138 - mae: 0.0825\n",
      "Learning rate after epoch 554 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0519 - val_loss: 0.0151 - val_mae: 0.0873\n",
      "Epoch 556/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0436\n",
      "Learning rate after epoch 555 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0565 - val_loss: 0.0266 - val_mae: 0.1405\n",
      "Epoch 557/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0646\n",
      "Learning rate after epoch 556 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0552 - val_loss: 0.0083 - val_mae: 0.0564\n",
      "Epoch 558/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0517\n",
      "Learning rate after epoch 557 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0482 - val_loss: 0.0244 - val_mae: 0.1392\n",
      "Epoch 559/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0546\n",
      "Learning rate after epoch 558 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0592 - val_loss: 0.0096 - val_mae: 0.0647\n",
      "Epoch 560/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0402\n",
      "Learning rate after epoch 559 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0429 - val_loss: 0.0442 - val_mae: 0.1868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0457\n",
      "Learning rate after epoch 560 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0500 - val_loss: 0.0076 - val_mae: 0.0533\n",
      "Epoch 562/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0365\n",
      "Learning rate after epoch 561 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0608 - val_loss: 0.0448 - val_mae: 0.1941\n",
      "Epoch 563/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0537\n",
      "Learning rate after epoch 562 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0525 - val_loss: 0.0518 - val_mae: 0.2003\n",
      "Epoch 564/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0436\n",
      "Learning rate after epoch 563 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0605 - val_loss: 0.0152 - val_mae: 0.0911\n",
      "Epoch 565/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0429\n",
      "Learning rate after epoch 564 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0454 - val_loss: 0.0178 - val_mae: 0.1013\n",
      "Epoch 566/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0331\n",
      "Learning rate after epoch 565 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0468 - val_loss: 0.0188 - val_mae: 0.1143\n",
      "Epoch 567/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.0773\n",
      "Learning rate after epoch 566 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0510 - val_loss: 0.0054 - val_mae: 0.0292\n",
      "Epoch 568/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0119 - mae: 0.0792\n",
      "Learning rate after epoch 567 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0515 - val_loss: 0.0050 - val_mae: 0.0199\n",
      "Epoch 569/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0314\n",
      "Learning rate after epoch 568 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0502 - val_loss: 0.0054 - val_mae: 0.0282\n",
      "Epoch 570/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0380\n",
      "Learning rate after epoch 569 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0470 - val_loss: 0.0146 - val_mae: 0.0894\n",
      "Epoch 571/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0536\n",
      "Learning rate after epoch 570 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0499 - val_loss: 0.0183 - val_mae: 0.0938\n",
      "Epoch 572/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0147 - mae: 0.0903\n",
      "Learning rate after epoch 571 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0552 - val_loss: 0.0396 - val_mae: 0.1835\n",
      "Epoch 573/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0492\n",
      "Learning rate after epoch 572 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0554 - val_loss: 0.0317 - val_mae: 0.1631\n",
      "Epoch 574/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0361\n",
      "Learning rate after epoch 573 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0462 - val_loss: 0.0256 - val_mae: 0.1377\n",
      "Epoch 575/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0124 - mae: 0.0821\n",
      "Learning rate after epoch 574 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0536 - val_loss: 0.0165 - val_mae: 0.0948\n",
      "Epoch 576/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0349\n",
      "Learning rate after epoch 575 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0551 - val_loss: 0.0111 - val_mae: 0.0765\n",
      "Epoch 577/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0401\n",
      "Learning rate after epoch 576 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0518 - val_loss: 0.0060 - val_mae: 0.0350\n",
      "Epoch 578/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0131 - mae: 0.0837\n",
      "Learning rate after epoch 577 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0536 - val_loss: 0.0118 - val_mae: 0.0800\n",
      "Epoch 579/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0236\n",
      "Learning rate after epoch 578 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0457 - val_loss: 0.0103 - val_mae: 0.0660\n",
      "Epoch 580/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0351\n",
      "Learning rate after epoch 579 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0588 - val_loss: 0.0089 - val_mae: 0.0561\n",
      "Epoch 581/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0080 - mae: 0.0457\n",
      "Learning rate after epoch 580 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0455 - val_loss: 0.1960 - val_mae: 0.4150\n",
      "Epoch 582/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0386\n",
      "Learning rate after epoch 581 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0563 - val_loss: 0.1187 - val_mae: 0.3059\n",
      "Epoch 583/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0129 - mae: 0.0797\n",
      "Learning rate after epoch 582 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0593 - val_loss: 0.0139 - val_mae: 0.0891\n",
      "Epoch 584/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0476\n",
      "Learning rate after epoch 583 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0497 - val_loss: 0.1120 - val_mae: 0.3113\n",
      "Epoch 585/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0706\n",
      "Learning rate after epoch 584 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0517 - val_loss: 0.0113 - val_mae: 0.0652\n",
      "Epoch 586/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0624\n",
      "Learning rate after epoch 585 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0473 - val_loss: 0.1666 - val_mae: 0.3810\n",
      "Epoch 587/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0613\n",
      "Learning rate after epoch 586 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0457 - val_loss: 0.0711 - val_mae: 0.2283\n",
      "Epoch 588/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0608\n",
      "Learning rate after epoch 587 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0615 - val_loss: 0.0220 - val_mae: 0.1206\n",
      "Epoch 589/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0336\n",
      "Learning rate after epoch 588 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0533 - val_loss: 0.0177 - val_mae: 0.0985\n",
      "Epoch 590/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0410\n",
      "Learning rate after epoch 589 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0421 - val_loss: 0.0428 - val_mae: 0.1891\n",
      "Epoch 591/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0394\n",
      "Learning rate after epoch 590 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0511 - val_loss: 0.0185 - val_mae: 0.0999\n",
      "Epoch 592/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0329\n",
      "Learning rate after epoch 591 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0476 - val_loss: 0.0728 - val_mae: 0.2554\n",
      "Epoch 593/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0414\n",
      "Learning rate after epoch 592 is 0.0099\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0532 - val_loss: 0.0183 - val_mae: 0.1152\n",
      "Epoch 594/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0713\n",
      "Learning rate after epoch 593 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0478 - val_loss: 0.0157 - val_mae: 0.0907\n",
      "Epoch 595/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0339\n",
      "Learning rate after epoch 594 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0575 - val_loss: 0.0101 - val_mae: 0.0700\n",
      "Epoch 596/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0383\n",
      "Learning rate after epoch 595 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0497 - val_loss: 0.0869 - val_mae: 0.2818\n",
      "Epoch 597/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0501\n",
      "Learning rate after epoch 596 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0492 - val_loss: 0.0979 - val_mae: 0.2967\n",
      "Epoch 598/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0309\n",
      "Learning rate after epoch 597 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0551 - val_loss: 0.0470 - val_mae: 0.1801\n",
      "Epoch 599/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0483\n",
      "Learning rate after epoch 598 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0473 - val_loss: 0.0194 - val_mae: 0.1118\n",
      "Epoch 600/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0489\n",
      "Learning rate after epoch 599 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0470 - val_loss: 0.0102 - val_mae: 0.0677\n",
      "Epoch 601/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0450\n",
      "Learning rate after epoch 600 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0536 - val_loss: 0.0054 - val_mae: 0.0238\n",
      "Epoch 602/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0329\n",
      "Learning rate after epoch 601 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0554 - val_loss: 0.0065 - val_mae: 0.0395\n",
      "Epoch 603/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0733\n",
      "Learning rate after epoch 602 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0514 - val_loss: 0.0081 - val_mae: 0.0524\n",
      "Epoch 604/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0362\n",
      "Learning rate after epoch 603 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0569 - val_loss: 0.0072 - val_mae: 0.0433\n",
      "Epoch 605/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0589\n",
      "Learning rate after epoch 604 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0508 - val_loss: 0.0156 - val_mae: 0.0894\n",
      "Epoch 606/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0449\n",
      "Learning rate after epoch 605 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0514 - val_loss: 0.0101 - val_mae: 0.0688\n",
      "Epoch 607/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0506\n",
      "Learning rate after epoch 606 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0562 - val_loss: 0.0384 - val_mae: 0.1756\n",
      "Epoch 608/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0210 - mae: 0.1002\n",
      "Learning rate after epoch 607 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0582 - val_loss: 0.0209 - val_mae: 0.1269\n",
      "Epoch 609/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.0768\n",
      "Learning rate after epoch 608 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0442 - val_loss: 0.0071 - val_mae: 0.0476\n",
      "Epoch 610/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0250 - mae: 0.1381\n",
      "Learning rate after epoch 609 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0673 - val_loss: 0.0654 - val_mae: 0.2441\n",
      "Epoch 611/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0347\n",
      "Learning rate after epoch 610 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0482 - val_loss: 0.0802 - val_mae: 0.2629\n",
      "Epoch 612/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0364\n",
      "Learning rate after epoch 611 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0463 - val_loss: 0.0153 - val_mae: 0.0903\n",
      "Epoch 613/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0403\n",
      "Learning rate after epoch 612 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0471 - val_loss: 0.0230 - val_mae: 0.1209\n",
      "Epoch 614/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0417\n",
      "Learning rate after epoch 613 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0581 - val_loss: 0.0082 - val_mae: 0.0415\n",
      "Epoch 615/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0254\n",
      "Learning rate after epoch 614 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0504 - val_loss: 0.0076 - val_mae: 0.0513\n",
      "Epoch 616/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0087 - mae: 0.0529\n",
      "Learning rate after epoch 615 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0540 - val_loss: 0.0065 - val_mae: 0.0417\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0088 - mae: 0.0547\n",
      "Learning rate after epoch 616 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0547 - val_loss: 0.0096 - val_mae: 0.0624\n",
      "Epoch 618/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0479\n",
      "Learning rate after epoch 617 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0537 - val_loss: 0.0063 - val_mae: 0.0364\n",
      "Epoch 619/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0517\n",
      "Learning rate after epoch 618 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0502 - val_loss: 0.0053 - val_mae: 0.0197\n",
      "Epoch 620/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0434\n",
      "Learning rate after epoch 619 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0548 - val_loss: 0.0267 - val_mae: 0.1083\n",
      "Epoch 621/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0470\n",
      "Learning rate after epoch 620 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0493 - val_loss: 0.0122 - val_mae: 0.0849\n",
      "Epoch 622/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.0674\n",
      "Learning rate after epoch 621 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0609 - val_loss: 0.1518 - val_mae: 0.3657\n",
      "Epoch 623/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0456\n",
      "Learning rate after epoch 622 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0503 - val_loss: 0.0122 - val_mae: 0.0846\n",
      "Epoch 624/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0567\n",
      "Learning rate after epoch 623 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0488 - val_loss: 0.0068 - val_mae: 0.0443\n",
      "Epoch 625/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0435\n",
      "Learning rate after epoch 624 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0529 - val_loss: 0.0059 - val_mae: 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0847\n",
      "Learning rate after epoch 625 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0522 - val_loss: 0.0194 - val_mae: 0.0882\n",
      "Epoch 627/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0625\n",
      "Learning rate after epoch 626 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0530 - val_loss: 0.0860 - val_mae: 0.2786\n",
      "Epoch 628/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0132 - mae: 0.0803\n",
      "Learning rate after epoch 627 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0509 - val_loss: 0.0334 - val_mae: 0.1642\n",
      "Epoch 629/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0442\n",
      "Learning rate after epoch 628 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0592 - val_loss: 0.0112 - val_mae: 0.0793\n",
      "Epoch 630/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0399\n",
      "Learning rate after epoch 629 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0436 - val_loss: 0.0077 - val_mae: 0.0458\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0092 - mae: 0.0554\n",
      "Learning rate after epoch 630 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0554 - val_loss: 0.0111 - val_mae: 0.0747\n",
      "Epoch 632/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0512\n",
      "Learning rate after epoch 631 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0517 - val_loss: 0.0184 - val_mae: 0.0990\n",
      "Epoch 633/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.0705\n",
      "Learning rate after epoch 632 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0516 - val_loss: 0.0209 - val_mae: 0.1206\n",
      "Epoch 634/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0075 - mae: 0.0454\n",
      "Learning rate after epoch 633 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0447 - val_loss: 0.0558 - val_mae: 0.2155\n",
      "Epoch 635/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0641\n",
      "Learning rate after epoch 634 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0451 - val_loss: 0.0168 - val_mae: 0.1080\n",
      "Epoch 636/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0335\n",
      "Learning rate after epoch 635 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0528 - val_loss: 0.0228 - val_mae: 0.1301\n",
      "Epoch 637/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0520\n",
      "Learning rate after epoch 636 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0566 - val_loss: 0.0271 - val_mae: 0.1237\n",
      "Epoch 638/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0349\n",
      "Learning rate after epoch 637 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0487 - val_loss: 0.0358 - val_mae: 0.1506\n",
      "Epoch 639/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0571\n",
      "Learning rate after epoch 638 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0538 - val_loss: 0.0615 - val_mae: 0.2071\n",
      "Epoch 640/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0514\n",
      "Learning rate after epoch 639 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0517 - val_loss: 0.0112 - val_mae: 0.0688\n",
      "Epoch 641/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0272\n",
      "Learning rate after epoch 640 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0569 - val_loss: 0.0067 - val_mae: 0.0396\n",
      "Epoch 642/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0114 - mae: 0.0714\n",
      "Learning rate after epoch 641 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0516 - val_loss: 0.0115 - val_mae: 0.0735\n",
      "Epoch 643/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0347\n",
      "Learning rate after epoch 642 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0510 - val_loss: 0.0098 - val_mae: 0.0621\n",
      "Epoch 644/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0314\n",
      "Learning rate after epoch 643 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0524 - val_loss: 0.0080 - val_mae: 0.0529\n",
      "Epoch 645/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0359\n",
      "Learning rate after epoch 644 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0507 - val_loss: 0.0132 - val_mae: 0.0839\n",
      "Epoch 646/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0499\n",
      "Learning rate after epoch 645 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0519 - val_loss: 0.0087 - val_mae: 0.0571\n",
      "Epoch 647/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0331\n",
      "Learning rate after epoch 646 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0541 - val_loss: 0.1379 - val_mae: 0.3551\n",
      "Epoch 648/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0719\n",
      "Learning rate after epoch 647 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0555 - val_loss: 0.1985 - val_mae: 0.4212\n",
      "Epoch 649/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0398\n",
      "Learning rate after epoch 648 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0524 - val_loss: 0.1242 - val_mae: 0.3325\n",
      "Epoch 650/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0368\n",
      "Learning rate after epoch 649 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0565 - val_loss: 0.1066 - val_mae: 0.3061\n",
      "Epoch 651/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0092 - mae: 0.0547\n",
      "Learning rate after epoch 650 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0564 - val_loss: 0.0462 - val_mae: 0.1975\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0089 - mae: 0.0562\n",
      "Learning rate after epoch 651 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0562 - val_loss: 0.0223 - val_mae: 0.1154\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0080 - mae: 0.0463\n",
      "Learning rate after epoch 652 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0463 - val_loss: 0.0108 - val_mae: 0.0713\n",
      "Epoch 654/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0417\n",
      "Learning rate after epoch 653 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0527 - val_loss: 0.0109 - val_mae: 0.0629\n",
      "Epoch 655/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0465\n",
      "Learning rate after epoch 654 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0523 - val_loss: 0.0487 - val_mae: 0.2000\n",
      "Epoch 656/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0364\n",
      "Learning rate after epoch 655 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0572 - val_loss: 0.0430 - val_mae: 0.1862\n",
      "Epoch 657/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0413\n",
      "Learning rate after epoch 656 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0509 - val_loss: 0.0252 - val_mae: 0.1163\n",
      "Epoch 658/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0348\n",
      "Learning rate after epoch 657 is 0.0099\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0516 - val_loss: 0.0448 - val_mae: 0.1664\n",
      "Epoch 659/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0264\n",
      "Learning rate after epoch 658 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0512 - val_loss: 0.0201 - val_mae: 0.0919\n",
      "Epoch 660/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0751\n",
      "Learning rate after epoch 659 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0560 - val_loss: 0.0183 - val_mae: 0.1022\n",
      "Epoch 661/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0603\n",
      "Learning rate after epoch 660 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0467 - val_loss: 0.0189 - val_mae: 0.1066\n",
      "Epoch 662/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0508\n",
      "Learning rate after epoch 661 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0445 - val_loss: 0.0111 - val_mae: 0.0769\n",
      "Epoch 663/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0747\n",
      "Learning rate after epoch 662 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0509 - val_loss: 0.0160 - val_mae: 0.0957\n",
      "Epoch 664/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0610\n",
      "Learning rate after epoch 663 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0632 - val_loss: 0.0192 - val_mae: 0.1118\n",
      "Epoch 665/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0125 - mae: 0.0707\n",
      "Learning rate after epoch 664 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0573 - val_loss: 0.0268 - val_mae: 0.1432\n",
      "Epoch 666/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0582\n",
      "Learning rate after epoch 665 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0562 - val_loss: 0.0188 - val_mae: 0.1041\n",
      "Epoch 667/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0375\n",
      "Learning rate after epoch 666 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0407 - val_loss: 0.0066 - val_mae: 0.0319\n",
      "Epoch 668/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0313\n",
      "Learning rate after epoch 667 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0541 - val_loss: 0.2926 - val_mae: 0.5114\n",
      "Epoch 669/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0334\n",
      "Learning rate after epoch 668 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0466 - val_loss: 0.1936 - val_mae: 0.4093\n",
      "Epoch 670/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0499\n",
      "Learning rate after epoch 669 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0469 - val_loss: 0.1599 - val_mae: 0.3812\n",
      "Epoch 671/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.0829\n",
      "Learning rate after epoch 670 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0641 - val_loss: 0.0832 - val_mae: 0.2737\n",
      "Epoch 672/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0684\n",
      "Learning rate after epoch 671 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0510 - val_loss: 0.0079 - val_mae: 0.0577\n",
      "Epoch 673/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0336\n",
      "Learning rate after epoch 672 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0517 - val_loss: 0.0277 - val_mae: 0.1420\n",
      "Epoch 674/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0489\n",
      "Learning rate after epoch 673 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0528 - val_loss: 0.0295 - val_mae: 0.1449\n",
      "Epoch 675/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0731\n",
      "Learning rate after epoch 674 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0519 - val_loss: 0.0164 - val_mae: 0.1069\n",
      "Epoch 676/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0530\n",
      "Learning rate after epoch 675 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0466 - val_loss: 0.0130 - val_mae: 0.0695\n",
      "Epoch 677/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0164 - mae: 0.1002\n",
      "Learning rate after epoch 676 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0537 - val_loss: 0.0105 - val_mae: 0.0684\n",
      "Epoch 678/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0476\n",
      "Learning rate after epoch 677 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0514 - val_loss: 0.0181 - val_mae: 0.0872\n",
      "Epoch 679/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0135 - mae: 0.0822\n",
      "Learning rate after epoch 678 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0516 - val_loss: 0.0099 - val_mae: 0.0679\n",
      "Epoch 680/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0318\n",
      "Learning rate after epoch 679 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0596 - val_loss: 0.0063 - val_mae: 0.0292\n",
      "Epoch 681/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0493\n",
      "Learning rate after epoch 680 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0492 - val_loss: 0.0087 - val_mae: 0.0573\n",
      "Epoch 682/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0312\n",
      "Learning rate after epoch 681 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0476 - val_loss: 0.1927 - val_mae: 0.4173\n",
      "Epoch 683/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0716\n",
      "Learning rate after epoch 682 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0534 - val_loss: 0.2612 - val_mae: 0.4778\n",
      "Epoch 684/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0371\n",
      "Learning rate after epoch 683 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0508 - val_loss: 0.0061 - val_mae: 0.0375\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0089 - mae: 0.0519\n",
      "Learning rate after epoch 684 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0519 - val_loss: 0.0303 - val_mae: 0.1390\n",
      "Epoch 686/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0094 - mae: 0.0569\n",
      "Learning rate after epoch 685 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0568 - val_loss: 0.0321 - val_mae: 0.1467\n",
      "Epoch 687/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0347\n",
      "Learning rate after epoch 686 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0571 - val_loss: 0.0106 - val_mae: 0.0626\n",
      "Epoch 688/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0384\n",
      "Learning rate after epoch 687 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0444 - val_loss: 0.0157 - val_mae: 0.1007\n",
      "Epoch 689/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0276\n",
      "Learning rate after epoch 688 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0508 - val_loss: 0.0067 - val_mae: 0.0429\n",
      "Epoch 690/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0283\n",
      "Learning rate after epoch 689 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0504 - val_loss: 0.1254 - val_mae: 0.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0377\n",
      "Learning rate after epoch 690 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0474 - val_loss: 0.1185 - val_mae: 0.3214\n",
      "Epoch 692/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0529\n",
      "Learning rate after epoch 691 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0506 - val_loss: 0.0716 - val_mae: 0.2319\n",
      "Epoch 693/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0317\n",
      "Learning rate after epoch 692 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0566 - val_loss: 0.1753 - val_mae: 0.3939\n",
      "Epoch 694/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0499\n",
      "Learning rate after epoch 693 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0517 - val_loss: 0.1029 - val_mae: 0.3023\n",
      "Epoch 695/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0184 - mae: 0.1058\n",
      "Learning rate after epoch 694 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0591 - val_loss: 0.1915 - val_mae: 0.4111\n",
      "Epoch 696/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0319\n",
      "Learning rate after epoch 695 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0476 - val_loss: 0.0647 - val_mae: 0.2301\n",
      "Epoch 697/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0383\n",
      "Learning rate after epoch 696 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0558 - val_loss: 0.0348 - val_mae: 0.1541\n",
      "Epoch 698/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0412\n",
      "Learning rate after epoch 697 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0599 - val_loss: 0.0285 - val_mae: 0.1320\n",
      "Epoch 699/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0490\n",
      "Learning rate after epoch 698 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0519 - val_loss: 0.0120 - val_mae: 0.0762\n",
      "Epoch 700/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0349\n",
      "Learning rate after epoch 699 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0481 - val_loss: 0.0102 - val_mae: 0.0703\n",
      "Epoch 701/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0771\n",
      "Learning rate after epoch 700 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0602 - val_loss: 0.0088 - val_mae: 0.0582\n",
      "Epoch 702/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0114 - mae: 0.0733\n",
      "Learning rate after epoch 701 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0577 - val_loss: 0.0057 - val_mae: 0.0255\n",
      "Epoch 703/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0393\n",
      "Learning rate after epoch 702 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0465 - val_loss: 0.0147 - val_mae: 0.0871\n",
      "Epoch 704/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0306\n",
      "Learning rate after epoch 703 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0477 - val_loss: 0.0859 - val_mae: 0.2738\n",
      "Epoch 705/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0531\n",
      "Learning rate after epoch 704 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0505 - val_loss: 0.0195 - val_mae: 0.1042\n",
      "Epoch 706/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0355\n",
      "Learning rate after epoch 705 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0512 - val_loss: 0.0101 - val_mae: 0.0671\n",
      "Epoch 707/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0429\n",
      "Learning rate after epoch 706 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0515 - val_loss: 0.0157 - val_mae: 0.0936\n",
      "Epoch 708/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0493\n",
      "Learning rate after epoch 707 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0511 - val_loss: 0.0134 - val_mae: 0.0880\n",
      "Epoch 709/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0406\n",
      "Learning rate after epoch 708 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0576 - val_loss: 0.0256 - val_mae: 0.1392\n",
      "Epoch 710/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0466\n",
      "Learning rate after epoch 709 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0489 - val_loss: 0.0152 - val_mae: 0.0982\n",
      "Epoch 711/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0448\n",
      "Learning rate after epoch 710 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0510 - val_loss: 0.0083 - val_mae: 0.0541\n",
      "Epoch 712/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0458\n",
      "Learning rate after epoch 711 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0446 - val_loss: 0.0500 - val_mae: 0.1962\n",
      "Epoch 713/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0716\n",
      "Learning rate after epoch 712 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0542 - val_loss: 0.1046 - val_mae: 0.3006\n",
      "Epoch 714/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0444\n",
      "Learning rate after epoch 713 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0539 - val_loss: 0.2562 - val_mae: 0.4734\n",
      "Epoch 715/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0527\n",
      "Learning rate after epoch 714 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0531 - val_loss: 0.0331 - val_mae: 0.1666\n",
      "Epoch 716/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0271\n",
      "Learning rate after epoch 715 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0531 - val_loss: 0.0054 - val_mae: 0.0303\n",
      "Epoch 717/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0430\n",
      "Learning rate after epoch 716 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0474 - val_loss: 0.0688 - val_mae: 0.2384\n",
      "Epoch 718/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0108 - mae: 0.0692\n",
      "Learning rate after epoch 717 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0489 - val_loss: 0.0108 - val_mae: 0.0730\n",
      "Epoch 719/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0396\n",
      "Learning rate after epoch 718 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0428 - val_loss: 0.0292 - val_mae: 0.1447\n",
      "Epoch 720/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0367\n",
      "Learning rate after epoch 719 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0508 - val_loss: 0.0142 - val_mae: 0.0845\n",
      "Epoch 721/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0081 - mae: 0.0488\n",
      "Learning rate after epoch 720 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0492 - val_loss: 0.0095 - val_mae: 0.0647\n",
      "Epoch 722/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0518\n",
      "Learning rate after epoch 721 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0538 - val_loss: 0.0113 - val_mae: 0.0686\n",
      "Epoch 723/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0406\n",
      "Learning rate after epoch 722 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0498 - val_loss: 0.0056 - val_mae: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0616\n",
      "Learning rate after epoch 723 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0510 - val_loss: 0.0084 - val_mae: 0.0582\n",
      "Epoch 725/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0304\n",
      "Learning rate after epoch 724 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0533 - val_loss: 0.0062 - val_mae: 0.0334\n",
      "Epoch 726/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0428\n",
      "Learning rate after epoch 725 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0545 - val_loss: 0.0074 - val_mae: 0.0459\n",
      "Epoch 727/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0466\n",
      "Learning rate after epoch 726 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0488 - val_loss: 0.0088 - val_mae: 0.0602\n",
      "Epoch 728/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0140 - mae: 0.0912\n",
      "Learning rate after epoch 727 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0556 - val_loss: 0.0131 - val_mae: 0.0695\n",
      "Epoch 729/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0288\n",
      "Learning rate after epoch 728 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0600 - val_loss: 0.0361 - val_mae: 0.1629\n",
      "Epoch 730/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0423\n",
      "Learning rate after epoch 729 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0479 - val_loss: 0.1128 - val_mae: 0.3148\n",
      "Epoch 731/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0619\n",
      "Learning rate after epoch 730 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0580 - val_loss: 0.1245 - val_mae: 0.3343\n",
      "Epoch 732/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0541\n",
      "Learning rate after epoch 731 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0572 - val_loss: 0.1601 - val_mae: 0.3836\n",
      "Epoch 733/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0103 - mae: 0.0636\n",
      "Learning rate after epoch 732 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0491 - val_loss: 0.1715 - val_mae: 0.3957\n",
      "Epoch 734/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0367\n",
      "Learning rate after epoch 733 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0587 - val_loss: 0.0993 - val_mae: 0.3018\n",
      "Epoch 735/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0106 - mae: 0.0665\n",
      "Learning rate after epoch 734 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0603 - val_loss: 0.0927 - val_mae: 0.2852\n",
      "Epoch 736/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0118 - mae: 0.0740\n",
      "Learning rate after epoch 735 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0542 - val_loss: 0.0352 - val_mae: 0.1742\n",
      "Epoch 737/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0466\n",
      "Learning rate after epoch 736 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0520 - val_loss: 0.0496 - val_mae: 0.2065\n",
      "Epoch 738/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0441\n",
      "Learning rate after epoch 737 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0478 - val_loss: 0.0350 - val_mae: 0.1676\n",
      "Epoch 739/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0095 - mae: 0.0626\n",
      "Learning rate after epoch 738 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0571 - val_loss: 0.0718 - val_mae: 0.2501\n",
      "Epoch 740/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0526\n",
      "Learning rate after epoch 739 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0538 - val_loss: 0.0166 - val_mae: 0.1083\n",
      "Epoch 741/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0423\n",
      "Learning rate after epoch 740 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0526 - val_loss: 0.0200 - val_mae: 0.1219\n",
      "Epoch 742/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0454\n",
      "Learning rate after epoch 741 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0506 - val_loss: 0.0294 - val_mae: 0.1525\n",
      "Epoch 743/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0364\n",
      "Learning rate after epoch 742 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0484 - val_loss: 0.0333 - val_mae: 0.1659\n",
      "Epoch 744/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0321\n",
      "Learning rate after epoch 743 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0511 - val_loss: 0.0310 - val_mae: 0.1393\n",
      "Epoch 745/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0121 - mae: 0.0745\n",
      "Learning rate after epoch 744 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0519 - val_loss: 0.0364 - val_mae: 0.1406\n",
      "Epoch 746/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0203 - mae: 0.1177\n",
      "Learning rate after epoch 745 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0629 - val_loss: 0.0382 - val_mae: 0.1794\n",
      "Epoch 747/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0353\n",
      "Learning rate after epoch 746 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0548 - val_loss: 0.0516 - val_mae: 0.2149\n",
      "Epoch 748/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0597\n",
      "Learning rate after epoch 747 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0450 - val_loss: 0.0390 - val_mae: 0.1803\n",
      "Epoch 749/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0119 - mae: 0.0780\n",
      "Learning rate after epoch 748 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0609 - val_loss: 0.0207 - val_mae: 0.1121\n",
      "Epoch 750/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0357\n",
      "Learning rate after epoch 749 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0581 - val_loss: 0.0073 - val_mae: 0.0513\n",
      "Epoch 751/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0530\n",
      "Learning rate after epoch 750 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0579 - val_loss: 0.0056 - val_mae: 0.0250\n",
      "Epoch 752/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0148 - mae: 0.0916\n",
      "Learning rate after epoch 751 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0623 - val_loss: 0.0066 - val_mae: 0.0310\n",
      "Epoch 753/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0333\n",
      "Learning rate after epoch 752 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0485 - val_loss: 0.0083 - val_mae: 0.0501\n",
      "Epoch 754/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0402\n",
      "Learning rate after epoch 753 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0499 - val_loss: 0.0154 - val_mae: 0.0797\n",
      "Epoch 755/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0508\n",
      "Learning rate after epoch 754 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0528 - val_loss: 0.0180 - val_mae: 0.0910\n",
      "Epoch 756/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0462\n",
      "Learning rate after epoch 755 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0482 - val_loss: 0.0141 - val_mae: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0591\n",
      "Learning rate after epoch 756 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0531 - val_loss: 0.0139 - val_mae: 0.0867\n",
      "Epoch 758/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0758\n",
      "Learning rate after epoch 757 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0519 - val_loss: 0.0155 - val_mae: 0.0782\n",
      "Epoch 759/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0313\n",
      "Learning rate after epoch 758 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0568 - val_loss: 0.0089 - val_mae: 0.0527\n",
      "Epoch 760/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0460\n",
      "Learning rate after epoch 759 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0462 - val_loss: 0.0346 - val_mae: 0.1671\n",
      "Epoch 761/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0578\n",
      "Learning rate after epoch 760 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0539 - val_loss: 0.0260 - val_mae: 0.1398\n",
      "Epoch 762/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0480\n",
      "Learning rate after epoch 761 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0578 - val_loss: 0.0079 - val_mae: 0.0536\n",
      "Epoch 763/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0635\n",
      "Learning rate after epoch 762 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0429 - val_loss: 0.0080 - val_mae: 0.0582\n",
      "Epoch 764/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0437\n",
      "Learning rate after epoch 763 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0568 - val_loss: 0.0066 - val_mae: 0.0404\n",
      "Epoch 765/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0339\n",
      "Learning rate after epoch 764 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0550 - val_loss: 0.0116 - val_mae: 0.0810\n",
      "Epoch 766/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0292\n",
      "Learning rate after epoch 765 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0502 - val_loss: 0.0136 - val_mae: 0.0857\n",
      "Epoch 767/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0339\n",
      "Learning rate after epoch 766 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0524 - val_loss: 0.0211 - val_mae: 0.1006\n",
      "Epoch 768/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0273\n",
      "Learning rate after epoch 767 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0489 - val_loss: 0.0276 - val_mae: 0.1143\n",
      "Epoch 769/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0460\n",
      "Learning rate after epoch 768 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0534 - val_loss: 0.0512 - val_mae: 0.1959\n",
      "Epoch 770/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0530\n",
      "Learning rate after epoch 769 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0670 - val_loss: 0.0616 - val_mae: 0.2186\n",
      "Epoch 771/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0299\n",
      "Learning rate after epoch 770 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0555 - val_loss: 0.0537 - val_mae: 0.1945\n",
      "Epoch 772/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0614\n",
      "Learning rate after epoch 771 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0474 - val_loss: 0.0522 - val_mae: 0.1869\n",
      "Epoch 773/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0589\n",
      "Learning rate after epoch 772 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0453 - val_loss: 0.0260 - val_mae: 0.1215\n",
      "Epoch 774/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0480\n",
      "Learning rate after epoch 773 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0509 - val_loss: 0.0217 - val_mae: 0.0958\n",
      "Epoch 775/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0316\n",
      "Learning rate after epoch 774 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0572 - val_loss: 0.1539 - val_mae: 0.3726\n",
      "Epoch 776/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0088 - mae: 0.0459\n",
      "Learning rate after epoch 775 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0440 - val_loss: 0.0215 - val_mae: 0.1002\n",
      "Epoch 777/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0475\n",
      "Learning rate after epoch 776 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0438 - val_loss: 0.0093 - val_mae: 0.0617\n",
      "Epoch 778/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0393\n",
      "Learning rate after epoch 777 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0478 - val_loss: 0.0399 - val_mae: 0.1721\n",
      "Epoch 779/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0609\n",
      "Learning rate after epoch 778 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0538 - val_loss: 0.0776 - val_mae: 0.2566\n",
      "Epoch 780/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0262\n",
      "Learning rate after epoch 779 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0479 - val_loss: 0.0065 - val_mae: 0.0403\n",
      "Epoch 781/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0109 - mae: 0.0717\n",
      "Learning rate after epoch 780 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0441 - val_loss: 0.0130 - val_mae: 0.0789\n",
      "Epoch 782/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0383\n",
      "Learning rate after epoch 781 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0465 - val_loss: 0.0424 - val_mae: 0.1858\n",
      "Epoch 783/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0271\n",
      "Learning rate after epoch 782 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0494 - val_loss: 0.0522 - val_mae: 0.1954\n",
      "Epoch 784/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0412\n",
      "Learning rate after epoch 783 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0445 - val_loss: 0.0397 - val_mae: 0.1760\n",
      "Epoch 785/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0094 - mae: 0.0627\n",
      "Learning rate after epoch 784 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0499 - val_loss: 0.0217 - val_mae: 0.1134\n",
      "Epoch 786/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0344\n",
      "Learning rate after epoch 785 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0524 - val_loss: 0.0182 - val_mae: 0.1011\n",
      "Epoch 787/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0556\n",
      "Learning rate after epoch 786 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0448 - val_loss: 0.0216 - val_mae: 0.1110\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0091 - mae: 0.0542\n",
      "Learning rate after epoch 787 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0542 - val_loss: 0.0252 - val_mae: 0.1355\n",
      "Epoch 789/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0088 - mae: 0.0547\n",
      "Learning rate after epoch 788 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0532 - val_loss: 0.0217 - val_mae: 0.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0087 - mae: 0.0505\n",
      "Learning rate after epoch 789 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0499 - val_loss: 0.0141 - val_mae: 0.0887\n",
      "Epoch 791/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0075 - mae: 0.0460\n",
      "Learning rate after epoch 790 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0490 - val_loss: 0.0080 - val_mae: 0.0518\n",
      "Epoch 792/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0639\n",
      "Learning rate after epoch 791 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0557 - val_loss: 0.2628 - val_mae: 0.4790\n",
      "Epoch 793/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0172 - mae: 0.1039\n",
      "Learning rate after epoch 792 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0596 - val_loss: 0.2064 - val_mae: 0.4250\n",
      "Epoch 794/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0421\n",
      "Learning rate after epoch 793 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0494 - val_loss: 0.0313 - val_mae: 0.1461\n",
      "Epoch 795/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0584\n",
      "Learning rate after epoch 794 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0521 - val_loss: 0.0196 - val_mae: 0.1055\n",
      "Epoch 796/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0137 - mae: 0.0902\n",
      "Learning rate after epoch 795 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0617 - val_loss: 0.0085 - val_mae: 0.0460\n",
      "Epoch 797/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0774\n",
      "Learning rate after epoch 796 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0125 - val_mae: 0.0664\n",
      "Epoch 798/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0471\n",
      "Learning rate after epoch 797 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0596 - val_loss: 0.0623 - val_mae: 0.2385\n",
      "Epoch 799/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0081 - mae: 0.0491\n",
      "Learning rate after epoch 798 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0592 - val_loss: 0.1218 - val_mae: 0.3326\n",
      "Epoch 800/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0618\n",
      "Learning rate after epoch 799 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0590 - val_loss: 0.2047 - val_mae: 0.4355\n",
      "Epoch 801/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0354\n",
      "Learning rate after epoch 800 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0559 - val_loss: 0.0849 - val_mae: 0.2813\n",
      "Epoch 802/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0250\n",
      "Learning rate after epoch 801 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0499 - val_loss: 0.0678 - val_mae: 0.2325\n",
      "Epoch 803/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0324\n",
      "Learning rate after epoch 802 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0540 - val_loss: 0.3038 - val_mae: 0.5203\n",
      "Epoch 804/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0305\n",
      "Learning rate after epoch 803 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0446 - val_loss: 0.2011 - val_mae: 0.4207\n",
      "Epoch 805/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0612\n",
      "Learning rate after epoch 804 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0555 - val_loss: 0.0699 - val_mae: 0.2496\n",
      "Epoch 806/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0248\n",
      "Learning rate after epoch 805 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0570 - val_loss: 0.0139 - val_mae: 0.0850\n",
      "Epoch 807/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0399\n",
      "Learning rate after epoch 806 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0501 - val_loss: 0.0063 - val_mae: 0.0328\n",
      "Epoch 808/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0352\n",
      "Learning rate after epoch 807 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0614 - val_loss: 0.0375 - val_mae: 0.1678\n",
      "Epoch 809/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0305\n",
      "Learning rate after epoch 808 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0475 - val_loss: 0.0093 - val_mae: 0.0547\n",
      "Epoch 810/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0383\n",
      "Learning rate after epoch 809 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0516 - val_loss: 0.1970 - val_mae: 0.4174\n",
      "Epoch 811/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0501\n",
      "Learning rate after epoch 810 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0542 - val_loss: 0.0884 - val_mae: 0.2762\n",
      "Epoch 812/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0597\n",
      "Learning rate after epoch 811 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0567 - val_loss: 0.0450 - val_mae: 0.1923\n",
      "Epoch 813/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0532\n",
      "Learning rate after epoch 812 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0543 - val_loss: 0.0051 - val_mae: 0.0186\n",
      "Epoch 814/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0349\n",
      "Learning rate after epoch 813 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0469 - val_loss: 0.0077 - val_mae: 0.0508\n",
      "Epoch 815/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0748\n",
      "Learning rate after epoch 814 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0548 - val_loss: 0.0099 - val_mae: 0.0679\n",
      "Epoch 816/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0365\n",
      "Learning rate after epoch 815 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0536 - val_loss: 0.0153 - val_mae: 0.0828\n",
      "Epoch 817/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0650\n",
      "Learning rate after epoch 816 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0469 - val_loss: 0.0078 - val_mae: 0.0502\n",
      "Epoch 818/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0410\n",
      "Learning rate after epoch 817 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0507 - val_loss: 0.0068 - val_mae: 0.0379\n",
      "Epoch 819/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0534\n",
      "Learning rate after epoch 818 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0545 - val_loss: 0.0742 - val_mae: 0.2545\n",
      "Epoch 820/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0306\n",
      "Learning rate after epoch 819 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0477 - val_loss: 0.0667 - val_mae: 0.2479\n",
      "Epoch 821/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0371\n",
      "Learning rate after epoch 820 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0466 - val_loss: 0.0058 - val_mae: 0.0312\n",
      "Epoch 822/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0318\n",
      "Learning rate after epoch 821 is 0.0099\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0476 - val_loss: 0.0112 - val_mae: 0.0792\n",
      "Epoch 823/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0408\n",
      "Learning rate after epoch 822 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0671 - val_loss: 0.0194 - val_mae: 0.1119\n",
      "Epoch 824/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0636\n",
      "Learning rate after epoch 823 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0482 - val_loss: 0.0151 - val_mae: 0.0917\n",
      "Epoch 825/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0450\n",
      "Learning rate after epoch 824 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0548 - val_loss: 0.0219 - val_mae: 0.0977\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0089 - mae: 0.0545\n",
      "Learning rate after epoch 825 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0545 - val_loss: 0.0094 - val_mae: 0.0669\n",
      "Epoch 827/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0282\n",
      "Learning rate after epoch 826 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0593 - val_loss: 0.0147 - val_mae: 0.0978\n",
      "Epoch 828/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0543\n",
      "Learning rate after epoch 827 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0490 - val_loss: 0.0108 - val_mae: 0.0592\n",
      "Epoch 829/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0710\n",
      "Learning rate after epoch 828 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0457 - val_loss: 0.0186 - val_mae: 0.1115\n",
      "Epoch 830/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0427\n",
      "Learning rate after epoch 829 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0491 - val_loss: 0.0187 - val_mae: 0.0861\n",
      "Epoch 831/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0414\n",
      "Learning rate after epoch 830 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0504 - val_loss: 0.0906 - val_mae: 0.2841\n",
      "Epoch 832/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0102 - mae: 0.0632\n",
      "Learning rate after epoch 831 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.1042\n",
      "Epoch 833/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0372\n",
      "Learning rate after epoch 832 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0468 - val_loss: 0.0512 - val_mae: 0.2116\n",
      "Epoch 834/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0330\n",
      "Learning rate after epoch 833 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0541 - val_loss: 0.1021 - val_mae: 0.3028\n",
      "Epoch 835/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0098 - mae: 0.0592\n",
      "Learning rate after epoch 834 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0471 - val_loss: 0.0199 - val_mae: 0.1164\n",
      "Epoch 836/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0361\n",
      "Learning rate after epoch 835 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0551 - val_loss: 0.0181 - val_mae: 0.1127\n",
      "Epoch 837/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0563\n",
      "Learning rate after epoch 836 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0478 - val_loss: 0.0046 - val_mae: 0.0091\n",
      "Epoch 838/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0244 - mae: 0.1296\n",
      "Learning rate after epoch 837 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0599 - val_loss: 0.0107 - val_mae: 0.0756\n",
      "Epoch 839/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0151 - mae: 0.0933\n",
      "Learning rate after epoch 838 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0416 - val_loss: 0.0088 - val_mae: 0.0537\n",
      "Epoch 840/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0423\n",
      "Learning rate after epoch 839 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0481 - val_loss: 0.0121 - val_mae: 0.0706\n",
      "Epoch 841/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0491\n",
      "Learning rate after epoch 840 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0517 - val_loss: 0.0304 - val_mae: 0.1566\n",
      "Epoch 842/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0238\n",
      "Learning rate after epoch 841 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0476 - val_loss: 0.0767 - val_mae: 0.2517\n",
      "Epoch 843/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0403\n",
      "Learning rate after epoch 842 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0595 - val_loss: 0.0122 - val_mae: 0.0816\n",
      "Epoch 844/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0365\n",
      "Learning rate after epoch 843 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0462 - val_loss: 0.2301 - val_mae: 0.4498\n",
      "Epoch 845/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0532\n",
      "Learning rate after epoch 844 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0507 - val_loss: 0.1022 - val_mae: 0.3045\n",
      "Epoch 846/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0326\n",
      "Learning rate after epoch 845 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0617 - val_loss: 0.0441 - val_mae: 0.1956\n",
      "Epoch 847/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0469\n",
      "Learning rate after epoch 846 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0952\n",
      "Epoch 848/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0154 - mae: 0.0945\n",
      "Learning rate after epoch 847 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0547 - val_loss: 0.0120 - val_mae: 0.0844\n",
      "Epoch 849/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0594\n",
      "Learning rate after epoch 848 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0438 - val_loss: 0.0149 - val_mae: 0.0878\n",
      "Epoch 850/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0397\n",
      "Learning rate after epoch 849 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0470 - val_loss: 0.0111 - val_mae: 0.0731\n",
      "Epoch 851/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0357\n",
      "Learning rate after epoch 850 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0486 - val_loss: 0.0053 - val_mae: 0.0256\n",
      "Epoch 852/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0438\n",
      "Learning rate after epoch 851 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0554 - val_loss: 0.0087 - val_mae: 0.0614\n",
      "Epoch 853/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0444\n",
      "Learning rate after epoch 852 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0543 - val_loss: 0.0142 - val_mae: 0.0731\n",
      "Epoch 854/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0687\n",
      "Learning rate after epoch 853 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0548 - val_loss: 0.0786 - val_mae: 0.2684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0476\n",
      "Learning rate after epoch 854 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0573 - val_loss: 0.0734 - val_mae: 0.2557\n",
      "Epoch 856/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0084 - mae: 0.0495\n",
      "Learning rate after epoch 855 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0360 - val_mae: 0.1756\n",
      "Epoch 857/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0553\n",
      "Learning rate after epoch 856 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0445 - val_loss: 0.0198 - val_mae: 0.1129\n",
      "Epoch 858/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0498\n",
      "Learning rate after epoch 857 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0527 - val_loss: 0.0071 - val_mae: 0.0484\n",
      "Epoch 859/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0355\n",
      "Learning rate after epoch 858 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0489 - val_loss: 0.0094 - val_mae: 0.0649\n",
      "Epoch 860/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0233 - mae: 0.1326\n",
      "Learning rate after epoch 859 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0564 - val_loss: 0.0132 - val_mae: 0.0877\n",
      "Epoch 861/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0117 - mae: 0.0697\n",
      "Learning rate after epoch 860 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0582 - val_loss: 0.0119 - val_mae: 0.0656\n",
      "Epoch 862/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0477\n",
      "Learning rate after epoch 861 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0511 - val_loss: 0.0168 - val_mae: 0.1002\n",
      "Epoch 863/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0105 - mae: 0.0651\n",
      "Learning rate after epoch 862 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0500 - val_loss: 0.0535 - val_mae: 0.2091\n",
      "Epoch 864/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0388\n",
      "Learning rate after epoch 863 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0511 - val_loss: 0.0142 - val_mae: 0.0906\n",
      "Epoch 865/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0284\n",
      "Learning rate after epoch 864 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0488 - val_loss: 0.0347 - val_mae: 0.1606\n",
      "Epoch 866/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0522\n",
      "Learning rate after epoch 865 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0491 - val_loss: 0.0962 - val_mae: 0.2952\n",
      "Epoch 867/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0107 - mae: 0.0701\n",
      "Learning rate after epoch 866 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0552 - val_loss: 0.0619 - val_mae: 0.2289\n",
      "Epoch 868/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0388\n",
      "Learning rate after epoch 867 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0566 - val_loss: 0.0412 - val_mae: 0.1786\n",
      "Epoch 869/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0467\n",
      "Learning rate after epoch 868 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0475 - val_loss: 0.0147 - val_mae: 0.0982\n",
      "Epoch 870/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0336\n",
      "Learning rate after epoch 869 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0470 - val_loss: 0.0112 - val_mae: 0.0745\n",
      "Epoch 871/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0544\n",
      "Learning rate after epoch 870 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0483 - val_loss: 0.0144 - val_mae: 0.0869\n",
      "Epoch 872/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0653\n",
      "Learning rate after epoch 871 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0573 - val_loss: 0.0148 - val_mae: 0.0999\n",
      "Epoch 873/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0312\n",
      "Learning rate after epoch 872 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0468 - val_loss: 0.0095 - val_mae: 0.0611\n",
      "Epoch 874/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0352\n",
      "Learning rate after epoch 873 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0462 - val_loss: 0.0115 - val_mae: 0.0686\n",
      "Epoch 875/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0468\n",
      "Learning rate after epoch 874 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0527 - val_loss: 0.0200 - val_mae: 0.1184\n",
      "Epoch 876/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0348\n",
      "Learning rate after epoch 875 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0482 - val_loss: 0.0060 - val_mae: 0.0401\n",
      "Epoch 877/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0178 - mae: 0.1076\n",
      "Learning rate after epoch 876 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0559 - val_loss: 0.0109 - val_mae: 0.0714\n",
      "Epoch 878/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0162 - mae: 0.1005\n",
      "Learning rate after epoch 877 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0527 - val_loss: 0.0104 - val_mae: 0.0721\n",
      "Epoch 879/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0270\n",
      "Learning rate after epoch 878 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0549 - val_loss: 0.0094 - val_mae: 0.0647\n",
      "Epoch 880/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0369\n",
      "Learning rate after epoch 879 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0478 - val_loss: 0.0156 - val_mae: 0.0792\n",
      "Epoch 881/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0357\n",
      "Learning rate after epoch 880 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0527 - val_loss: 0.0275 - val_mae: 0.1372\n",
      "Epoch 882/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0115 - mae: 0.0787\n",
      "Learning rate after epoch 881 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0573 - val_loss: 0.0301 - val_mae: 0.1443\n",
      "Epoch 883/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0292\n",
      "Learning rate after epoch 882 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0506 - val_loss: 0.0260 - val_mae: 0.1202\n",
      "Epoch 884/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0541\n",
      "Learning rate after epoch 883 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0459 - val_loss: 0.0046 - val_mae: 0.0087\n",
      "Epoch 885/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0491\n",
      "Learning rate after epoch 884 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0511 - val_loss: 0.0064 - val_mae: 0.0437\n",
      "Epoch 886/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0543\n",
      "Learning rate after epoch 885 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0506 - val_loss: 0.0059 - val_mae: 0.0333\n",
      "Epoch 887/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0386\n",
      "Learning rate after epoch 886 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0495 - val_loss: 0.0048 - val_mae: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0444\n",
      "Learning rate after epoch 887 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0560 - val_loss: 0.0081 - val_mae: 0.0471\n",
      "Epoch 889/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0671\n",
      "Learning rate after epoch 888 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0546 - val_loss: 0.0117 - val_mae: 0.0689\n",
      "Epoch 890/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0350\n",
      "Learning rate after epoch 889 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0526 - val_loss: 0.0364 - val_mae: 0.1695\n",
      "Epoch 891/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0431\n",
      "Learning rate after epoch 890 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0561 - val_loss: 0.0061 - val_mae: 0.0289\n",
      "Epoch 892/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0472\n",
      "Learning rate after epoch 891 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0540 - val_loss: 0.2930 - val_mae: 0.5120\n",
      "Epoch 893/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0225 - mae: 0.1011\n",
      "Learning rate after epoch 892 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0523 - val_loss: 0.0471 - val_mae: 0.2000\n",
      "Epoch 894/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0680\n",
      "Learning rate after epoch 893 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0455 - val_loss: 0.0805 - val_mae: 0.2614\n",
      "Epoch 895/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0597\n",
      "Learning rate after epoch 894 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0533 - val_loss: 0.0307 - val_mae: 0.1426\n",
      "Epoch 896/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0420\n",
      "Learning rate after epoch 895 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0490 - val_loss: 0.0212 - val_mae: 0.1229\n",
      "Epoch 897/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0384\n",
      "Learning rate after epoch 896 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0466 - val_loss: 0.0059 - val_mae: 0.0321\n",
      "Epoch 898/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0087 - mae: 0.0496\n",
      "Learning rate after epoch 897 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0516 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "Epoch 899/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0326\n",
      "Learning rate after epoch 898 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0614 - val_loss: 0.0096 - val_mae: 0.0614\n",
      "Epoch 900/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0386\n",
      "Learning rate after epoch 899 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0478 - val_loss: 0.0074 - val_mae: 0.0479\n",
      "Epoch 901/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0150 - mae: 0.0928\n",
      "Learning rate after epoch 900 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0583 - val_loss: 0.0213 - val_mae: 0.1168\n",
      "Epoch 902/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0785\n",
      "Learning rate after epoch 901 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0543 - val_loss: 0.0171 - val_mae: 0.1109\n",
      "Epoch 903/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0311\n",
      "Learning rate after epoch 902 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0502 - val_loss: 0.0326 - val_mae: 0.1567\n",
      "Epoch 904/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0082 - mae: 0.0458\n",
      "Learning rate after epoch 903 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0585 - val_loss: 0.0510 - val_mae: 0.1992\n",
      "Epoch 905/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0579\n",
      "Learning rate after epoch 904 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0596 - val_loss: 0.0337 - val_mae: 0.1627\n",
      "Epoch 906/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0456\n",
      "Learning rate after epoch 905 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0561 - val_loss: 0.0193 - val_mae: 0.1197\n",
      "Epoch 907/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0170 - mae: 0.0919\n",
      "Learning rate after epoch 906 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0515 - val_loss: 0.0180 - val_mae: 0.1120\n",
      "Epoch 908/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0388\n",
      "Learning rate after epoch 907 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0492 - val_loss: 0.0132 - val_mae: 0.0698\n",
      "Epoch 909/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0588\n",
      "Learning rate after epoch 908 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0467 - val_loss: 0.0136 - val_mae: 0.0798\n",
      "Epoch 910/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0409\n",
      "Learning rate after epoch 909 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0528 - val_loss: 0.0090 - val_mae: 0.0591\n",
      "Epoch 911/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0086 - mae: 0.0538\n",
      "Learning rate after epoch 910 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0496 - val_loss: 0.0131 - val_mae: 0.0672\n",
      "Epoch 912/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0547\n",
      "Learning rate after epoch 911 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0521 - val_loss: 0.0209 - val_mae: 0.1249\n",
      "Epoch 913/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0375\n",
      "Learning rate after epoch 912 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0495 - val_loss: 0.0237 - val_mae: 0.1336\n",
      "Epoch 914/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.0693\n",
      "Learning rate after epoch 913 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0512 - val_loss: 0.0281 - val_mae: 0.1496\n",
      "Epoch 915/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0333\n",
      "Learning rate after epoch 914 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0523 - val_loss: 0.0150 - val_mae: 0.0923\n",
      "Epoch 916/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0787\n",
      "Learning rate after epoch 915 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0530 - val_loss: 0.2306 - val_mae: 0.4481\n",
      "Epoch 917/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0339\n",
      "Learning rate after epoch 916 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0524 - val_loss: 0.2606 - val_mae: 0.4769\n",
      "Epoch 918/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0336\n",
      "Learning rate after epoch 917 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0570 - val_loss: 0.2449 - val_mae: 0.4632\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0096 - mae: 0.0545\n",
      "Learning rate after epoch 918 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0545 - val_loss: 0.0649 - val_mae: 0.2387\n",
      "Epoch 920/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0546\n",
      "Learning rate after epoch 919 is 0.0098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0543 - val_loss: 0.0362 - val_mae: 0.1664\n",
      "Epoch 921/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0458\n",
      "Learning rate after epoch 920 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0479 - val_loss: 0.1946 - val_mae: 0.4166\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0075 - mae: 0.0422\n",
      "Learning rate after epoch 921 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0422 - val_loss: 0.0195 - val_mae: 0.1139\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0126 - mae: 0.0673\n",
      "Learning rate after epoch 922 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0673 - val_loss: 0.2423 - val_mae: 0.4612\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0093 - mae: 0.0530\n",
      "Learning rate after epoch 923 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0530 - val_loss: 0.0498 - val_mae: 0.2083\n",
      "Epoch 925/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0316\n",
      "Learning rate after epoch 924 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0595 - val_loss: 0.0372 - val_mae: 0.1733\n",
      "Epoch 926/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.0768\n",
      "Learning rate after epoch 925 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0526 - val_loss: 0.0322 - val_mae: 0.1503\n",
      "Epoch 927/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0158 - mae: 0.1014\n",
      "Learning rate after epoch 926 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0573 - val_loss: 0.0632 - val_mae: 0.2264\n",
      "Epoch 928/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0446\n",
      "Learning rate after epoch 927 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0577 - val_loss: 0.0592 - val_mae: 0.2194\n",
      "Epoch 929/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0451\n",
      "Learning rate after epoch 928 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0565 - val_loss: 0.0154 - val_mae: 0.0767\n",
      "Epoch 930/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0626\n",
      "Learning rate after epoch 929 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0566 - val_loss: 0.0132 - val_mae: 0.0870\n",
      "Epoch 931/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0104 - mae: 0.0693\n",
      "Learning rate after epoch 930 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0426 - val_loss: 0.0236 - val_mae: 0.1025\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0074 - mae: 0.0427\n",
      "Learning rate after epoch 931 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0427 - val_loss: 0.0205 - val_mae: 0.0973\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0080 - mae: 0.0465\n",
      "Learning rate after epoch 932 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0465 - val_loss: 0.0126 - val_mae: 0.0776\n",
      "Epoch 934/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0329\n",
      "Learning rate after epoch 933 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0445 - val_loss: 0.0814 - val_mae: 0.2591\n",
      "Epoch 935/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0708\n",
      "Learning rate after epoch 934 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0464 - val_loss: 0.1722 - val_mae: 0.3870\n",
      "Epoch 936/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0462\n",
      "Learning rate after epoch 935 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0449 - val_loss: 0.0679 - val_mae: 0.2212\n",
      "Epoch 937/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0383\n",
      "Learning rate after epoch 936 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0443 - val_loss: 0.0078 - val_mae: 0.0515\n",
      "Epoch 938/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0066 - mae: 0.0406\n",
      "Learning rate after epoch 937 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0535 - val_loss: 0.0108 - val_mae: 0.0728\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0086 - mae: 0.0522\n",
      "Learning rate after epoch 938 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0522 - val_loss: 0.0054 - val_mae: 0.0212\n",
      "Epoch 940/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0456\n",
      "Learning rate after epoch 939 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0525 - val_loss: 0.0069 - val_mae: 0.0411\n",
      "Epoch 941/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0462\n",
      "Learning rate after epoch 940 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0561 - val_loss: 0.2980 - val_mae: 0.5160\n",
      "Epoch 942/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0097 - mae: 0.0637\n",
      "Learning rate after epoch 941 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0569 - val_loss: 0.3038 - val_mae: 0.5205\n",
      "Epoch 943/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0255\n",
      "Learning rate after epoch 942 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0496 - val_loss: 0.0437 - val_mae: 0.1926\n",
      "Epoch 944/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0469\n",
      "Learning rate after epoch 943 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0500 - val_loss: 0.1641 - val_mae: 0.3777\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0090 - mae: 0.0541\n",
      "Learning rate after epoch 944 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0541 - val_loss: 0.0119 - val_mae: 0.0787\n",
      "Epoch 946/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0474\n",
      "Learning rate after epoch 945 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0527 - val_loss: 0.0095 - val_mae: 0.0571\n",
      "Epoch 947/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0390\n",
      "Learning rate after epoch 946 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0435 - val_loss: 0.0139 - val_mae: 0.0844\n",
      "Epoch 948/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0069 - mae: 0.0416\n",
      "Learning rate after epoch 947 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0485 - val_loss: 0.0068 - val_mae: 0.0366\n",
      "Epoch 949/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0427\n",
      "Learning rate after epoch 948 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0504 - val_loss: 0.0098 - val_mae: 0.0651\n",
      "Epoch 950/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0137 - mae: 0.0882\n",
      "Learning rate after epoch 949 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0587 - val_loss: 0.0048 - val_mae: 0.0181\n",
      "Epoch 951/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0620\n",
      "Learning rate after epoch 950 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0509 - val_loss: 0.0135 - val_mae: 0.0866\n",
      "Epoch 952/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0405\n",
      "Learning rate after epoch 951 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0540 - val_loss: 0.0119 - val_mae: 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0336\n",
      "Learning rate after epoch 952 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0570 - val_loss: 0.0070 - val_mae: 0.0465\n",
      "Epoch 954/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0480\n",
      "Learning rate after epoch 953 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0525 - val_loss: 0.0099 - val_mae: 0.0577\n",
      "Epoch 955/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0341\n",
      "Learning rate after epoch 954 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0538 - val_loss: 0.0058 - val_mae: 0.0299\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0089 - mae: 0.0511\n",
      "Learning rate after epoch 955 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0511 - val_loss: 0.0055 - val_mae: 0.0292\n",
      "Epoch 957/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0596\n",
      "Learning rate after epoch 956 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0505 - val_loss: 0.0062 - val_mae: 0.0348\n",
      "Epoch 958/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0374\n",
      "Learning rate after epoch 957 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0599 - val_loss: 0.0054 - val_mae: 0.0253\n",
      "Epoch 959/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0588\n",
      "Learning rate after epoch 958 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0521 - val_loss: 0.0052 - val_mae: 0.0154\n",
      "Epoch 960/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0357\n",
      "Learning rate after epoch 959 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0499 - val_loss: 0.0130 - val_mae: 0.0720\n",
      "Epoch 961/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0304\n",
      "Learning rate after epoch 960 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0483 - val_loss: 0.0085 - val_mae: 0.0537\n",
      "Epoch 962/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0056 - mae: 0.0315\n",
      "Learning rate after epoch 961 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0558 - val_loss: 0.0100 - val_mae: 0.0699\n",
      "Epoch 963/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0116 - mae: 0.0697\n",
      "Learning rate after epoch 962 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0494 - val_loss: 0.0050 - val_mae: 0.0208\n",
      "Epoch 964/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0592\n",
      "Learning rate after epoch 963 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0467 - val_loss: 0.0107 - val_mae: 0.0714\n",
      "Epoch 965/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0684\n",
      "Learning rate after epoch 964 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0609 - val_loss: 0.0316 - val_mae: 0.1525\n",
      "Epoch 966/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0101 - mae: 0.0690\n",
      "Learning rate after epoch 965 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0557 - val_loss: 0.0102 - val_mae: 0.0673\n",
      "Epoch 967/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0253\n",
      "Learning rate after epoch 966 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0495 - val_loss: 0.0060 - val_mae: 0.0359\n",
      "Epoch 968/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0467\n",
      "Learning rate after epoch 967 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0467 - val_loss: 0.0318 - val_mae: 0.1412\n",
      "Epoch 969/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0491\n",
      "Learning rate after epoch 968 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0499 - val_loss: 0.0079 - val_mae: 0.0506\n",
      "Epoch 970/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0259\n",
      "Learning rate after epoch 969 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0451 - val_loss: 0.2401 - val_mae: 0.4577\n",
      "Epoch 971/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0351\n",
      "Learning rate after epoch 970 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0466 - val_loss: 0.1749 - val_mae: 0.3905\n",
      "Epoch 972/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.0728\n",
      "Learning rate after epoch 971 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0555 - val_loss: 0.1125 - val_mae: 0.3141\n",
      "Epoch 973/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0166 - mae: 0.1025\n",
      "Learning rate after epoch 972 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0517 - val_loss: 0.0674 - val_mae: 0.2336\n",
      "Epoch 974/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0410\n",
      "Learning rate after epoch 973 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0522 - val_loss: 0.0304 - val_mae: 0.1458\n",
      "Epoch 975/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0431\n",
      "Learning rate after epoch 974 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0489 - val_loss: 0.0103 - val_mae: 0.0687\n",
      "Epoch 976/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0354\n",
      "Learning rate after epoch 975 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0534 - val_loss: 0.0124 - val_mae: 0.0672\n",
      "Epoch 977/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0374\n",
      "Learning rate after epoch 976 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0486 - val_loss: 0.0099 - val_mae: 0.0710\n",
      "Epoch 978/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0355\n",
      "Learning rate after epoch 977 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0548 - val_loss: 0.0283 - val_mae: 0.1516\n",
      "Epoch 979/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0087 - mae: 0.0465\n",
      "Learning rate after epoch 978 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0525 - val_loss: 0.0195 - val_mae: 0.0882\n",
      "Epoch 980/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0589\n",
      "Learning rate after epoch 979 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0582 - val_loss: 0.0451 - val_mae: 0.1946\n",
      "Epoch 981/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0131 - mae: 0.0879\n",
      "Learning rate after epoch 980 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0552 - val_loss: 0.0202 - val_mae: 0.1212\n",
      "Epoch 982/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0130 - mae: 0.0785\n",
      "Learning rate after epoch 981 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0521 - val_loss: 0.0078 - val_mae: 0.0494\n",
      "Epoch 983/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0125 - mae: 0.0742\n",
      "Learning rate after epoch 982 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0550 - val_loss: 0.0152 - val_mae: 0.1002\n",
      "Epoch 984/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0639\n",
      "Learning rate after epoch 983 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0593 - val_loss: 0.0113 - val_mae: 0.0613\n",
      "Epoch 985/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0128 - mae: 0.0859\n",
      "Learning rate after epoch 984 is 0.0098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0588 - val_loss: 0.0182 - val_mae: 0.0851\n",
      "Epoch 986/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0345\n",
      "Learning rate after epoch 985 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0467 - val_loss: 0.0080 - val_mae: 0.0524\n",
      "Epoch 987/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0167 - mae: 0.0948\n",
      "Learning rate after epoch 986 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0581 - val_loss: 0.0045 - val_mae: 0.0070\n",
      "Epoch 988/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0393\n",
      "Learning rate after epoch 987 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0574 - val_loss: 0.0160 - val_mae: 0.0828\n",
      "Epoch 989/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0177 - mae: 0.0996\n",
      "Learning rate after epoch 988 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0491 - val_loss: 0.0053 - val_mae: 0.0292\n",
      "Epoch 990/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0762\n",
      "Learning rate after epoch 989 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0526 - val_loss: 0.0144 - val_mae: 0.0778\n",
      "Epoch 991/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0172 - mae: 0.1004\n",
      "Learning rate after epoch 990 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0475 - val_loss: 0.1438 - val_mae: 0.3587\n",
      "Epoch 992/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0576\n",
      "Learning rate after epoch 991 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0507 - val_loss: 0.2624 - val_mae: 0.4788\n",
      "Epoch 993/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0401\n",
      "Learning rate after epoch 992 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0492 - val_loss: 0.2586 - val_mae: 0.4751\n",
      "Epoch 994/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0385\n",
      "Learning rate after epoch 993 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0531 - val_loss: 0.2261 - val_mae: 0.4468\n",
      "Epoch 995/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0323\n",
      "Learning rate after epoch 994 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0501 - val_loss: 0.1268 - val_mae: 0.3332\n",
      "Epoch 996/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0501\n",
      "Learning rate after epoch 995 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0558 - val_loss: 0.0511 - val_mae: 0.2034\n",
      "Epoch 997/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0455\n",
      "Learning rate after epoch 996 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0433 - val_loss: 0.0173 - val_mae: 0.0965\n",
      "Epoch 998/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0475\n",
      "Learning rate after epoch 997 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0548 - val_loss: 0.0115 - val_mae: 0.0732\n",
      "Epoch 999/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0596\n",
      "Learning rate after epoch 998 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0567 - val_loss: 0.0131 - val_mae: 0.0869\n",
      "Epoch 1000/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0263\n",
      "Learning rate after epoch 999 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0562 - val_loss: 0.0070 - val_mae: 0.0482\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add,Lambda,Flatten\n",
    "\n",
    "# Define the first parallel recurrent layer with return_sequences=True\n",
    "rnn_1 = GRU(units=11)(input_1)\n",
    "dropout1 = Dropout(rate=0.1)(rnn_1)\n",
    "\n",
    "# Define the second parallel recurrent layer\n",
    "rnn_2 = GRU(units=11)(input_2)\n",
    "dropout2 = Dropout(rate=0.1)(rnn_2)\n",
    "\n",
    "# Define the third parallel recurrent layer\n",
    "rnn_3 = GRU(units=11)(input_3)\n",
    "dropout3 = Dropout(rate=0.1)(rnn_3)\n",
    "\n",
    "# Define the fourth parallel recurrent layer\n",
    "rnn_4 = GRU(units=11)(input_4)\n",
    "dropout4 = Dropout(rate=0.1)(rnn_4)\n",
    "\n",
    "# Concatenate the outputs of the recurrent layers\n",
    "merged = concatenate([dropout1, dropout2, dropout3, dropout4], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the merged output\n",
    "flatten = Flatten()(merged)\n",
    "\n",
    "# ...\n",
    "activation_layer = Activation('tanh')(flatten)\n",
    "dense1 = Dense(units=50, activation='tanh', kernel_regularizer=regularizers.l1(0.001))(activation_layer)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(units=25, activation='relu', kernel_regularizer=regularizers.l1(0.001))(dense1)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the output layer\n",
    "output = Dense(units=1, activation='sigmoid')(dense2)\n",
    "\n",
    "\n",
    "# Create the model with the inputs and output\n",
    "regressor = Model(inputs=[input_1, input_2,input_3, input_4], outputs=output)\n",
    "\n",
    "# Compile the model with the desired optimizer, loss function, and metrics\n",
    "regressor.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model with the training data\n",
    "result=regressor.fit([X_train1, X_train2,X_train3, X_train4], y_train, epochs=1000, batch_size=25,validation_data=([X_val1, X_val2,X_val3, X_val4], y_val),callbacks=[LearningRateLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "852f54fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 11)           462         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 11)           462         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 11)           462         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 11)           462         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 11)           0           ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 11)           0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 11)           0           ['gru_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 11)           0           ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 44)           0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 44)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 44)           0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           2250        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50)          200         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           1275        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 25)          100         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            26          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,699\n",
      "Trainable params: 5,549\n",
      "Non-trainable params: 150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e751d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data\n",
    "trainPredict = regressor.predict([X_train1, X_train2, X_train3, X_train4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bb6ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8d54155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8298536 ],\n",
       "       [0.8308983 ],\n",
       "       [0.82540244],\n",
       "       [0.82572323],\n",
       "       [0.82585186],\n",
       "       [0.8259545 ],\n",
       "       [0.8245999 ],\n",
       "       [0.822877  ],\n",
       "       [0.8223266 ],\n",
       "       [0.82161695],\n",
       "       [0.8203436 ],\n",
       "       [0.82077897],\n",
       "       [0.8276254 ],\n",
       "       [0.8290206 ],\n",
       "       [0.8298263 ],\n",
       "       [0.8301886 ],\n",
       "       [0.8306108 ],\n",
       "       [0.8306706 ],\n",
       "       [0.83022   ],\n",
       "       [0.83007133],\n",
       "       [0.8281854 ],\n",
       "       [0.8267976 ],\n",
       "       [0.8239735 ],\n",
       "       [0.8223821 ],\n",
       "       [0.82074857],\n",
       "       [0.81806254],\n",
       "       [0.8155449 ],\n",
       "       [0.8132726 ],\n",
       "       [0.8107852 ],\n",
       "       [0.8074728 ],\n",
       "       [0.803406  ],\n",
       "       [0.7965367 ],\n",
       "       [0.79086643],\n",
       "       [0.7842217 ],\n",
       "       [0.7773431 ],\n",
       "       [0.77301824],\n",
       "       [0.76808774],\n",
       "       [0.76256645],\n",
       "       [0.7558036 ],\n",
       "       [0.7529631 ],\n",
       "       [0.75576395],\n",
       "       [0.757584  ],\n",
       "       [0.75785184],\n",
       "       [0.75697535],\n",
       "       [0.7557289 ],\n",
       "       [0.7526218 ],\n",
       "       [0.75051415],\n",
       "       [0.74731857],\n",
       "       [0.74507797],\n",
       "       [0.7381795 ],\n",
       "       [0.72590005],\n",
       "       [0.71478844],\n",
       "       [0.705253  ],\n",
       "       [0.6950285 ],\n",
       "       [0.6849487 ],\n",
       "       [0.67535335],\n",
       "       [0.666088  ],\n",
       "       [0.6559927 ],\n",
       "       [0.6465936 ],\n",
       "       [0.637251  ],\n",
       "       [0.62761307],\n",
       "       [0.617825  ],\n",
       "       [0.6078576 ],\n",
       "       [0.5992943 ],\n",
       "       [0.59037536],\n",
       "       [0.58093154],\n",
       "       [0.5712619 ],\n",
       "       [0.5623969 ],\n",
       "       [0.5529127 ],\n",
       "       [0.54457563],\n",
       "       [0.5386478 ],\n",
       "       [0.5317565 ],\n",
       "       [0.5241004 ],\n",
       "       [0.51638025],\n",
       "       [0.50991464],\n",
       "       [0.5033393 ],\n",
       "       [0.49662802],\n",
       "       [0.48974326],\n",
       "       [0.48305237],\n",
       "       [0.47605914],\n",
       "       [0.4681565 ],\n",
       "       [0.46696615],\n",
       "       [0.4666463 ],\n",
       "       [0.4656259 ],\n",
       "       [0.46318498],\n",
       "       [0.46067423],\n",
       "       [0.4582717 ],\n",
       "       [0.45649204],\n",
       "       [0.45479935],\n",
       "       [0.45261887],\n",
       "       [0.44946787],\n",
       "       [0.44072565],\n",
       "       [0.4317129 ],\n",
       "       [0.42398968],\n",
       "       [0.42000562],\n",
       "       [0.41644377],\n",
       "       [0.41218445],\n",
       "       [0.4077695 ],\n",
       "       [0.40369943],\n",
       "       [0.39907426],\n",
       "       [0.39571488],\n",
       "       [0.3921026 ],\n",
       "       [0.3885096 ],\n",
       "       [0.38455576],\n",
       "       [0.3780065 ],\n",
       "       [0.37179598],\n",
       "       [0.36689296],\n",
       "       [0.36195326],\n",
       "       [0.35713005],\n",
       "       [0.35273692],\n",
       "       [0.34820294],\n",
       "       [0.34900728],\n",
       "       [0.34852836],\n",
       "       [0.34700465],\n",
       "       [0.3451176 ],\n",
       "       [0.34331977],\n",
       "       [0.3412497 ],\n",
       "       [0.33897185],\n",
       "       [0.33676836],\n",
       "       [0.33447927],\n",
       "       [0.33198723],\n",
       "       [0.32498923],\n",
       "       [0.3197239 ],\n",
       "       [0.31548074],\n",
       "       [0.3151089 ],\n",
       "       [0.3128501 ],\n",
       "       [0.31072196],\n",
       "       [0.30872625],\n",
       "       [0.30623645],\n",
       "       [0.3046575 ],\n",
       "       [0.30305344],\n",
       "       [0.30113938],\n",
       "       [0.29909042],\n",
       "       [0.2969806 ],\n",
       "       [0.29186687],\n",
       "       [0.2885692 ],\n",
       "       [0.2853474 ],\n",
       "       [0.2823637 ],\n",
       "       [0.2794413 ],\n",
       "       [0.27609038],\n",
       "       [0.27316466],\n",
       "       [0.27295208],\n",
       "       [0.27410182],\n",
       "       [0.27469692],\n",
       "       [0.27440754],\n",
       "       [0.2739952 ],\n",
       "       [0.27353784],\n",
       "       [0.27332017],\n",
       "       [0.27316365],\n",
       "       [0.27277043],\n",
       "       [0.27207932],\n",
       "       [0.2689389 ],\n",
       "       [0.26505414],\n",
       "       [0.26170003],\n",
       "       [0.2589403 ],\n",
       "       [0.25660568],\n",
       "       [0.25412393],\n",
       "       [0.2518499 ],\n",
       "       [0.25321433],\n",
       "       [0.29941082],\n",
       "       [0.3504887 ],\n",
       "       [0.40693873],\n",
       "       [0.47200233],\n",
       "       [0.54379195],\n",
       "       [0.6208296 ],\n",
       "       [0.70037884],\n",
       "       [0.776336  ],\n",
       "       [0.84262466],\n",
       "       [0.8937702 ],\n",
       "       [0.89127815],\n",
       "       [0.8687139 ],\n",
       "       [0.86552656],\n",
       "       [0.8610693 ],\n",
       "       [0.85708207],\n",
       "       [0.8520389 ],\n",
       "       [0.84687316],\n",
       "       [0.84138846],\n",
       "       [0.83652395],\n",
       "       [0.83345264],\n",
       "       [0.8352609 ],\n",
       "       [0.8584511 ],\n",
       "       [0.8596749 ],\n",
       "       [0.8598488 ],\n",
       "       [0.8594666 ],\n",
       "       [0.859057  ],\n",
       "       [0.85792005],\n",
       "       [0.85768545],\n",
       "       [0.85633314],\n",
       "       [0.85330296],\n",
       "       [0.8449848 ],\n",
       "       [0.8370504 ],\n",
       "       [0.8336326 ],\n",
       "       [0.82948226],\n",
       "       [0.8247769 ],\n",
       "       [0.819783  ],\n",
       "       [0.81349444],\n",
       "       [0.80646557],\n",
       "       [0.79966575],\n",
       "       [0.7917405 ],\n",
       "       [0.782699  ],\n",
       "       [0.77387196],\n",
       "       [0.75998336],\n",
       "       [0.7477419 ],\n",
       "       [0.7394931 ],\n",
       "       [0.7309904 ],\n",
       "       [0.72147584],\n",
       "       [0.7107877 ],\n",
       "       [0.7055583 ],\n",
       "       [0.7101056 ],\n",
       "       [0.7130501 ],\n",
       "       [0.71536124],\n",
       "       [0.71670383],\n",
       "       [0.7155316 ],\n",
       "       [0.70849866],\n",
       "       [0.7024892 ],\n",
       "       [0.6972664 ],\n",
       "       [0.69197357],\n",
       "       [0.6809775 ],\n",
       "       [0.6594586 ],\n",
       "       [0.6397416 ],\n",
       "       [0.62033653],\n",
       "       [0.60089475],\n",
       "       [0.58361506],\n",
       "       [0.567726  ],\n",
       "       [0.55170786],\n",
       "       [0.5363479 ],\n",
       "       [0.5222003 ],\n",
       "       [0.5077186 ],\n",
       "       [0.4934796 ],\n",
       "       [0.48027834],\n",
       "       [0.4671845 ],\n",
       "       [0.4551132 ],\n",
       "       [0.44291118],\n",
       "       [0.43124858],\n",
       "       [0.420173  ],\n",
       "       [0.4094902 ],\n",
       "       [0.3989124 ],\n",
       "       [0.39252037],\n",
       "       [0.38819823],\n",
       "       [0.38097534],\n",
       "       [0.3739209 ],\n",
       "       [0.36703512],\n",
       "       [0.36115986],\n",
       "       [0.35548332],\n",
       "       [0.3495549 ],\n",
       "       [0.34262726],\n",
       "       [0.33577722],\n",
       "       [0.3273781 ],\n",
       "       [0.31745303],\n",
       "       [0.32188058],\n",
       "       [0.3276232 ],\n",
       "       [0.33180717],\n",
       "       [0.33386156],\n",
       "       [0.33527902],\n",
       "       [0.3362049 ],\n",
       "       [0.3379455 ],\n",
       "       [0.33951962],\n",
       "       [0.33939147],\n",
       "       [0.3393022 ],\n",
       "       [0.32692176],\n",
       "       [0.31413916],\n",
       "       [0.30312002],\n",
       "       [0.2964462 ],\n",
       "       [0.29299554],\n",
       "       [0.28923398],\n",
       "       [0.2849197 ],\n",
       "       [0.2801026 ],\n",
       "       [0.27549443],\n",
       "       [0.27192163],\n",
       "       [0.26790953],\n",
       "       [0.26325473],\n",
       "       [0.2590122 ],\n",
       "       [0.25329036],\n",
       "       [0.24573486],\n",
       "       [0.23909613],\n",
       "       [0.23274115],\n",
       "       [0.22732277],\n",
       "       [0.22293964],\n",
       "       [0.21885465],\n",
       "       [0.22075145],\n",
       "       [0.2229394 ],\n",
       "       [0.223508  ],\n",
       "       [0.22213362],\n",
       "       [0.2200512 ],\n",
       "       [0.21796115],\n",
       "       [0.21619248],\n",
       "       [0.21460693],\n",
       "       [0.2116863 ],\n",
       "       [0.20797867],\n",
       "       [0.19925478],\n",
       "       [0.19098975],\n",
       "       [0.18405062],\n",
       "       [0.17957938],\n",
       "       [0.17944683],\n",
       "       [0.17759985],\n",
       "       [0.17532842],\n",
       "       [0.17261238],\n",
       "       [0.17138536],\n",
       "       [0.16991104],\n",
       "       [0.16772796],\n",
       "       [0.16509399],\n",
       "       [0.16254602],\n",
       "       [0.15980747],\n",
       "       [0.15319683],\n",
       "       [0.14822464],\n",
       "       [0.14328972],\n",
       "       [0.13913442],\n",
       "       [0.13481547],\n",
       "       [0.1307414 ],\n",
       "       [0.12577026],\n",
       "       [0.12745598],\n",
       "       [0.12797616],\n",
       "       [0.12659086],\n",
       "       [0.12498034],\n",
       "       [0.12344424],\n",
       "       [0.12237506],\n",
       "       [0.12087342],\n",
       "       [0.11863668],\n",
       "       [0.1164775 ],\n",
       "       [0.11563998],\n",
       "       [0.10927465],\n",
       "       [0.10434324],\n",
       "       [0.10035303],\n",
       "       [0.09715316],\n",
       "       [0.09419462],\n",
       "       [0.09159865],\n",
       "       [0.09044093],\n",
       "       [0.12388933],\n",
       "       [0.16515759],\n",
       "       [0.21393569],\n",
       "       [0.2718286 ],\n",
       "       [0.34245756],\n",
       "       [0.42913225],\n",
       "       [0.5309383 ],\n",
       "       [0.6427641 ],\n",
       "       [0.7526391 ],\n",
       "       [0.84423155],\n",
       "       [0.84736377],\n",
       "       [0.83385867],\n",
       "       [0.8344774 ],\n",
       "       [0.8358664 ],\n",
       "       [0.8359976 ],\n",
       "       [0.83609873],\n",
       "       [0.83538604],\n",
       "       [0.83560914],\n",
       "       [0.83488715],\n",
       "       [0.8347326 ],\n",
       "       [0.8340896 ],\n",
       "       [0.84702176],\n",
       "       [0.8472733 ],\n",
       "       [0.8474103 ],\n",
       "       [0.8470101 ],\n",
       "       [0.8465523 ],\n",
       "       [0.8467145 ],\n",
       "       [0.84583104],\n",
       "       [0.8459609 ],\n",
       "       [0.8446996 ],\n",
       "       [0.8444469 ],\n",
       "       [0.8436065 ],\n",
       "       [0.8426267 ],\n",
       "       [0.84072894],\n",
       "       [0.83965206],\n",
       "       [0.8372094 ],\n",
       "       [0.83476686],\n",
       "       [0.8332297 ],\n",
       "       [0.8308243 ],\n",
       "       [0.8276257 ],\n",
       "       [0.8238091 ],\n",
       "       [0.8208729 ],\n",
       "       [0.81697744],\n",
       "       [0.8137712 ],\n",
       "       [0.81067854],\n",
       "       [0.8077221 ],\n",
       "       [0.8044246 ],\n",
       "       [0.800135  ],\n",
       "       [0.79843825],\n",
       "       [0.79891527],\n",
       "       [0.79954696],\n",
       "       [0.7987979 ],\n",
       "       [0.79705375],\n",
       "       [0.7949059 ],\n",
       "       [0.7925643 ],\n",
       "       [0.7910843 ],\n",
       "       [0.7890477 ],\n",
       "       [0.7867181 ],\n",
       "       [0.78200585],\n",
       "       [0.77449757],\n",
       "       [0.76676697],\n",
       "       [0.76066315],\n",
       "       [0.754599  ],\n",
       "       [0.74784106],\n",
       "       [0.7417541 ],\n",
       "       [0.7348403 ],\n",
       "       [0.7283053 ],\n",
       "       [0.7205618 ],\n",
       "       [0.7133993 ],\n",
       "       [0.7060775 ],\n",
       "       [0.69877565],\n",
       "       [0.6907088 ],\n",
       "       [0.68289405],\n",
       "       [0.67549926],\n",
       "       [0.66773975],\n",
       "       [0.66031903],\n",
       "       [0.6522652 ],\n",
       "       [0.645293  ],\n",
       "       [0.6384307 ],\n",
       "       [0.63317764],\n",
       "       [0.6267391 ],\n",
       "       [0.6206299 ],\n",
       "       [0.6152271 ],\n",
       "       [0.6102727 ],\n",
       "       [0.60561615],\n",
       "       [0.6003262 ],\n",
       "       [0.5954966 ],\n",
       "       [0.5911484 ],\n",
       "       [0.58581775],\n",
       "       [0.5798366 ],\n",
       "       [0.5809362 ],\n",
       "       [0.5818091 ],\n",
       "       [0.5822074 ],\n",
       "       [0.58141845],\n",
       "       [0.5800845 ],\n",
       "       [0.5787573 ],\n",
       "       [0.5778589 ],\n",
       "       [0.5765916 ],\n",
       "       [0.5749285 ],\n",
       "       [0.5732919 ],\n",
       "       [0.5658641 ],\n",
       "       [0.55889434],\n",
       "       [0.5522924 ],\n",
       "       [0.548968  ],\n",
       "       [0.5465922 ],\n",
       "       [0.54360485],\n",
       "       [0.5398848 ],\n",
       "       [0.53725916],\n",
       "       [0.53376585],\n",
       "       [0.53087336],\n",
       "       [0.52810186],\n",
       "       [0.5247943 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76b50669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "testPredict = regressor.predict([X_test1, X_test2, X_test3, X_test4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a8bdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "valPredict = regressor.predict([X_val1, X_val2,X_val3, X_val4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b6f7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bb9e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.05\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_val,valPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3056cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.22\n"
     ]
    }
   ],
   "source": [
    "MAE = math.sqrt(mean_absolute_error(y_val,valPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c58d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.601068 0.618226]\n",
      " [0.60035  0.616004]\n",
      " [0.597037 0.611976]\n",
      " [0.591915 0.606466]\n",
      " [0.586157 0.600399]\n",
      " [0.579252 0.59468 ]\n",
      " [0.57294  0.588161]\n",
      " [0.575522 0.599026]\n",
      " [0.586782 0.607449]\n",
      " [0.59719  0.614321]\n",
      " [0.60654  0.620085]\n",
      " [0.607427 0.618894]\n",
      " [0.608844 0.618589]\n",
      " [0.612977 0.617772]\n",
      " [0.618487 0.617245]\n",
      " [0.627769 0.616607]\n",
      " [0.63252  0.626267]\n",
      " [0.623854 0.615608]\n",
      " [0.613591 0.605407]\n",
      " [0.607858 0.594143]\n",
      " [0.601751 0.584187]\n",
      " [0.59447  0.571555]\n",
      " [0.587811 0.560286]\n",
      " [0.575925 0.549715]\n",
      " [0.566851 0.539831]\n",
      " [0.558461 0.530674]\n",
      " [0.550799 0.511971]\n",
      " [0.544749 0.495426]\n",
      " [0.529885 0.481608]\n",
      " [0.51449  0.470458]\n",
      " [0.499567 0.464694]\n",
      " [0.487599 0.459712]\n",
      " [0.474676 0.452987]\n",
      " [0.464478 0.447083]\n",
      " [0.458352 0.44105 ]\n",
      " [0.4522   0.434763]\n",
      " [0.445264 0.428739]\n",
      " [0.43824  0.423982]\n",
      " [0.431951 0.418628]\n",
      " [0.426045 0.412638]\n",
      " [0.420052 0.402674]\n",
      " [0.413742 0.392628]\n",
      " [0.408636 0.384978]\n",
      " [0.401453 0.377099]\n",
      " [0.39197  0.369881]\n",
      " [0.382684 0.368531]\n",
      " [0.375248 0.365946]\n",
      " [0.368654 0.362834]\n",
      " [0.362961 0.359163]\n",
      " [0.361016 0.355158]\n",
      " [0.358291 0.35538 ]\n",
      " [0.355316 0.353624]\n",
      " [0.35224  0.351206]\n",
      " [0.349877 0.349589]\n",
      " [0.348958 0.347214]\n",
      " [0.348445 0.339632]\n",
      " [0.347447 0.332747]\n",
      " [0.34496  0.32666 ]\n",
      " [0.341682 0.321841]\n",
      " [0.33562  0.317283]\n",
      " [0.330559 0.308674]\n",
      " [0.326057 0.301509]\n",
      " [0.321091 0.295782]\n",
      " [0.316371 0.2899  ]\n",
      " [0.310406 0.28385 ]\n",
      " [0.304706 0.290273]\n",
      " [0.299393 0.296851]\n",
      " [0.295027 0.302358]\n",
      " [0.295967 0.307177]\n",
      " [0.301329 0.311652]\n",
      " [0.306683 0.315234]\n",
      " [0.311339 0.318768]\n",
      " [0.316892 0.321485]\n",
      " [0.321975 0.324215]\n",
      " [0.325174 0.327836]\n",
      " [0.328966 0.318914]\n",
      " [0.3326   0.309782]\n",
      " [0.335875 0.30071 ]\n",
      " [0.334021 0.292138]\n",
      " [0.326831 0.283668]\n",
      " [0.319515 0.285268]\n",
      " [0.31266  0.286197]\n",
      " [0.305322 0.285969]\n",
      " [0.301442 0.285747]\n",
      " [0.303144 0.28379 ]\n",
      " [0.304137 0.282738]\n",
      " [0.303725 0.281808]\n",
      " [0.30404  0.281563]\n",
      " [0.303832 0.282109]\n",
      " [0.303189 0.282805]\n",
      " [0.303536 0.273904]\n",
      " [0.304719 0.265824]\n",
      " [0.305904 0.258342]\n",
      " [0.304707 0.251266]\n",
      " [0.298463 0.246198]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "print(np.concatenate((testPredict.reshape(len(testPredict),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c431e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.04\n",
      "Test RMSE: 0.02\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_train,trainPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n",
    "\n",
    "RMSE = math.sqrt(mean_squared_error(y_test,testPredict))\n",
    "print('Test RMSE: %.2f' % (RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca612703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001318536480168418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0005144523578225843"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse=mean_squared_error(y_train,trainPredict)\n",
    "print(mse)\n",
    "\n",
    "mse=mean_squared_error(y_test,testPredict)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89fbbc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002684150138490828"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse=mean_squared_error(y_val,valPredict)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1ddd352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_train,trainPredict))\n",
    "print('Train MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f7067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_test,testPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77df0e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801043499884434"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, trainPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd26b337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054122735273364"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, valPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e65e48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681678043597348"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c16b02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(combined_datap, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf13af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.arange(439, 628)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce594b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = np.arange(439, 628)\n",
    "                   \n",
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(trainPredict,color = 'blue', label = 'Predicted SOH(Training)')\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "plt.plot( X_data,z,color = 'darkgreen', label = 'Predicted SOH(Testing )')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f582902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4OElEQVR4nO3dd3iT1RfA8W/SvdkthQJFtsgGBdlTliKgLGUjoICACAI/mcpQQERkKMvBUgFBlhSZykaWLJG9N20ZbWn7/v64TZrSFrrfjPN5nj5J37xJDiamJ/fce65B0zQNIYQQQgidGPUOQAghhBCOTZIRIYQQQuhKkhEhhBBC6EqSESGEEELoSpIRIYQQQuhKkhEhhBBC6EqSESGEEELoSpIRIYQQQujKWe8AUiI2NpYrV67g4+ODwWDQOxwhhBBCpICmaYSHhxMYGIjRmPz4h00kI1euXCEoKEjvMIQQQgiRBhcvXiR//vzJ3m4TyYiPjw+g/jG+vr46RyOEEEKIlAgLCyMoKMj8dzw5NpGMmEozvr6+kowIIYQQNuZZUyxkAqsQQgghdCXJiBBCCCF0JcmIEEIIIXRlE3NGUkLTNKKjo4mJidE7FGHjnJyccHZ2lmXkQgiRRewiGYmKiuLq1as8fPhQ71CEnfD09CRv3ry4urrqHYoQQtg9m09GYmNjOXv2LE5OTgQGBuLq6irfaEWaaZpGVFQUN2/e5OzZsxQtWvSpjXqEEEKkn80nI1FRUcTGxhIUFISnp6fe4Qg74OHhgYuLC+fPnycqKgp3d3e9QxJCCLtmN1/55NuryEjyfhJCiKwjn7hCCCGE0FWqk5Ft27bRvHlzAgMDMRgM/Prrr8+8z9atW6lYsSLu7u4ULlyYWbNmpSVWIYQQQtihVCcjDx48oGzZskyfPj1F5589e5YmTZpQo0YNDhw4wLBhw+jXrx/Lli1LdbAibUaNGkW5cuXMv3fu3JkWLVpkeRznzp3DYDBw8ODBLH9uIYQQ1ivVyUjjxo355JNPaNmyZYrOnzVrFgUKFGDq1KmULFmS7t2707VrVyZNmpTqYO1J586dMRgMGAwGXFxcKFy4MIMGDeLBgweZ/txffvklCxYsSNG5WZ1AnDlzhnbt2hEYGIi7uzv58+fntdde499//01w3urVq6lduzY+Pj54enpSuXLlRP+mp8Veu3Zt+vfvn3n/ECGEECmW6XNGdu7cScOGDRMca9SoEfv27ePx48dJ3icyMpKwsLAEP/bolVde4erVq5w5c4ZPPvmEGTNmMGjQoCTPTe6/VVr4+fmRLVu2DHu8jBIVFUWDBg0ICwtj+fLlnDx5kqVLl1K6dGlCQ0PN53311Ve89tprVKtWjd27d3P48GHatm1Lr169kv3vZzdOnIDx4yEiQu9IhBAiw2R6MnLt2jX8/f0THPP39yc6Oppbt24leZ/x48fj5+dn/gkKCkrx82kaPHigz4+mpe6/jZubGwEBAQQFBdG+fXs6dOhgnoNjKq3MmzePwoUL4+bmhqZphIaG8s4775AnTx58fX2pW7cuhw4dSvC4EyZMwN/fHx8fH7p160bEE3+4nizTxMbGMnHiRIoUKYKbmxsFChTg008/BSA4OBiA8uXLYzAYqF27tvl+8+fPp2TJkri7u1OiRAlmzJiR4Hn27NlD+fLlcXd3p1KlShw4cOCp/z2OHTvGmTNnmDFjBi+99BIFCxbk5Zdf5tNPP6Vy5coAXLx4kQ8++ID+/fszbtw4SpUqRZEiRfjggw/4/PPPmTx5Mrt3707xa2BzRoyAYcPg22/1jkQIITJMlqymebIJmRb3Vzu55mRDhw4lNDTU/HPx4sUUP9fDh+Dtrc9PehvAenh4JBgB+e+///jpp59YtmyZudTQtGlTrl27xtq1a9m/fz8VKlSgXr163LlzB4CffvqJkSNH8umnn7Jv3z7y5s2bKEl40tChQ5k4cSIff/wxx44dY9GiReYEcs+ePQBs3LiRq1evsnz5cgC+/fZbhg8fzqeffsrx48cZN24cH3/8Md999x2g5hY1a9aM4sWLs3//fkaNGvXMUYvcuXNjNBr55Zdfkm3r/8svv/D48eMkH6tnz554e3uzePHipz6PTTMl8OvW6RuHEEJkoExvehYQEMC1a9cSHLtx4wbOzs7kzJkzyfu4ubnh5uaW2aFZlT179rBo0SLq1atnPhYVFcUPP/xA7ty5Adi0aRNHjhzhxo0b5v8+kyZN4tdff+WXX37hnXfeYerUqXTt2pXu3bsD8Mknn7Bx48ZEoyMm4eHhfPnll0yfPp1OnToB8Nxzz1G9enUA83PnzJmTgIAA8/3Gjh3L5MmTzXOHgoODOXbsGLNnz6ZTp04sXLiQmJgY5s2bh6enJ88//zyXLl2id+/eyf43yJcvH9OmTWPw4MGMHj2aSpUqUadOHTp06EDhwoUB+Pfff/Hz8yNv3ryJ7u/q6krhwoUTzS+pVq1aor4hjx49SjCp12aYMt4tW+DRI/Dw0DUcIYTICJmejFStWpXffvstwbENGzZQqVIlXFxcMvz5PD3h/v0Mf9gUP3dqrF69Gm9vb6Kjo3n8+DGvvfYaX331lfn2ggULmpMBgP3793P//v1ESdyjR484ffo0AMePH6dXr14Jbq9atSqbN29OMobjx48TGRmZIAl6lps3b3Lx4kW6detGjx49zMejo6Px8/MzP27ZsmUTdMWtWrXqMx/7vffeo2PHjmzevJndu3fz888/M27cOFatWkWDBg2eeX9N0xKNuC1dupSSJUsmONahQ4dnPpZVMk1wfvQItm+HJ+ZjCSGELUp1MnL//n3+++8/8+9nz57l4MGD5MiRgwIFCjB06FAuX77M999/D0CvXr2YPn06AwcOpEePHuzcuZO5c+dm2lC6wQBeXpny0BmuTp06zJw5ExcXFwIDAxMlZ15P/ENiY2PJmzcvW7ZsSfRYaZ2Q6pGGb9axsbGAKtW8+OKLCW5zcnIC4ktxaeHj48Orr77Kq6++yieffEKjRo345JNPaNCgAcWKFSM0NJQrV64QGBiY4H5RUVGcOXOGunXrJjgeFBREkSJFEhxLy7/bKljWAtevl2RECGEXUj1nZN++fZQvX57y5csDMHDgQMqXL8+IESMAuHr1KhcuXDCfHxwczNq1a9myZQvlypVj7NixTJs2jVatWmXQP8F2eXl5UaRIEQoWLJiiUaIKFSpw7do1nJ2dKVKkSIKfXLlyAVCyZEl27dqV4H5P/m6paNGieHh48McffyR5u2nXWss5HP7+/uTLl48zZ84kisM04bVUqVIcOnSIR48epSiO5BgMBkqUKGFe8tyqVSucnZ2ZPHlyonNnzZrFgwcPaNeuXaqfx2Y8mYwIIYQdSPXISO3atZ/6rTep/hW1atXi77//Tu1TiSfUr1+fqlWr0qJFCyZOnEjx4sW5cuUKa9eupUWLFlSqVIn333+fTp06UalSJapXr87ChQs5evSoec7Fk9zd3RkyZAiDBw/G1dWVl19+mZs3b3L06FG6detGnjx58PDwYP369eTPnx93d3f8/PwYNWoU/fr1w9fXl8aNGxMZGcm+ffu4e/cuAwcOpH379gwfPpxu3brxv//9j3Pnzj2zt8zBgwcZOXIkb7/9NqVKlcLV1ZWtW7cyb948hgwZAkCBAgX47LPPGDRoEO7u7rz99tu4uLiwcuVKhg0bxgcffJBotMauWPahOX4cLlyAAgX0i0cIITKAze/a60gMBgNr165l+PDhdO3alZs3bxIQEEDNmjXNq1/atGnD6dOnGTJkCBEREbRq1YrevXvz+++/J/u4H3/8Mc7OzowYMYIrV66QN29e87wTZ2dnpk2bxpgxYxgxYgQ1atRgy5YtdO/eHU9PTz7//HMGDx6Ml5cXL7zwgrmRmLe3N7/99hu9evWifPnylCpViokTJz51RCx//vwUKlSI0aNHmxuWmX4fMGCA+bwBAwbw3HPPMWnSJL788ktiYmJ4/vnnmTlzJl26dMmA/9JWStPiR0aCg+HsWfj9d7CYtyOEELbIoKWnuJ9FwsLC8PPzIzQ0FF9f3wS3RUREcPbsWYKDg2Wrd5FhrPJ9FRkJplg++AAmT4aWLUG2VhBCWKmn/f22JLv2CmErLOeLmLZj2LgRMrA7rxBC6EGSESFshWm+iIsLvPQS5MoFYWGQhonBQghhTSQZEcJWmEZGPD3BaIxf1rthg34xCSFEBpBkRAhbYUpGTP1nTP1Ukug7I4QQtkSSESFshalMY+pqW6eOuty9O/0bIwkhhI4kGRHCVjw5MhIcDEFBagLrjh36xSWEEOkkyYgQtuLJkRGDIX50JJm9h4QQwhZIMiKErbCcwGpSu7a6lGRECGHDJBkRSTIYDPz66696hyEsmUZGLDdQNI2M7N2r33bVQgiRTpKM6GzHjh04OTnxyiuvpPq+hQoVYurUqRkfVArcuHGDnj17UqBAAdzc3AgICKBRo0bs3LkzwXk7duygSZMmZM+eHXd3d1544QUmT56cYOM9SD756dy5My1atMjEf4kNSWpkpFAhKFgQoqPhr790CUsIIdJLkhGdzZs3j759+/Lnn38m2O3Y2rVq1YpDhw7x3Xff8e+//7Jq1Spq167NnTt3zOesWLGCWrVqkT9/fjZv3syJEyd4//33+fTTT2nbtu1TN1wUSXhyAquJaXRk69asjUcIITKIJCM6evDgAT/99BO9e/emWbNmSe54vGrVKipVqoS7uzu5cuWiZVwb8Nq1a3P+/HkGDBiAwWDAYDAAMGrUKMqVK5fgMaZOnUqhQoXMv+/du5cGDRqQK1cu/Pz8Ur2r8r179/jzzz+ZOHEiderUoWDBglSpUoWhQ4fStGlT87+tR48evPrqq3zzzTeUK1eOQoUK0b17d7777jt++eUXfvrpp9T9B3N0T05gNalWTV3u2ZO18QghRAaxv2RE09SHth4/qfymv3TpUooXL07x4sV56623mD9/foLRgjVr1tCyZUuaNm3KgQMH+OOPP6hUqRIAy5cvJ3/+/IwZM4arV69y9erVFD9veHg4nTp1Yvv27ezatYuiRYvSpEkTwsPDU3R/b29vvL29+fXXX4mMjEzynA0bNnD79m0GDRqU6LbmzZtTrFgxFi9enOKYBcmPjFSpoi737oXY2KyNSQghMoCz3gFkuIcPwdtbn+e+fz/xH4qnmDt3Lm+99RYAr7zyCvfv3+ePP/6gfv36AOZyxujRo833KVu2LAA5cuTAyckJHx8fAgICUhVmXVPnzjizZ88me/bsbN26lWbNmj3z/s7OzixYsIAePXowa9YsKlSoQK1atWjbti1lypQB4N9//wWgZMmSST5GiRIlzOeYtGvXDicnpwTHIiMjzaMtDi+5kZHnnwcPD7VPzb//QokSWR+bEEKkg/2NjNiIkydPsmfPHtq2bQuoP/Bt2rRh3rx55nMOHjxIvXr1Mvy5b9y4Qa9evShWrBh+fn74+flx//79VM1ZadWqFVeuXGHVqlU0atSILVu2UKFChUSlpuTmhWiaZi4tmXzxxRccPHgwwc+rr76a6n+f3UpqAiuAszNUqKCu792btTEJIUQGsL+REU9P/ZY4PvlH4inmzp1LdHQ0+fLlMx/TNA0XFxfu3r1L9uzZ8fDwSHUIRqMxUQLw+Ikt5jt37szNmzeZOnUqBQsWxM3NjapVqxIVFZWq53J3d6dBgwY0aNCAESNG0L17d0aOHEnnzp0pVqwYAMePH6eaaU6DhRMnTlCqVKkExwICAihSpEiCYz4+Pty7dy9Vcdmt5Mo0oEo1f/2l5o28/XbWxiWEEOlkfyMjBoP6sNbj54lv+smJjo7m+++/Z/LkyQlGAQ4dOkTBggVZuHAhAGXKlOGPP/5I9nFcXV0TLZHNnTs3165dS5CQHDx4MME527dvp1+/fjRp0oTnn38eNzc3bt26lcL/wMkrVaoUD+JKCQ0bNiRHjhxMnjw50XmrVq3i1KlTtGvXLt3P6VCSK9NA/LwRmcQqhLBB9peM2IDVq1dz9+5dunXrRunSpRP8tG7dmrlz5wIwcuRIFi9ezMiRIzl+/DhHjhzhs88+Mz9OoUKF2LZtG5cvXzYnE7Vr1+bmzZt89tlnnD59mq+//pp169YleP4iRYrwww8/cPz4cXbv3k2HDh1SNQpz+/Zt6taty48//sjhw4c5e/YsP//8M5999hmvvfYaAF5eXsyePZuVK1fyzjvvcPjwYc6dO8fcuXPp3LkzrVu35s0330zvf0rH8qyREYCDByGZScVCCGGtJBnRwdy5c6lfvz5+fn6JbmvVqhUHDx7k77//pnbt2vz888+sWrWKcuXKUbduXXbv3m0+d8yYMZw7d47nnnuO3LlzA2rC6IwZM/j6668pW7Yse/bsSbSiZd68edy9e5fy5cvz9ttv069fP/LkyZPi+L29vXnxxRf54osvqFmzJqVLl+bjjz+mR48eTJ8+3Xxe69at2bx5MxcvXqRmzZoUL16cKVOmMHz4cJYsWZJozoh4hqeNjAQHQ86cEBUFhw9nbVxCCJFOBs0GOk+FhYXh5+dHaGgovr6+CW6LiIjg7NmzBAcH4+7urlOEwt5Y5fuqZEk4cUI1N6tZM/HtTZrAunUwfTq8917WxyeEEE942t9vSzIyIoSteNrICCTsNyKEEDZEkhEhbEVyS3tNZBKrEMJGSTIihK142gRWgMqV1eWJExAamjUxCSFEBpBkRAhbEBsLjx6p68mNjOTOrXbx1TTYvz/LQhNCiPSSZEQIW2BKRODpWw5IqUZYm0uX4Jdf4Inmi0JYsptkxAYWBQkbYnXvJ9PkVYCnre558UV1uWNHwuPnzqkVOIGB8NprsGGDbKonskbfvvDGG9CsmZQPRbJsPhlxcXEB4KGpni5EBjC9n0zvL93FxRPt5snLNYxs2ZLMebVqqctt2yAmBm7fhhkzoFo12L4drl6FVaugUSO1VHjRoiwJXzgw047iGzbAyy/D+fP6xiOsks3vTePk5ES2bNm4ceMGAJ6entJMS6SZpmk8fPiQGzdukC1btkS7COsmbmTkfqwnO3ZAnTpqBW+lSk+cV64c+Pqqb6A1a6qOrKZE3ccHvvkGdu6E+fPVDr8dOsCFC/DRR1n5rxGOxFRidHGBo0fV6N2qVfElRSGwg6ZnoP6AXLt2TTZUExkmW7ZsBAQEWE9iu3cvVKnCZZeC5H98DoDRo2HEiCTObdoU1q6N/71MGahRA3r0gLJl1bHwcBg/Xv24ukJYGLi5Zfo/Qzig4sVV4rtoEUyYoDoEe3jADz9Aq1Z6RycyWUqbntn8yAiAwWAgb9685MmTJ9EOtUKklouLi/WMiJjEjW48MsSvpDl9OplzX3lFJSM+PmriYIMGiTdx9PGBTz9VIyW3b6s/EKalwUJkJNPISNGi8Oef0Laten+2bg2ffQaDBj17k1FNg/XrYeZMuHED2reHfv0yP3aRZewiGTFxcnKyvj8iQmSEuDLNg9j4ZOTMmWTOfecdlWw0aAD58iX/mAaDqvP8/rsaeZFkRGQGUzLi4aHelytXwoABatuCwYPVfkrDhye+X3Q0LFumEuZ//1Wrckx274bVq9W2B6++muId04X1svkJrEI4hLiRkbDY+GW9yY6MuLlB585PT0RMTAmItJAXmcWUjJhWgTk7w1dfwaRJ6vcRI2DTpvjzo6PVCEjx4moUZdMmlYh4e8PAgWpEBSAkBFq0gG7dZNmwHbCrkREh7JbFBFaTq1dVjpJcD7QUMSUj0pdEZJaICHXp4ZHw+AcfwLFjMG8etGsHf/+tyjE9e8bPecqVS41+1KoF5ctDtmxqSfpnn6nRkVWr1GTs+/dhyRIwyvdrWyWvnBC2IG5k5AFqZMTHRx1OtlSTUi+9BE5O8X8UhMhIjx+rJeaQOBkBVaopU0bNA6lQAYKDVSLi4QFffqmWAY8apZaPZcum7mM0qtVfK1aoko+rK/z8M0yZklX/KpEJJBkRwhbEJSMP8cTbW80FhKeUalIqTx71YQ9qQqA0pRIZybJzcFLJiIeHSioKF1YJSXS0GgXZtk29H5817NesmSr5AAwdCrt2ZVzsIktJMiKELTBNYMWLbNmgWDF1eNq0+FHwNBs2TDVAe/AAli5N54MJYcEyGUlu6XjhwqrkMmkS7NsHW7Yk0UDnKXr0gDZtVCLTpg1cu5aukIU+JBkRwhZYjIz4+cGHH6r5fJs2qdJ7uhiN0KWLuj5/fjofTAgLpkzZ3f3pK15y5VJv5IoVU/8cBoNacVOkiGrg16wZREamLV6hG0lGhLAFcSMjpmSkQgXVQgRUt/eQkOTvGhYGP/4In38Oc+bAH38kUY15+201d2TXLjV/RIiMYLmsNzP5+sK6dSqp2b9fNVcTNkWSESFsgcUEVtM8vkaN1EIDgK5dIakGxCdOQIECKtcYPFiNaNevDwEBau5q//5xW4UEBKjOrSCjIyLjZFUyAmpkZPp0dX3cODh+PPOfU2QYSUaEsAVPjIyYTJyoPoMvXVKJxZMsR0Heeks1Zw0OVqPnu3erBQvlyqlSPV27qhN/+CF+BYQQ6WFZpskKb76pkuqoKJV5y87UNkOSESFsgcXIiGUy4uUF332npn18951qu2DJtPS3f3+VY6xbp1bgHD4MixereYL37kHz5hBZr4maiHL9unyrFBkjK0dGQM0fmTFDvY//+kvNJRE2QZIRIWyBxQRWU5nGpFq1+Ems/frFb9ILcPasunzuufhjBgO88EJ8c8u8edUChNW/u6jGUqAaUAmRXnHJSKybB4cPp/xuly+rzaV//129FUND1eBgirZ1LVBA7bsEMGSIejBh9Rw7GYmJgZ9+SuE7XAgdPbGa5kmjRqnP4PPnVenGxDQyUrhw0g/r4wMdO6rrCxYQv5ph//6MiFo4urhk5OBJd8qWhQ0bnn2XTZsgf36VZL/yinpLZsumBjsCA1XT4C5dVMPVo0eT+fh+7z148UU1e7tv3wz9J4nM4bjJSGysqi22aQOzZukdjRBP94xkxNMzvgHlxIkqCdG0ZycjEL+qd906uPecJCMiA8XNGbn1QJVpTF3en+bXX9VljhyqOau/f/xt166p+U0LFqgO8qVLqzlQw4erjvBmTk7w7bdqH5wVK9QEKWHVHDcZMRrVsgKA99+XN6uwbhbJiK9v0qe0bAn16qkWCwMHwu3bEB6ubitUKPmHLl4cqlZVA4XLz8clIwcOyCRWkX5xIyOPUMnIzp3Pvsv27epy5kw4dEglIOHhcOeOGjX5+Wc1N/Xll1UftfPn1eKZQoXUijFzi5EXXoA33lDXTevghdVy3GQEVKG9ZUu1f0Lr1qodsRDWKC4ZeYSHeV+aJxkMqiOrs7PassPUJTtfvmcvZujcWV1O/q0Ymq+vej4ZHRHp9UQy8vffarn5rFlqr7sJE9RIyKpVamL1tWsqAQGoUSP+Yby9IXt2tUVN69ZqXuqff6oEZelSNTpy+7bqpVOrlsU0kVat1OXy5VKOt3KOnYwYDKqnQrFiam1k9eoZsNmHEJkg7kPdtDdNckqVUgN9AGPGqMvg4Gc/fJs2av7IsZNO7MveUB1csyYdAQuB+X0bgcqGo6PVzgO9e6u5pUOHwuuvw2uvqSXqefOqnOG559T1Z/H0VKt5//1XDX5kz64GucuUgcmTIabBKyoTP3MG9u7NzH+pSCeHTkZOnIDRX/jyfuHfeJyvIJw6pcarDx586v1u3lRDhZ9/DoPfj2TOS3O4lL00kW4+XK/6Glq0DG+LDPbERnlPM3asKteAGiXp1+/ZD+/np75hOjnB1+fjmp+tXp2OgIXAPGfkER6UKhV/uEYN6NQJ2rdXC7jKlgUXl/jbmzdP3dM4O6tBkH371GPduQODBkHTN72IbtFanTRuXDr/MSJTaTYgNDRUA7TQ0NAMfdzq1TVN5eGa9maNK1pshQqaBlpMgUKadudOovMjIjStWzdNc3bWNAMxWl++1C4RGP8gcT+bA9po/0z7Q9Pu38/QeIWDiokxv7dyclM7evTZd3n4UNPmztW048dT91TjxmlaHq5pMRjUc16+nLaYhdA0TRsyRNNAm8wAbft2TVu/XtPOnk361JgYTbt9W9P271eftWn1+LGmzZ6taR4e6i3c+aXjWqwh7v28e3faH1ikSUr/fjv0yMhbb0GJEur6T9vzkvvQH5ymMMYL59hepDN/bExYY/z6a5g7F/yib/FbtreZxvvk4wrhfvnY2Hgyf5TsA0Dta0t5vl89IvIEof24MKv/WcLeWGzL+wiPZ46MgOox1bVr/Ps7pQYPhiLV/NlDFQBiV6dg+YMQybGYM5Inj9rCILnJ1EajWkFToULyG/ymhLMzvPOOmuzq7Q0LdpVgZ5G31Y3vvisTs62UQycjPXuqRpPDh6vfb8dk4w1+JhJXatxZxdoGU8ifX9U0Z86E0R894nMGcdW1IE3vLVJj2l9+ic/109RfO5B6ByfzoE4zLvsU5wp5cX94F8Pbb3GpdX9pSyzSzqKLWUqTkbRycoLvv4cQF1WquTBTSjUiHSzmjGRVE1aTl15S5XSDAVqemkiEq6+alC1dWa2SQycjJmPGqAlQFy/Cnw8q8HD8lwBMZAjPXd7Kr7/C8HfvsOZxAwYxGZeohyp937BBFeRNabyrK16bfiMw9ATfjznPeJcRAORf9iX7q/VFi5XZ3CINzCtp3NEwZmoyAmryYHDfZgDkPhjC3asRz7iHEEmLfRQ/ZySrtqex9Morav+l6wQwKCquK+uwYbJy0gpJMoIaHixaVHX98/SE7EN6Qrt2OBPDJvcm/NpiPnvcalKdv4jy9FPrJvftg7p1k3w8gwE++tiFrhdHM7fW98RioOLuGawrM4SIR5KQiFSyWNbr7Ayurpn/lG0nlOO6cyBePOT3YVsz/wmFXYp9EF+myeqREZO+fWHSJJhJb/6mvNqMadIkfYIRyZJkJCkGg+re98orOEU85LVfu1Ik8igEBuK6azu8+qo65xn8/aHblrfZ2n42AE2Ofs6kEnM4dy6T4xf2JYXLejOSs4uBsOqqVPNg6WrLaStCpFjs/fgyjR4jIyYDB0KHt534mLEARH81QzUmEVYjTcnIjBkzCA4Oxt3dnYoVK7Ld1DIvGQsXLqRs2bJ4enqSN29eunTpwm1rfyN4ealOPKaNO4oXhx07VFe/VKqzsAenuqghwg8v9KF92aPPWj0sRLxULOvNSKZSTZ1Ha/jhexnRE6lnKtNEGdWonl4MBrX4wK1FEw5QDueIB5wdOE2/gEQiqU5Gli5dSv/+/Rk+fDgHDhygRo0aNG7cmAsXLiR5/p9//knHjh3p1q0bR48e5eeff2bv3r1079493cFnOhcXtQnC7t1q4lPBgml+qKJzh/KwThPciGJc2Hs0aqhx/nzGhSrsmE7JiHOjekQ7u1GYs/w67pjMwRappj1UIyMxrjrVaCy4uMCSpQbWVfgfAPm/H8c/n69T/aWkO6vuUp2MTJkyhW7dutG9e3dKlizJ1KlTCQoKYubMmUmev2vXLgoVKkS/fv0IDg6mevXq9OzZk3379qU7+CxhMECVKmqkJJ2P4zl/BpqHB7XZSpebE3nzTYiKypgwhR2zmDOSlckIXl5QR82LKn1+Nb/9loXPLexDXIkxxk3/ZATUfKuB21/nvFdJXIim9OAmqgP3iy8+s9mlyFypSkaioqLYv38/DRs2THC8YcOG7NixI8n7VKtWjUuXLrF27Vo0TeP69ev88ssvNG3aNO1R26qCBTHEba06jmH47NnI/Pk6xySsnw5zRkycW6hSTTNWM3ly1j63sANx713cdJww8gR3TyP+25fxV67XOEdBHuMMe/eiVa/O2W9CZH6UTlKVjNy6dYuYmBj8Lfd0Bvz9/bl27VqS96lWrRoLFy6kTZs2uLq6EhAQQLZs2fjKtItXEiIjIwkLC0vwYzd69YIePTCiMZ8ufDspVIa/xdPpVKYBIO5LQzV2cHT7bdk7T6SKIe4ve6yVjIyYuJcvSYkTv1I93znycZmNxgYYHjzAv+drNPLdSb9+atGNyDppmsBqeGIliaZpiY6ZHDt2jH79+jFixAj279/P+vXrOXv2LL169Ur28cePH4+fn5/5JygoKC1hWq8vviC2UGGCuET5/35i1Sq9AxJWzaJMk95qYaoVLAhlyuBELI1Zx5w5Wfz8wqYZIuNGRvRa1/sUOXPCihWQrWgemsSuZg1N8OQR8x93YP5X4ZQrBzt36h2l40hVMpIrVy6cnJwSjYLcuHEj0WiJyfjx43n55Zf58MMPKVOmDI0aNWLGjBnMmzePq1evJnmfoUOHEhoaav65ePFiasK0fl5eGLt0AqARvzN8uNrNUogk6VimAaBZfKlm0aIEDWGFeCqjFScjAJUrw9GjsPegK1XPLkYrWJDCnGW274ecP6829OvfX3qkZYVUJSOurq5UrFiRkJCQBMdDQkKoVq1akvd5+PAhRmPCp3FycgLUiEpS3Nzc8PX1TfBjdxo1AqCBYSMnj0WzeLHO8QjrpWeZBszJSBPjeh6GPWblSh1iEDbJlIwYPKxnzsiTXFzUTr85CvliiJvE1z5sNuNr/05MjOrgWro0rFmjc6B2LtVlmoEDBzJnzhzmzZvH8ePHGTBgABcuXDCXXYYOHUpHU28OoHnz5ixfvpyZM2dy5swZ/vrrL/r160eVKlUIDAzMuH+JralUCbJnx08L5UV2M2mSrC4TydA7GalSBXLnxjc2lKrsZOlSHWIQticmBqeYxwAYPK1zZCSROnVUy1ZgyKlu/LHsHi+8ADdvqpx8/Hid47NjqU5G2rRpw9SpUxkzZgzlypVj27ZtrF27loJxPTiuXr2aoOdI586dmTJlCtOnT6d06dK88cYbFC9enOXLl2fcv8IWOTlBkyYAdHH+kcOHYeNGnWMS1kmvpb0mTk5QuzYANdjOunUyuU+kgMWyFKOXjSQjABMmQNGiGC5fpu6v/dizR5VqAP73P7UTiMh4aZrA+u6773Lu3DkiIyPZv38/NWvWNN+2YMECtmzZkuD8vn37cvToUR4+fMiVK1f48ccfyZcvX7oCtwtduwLwlnEhnjyQ7RJE0vSeMwKqeA409tpOVBT8+qtOcQjbYVrWCzh5WW+ZJhFPT/juO7Vp2Q8/4L5mGV98AW3bqs3XTYmJyFiyN42eateG557DPSqcLoYFbNggfXdEEvQu0wBUrw5A5egdGImRUo14triRkShccPN00jmYVKpaFQYPVte7dIETJ5gyBZyd4a+/4MgRfcOzR5KM6MlohAEDABjr9gmePKB7d+nKKp6g59JekzJlwNcXt8hwXuAIISFw65ZOsQjb8Ej/HXvTZfRoqFkTwsNhwADy5oXXXlM3ffONvqHZI0lG9NajBwQHkz3iGgM9ZrF/P0ycqHdQwqpYjIzolow4OUG5cgA0KXCUmBhYt06nWIRtsEhG9NyxN81cXTE31gkJgevX6dlT/frDD7LEPaNJMqI3V1cYNgyAjzym4sxjxo+HZPYdFI7IYs6Ip6eOcTz3HAA1850GpCGUeIa4920E7rY5MgJQtKhaTRYTAz/9RL16ULgwhIYipcoMJsmINXjrLfD3x+vOJUYVX8KjR/Dhh3oHJayGRZnGGpKREi4qGdm1S8dYhPWLmzNisyMjJh06qMtFizAa4Z131K9ffy3tGDKSJCPWwN0d3n8fgIGxn2M0aPz0EzyxKEk4KosyjTUkI3kfnQHg8GF48EDHeIR1s/U5IyZvvqnm9+3aBadP07Wraii7fz9s2KB3cPZDkhFr0asXeHnhceoIU5uod/jYsfE337ihZnBbrJYTjsLKkhG3S6fJl0+NXO/dq2M8wrrZ+pwRk4AAqF9fXV+0iNy51cc1wJgxMjqSUSQZsRbZs6vJrECPe59T3niICps+5/DoFXRr/wh/f7WgIUcOaNcOTpzQOV6RZTQrmzPC1avUqqwSpD//1DEeYd3sYc6ISfv26nLhQtA0PvwQ3Nxgxw7YvFnf0OyFJCPWpH9/cHLC/a8/+Du2HJ8zmDKjWjJxcRDvMxU/r2giImDJEtX24cABvQMWWcJa5ozkyAHZsgHQrJQq1UgpUSTLYs6IzScjr7+uyuknT8KBA+TNa/7uyJgx+oZmLyQZsSYFC5ozcM3ZmV0etTlPAXJxm6kM4G791uzb9ZjKleH2bdWXR7Z0t3OaZj1lGoAiRQConvskoL4ZRkbqGZCwWvZSpgHw9YXmzdX1RYsAGDJELYbcuhW2bdMxNjshyYi1mTEDFi7EcP48z53fzG9Tz3B3wmxwd8ewciUVv3ibDetiaNJE/RHo0UNmddu1qCgMcS9utIsnzs46x1O2LAD5bx4gd27192bPHp1jEtbJokzj5qZzLBnBtKpm8WKIiSF/ftWcFRLO7xNpI8mItfH2VqMjgYHkzg193nci+5B3YNkytdf10qVkG9Sd1atiGThQ3aVPH/jgA33DFpnEorOSVex8WrEiAIa/91Ovnjok+9SIJNnL0l6TV15RZcorV8xDIR99pFrEb9wofXfSS5IRW9GkiZos4uQECxZg6NeXSZ9rTJigbv7ySzh3TtcIRWaIS0Ye44yrl4vOwWBORti/n3Zt1YjNwoUQHa1jTMI6WZRp7GJkxM0N3nhDXV+4EIBChaBjR3VIRkfSR5IRW9KypdpN0mCAGTMwDP6QIYM1GjRQu0lOm6Z3gCLDWdN8EVBLupyc4OZNXil9iVy54Pp19c1QiATsLRmB+FU1v/xiniw1dKhqQ7JuHRw7pmNsNk6SEVvToUP8Lk2TJ8OkSaa99vj+e5WUCDtiLct6Tdzd4fnnAXA9uIe2bdXh77/XMSZhnextzgiojfPy5VP94NeuBdScbtMGevKFMO0kGbFF3burRARg0iTq143F21utsDl8WN/QRAazlmW9lmrWVJcbN5qHqFesgLAw/UISVshizojdJCNGo2r0BOZSDUC/fury++/h7l0d4rIDkozYqj59wMcHbtzA5fB+89+HP/7QNyyRwaytTAPQqJG6/P13KlXUKF5c/d1ZvlzfsISVsccyDai9xABWrVI1SqBWLVXBfPRI2i2klSQjtsrVFRo0UNfXrjWvbJBkxM5YYzJSu7Za2XX2LIbT/yUoowthotlrMlK2rNrJ9/FjmD8fUNP44rYXY/p0mdCdFpKM2LKmTdXlmjXmZGTrVoiK0i8kkcEsPtC9vHSOxcTbW7UABvj9d1q1UldDQqRUI+JpD+LnjNjF0l5LvXury9mzzRP12rWDnDnhwgU1aCJSR5IRW9a4sbrcu5cX8lwnd271RXr3bn3DEhnIGkdGIEGpplQpKF5cJcFr1ugblrAesY/scM6IyZtvqp4j587B778Daiffnj3VzV9+qVtkNkuSEVuWNy9UqACAccN66tZVh6VUY0esPRnZvBnD4yhef139+mQyEh6uFh2cP5+14Qn9aQ/jR/VcXXUOJqN5ekKnTur6rFnmw+++q1a+b9sGBw/qE5qtkmTE1iVRqpFkxI5Y29JekzJlIE8eePAAduwwD9KtXw8xMer6ggUQFKTeosHBMHOmbtEKPcQlI9FO7hjt8S9Nr17qcvVquHgRUKt+W7dWh2WZb+rY41vEsZiSkXXraFBd/c+/c6csL7Mb1ri0F9QSx4YN1fXff6dqVfDzU8vL9+6FDz9U+3aEhqpTNA2GD1e5i3AQcUt7Y1ytYBuDzFCihJrMHRsL335rPmyayLpoEdy6pU9otkiSEVtXpYra7ff+fQodXcPzz6tvpnH9eISts9YyDSSYN+LiEr+4q2pVmDRJXR89Ws0lKVxYJcg//KBPqEIHEerLkd0mIxA/kXXOHLW6BnjpJbVrQmSkapgtUkaSEVtnMGBug7l4MS1aqKsrV+oWkchI1pyMmEZGDhyA69d57z0wEEthTuPOI6ZPhxEj1CpgU1Oozz83f2YLO2dwhGSkRQtVrrx6FX77DVAfyaaJrBaLbcQzSDJiD0wdAdesoWU9NS6+bp156wRhyyyW9lpdMpInD5Qvr66HhFC7wBlO5KjGaYoQZvDj3S1vwKVLgGoanCcPnDkj3xYdhTEuGbG/db0WXF2hWzd13WJSVLt2qiflqVOwebNOsdkYSUbsQZkyULIkREZS7tyvBAbC/fuwaZPegYl0s+aREYgfHVm3Dlq1otgdta7cRXuM4ZdfVLdKTcPLS223DjBypHp/CjumaRij1JwRzd2OR0YA3nlHDYds3KiyD1QrnrffVjfPnq1jbDZEkhF7YFGqMS5dbN60SUo1dsAiGbGapmeW6tdXl4sWqbWMOXOqdbx79qgt17duNU9g6t1bzR25cgXGjdMvZJEFLIZl7T4ZKVQovueTaRNT4ks1K1bAtWtZH5atkWTEXphKNRs30rrWTUAlI1KvtHHWPjJi6sRq8vXXUKAAVK4cP1FkyhRAjdbHXWXyZDh9OgvjFFkrrrwIDpCMQPwy3/nzzauIypRRk7mjo2HePB1jsxGSjNiLokXVFO6YGGre+AVfX5WN792rd2AiXax5zgioDKN0aXW9QAHVmdLkvffU5ebNqkc28OqratVNVBQMG5bFsYqsE/e+jcGIs7uzzsFkgSZNVFOd27cTbNJkylG++Sa+/45ImiQj9iRudMT558XmUcNff9UvHJEBrH1kBFSPhfbtVUnGYIg/XrCg6sOgaWpvddTN48erm1evNn+JFPYmwqIVvLvhGSfbAScnNXcEEnRkfeMNyJ5dVS43bNApNhshyYg9adNGXW7fTvsaqiOgJCM2zlqbnll66SVYuFDVzp/Utau6nD7d/G25QgW1k8HDh/Dnn1kXpshCFiN69ryYJoFu3cDZGf76C44cAdR+NR07qpst+qKJJEgyYk/y54caNQBocHcpLi5w4gScPKlzXCLtrLUdfEq1batGSK5fN38aGwwJmrcKe/Qofsdeu9skLzl582Ju9GQxOtKjh7pctUq1IxFJk2TE3sSVajxWLKZOHXVIVtXYLs0WRkaexsUFhg5V10ePNvfHNjVvlX2U7FSEHe/Y+zSmSSI//ABhYQA8/zy8/LKaMzJ/vo6xWTlJRuxN69aqfvn333Sq+i8gpRqb9tDKJ7CmRLduamnBnTvmZiOVKqmbTpyQFV92yaJM41DJSJ06qudTeHiCuoxpOsm338r7PTmSjNib3LnNm4Q0u78EUBvnyfCgjYrrYhlh8LTdbdidnWHGDHV97lzYuZNChdThR4/g8mVdoxOZwVGTEaMRPvhAXZ861bz3wRtvQLZscO6c6o0mEpNkxB7FlWp8Vy/ixSoaIKMjNikmBkNUFAAGT48EC1VszssvQ+fO6vq4cbi4qAZoAP/+q1tUIrM44pwRkw4dwN9fbYXw00+Amshq6shq0RdNWJBkxB61aKH6P5w8ybtV9gGwfLm+IYk0sGgcZfSyg8ZR3bury7iVBsWKqV8lGbFDjjpnBNRnr+XOkJr6QmiayLpypXRkTYokI/bI1xdefx2AV++pXck2b1Yle2FDLJIRg6cdJCOm7OPCBXj0SJIRe+aIS3st9eoFnp5w6JB5lvYLL8R3ZF2wQN/wrJEkI/aqUycAsq1dTMXSkcTEqKVlwobEraSJwA0PLzv4XzVXLlU41zQ4fVqSEXvmqHNGTHLkiN/N9/PPzYdlImvy7OATTiSpfn0IDIQ7dxhcajUgpRqbY+2t4FPLYEhQm5FkxI458pwRkwED1ITWDRvg8GFA7Zbg5wdnzsiu6k+SZMReOTmZZ0y9ckOVajZsUCvOhI2w9YZnSUkiGTl7Vu1VI+yII88ZMQkOVq0WQO0MiarcvPWWOiQTWROSZMSexZVqfLav5aXg60RGmndzF7bA1hueJcUiGQkMVB/OMTEqIRF2xNHLNCYffqguFy1Sq2uIn8i6YoVqTCwUSUbsWcmSUKUKhpgYhgcvAqRUY1PsrUwDCZKRJ6o2wp5IMqJUqgS1aqlZq9OmAVC2LLz4ojokoyPxJBmxd3GjI3UvqlLNmjWyU6rNsPMyTRK/Cnshc0biDRqkLmfPNreIf/99dejrryEyUqe4rIwkI/aubVtwdcXz1CEa+R/kwQMICdE7KJEiFmUaLy+dY8koRYuqy5s34e5dSUbslcWcEYdc2mupSRM1Sh0WZm4R37q12tf0+nVYvFjn+KyEJCP2LkcOePVVAD7Kq0ZHli3TMyCRYvZYpvH2Vqu8AE6dkmTEXkmZJl4SLeJdXKBPH3Xoiy/MfdEcmiQjjiCuVFPt3EKcecyqVeYtE4Q1s8cyDSS5oubkSf3CEZlAyjQJvfVWfIv4pUsB1XPE01Ot+v39d53jswKSjDiCRo0gTx5c792krd967t6FLVv0Dko8kz2upoEEyUjJkurq1atw755uEYmMJmWahNzc4lvET5oEmkb27NCzpzo0aJB8QZRkxBG4uKjNm4AB2RcAsqrGJthjmQYSJCO+vqp2DnD8uH4hiQwmZZrEevUCL68ELeI//hhy5oSjR2HePJ3j05kkI44ibsfUcpd+Iwe3WbFC9XcQVszeyzQnTgBQqpT69dgxneIRGU+SkcSSaBGfPTuMGKEOjR/v2KMjkow4ijJloFw5jNGP6eqxhOvXYccOvYMST2WvZZoXXlCXx4/D48eSjNgjizkjUqax0L9/fIv4v/8GVBM0f384fx5++EHf8PQkyYgjiZvI2ttTraqRUo2Vs9cyTcGC4OOjesBbzBuRZMSOSDv4pAUHQ7t26vqHH4Km4eER36h13DjVDM0RSTLiSNq3B2dnCt/eSymOsny5LCmzavZapjEY4kdHDh+WkRE7pEmZJnmffKImtG7aBKvVJqY9e6q5I6dPw48/6hyfTiQZcSR58kCzZgD0cp7LhQuwb5/OMYnk2WPTM5MyZdTl4cPmkZELF2QjR7thkYxImeYJhQqpHX1BDYk8foy3NwwZog4NHWpu1OpQJBlxNHETqDoZf8CFKCnVWDN7LdNAgmQkZ05VMwfznFZhyzRN+ow8y9ChkDu3arCzYAGgVv4WLQrXrsGYMfqGpwdJRhzNK69A3rz4Rt3iVVaxbJmUaqyWvZZpIEEyArKixq5ER2OIjQUgAg+cnXWOxxr5+sKwYer6hAkQHY2bG3z5pTr05ZeOt9Q9TcnIjBkzCA4Oxt3dnYoVK7J9+/annh8ZGcnw4cMpWLAgbm5uPPfcc8xz9EXVenF2Ni/z7WGYy6lT8M8/+oYkkmGvq2kASpdWl5cuwd27kozYk7gkGkBz98Bg0DEWa9ajB+TKBWfOwJIlADRurHbviI5WN8fldA4h1cnI0qVL6d+/P8OHD+fAgQPUqFGDxo0bc+HChWTv8+abb/LHH38wd+5cTp48yeLFiylRokS6Ahfp0LUrAA2038nPRdmrxkpp9lym8fNTq2oAjhyRZMSeWCQjUqN5Ci+v+Lkj48ebM4+vvlJbOP31F8yYoWN8WSzVyciUKVPo1q0b3bt3p2TJkkydOpWgoCBmzpyZ5Pnr169n69atrF27lvr161OoUCGqVKlCtWrV0h28SKMiRaBWLYxodGG+zBuxUtoDOy7TQIJSjSQjdsS8rNcdN3cZFnmq995TifmxY+YdTAsUgIkT1c3Dh6s5JI4gVclIVFQU+/fvp2HDhgmON2zYkB3JdNBatWoVlSpV4rPPPiNfvnwUK1aMQYMG8cgye35CZGQkYWFhCX5EBuveHYAuzOefI7Gya6oV0izKNHa5IiGJZOTs2YRfrIUNkpU0KefnpxqhgeoNH9dkpGdPqFRJraox9SCxd6lKRm7dukVMTAz+pqnvcfz9/bmWTPp25swZ/vzzT/755x9WrFjB1KlT+eWXX3jvvfeSfZ7x48fj5+dn/gkKCkpNmCIlWrUCPz+COUddNvHLL3oHJBKJ+1DX3Dww2uNUc1MycugQuXOrPguaJjv42jzpMZI6AwequSMnT8KcOQA4OcHMmaolz48/OsbGpmn6iDM8MSNJ07REx0xiY2MxGAwsXLiQKlWq0KRJE6ZMmcKCBQuSHR0ZOnQooaGh5p+LFy+mJUzxNB4eqgka0I25/PyzzvGIRAwRccmIhz3WaICyZdXlkSMYYqKlVGMvZFlv6vj6wsiR6vqwYXDzJqBGRky7+nbtav89eFKVjOTKlQsnJ6dEoyA3btxINFpikjdvXvLly4efn5/5WMmSJdE0jUuXLiV5Hzc3N3x9fRP8iEwQ13OkJcu5cPA2p07pHI+Ip2kYH6kyjdHLQ+dgMknRoqot/KNHcPy4JCP2wqIVvJRpUqhXL5Wc372repDEmTBBzfM+exY++kjH+LJAqpIRV1dXKlasSEhISILjISEhyU5Iffnll7ly5Qr37983H/v3338xGo3kN+0dLvRRoQKULYsbUbRhqYyOWJPISPNVg6edJiNGo3oPAuzbJ8mIvZAyTeo5O8PXX6vrc+fCrl2AmlJi6oIxezZ2Pbcv1WWagQMHMmfOHObNm8fx48cZMGAAFy5coFevXoAqsXTs2NF8fvv27cmZMyddunTh2LFjbNu2jQ8//JCuXbvi4WGnH7K2wmCAuNfqbX6QZMSaWJQwjd52WqYBNRYNsH+/JCP2QpKRtHn5ZfNmpgwaZO5GWbcuNG0KMTHxfdIePVKJicV3fJuX6mSkTZs2TJ06lTFjxlCuXDm2bdvG2rVrKRjXM+Dq1asJeo54e3sTEhLCvXv3qFSpEh06dKB58+ZMmzYt4/4VIu3atUMzGqnKLu4fPGXXmbdNiVtJE40Trl4uOgeTiSpWVJcWIyOnTsmKGptmMWdEyjSp9Omn4O6umoysWWM+PGGCGkhctkwlJ35+ULw4ZM8OzZvDxo2230k7TRNY3333Xc6dO0dkZCT79++nZs2a5tsWLFjAliem/pYoUYKQkBAePnzIxYsXmTx5soyKWIu8eTE0aADAW/woDdCshT03PLNUpYq6PHCAvNkjyJNH9X46ckTfsEQ6WMwZkZGRVMqXD95/X10fONBcri1dOn7QZPNmePxY9ZOLjlYb/zZoAMHBakDl7FmdYk8ne1wwKFLr7bcBlYz88rONp9f2wp73pbFUuDAEBEBUFIa9e8xTSP7+W9+wRDpImSZ9hg1T/0+cOgVTppgPf/aZahE/bpzatyZu3jd9+qhmrufPw+TJUKwY9O0LN27o+G9IA0lGBLRogebpxXOcwf3ADs6c0TsgYdf70lgyGKBGDXV9+3bKl1dXJRmxYVKmSR9fX5g0SV3/5BOIa22RKxd8M/oqQ9uepUTRGAwGKFFCtY+/cQNWrID69dVoyfTpUK1agnnwVk+SEQFeXhjavAnAu8yQUo01cJQyDcQnI9u2yciIPZAyTfq1bw/Vq6svJYMGwfXrUKsWBAaq0cRixeD7780TRTw9oUULCAmBTZvA3x9On8ammllKMiKUPn0AeJOf2LLois7BCIcp00B8MrJjBxXKqHbYR46ouriwQVKmST+DQQ1vGI3w00/w+uuwbZu6zdlZ7fTbqRNUrgzffWdOAAHq1DF/nPPVVzrEnkaSjAilQgWiXqyOC9E0PziG8+f1DsjBWZRpvLx0jiWzvfCCGpq+f5/gsEP4+UFUlCzxtVmyN03GKFsW3n1XXd+5U10uXAihoWqXX3d32L8fOneG55+H7dvNd33nHXB1hd27Ye/erA89LSQZEWaun30KwDt8w9avDukcjYNzpDKNk5PqsQAY/twupRpbJ+3gM86YMZA7t7qeJw+88YaqyXz0EVy4oJKSwEA1UlKnjuqMFnfqm6rybjOjI5KMiHg1a3Kq/BsY0cj1/ZRnny8yjyOVaUAmsdoTmTOScbJnhy+/VGWbPn3AxaLnUO7cKik5fhzatVNd0Xr1Mu9z07evOm3pUrh6VYfYU0mSEZFAttEDAah7cylXjtzWORoH5iiraUwskpEK5dWkvAMHdIxHpJ2UaTJWu3Zqz5r//S/p2319Vflm7Fj1+/jxEBlJlSpqRU1UlMpnrJ0kIyKB3M1e5F+vcrgTyan/LdA7HMflSGUaUBPx3Nzg5k1eyqHaAB88qL7sCRsjE1gznp+fGh1JjsEAw4dDzpxq5vfhwwAMGaJunjFDDaBYM0lGREIGA5eb9wag0O+zVTtMkfUcrUzj5mbuxhp8aTuenvDgAbKTtC2SOSP6MBhUUg+wZw8AzZpB1aoQHq56kMQdtkqSjIhEXhjfnjB8KBh5irNzN+kdjmNytDINmEs1xr+2U7asOiTzRmyQxZwRKdNkMdP2CnFLaIxGWLUKSpWCK1egZk1Yu1bH+J5CkhGRSK5C3vwZrHbzvTN+ts7ROChHGxmBJJufybwRGyRlGv2YRkZ27zYfypULduxQoySRkaplyZ9/6hTfU0gyIpIUMLInAGXO/sq53dd1jsYBWXyg232fEZNq1dRXuXPnqFFQ7fwtIyM2SMo0+nnpJbVU/sQJ87wRUFNOli9XXVqjoqBlS+tL9CUZEUmq0OkFjvu9hAvRHOo7R+9wHI9FmcbbW+dYsoqvL1SsCMBLkVsBlYzY+tboDkfKNPrJlUtlGqA6uFpwcYEff4QKFeDmTTUQaU1zSCQZEcnS3lM9havt/ZLQqw91jsbBWJRpHGZkBKB2bQDyn96Cmxvcu6f22BA2RMo0+jI1GPnxR7Uk2IKXF/zxh+qP9uCBKt1YyyobSUZEskqOasMll0Lk5iYH+s7VOxyHEvsw/gPdYUZGwJyMOG3bYp43YlH+FrZA+ozoq3p1KFNGvQ7z5iW6OVs2WLkSypdXIyS1a8M//2R5lIlIMiKSZXBx5nQrtVC92MrPiY2I0jkixxEb7kB701iqXl3NGzlzhldKqXkju3bpHJNIHZkzoi+DIX50ZPp0NUnkCT4+sGEDlCsHN26ohOTgwawMMjFJRsRTVfyqM9cMAQRGX+To8IV6h+MwTCMjkUZPXF11DiYrWcwbaeSu5o1IMmJDYmLM2y1LmUZH7durDWrOnYMvvkjylFy5YNMmtQDn9m2oWxf27cvaMC1JMiKeyjuXO7te/gCAHN9MkJaYWUSLS0bw8Hhq40W7FFeqef7mFkB9Y4v7si2sncVW9lKm0ZGnJ0yapK5//DHMSXoRQvbsEBKiGqPdvavv6jVJRsQzFZ/ckztkJ9/9f7k7b4Xe4TiGuNU0eHjoG4ce4pIRr31bCAiA6GhZ4mszLLJGKdPo7K231L42jx9Djx7Jbt/r5we//6421HvnnSyO0YIkI+KZSlbx4df8qgYZMXKcrLXMAoYI9aFu8HKUjmcW4uaNGM6coWmZi4CUamxGXDIShQuxOEkyoieDQW2g99FH6vd+/WDWrCRP9fGBN9/MwtiSIMmISBHvYf24jxd5rx4g6rff9Q7H7pmTEU8HHBmxmDfyWnaZN2JTLHqMAFKm0ZvBAOPGweDB6vfeveGXX/SNKRmSjIgUeb17Tpb4qDG8m4M/1zka++cUqco0zj4OmIyAuVRTKXwLIMmIzbBY1gvIyIg1MBhgwgR49131+9tvW+X/UJKMiBRxcQHjgPeJwUi+k5uIOXhE75DsV3Q0xphoAIzeDlimAXMy4n9iC0YjXLqkfoSVs1jWazSCs7PO8QjFYIBp01SXs4gIePVVOHNG76gSkGREpFibwQVZ7aJaDZ//YJrO0dgxi0mArn4OOjISN2/EeOY0DUqoeSPS/MwGSCt46+XkBIsXx3c7a9oUbt3SOyozSUZEinl5wa0O7wMQuPlHtJvW80a2Kw/jW++7+DjoJ7rFvJE2ATJvxGZIK3jr5u0Nq1dD/vxqM72GDSEsTO+oAElGRCq99tnLHDBUwF2L4PRH3+odjn0y70vjgbePozUZsRBXqnk5egsgyYhNkGTE+gUGquYiefKorXs7doTYWL2jkmREpE6u3AaO1lXLfF2Xfi/LfDODxQe6Q7WCf1KtWgAUOq9GRvbtMzf3FNbKYs6IlGmsWIkS8NtvaobxypXwySd6RyTJiEi96lNaEoEbBR6c4NRymcia4R7G70vjUJvkPSlu3ojr+f943u8SERFw+LDeQYmnspgzIiMjVq5KFZg5U10fOVJtVqMjSUZEqhUq48uhwCYAnByzBK5cgfXr4fJlnSOzE+Yyjadjj4z4+WHaurdjQZk3YhOkTGNbunSBXr3ir9+9q1sokoyINMn2bjsAmh0ejxYUBI0bQ6FC8OGHsn9NekmZJl7cvJH6zlsASUasnsV7V8o0NmLyZChWTH2pnDxZtzAkGRFpUnxwC+455wTAYJr8FB2tNmd64w3Z2Sw9pEwTL27eSPHrMjJiEyzmjMjIiI3w9IQffoD//Q9GjNAtDElGRNq4uHC5lVrmG4ORh1fuqZ2WXF1hxQq1H7UVrWG3KVKmiRc3b8Tr8imCuMB//8nbyqrJnBHbVKUKjB2rPr91IsmISLMS337AdL/hvMQuvl/pp3Za2rhR7Uu9a5eq9+s8KcomWQx1O/zISLZsUK0aAL381Y7Rf/2lYzzi6aRMI9JIkhGRZk4+nsSM/oR9VOarr+JW+daoof5aFC4MFy+quSTTp+sdqm2xKNM4/MgIQKtWALxhWAbAtm16BiOeSso0Io0kGRHp0qmT2pnz2DGLdt0lS6o1mF26qGY6ffuqia3SkyRlLMo0Dj8yAtBSbUFQ5Pqf+HONrVt1jkckT1bTiDSSZESkS7Zsar4qqMTkm2/g4EHQPL1g7lz49FN146RJMHq0XmHaFllNk1CBAlC5MgZNowW/cuCA1XSwFk+SvWlEGkkyItKtTx+1q++//0LPnmofprp14foNAwwbBjNmqBPHjtV1Hbut0B7IappE4ko1HTyWExsLO3boHI9ImoyMiDSSZESkW5UqsHcvDBgAjRqpDsNbtqh9zvbsAXr3huBgVbLZv1/vcK3e43BZTZNIXDJSNWIz2bkjpRprJXNGRBpJMiIyRNmyMGWKasR66JDa+uDyZahZU5VutMqV1Yl79+obqA2IDjd9oHvg4aFzMNaiSBEoUwZnLZpXWSWTWK2VlGlEGkkyIjJc8eJqMuurr0JkpCrdzNwryUhKxYSpMk20qwdG+T80XtzoSCuWsXevedGRsCZSphFpJB91IlP4+qreZ5MmqQZ/S8+qZCT0j72yqOYZYh6oD/QYV0+dI7EycatqGrIB98dh7NypczwiMUlGRBpJMiIyjdEIH3yglv3mbVKBGIz4hV3ikx7n9Q7NqmlxyYgmNZqEnn8eihXDjSiasobNm/UOSCRiMWdEyjQiNSQZEZmuYEFYssaHG0VfBuDq3DUcPapzUFZMM9Uf3CUZScBgSFCq2bRJ53hEYtIOXqSRJCMiy+Tt3gyA5vzGjz/qHIw1exi3yaCnlGkSiUtGGrOOI7sfEh6uczwiISnTiDSSZERknWYqGanLJlb8cB/TZr8iIUOE+kA3eMrISCIVKkChQnjxkAax6/nzT70DEgnI3jQijSQZEVmnZElinyuCG1GUv/ybLM9MhjFClWmcvCUZScRgME9klVKNldE0c5lG+oyI1JJkRGQdgwFj2zYAtGGplGqSYYxS3y6N3lKmSVJcqaYZq9m+MVLnYIRZZPxrIWUakVqSjIis1UYlI41Zx6alN01fpIQFp7hkxNlHRkaS9NJLxAQE4kcYuQ5u5M4dvQMSgLlEA1KmEaknyYjIWqVLo1WqhBtR9L0/jt9+0zsg6+PyWJVpJBlJhtGIU6vXAWjJMlniay3ikpEYjETjLCMjIlUkGRFZy2DAELeT77vM4K+vD+gckJXRNFyi1XCRazYp0yQrrlTzGisJWftY52AEED9fxOABGGRkRKSKJCMi6zVoQHjt5rgRRf+tr3PhkOzka2ZRt3L1k5GRZNWoQZRvLnJyh3urtklXX2tgsZIGkH2VRKpIMiKynsGAz/LvuOT+HIU4z7F6fYmK0jsoK2Gx4YpbNvk0T5azM8bXXwOg5q1l0kTPGkgyItJBkhGhj+zZMS5aSAxGXrm9kO/arNU7IusQ94EehQuevs46B2PdnNuoUs3rrGDdGmlaoztTMqKp+owkIyI1JBkRugl8/UXOthgAQK1f+7PyJ1mmafnt0stL51isXb16RHr4kZdruM2doXc0wqIVPEgyIlJHkhGhqyLfjSDMK4BinGJLp/mcOaN3RDqLK9M8wgNvb51jsXaurjx4uzcA/U715dHs73UOyMFJmUakQ5qSkRkzZhAcHIy7uzsVK1Zk+/btKbrfX3/9hbOzM+XKlUvL0wp75OuL1yfDAOgfMZ72raMseyc5nrgP9Id4yshICuSYNY5v/QYB4DygD5yXHaF180QyIqtpRGqkOhlZunQp/fv3Z/jw4Rw4cIAaNWrQuHFjLly48NT7hYaG0rFjR+rVq5fmYIV9curVg5g8eSnIBcocWMAHH+gdkY6kTJM6BgP/dBjPX1TD5VE4dO6MbHqkk7j3bgTuuLurzv1CpFSqk5EpU6bQrVs3unfvTsmSJZk6dSpBQUHMnDnzqffr2bMn7du3p2rVqmkOVtgpd3echg0BYBjj+ObrKFau1DkmvViUaXx9dY7FRjRq6kxHvueBwQu2bIG5c/UOyTFZzBmREo1IrVQlI1FRUezfv5+GDRsmON6wYUN27NiR7P3mz5/P6dOnGTlyZIqeJzIykrCwsAQ/ws698w4EBFCI83zI5/TqBbdu6R1U1ot9EF+mkWQkZWrXhstuzzFc+0QdGDMG2WdABxajepKMiNRKVTJy69YtYmJi8Pf3T3Dc39+fa9euJXmfU6dO8dFHH7Fw4UKcnVO2VHH8+PH4+fmZf4KCglITprBFHh7w+ecAjGQ0/tcO0rKl4/1NibwX/4EuyUjKeHpCnTowk97c8wmCS5dg9my9w3I8FmUaSUZEaqVpAqvhiWKgpmmJjgHExMTQvn17Ro8eTbFixVL8+EOHDiU0NNT8c/HixbSEKWxNhw7w+uu48pgfjR3ZvT2SLl0cawpAxB1Vpok0yK6nqdG7N0Thxoio/6kD48bBgwf6BuVopEwj0iFVyUiuXLlwcnJKNApy48aNRKMlAOHh4ezbt48+ffrg7OyMs7MzY8aM4dChQzg7O7Np06Ykn8fNzQ1fX98EP8IBGAzqG23u3JSOPcIQ4+csWQLDh+sdWNYxjYw8dvGUCYCp0KwZvPACzIzswk3fwnDjBkyerHdYjkXKNCIdUpWMuLq6UrFiRUJCQhIcDwkJoVq1aonO9/X15ciRIxw8eND806tXL4oXL87Bgwd58cUX0xe9sD+5c8O0aQCMcB5HAc4zYQIsWKBvWFklKjRu51NX+TRPDaMRvvgConGhb5jaiJHx45HGNVlIkhGRDqku0wwcOJA5c+Ywb948jh8/zoABA7hw4QK9evUCVImlY8eO6sGNRkqXLp3gJ0+ePLi7u1O6dGm8ZO2iSEqbNlCrFs5Rj1hbUq3z7d0bjhzROa4s8DhMlWli3eTTPLXq1YM+fWApbfg7W11VNujXj1Ttoqdpas7JsWNw4gSyaVIqWMwZ8ZQNp0UqpToZadOmDVOnTmXMmDGUK1eObdu2sXbtWgoWLAjA1atXn9lzRIinMhjgq6/AyYnnjy/joyqbiIhwjHJNTLj6QI/1kE/ztBg8GJycDLS/9zWxzi6wZg389tuz7/j4sRpJCQpSP88/DyVLQuXKqUtmHJnMGRHpkKYJrO+++y7nzp0jMjKS/fv3U7NmTfNtCxYsYMuWLcned9SoURw8eDAtTyscyQsvQNxo28eGTzAa1d+Uw4d1jiuTxdxXyYh8mqdNUBC0bAknKcHvpQaqgyNGPD2huHwZmjSBYcPUdWdnyJlT3Xb4MNy8mfmB2wMp04h0kL1phPUaMgRcXPDcvZmhdXcDapGEPYt9oMo0Bvk0T7P331eX3U58SKyXNxw6BKtXJ33ytm1qBGTjRvDygnnzIDxcNbkJDlbnnDiRNYHbOklGRDpIMiKsV1AQtG8PwEDvbwD46Sf49189g8pkD9UHusFbyjRpVa0aVKwIV6NysqvCu+rgoEEk2vToyBE1IhIeDi++CLt3Q5cu8ZuqlCihLiUZSRnpMyLSQZIRYd26dgUgxx8/06rxQzQNPvzQjsv4cR/oTt7yaZ5WBkP86EjXU8PQAgJUBvvZZ/EnRUaqvjYPHkDduqqN/PPPJ3wgSUZSR+aMiHSQZERYt+rVoWBBCA9nau1fcXGBVavgl1/0DixzGCJUmcbFRz7N0+PNN8HfH05e8+OvVl+og59+Cv/9p65//70aGcmdGxYvTnqLWUlGUkfKNCIdJBkR1s1oVDuxAvmXT2PoR2pIpE8fuHNHx7gyiTFSfaA7+0qZJj3c3OC999T17iFtiK1XX42GfBK3f42pcc2HH0KePEk/SPHi6vLkyUyN1W5ImUakgyQjwvr17q3+uuzezfA6OyhZUjXYHDRI78AynnOU+kB39ZNP8/R6/33IkQNO/mtgfcW4NvGrV6uRjh07VKL71lvJP0DJkury7Fm4fz/zA7Z1UqYR6SDJiLB+/v7w9tsAuE6bxJw5al7A/PlqEYQ9cX6syjRu2eTTPL18fWHoUHX9vUUvo2XPDrdvw0cfqYP16kHevMk/QJ48kC+fmqD099+ZH7CtkzKNSAdJRoRtGBjXM2LlSqrlPmUegn/nHfvaD80lWn2gu+eQMk1GeO89lU+cu+TMycJN1MGVK9VlgwbPfoAqVdTlnj2ZE6A9kWREpIMkI8I2lCyplmFqGowezbhxauXv2bPw8cd6B5dx3GLUB7pHDvk0zwgeHqrnGcCEU60S3mjRrDFZkoykjKbJnBGRLpKMCNsxerSqzyxciM/B7cyerQ5/8YVaFNG4MXz3HcTE6BtmerjHqjKNJCMZp0sXKFIEFoY1S3hDhQrPvrMpGdm7N+MDsyfR0RAbC8jIiEgbSUaE7ahUCXr0UNffe4/GDaJNbUi4dQvWr1cLbypVgq1bdYsyzTQN3FHfLn38pUyTUVxcYORItaPvYvcu6mDx4uqGZ6lUSU10PXdObaAnkhY3KgKSjIi0kWRE2JZPP1VLJI4cgVmz+OormDIFfvgBxowBPz84eBBq14Zu3Wxr+e+De49xRg3r+PrLp3lGatMG8ueH7hFfceC1UbBiRcru6Our2rkC/PFHpsVn8yySkUjcJBkRqSbJiLAtuXLB2LHq+tixeGoPGDBArdD8+GPV06pnT3XzvHlQpgz8+ad+4aZG6NWH5utSpslYLi7Qty88xItOZ0ailSj51PNv31ajKZ07w7rouImuISGZH6itMk9edQcMeMrAnkglSUaE7enRA557TjUb6dABliwxD4HkygWzZqkEpFgxtQlr7dqqE3hcSdtqhV1XH+ixGDC4u+kcjf3p0UPthXfkSPKDHP/+q6YmPfecGmn77juYeEAlIzEbNtrxPgTpFNdjJAKVRHt56RmMsEWSjAjb4+ICkyapyawrV0K7dmoOwPr15lNefhn27VP77MXEqA2AX3vNuss24TfiViMYPNS/TWSo7NnNWx3x1VcJbzt3Tr0/iheHUaMgNBTKllW7RF8pUJX7eOF087p6U4nE4kZGHkoyItJIkhFhm1q0UF00W7dWa3xv3VLHLL7y+vjAjz+qkRI3N9V8s3Zt611t8+CWKtNEOUmJJrP06qUu166FmzfV9cOHVeKxapXKARs1goULVZ+zoUOhcQs31tBUnbxsmT6BWzuLZb0gyYhIPUlGhO166SX4+Wc1UeT119XeI6+9Brt2mU8xGNQckp071TfjI0fUHx1r9PCW+kCPcpaCe2YpVUrNR42OVtW9hw+hbVsIC1OreI8dUwNs7durRTQAderAclqqX5Ytk1JNUixawYMkIyL1JBkRts/VVe282qCBasfauLH6umuhfPn4b8VffKFDjCkQcVclI9EuMjKSmeJ2FmDJEpg6FY4fV13hV6+O36jXUq1asI4mqgTx338wcWKWxmsTLLqvurmBk5PO8QibI8mIsA9ubmq5ZtWqcO8eNGwIp04lOOW999R0k+3bYc0afcJ8mog7qkwT4yrJSGZqGTfIsWMHDB+urk+apBrnJSV7dihS3ocBxGWxw4ZJR9YnWSQjMioi0kKSEWE/vLzUZICyZeH6dahfHy5eNN+cLx/076+u9++vhuitSVRo3GoaNynTZKagoPjWIaDeLm3bPv0+derAN/RkV5EOqkzTu7f1Tj7Sg8WcEUlGRFpIMiLsS7ZssGGDWtd74YIq2VjspPe//0FgoBptr1cvwQIc3ZmSEc1dRkYyW5Mm8de//TZ+fkhy6tRRl/2jJ6v32N9/q22jhWIxZ0SSEZEWkowI+5Mnj2pQFRAAR4+qGaxxkw59feH779XE1l27VK7SsSOEh+scMxAdFjdU4ynJSGZ79121surbb6Fy5WefX6OGSlh2n/PnXr+4nff+9z/reONYAynTiHSSZETYpwIFYOlSNZNu4ULMu+qhRkTWrVP90oxG1Uq+fHn990KLua8+0I1eUqbJbAEBsHkzdO+esvP9/OJLO2sKvad23rt+XSazmkgyItJJkhFhv2rWhPHj1fXBg+H+ffNNjRqpHiTbtqm85fRpqFYNJkyAx4/1CTf2gfpAd/KWkRFrZCrV/LHdFT7/XP0yebLqmOboZM6ISCdJRoR9++ADKFpUDacvXpzo5pdfVhvrvfGG6j0xdCg8/7xamJPl7STiZtQ6+0gyYo1Mycjmzah+NrVrq7kSplnRjkzmjIh0kmRE2DejMX7nvJkzk8wwsmdXFZ3589V0k1On1PLPWrXgxIksjDXu26WLn5RprFH16uDsrAZCDh8xwPTp6sDKlapJiSOzKNN4e+sci7BJkowI+9epk+pDcuBAsnuLGAxqh9b//lPzEj08VD+S8uVVk7TMHiWJjQVjpPpAd/WTkRFr5O2tGv2Cqs7w/PMwYIA60Lev9a0Vz0pSphHpJMmIsH+5cqk6DKiNap7CxwfGjoWTJ9W8kogIGDjwmXdLt/v3wQP1x8wtuyQj1urDD9XlokVxee2IEZA/vxouMc1PckRSphHpJMmIcAymXvCLF6sOrc8QFKRW3IwapX4fNgyuXcu06Lh7FzyIK9P4SpnGWlWurEZHoqOheXO4eNcbvvxS3fjZZ6q3vCOS1TQinSQZEY6hWjUoXVp9aP74Y4ruYjCokk25cip/eeUVuHMnc8K7dy8+GcFDRkas2YIF6q107Ro0awYPG72uuqhFRammNXotx9KTJCMinSQZEY7BYIgfHfn6a/WHIwWcnNTkVn9/OHRIJSShoRkf3r174BlXppFkxLr5+qr5qv7+aj/GYcMN8M03qjPrvn0wbpzeIWY9mTMi0kmSEeE43npLLZ05cUIlJpGRKbpbsWLwxx9q6snevdC0aYKWJRkiwciIp5RprF3BgmqEBFSVZut/+WDGDHVg7Fg1WdqRyJwRkU6SjAjH4ecXX6KZP19NALhxI0V3ff551WE+Wzb466+MT0ikTGN7XnklvoNr165wv1lbaNVKbaA3eLC+wWU1KdOIdJJkRDiWJk3g559VQ5EjR9TmNGFhKbpruXJqDz5fX9W5NSMTEinT2KbJk1UH3zNnYOgwg+rM6uICGzfGdUdzEJKMiHSSZEQ4ntatVTaRO7faffXVV1M8h6RyZTVCYkpI6tVTm621aaNGT6pWVQ///vtq25Iff1R/k27efPrjSpnGNvn6wpw56vr06bD+ZDB06aIOfPedfoFlNZkzItLJWe8AhNBF8eKwfr3q8b11q2omMn16iu5apYpKSBo0gD171E9KtGmjdgx2dU18m5RpbFeDBtC7t2rw27YtHJn5NkHffKP2FJg1C9zd9Q4x88mcEZFOkowIx1WhgtrRt3lztcImKAiGDEnRXatUgU2bVB+SW7dUTlOjhvqCePkyXLmiLi9fhgsXVGfXpUvVdIKlS1WXekt370qZxpZ98YXa42jnTnhlTDWO5MuP8fIlWLtW7S1g76QdvEgnSUaEY2vWTNVThgyBjz5S9ZSJE9Wa3meoWBF++y1lT/P776oa9MsvqoHahAkJb5cyjW1zc4Nly6BSJTh2wsj6FzrQ5PJEleQ6QDKiPXqEAVWm8fXVOxphi2TOiBCDB8f3hpg8GVq0MH/TyyiNGsG8eer6xIkwd27C20PvxuJO3FJjGRmxSXnzqga/BgP0OvIusUYnNXx26JDeoWWumBgMcY3eHuEhyYhIE0lGhAAYOlTVT9zdVUerVq1SPKk1pTp0gI8/Vte7d4dPP43fgO/RHYvkR5IRm1WzJnzwAVykAL+5tFIHR47UN6jMFjdfBCDK6OEQU2RExpNkRAiTN99Ua3c9PNTGNO3bq0keGWj0aLXSBlSr+fbt4cEDiLwnyYi9GDtWtYv/KHIUMQYnWLlSTZK2VxajiK6+7hgMOsYibJYkI0JYqlEDfv1VLXlZtkz1jchABgNMnQqzZ4OzMyxZov5w3bqkPtBjXVxTNF9FWC93dzVV5AQl+YZ31MEPPoDYWH0DyyxxyUgULnj5yntXpI0kI0I8qWFDlS2A2iI+E3ZifecdNZ0gIEDtPm9aSWOQURG7ULOm6q83UhvFIxcf2L9fTSixRxbLemW+iEgrSUaESEqnTuqvyePHmbbxWY0aqudas2ZQvYL6dmnwkpU09mLgQLhJHiYahqoDQ4dm+MRoq2CxrNfHR+dYhM2SZESIpBgMMGaMur54MZw+nSlPkzevWh48d7o0PLM3depA0aIwMao/4dmD4OJFtauevbFIRmRkRKSVJCNCJKdiRbUbWkwM9OsXv/QlMzyUhmf2xmiE996DCDwY5RI3ujZunFrqO3UqLFqkuuHZOotW8JKMiLSSZESIp/niC7Xx2dq1akJrZnkkDc/sUbdukCMHfHGjPXeCK0B4uNpxccAAtda7aFG1jDwjt4DOahZzRqRMI9JKkhEhnqZECVXrBzU6EhqaOc/zSMo09sjbO25QDSO9XeehFSmibihTBl56SS2pWr4cqldX+wbYIinTiAwgyYgQzzJ0qPoGe/Wq6uWeGaRMY7f69AEvL/jpZFnWTz0JJ06omcs7d6qtn/PkUaWbKlVSvuuiNbEo08jIiEgrSUaEeBZ3d7X7KqitWXfuzPjnkDKN3cqZE3r2VNeHDjcSU6R4fC+ZqlVVAlKmDFy/rrYA/vtv/YJNCxkZERlAkhEhUqJuXejYUU1i7dw5fiQjo0iZxq4NHQp+fmoA5Ntvn7ixYEH46y/VnCQsTG1klAm9bTKNzBkRGUCSESFSaupUCAyEf/9VO/xmJCnT2LVcudRWAKCasZ48qeayfvGF2qdozhJvIn7+TW37e+sW1K8PZ8/qG3RKyciIyADOegcghM3Inl1tvfvKK/DVV1ChgvomGxGhvs2WLZv2x5Yyjd3r2xdWrVKdd1u2VHsSnT+vbps7Fz77zJf5k9bz8tCacOwYtG4N+/Zh9Zu9WMwZySEjIyKNZGREiNRo1Ah691bXu3RRu94NGaKWa770Esyfn7YSjpRp7J7RCD/8oOaQHDumEpGCBdUE17x54dQpqP5aToaU34Dm7h4/ydXaSTt4kQEkGREitaZOhebN1fXixaFpU7VEc/du6NpVlXJatoTvv4fIyJQ9ppRpHEJgICxcCEFBqiHaP/+oQbbjx+MnuX62MB+LtbbqF9MeSdZMyjQiA0gyIkRqubrCihVqCP3IEVi9Gi5dgvHjIThY9SJZsULtb/PCC2r55rNImcZhNGqkWopMn676kICa3DprFmzZovLbryLVbr9RS5aZRx6sluxNIzJAmpKRGTNmEBwcjLu7OxUrVmT79u3Jnrt8+XIaNGhA7ty58fX1pWrVqvz+++9pDlgIq+DkpNrFu7io3/391aTW//6D7dvVbMWAADX2XreuGp9/GinTCKBWLTVaUm/YS1wmENeoB2wbu0XnqJ4u9kH8nJFs2fSNRdiuVCcjS5cupX///gwfPpwDBw5Qo0YNGjduzIVkugdu27aNBg0asHbtWvbv30+dOnVo3rw5Bw4cSHfwQlgdo1F10xwxQi2Z6NBB7W3Tt69aPpEcKdOIOM7O8MmnBs6/oEqB/01eRVSUzkE9xePw+Dkjfn46ByNsVqqTkSlTptCtWze6d+9OyZIlmTp1KkFBQcycOTPJ86dOncrgwYOpXLkyRYsWZdy4cRQtWpTffvst3cELYdV8fdW8kWLFVOnmu++SP1fKNOIJL36ikpFGkStZ+1uMztEkLzpcvXc1Nw+cZX2mSKNUJSNRUVHs37+fhg0bJjjesGFDduzYkaLHiI2NJTw8nBw5ciR7TmRkJGFhYQl+hLBJRqNacQMwaVJ80vEkKdOIJzg1rMcDj5zk4wrHpqzXO5xkxdxX712Dp7x3RdqlKhm5desWMTEx+Pv7Jzju7+/PtWvXUvQYkydP5sGDB7z55pvJnjN+/Hj8/PzMP0FBQakJUwjr0qkT5M+v1nJOmJD0OVKmEU9yd+dB604AlNk5m3v39A0nOTFxc0acvd11jkTYsjRNYDU80YRH07REx5KyePFiRo0axdKlS8mTJ0+y5w0dOpTQ0FDzz8WLF9MSphDWwcsLpkxR1z/9VHW9epKUaUQS8gxXq2qaaKv5Y8ohnaNJmvZIzRlx9pVEWqRdqpKRXLly4eTklGgU5MaNG4lGS560dOlSunXrxk8//UT9+vWfeq6bmxu+vr4JfoSwaa1bw1tvqcmsb76ZuNW3lGlEUooX53jZthjRqDipHezfr3dEicW9d10lGRHpkKpkxNXVlYoVKxISEpLgeEhICNWqVUv2fosXL6Zz584sWrSIpk2bpi1SIWyZwQDffKP2Hrl9G1q0UP3ATaRMI5KR7auxPMKdQo+OE1u1GlhZawRjhCkZkTKNSLtUl2kGDhzInDlzmDdvHsePH2fAgAFcuHCBXr16AarE0rFjR/P5ixcvpmPHjkyePJmXXnqJa9euce3aNUJDQzPuXyGELfDwUM3Q/P3h8GE1lyQmRjVMu3VLnSNlGvGEvDWKMKzeHtbxCsbHUdCqFZw+rXdYZsYoVaZxzy6JtEi7VCcjbdq0YerUqYwZM4Zy5cqxbds21q5dS8GCBQG4evVqgp4js2fPJjo6mvfee4+8efOaf943rTAQwpHkzw/LlqlmacuWQYkS8Nxz8bebWnIKYaHVqBd4jZVsM9RUI2qdO0N0tN5hAeD0WI2MSDIi0sOgaZqmdxDPEhYWhp+fH6GhoTJ/RNiHX36BNm0gNlb9XrSomlcybpy+cQmrpGnw6qvwz+qzHKYMPtzn9tv9yfn9F3qHRpSzB64xEXw7/Bw9PimodzjCyqT077fsTSOEHlq3hr171X42S5eqbq2SiIhkGAzw7bcQExRMJ1TzvJw/TGVjx+/R9eukpuEao8o0XjllzohIO0lGhNBLhQpqP5s331R/bYR4ioAAOHEC+m9tyeIiHwNQ44cefNXsd27c0Ckoi12pvXNLmUaknSQjQghhIzw9oWZNaHtiFP++0Ao3ouixtgWv5v+bnj3h7t0sDsiio7BPHklGRNpJMiKEEDbG4GSk2L5F3KjUGA8iWPK4JUu+CaVsWcjSPUjjkpFonPDL5ZKFTyzsjSQjQghhi1xdyROyCK1wYQpxnml+I7h4EWrUgDVrsiiGuGQkAneyZ8+i5xR2SZIRIYSwVdmyYZg1C4CO4dN5t/JeHjxQK2++/jrznz4qTE1efYQH2bJl/vMJ+yXJiBBC2LIGDaBtWwyxsUwPfZueHR8RGwt9+mT+CEnoNTUy8ggP/Pwy97mEfZNkRAghbN3XX0NgIIZ/TzKz5DTiGmLz6adk6tLfsOsqGXlsdMcof01EOsjbRwghbF2OHDBhAgCGCeMZ1e8Obm6wcyds3px5T3v/lirTPHaRlTQifSQZEUIIe9C+PTz/PISG4r9pMd27q8N9+kBUVOY85YNbamQkRpIRkU6SjAghhD1wcoKuXdX1JUsYOxZy54bjx2Hy5Mx5yoe345IRN0lGRPpIMiKEEPaiTRvVzffPP8kefoEpU9ThMWMyZ6PfiLtxTc/cpRW8SB9JRoQQwl7ky6datAJ89x0dOkDduhARAW+9BY8fZ+zTRYaqOSMGDxkZEekjyYgQQtiTd95Rl998gyEmmrlzwc8Pdu2CESMy9qmiQtXIiNFLkhGRPpKMCCGEPWnVCnLlgkuXYOVKChWCOXPUTRMmQEhIxj1VdLhKRpy8JRkR6SPJiBBC2BM3N8yNRj75BDSN1q3jD739Nly/njFPFXNfJSMuPjJnRKSPJCNCCGFvBgwAHx84eBBWrgRgyhQoXVolIh07qtGSjz9WvUjSKuaBmjPi4icjIyJ9JBkRQgh7kyMH9O2rro8ZA5qGhwf8+KNaAbxhA/TooQZOqlWD+vVh27Y0PE/cRnlu2SQZEekjyYgQQtijgQPB2xsOHIDffgOgbFkYNEjdXLQoNG8Ozs7wxx9QqxaULw/ffJOyJmmxsWCIUMmIRzYp04j0kWRECCHsUc6c8aMjo0aZN6kZPx6OHIGjR2HVKvjvPzWfxMVFVXV69oRKldTtT3PnDrihyjSeOWVkRKSPJCNCCGGvLEdHVq8GVE+00qVV8gFQsCDMnAlXr6p5Jblzq2SlUiX44AO4cCHph75+HTxQIyPOPpKMiPSRZEQIIexVrlxqcxpIMDqSlJw51bzXI0fglVdUo7QpU6B27aSbpV27Fp+MIE3PRDpJMiKEEPbsgw/Aywv+/huWL3/m6f7+sGYNLF2qJruePQsLFyY+z3JkRNrBi/SSZEQIIexZrlxqyAOgdWvVjnXUqKfOUjUa4c03Ydw49fvYseaFM2bXroF73JwRGRkR6SXJiBBC2Lv//Q9eeEFdDwuD0aPh9dchMvKpd+vdGwID4cyZ+MTEJMHIiCQjIp0kGRFCCHvn5qZqL2PGwEcfqeRh7VoYPPipd/PxgWnT1PVx42Dr1vjbJBkRGUmSESGEcARBQarl6vjx8NNP6tj06Wo971O0bKlayMfGqm1vDh9WxxNMYJU5IyKdJBkRQghH06wZtGmjMoyuXZ86f8RggFmzoHJluH0b6tVTK26uX5c5IyLjSDIihBCOaOpUtZ73wAE1h+QpPD1VC/lKleDWLbXc9+BBKdOIjCPJiBBCOKKAAJg9W12fMAF27Hjq6dmyqYTkxRdV91XQpEwjMowkI0II4ahatYqfENKjR9LdzSxkzw6bN6v28b7uj3EiVt0gIyMinSQZEUIIR/bll6oXybFj8NVXzzzdw0O1j795MSLhQSHSQZIRIYRwZNmzw8SJ6vrYsXD3boru5hpj0QXNzS0TAhOORJIRIYRwdJ06qd3z7t2Dzz5L2X0eWcwXMRgyLTThGCQZEUIIR+fkFN9i9csv4cqVZ98nQpb1iowjyYgQQgjVe+Tll9WIxyefPPv8R7KsV2QcSUaEEEKoUsvYser6d99BaOjTz5dkRGQgSUaEEEIotWtDyZLw8CEsXPj0cx9JjxGRcSQZEUIIoRgM0LOnuv7DD08/V+aMiAwkyYgQQoh4LVqoy3374P795M+TMo3IQJKMCCGEiFewIBQoANHRsGtX8udJmUZkIElGhBBCJFSjhrrcvj35c2RkRGQgSUaEEEIkVLOmutyyJflzZM6IyECSjAghhEioXj11+ddfybeHl5ERkYEkGRFCCJHQc89BqVIQEwPr1yd9jswZERlIkhEhhBCJNW+uLn/7LenbpUwjMpAkI0IIIRJ77TV1uXp1/CiIJSnTiAwkyYgQQojEXnxRLfMND1cJyZMkGREZSJIRIYQQiRmN0L69up5Ua3iZMyIykCQjQgghkmZKRtauhTt3Et4mc0ZEBpJkRAghRNJKl4YyZeDxY1i2LOFtUqYRGUiSESGEEMnr0EFdPlmqkTKNyECSjAghhEhe27bqcutWuHgx/riMjIgMJMmIEEKI5BUoEN8efsmS+OMyZ0RkIElGhBBCPJ2pVPPjj6Bp6rqMjIgMJMmIEEKIp2vdGtzc4PBh2LdPHZM5IyIDpSkZmTFjBsHBwbi7u1OxYkW2P22baWDr1q1UrFgRd3d3ChcuzKxZs9IUrBBCCB3kyKESEoDZs9WllGlEBkp1MrJ06VL69+/P8OHDOXDgADVq1KBx48ZcuHAhyfPPnj1LkyZNqFGjBgcOHGDYsGH069ePZU8uExNCCGG9evZUlz/8AP/8I2UakaEMmmYqAKbMiy++SIUKFZg5c6b5WMmSJWnRogXjx49PdP6QIUNYtWoVx48fNx/r1asXhw4dYufOnSl6zrCwMPz8/AgNDcXX1zc14QohhMgImqY2z1uzBooXh5Mn1fGLFyF/fn1jE1YrpX+/UzUyEhUVxf79+2nYsGGC4w0bNmTHjh1J3mfnzp2Jzm/UqBH79u3j8ePHSd4nMjKSsLCwBD9CCCF0ZDDA3LkQGBifiIDMGREZIlXJyK1bt4iJicHf3z/BcX9/f65du5bkfa5du5bk+dHR0dy6dSvJ+4wfPx4/Pz/zT1BQUGrCFEIIkRn8/WHPHqhaVf3u6gre3vrGJOxCmiawGgyGBL9rmpbo2LPOT+q4ydChQwkNDTX/XLRstCOEEEI/+fLBn3/CTz/B8uUyMiIyhHNqTs6VKxdOTk6JRkFu3LiRaPTDJCAgIMnznZ2dyZkzZ5L3cXNzw83NLTWhCSGEyCpGI7zxht5RCDuSqpERV1dXKlasSEhISILjISEhVKtWLcn7VK1aNdH5GzZsoFKlSri4uKQyXCGEEELYm1SXaQYOHMicOXOYN28ex48fZ8CAAVy4cIFevXoBqsTSsWNH8/m9evXi/PnzDBw4kOPHjzNv3jzmzp3LoEGDMu5fIYQQQgiblaoyDUCbNm24ffs2Y8aM4erVq5QuXZq1a9dSsGBBAK5evZqg50hwcDBr165lwIABfP311wQGBjJt2jRatWqVcf8KIYQQQtisVPcZ0YP0GRFCCCFsT6b0GRFCCCGEyGiSjAghhBBCV5KMCCGEEEJXkowIIYQQQleSjAghhBBCV5KMCCGEEEJXkowIIYQQQleSjAghhBBCV5KMCCGEEEJXqW4HrwdTk9iwsDCdIxFCCCFESpn+bj+r2btNJCPh4eEABAUF6RyJEEIIIVIrPDwcPz+/ZG+3ib1pYmNjuXLlCj4+PhgMhgx73LCwMIKCgrh48aLseWNl5LWxXvLaWC95bayXo742mqYRHh5OYGAgRmPyM0NsYmTEaDSSP3/+THt8X19fh3pz2BJ5bayXvDbWS14b6+WIr83TRkRMZAKrEEIIIXQlyYgQQgghdOXQyYibmxsjR47Ezc1N71DEE+S1sV7y2lgveW2sl7w2T2cTE1iFEEIIYb8cemRECCGEEPqTZEQIIYQQupJkRAghhBC6kmRECCGEELpy6GRkxowZBAcH4+7uTsWKFdm+fbveIdm9bdu20bx5cwIDAzEYDPz6668Jbtc0jVGjRhEYGIiHhwe1a9fm6NGjCc6JjIykb9++5MqVCy8vL1599VUuXbqUhf8K+zN+/HgqV66Mj48PefLkoUWLFpw8eTLBOfLa6GPmzJmUKVPG3CyratWqrFu3zny7vC7WY/z48RgMBvr3728+Jq9PCmkOasmSJZqLi4v27bffaseOHdPef/99zcvLSzt//rzeodm1tWvXasOHD9eWLVumAdqKFSsS3D5hwgTNx8dHW7ZsmXbkyBGtTZs2Wt68ebWwsDDzOb169dLy5cunhYSEaH///bdWp04drWzZslp0dHQW/2vsR6NGjbT58+dr//zzj3bw4EGtadOmWoECBbT79++bz5HXRh+rVq3S1qxZo508eVI7efKkNmzYMM3FxUX7559/NE2T18Va7NmzRytUqJBWpkwZ7f333zcfl9cnZRw2GalSpYrWq1evBMdKlCihffTRRzpF5HieTEZiY2O1gIAAbcKECeZjERERmp+fnzZr1ixN0zTt3r17mouLi7ZkyRLzOZcvX9aMRqO2fv36LIvd3t24cUMDtK1bt2qaJq+NtcmePbs2Z84ceV2sRHh4uFa0aFEtJCREq1WrljkZkdcn5RyyTBMVFcX+/ftp2LBhguMNGzZkx44dOkUlzp49y7Vr1xK8Lm5ubtSqVcv8uuzfv5/Hjx8nOCcwMJDSpUvLa5eBQkNDAciRIwcgr421iImJYcmSJTx48ICqVavK62Il3nvvPZo2bUr9+vUTHJfXJ+VsYqO8jHbr1i1iYmLw9/dPcNzf359r167pFJUw/bdP6nU5f/68+RxXV1eyZ8+e6Bx57TKGpmkMHDiQ6tWrU7p0aUBeG70dOXKEqlWrEhERgbe3NytWrKBUqVLmP1byuuhnyZIl/P333+zduzfRbfL/Tco5ZDJiYjAYEvyuaVqiYyLrpeV1kdcu4/Tp04fDhw/z559/JrpNXht9FC9enIMHD3Lv3j2WLVtGp06d2Lp1q/l2eV30cfHiRd5//302bNiAu7t7sufJ6/NsDlmmyZUrF05OTomyzhs3biTKYEXWCQgIAHjq6xIQEEBUVBR3795N9hyRdn379mXVqlVs3ryZ/Pnzm4/La6MvV1dXihQpQqVKlRg/fjxly5blyy+/lNdFZ/v37+fGjRtUrFgRZ2dnnJ2d2bp1K9OmTcPZ2dn831den2dzyGTE1dWVihUrEhISkuB4SEgI1apV0ykqERwcTEBAQILXJSoqiq1bt5pfl4oVK+Li4pLgnKtXr/LPP//Ia5cOmqbRp08fli9fzqZNmwgODk5wu7w21kXTNCIjI+V10Vm9evU4cuQIBw8eNP9UqlSJDh06cPDgQQoXLiyvT0rpM29Wf6alvXPnztWOHTum9e/fX/Py8tLOnTund2h2LTw8XDtw4IB24MABDdCmTJmiHThwwLykesKECZqfn5+2fPly7ciRI1q7du2SXAaXP39+bePGjdrff/+t1a1b1+GWwWW03r17a35+ftqWLVu0q1evmn8ePnxoPkdeG30MHTpU27Ztm3b27Fnt8OHD2rBhwzSj0aht2LBB0zR5XayN5WoaTZPXJ6UcNhnRNE37+uuvtYIFC2qurq5ahQoVzMsYRebZvHmzBiT66dSpk6ZpaincyJEjtYCAAM3NzU2rWbOmduTIkQSP8ejRI61Pnz5ajhw5NA8PD61Zs2bahQsXdPjX2I+kXhNAmz9/vvkceW300bVrV/PnVO7cubV69eqZExFNk9fF2jyZjMjrkzIGTdM0fcZkhBBCCCEcdM6IEEIIIayHJCNCCCGE0JUkI0IIIYTQlSQjQgghhNCVJCNCCCGE0JUkI0IIIYTQlSQjQgghhNCVJCNCCCGE0JUkI0IIIYTQlSQjQgghhNCVJCNCCCGE0JUkI0IIIYTQ1f8BOBjBTg7C00AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_train, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c97df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4911dcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_val, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8517e995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testPredict, color = 'darkgreen', label = 'Predicted SOH(Testing)')\n",
    "plt.plot(y_test, color = 'blue', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b8bb10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(combined_data-combined_datap, color = 'blue', label = 'Predicted SOH')\n",
    "yticks_positions = [-0.3, -0.2,-0.1,0.0 ,0.1,0.2,0.3]\n",
    "#yticks_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "\n",
    "# Apply the yticks\n",
    "#plt.yticks(yticks_positions, yticks_labels)\n",
    "plt.yticks(yticks_positions)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5691222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744808708575012"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(combined_data, combined_datap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9979038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(y_train-trainPredict, color = 'blue', label = 'Training Error')\n",
    "#plt.plot(combined_data-combined_datap, color = 'blue', label = 'Error')\n",
    "X_data = np.arange(439, 628)\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "p=np.concatenate((y_val,y_test), axis=0)\n",
    "plt.plot(X_data,p-z, color = 'darkgreen', label = 'Testing Error')\n",
    "yticks_positions = [-0.3, -0.2,-0.1,0.0 ,0.1,0.2,0.3]\n",
    "#yticks_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "\n",
    "# Apply the yticks\n",
    "#plt.yticks(yticks_positions, yticks_labels)\n",
    "plt.yticks(yticks_positions)\n",
    "plt.legend()\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "824ddb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model =  regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1eff8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model_best\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./saved_model_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4e558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
