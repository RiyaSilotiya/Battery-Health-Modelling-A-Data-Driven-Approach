{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1c115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb60aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3548dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('output_Result0.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa98ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401.203</td>\n",
       "      <td>1003.485</td>\n",
       "      <td>949.140</td>\n",
       "      <td>792.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421.250</td>\n",
       "      <td>1021.578</td>\n",
       "      <td>925.547</td>\n",
       "      <td>788.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425.719</td>\n",
       "      <td>1035.750</td>\n",
       "      <td>907.328</td>\n",
       "      <td>704.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431.235</td>\n",
       "      <td>1042.703</td>\n",
       "      <td>900.469</td>\n",
       "      <td>766.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433.390</td>\n",
       "      <td>1044.985</td>\n",
       "      <td>902.468</td>\n",
       "      <td>781.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>209.157</td>\n",
       "      <td>482.406</td>\n",
       "      <td>623.969</td>\n",
       "      <td>714.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>202.657</td>\n",
       "      <td>491.234</td>\n",
       "      <td>627.188</td>\n",
       "      <td>690.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>203.046</td>\n",
       "      <td>492.938</td>\n",
       "      <td>615.297</td>\n",
       "      <td>720.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>107.875</td>\n",
       "      <td>419.500</td>\n",
       "      <td>693.657</td>\n",
       "      <td>744.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>198.750</td>\n",
       "      <td>475.953</td>\n",
       "      <td>606.657</td>\n",
       "      <td>714.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        F2       F3       F4\n",
       "0    401.203  1003.485  949.140  792.094\n",
       "1    421.250  1021.578  925.547  788.015\n",
       "2    425.719  1035.750  907.328  704.781\n",
       "3    431.235  1042.703  900.469  766.844\n",
       "4    433.390  1044.985  902.468  781.000\n",
       "..       ...       ...      ...      ...\n",
       "632  209.157   482.406  623.969  714.625\n",
       "633  202.657   491.234  627.188  690.843\n",
       "634  203.046   492.938  615.297  720.390\n",
       "635  107.875   419.500  693.657  744.625\n",
       "636  198.750   475.953  606.657  714.156\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8875c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa5f8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>186.1922</td>\n",
       "      <td>471.4906</td>\n",
       "      <td>650.2078</td>\n",
       "      <td>736.2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>186.3235</td>\n",
       "      <td>473.4359</td>\n",
       "      <td>651.3828</td>\n",
       "      <td>732.0997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>186.9906</td>\n",
       "      <td>475.8813</td>\n",
       "      <td>652.2797</td>\n",
       "      <td>733.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>192.5687</td>\n",
       "      <td>486.7563</td>\n",
       "      <td>647.7283</td>\n",
       "      <td>724.8138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>189.6234</td>\n",
       "      <td>481.9984</td>\n",
       "      <td>642.6893</td>\n",
       "      <td>723.8966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1        F2        F3        F4\n",
       "0         NaN       NaN       NaN       NaN\n",
       "1         NaN       NaN       NaN       NaN\n",
       "2         NaN       NaN       NaN       NaN\n",
       "3         NaN       NaN       NaN       NaN\n",
       "4         NaN       NaN       NaN       NaN\n",
       "..        ...       ...       ...       ...\n",
       "632  186.1922  471.4906  650.2078  736.2451\n",
       "633  186.3235  473.4359  651.3828  732.0997\n",
       "634  186.9906  475.8813  652.2797  733.2419\n",
       "635  192.5687  486.7563  647.7283  724.8138\n",
       "636  189.6234  481.9984  642.6893  723.8966\n",
       "\n",
       "[637 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f47a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>434.3110</td>\n",
       "      <td>1037.8001</td>\n",
       "      <td>901.6749</td>\n",
       "      <td>741.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439.2438</td>\n",
       "      <td>1041.3719</td>\n",
       "      <td>895.6578</td>\n",
       "      <td>733.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439.9047</td>\n",
       "      <td>1040.8891</td>\n",
       "      <td>887.2797</td>\n",
       "      <td>722.4185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1         F2        F3        F4\n",
       "0        NaN        NaN       NaN       NaN\n",
       "1        NaN        NaN       NaN       NaN\n",
       "2        NaN        NaN       NaN       NaN\n",
       "3        NaN        NaN       NaN       NaN\n",
       "4        NaN        NaN       NaN       NaN\n",
       "5        NaN        NaN       NaN       NaN\n",
       "6        NaN        NaN       NaN       NaN\n",
       "7        NaN        NaN       NaN       NaN\n",
       "8        NaN        NaN       NaN       NaN\n",
       "9   434.3110  1037.8001  901.6749  741.1248\n",
       "10  439.2438  1041.3719  895.6578  733.3810\n",
       "11  439.9047  1040.8891  887.2797  722.4185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfa1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset_train.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93af4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 434.311 , 1037.8001,  901.6749,  741.1248],\n",
       "       [ 439.2438, 1041.3719,  895.6578,  733.381 ],\n",
       "       [ 439.9047, 1040.8891,  887.2797,  722.4185],\n",
       "       ...,\n",
       "       [ 186.9906,  475.8813,  652.2797,  733.2419],\n",
       "       [ 192.5687,  486.7563,  647.7283,  724.8138],\n",
       "       [ 189.6234,  481.9984,  642.6893,  723.8966]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89596b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset_train_scaled = sc.fit_transform(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5180305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19477b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.4028562 , 0.36286962, 0.3943901 , 0.35852639],\n",
       "       [0.4155885 , 0.37341561, 0.38686102, 0.34226784],\n",
       "       [0.4088657 , 0.36880165, 0.37852534, 0.34049848]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f80fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result = pd.read_csv('SOH_RESULT12.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6e7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.917675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.677398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.670526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.666465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.665487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.664586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0    0.928244\n",
       "1    0.923164\n",
       "2    0.917675\n",
       "3    0.917631\n",
       "4    0.917323\n",
       "..        ...\n",
       "632  0.677398\n",
       "633  0.670526\n",
       "634  0.666465\n",
       "635  0.665487\n",
       "636  0.664586\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68a1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865ffac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.686977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.683707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.677815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.675764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOH\n",
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "..        ...\n",
       "632  0.686977\n",
       "633  0.683707\n",
       "634  0.680679\n",
       "635  0.677815\n",
       "636  0.675764\n",
       "\n",
       "[637 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ff2375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SOH\n",
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "5       NaN\n",
       "6       NaN\n",
       "7       NaN\n",
       "8       NaN\n",
       "9  0.917701"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca6fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_result=dataset_train_result.iloc[9:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf70b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91770118],\n",
       "       [0.91610779],\n",
       "       [0.91450152],\n",
       "       [0.91342167],\n",
       "       [0.91233057],\n",
       "       [0.91072819],\n",
       "       [0.90905045],\n",
       "       [0.90742212],\n",
       "       [0.9062877 ],\n",
       "       [0.90518789],\n",
       "       [0.90630852],\n",
       "       [0.90744841],\n",
       "       [0.90854719],\n",
       "       [0.90914862],\n",
       "       [0.90973227],\n",
       "       [0.91088145],\n",
       "       [0.91147766],\n",
       "       [0.91208714],\n",
       "       [0.9126322 ],\n",
       "       [0.9126316 ],\n",
       "       [0.91048415],\n",
       "       [0.91070341],\n",
       "       [0.91042974],\n",
       "       [0.9096061 ],\n",
       "       [0.90858091],\n",
       "       [0.90727069],\n",
       "       [0.90599129],\n",
       "       [0.90439899],\n",
       "       [0.9023522 ],\n",
       "       [0.90086581],\n",
       "       [0.89905556],\n",
       "       [0.89458119],\n",
       "       [0.89142686],\n",
       "       [0.88909488],\n",
       "       [0.88645091],\n",
       "       [0.88357453],\n",
       "       [0.88095694],\n",
       "       [0.88149199],\n",
       "       [0.88199975],\n",
       "       [0.88171608],\n",
       "       [0.88117336],\n",
       "       [0.88040114],\n",
       "       [0.87910614],\n",
       "       [0.87779384],\n",
       "       [0.8765234 ],\n",
       "       [0.87522125],\n",
       "       [0.87394335],\n",
       "       [0.86956288],\n",
       "       [0.86541898],\n",
       "       [0.86177976],\n",
       "       [0.85817401],\n",
       "       [0.85455419],\n",
       "       [0.85119679],\n",
       "       [0.84756148],\n",
       "       [0.84419609],\n",
       "       [0.84109847],\n",
       "       [0.83770449],\n",
       "       [0.83429666],\n",
       "       [0.83091786],\n",
       "       [0.82757651],\n",
       "       [0.82443764],\n",
       "       [0.82128021],\n",
       "       [0.81787991],\n",
       "       [0.8147698 ],\n",
       "       [0.81133757],\n",
       "       [0.80793431],\n",
       "       [0.80504878],\n",
       "       [0.80293221],\n",
       "       [0.80003196],\n",
       "       [0.79688942],\n",
       "       [0.79377144],\n",
       "       [0.79117924],\n",
       "       [0.78858555],\n",
       "       [0.78595354],\n",
       "       [0.78334691],\n",
       "       [0.78045317],\n",
       "       [0.77763228],\n",
       "       [0.77398833],\n",
       "       [0.77112612],\n",
       "       [0.77317197],\n",
       "       [0.77337613],\n",
       "       [0.77280662],\n",
       "       [0.77169093],\n",
       "       [0.77059487],\n",
       "       [0.76953091],\n",
       "       [0.76873007],\n",
       "       [0.767632  ],\n",
       "       [0.7665769 ],\n",
       "       [0.76524483],\n",
       "       [0.7592473 ],\n",
       "       [0.75507553],\n",
       "       [0.75143143],\n",
       "       [0.74910783],\n",
       "       [0.74756478],\n",
       "       [0.74575695],\n",
       "       [0.74364978],\n",
       "       [0.74101665],\n",
       "       [0.73864669],\n",
       "       [0.73685566],\n",
       "       [0.73501435],\n",
       "       [0.73292721],\n",
       "       [0.730839  ],\n",
       "       [0.72821362],\n",
       "       [0.72481227],\n",
       "       [0.72191826],\n",
       "       [0.71930199],\n",
       "       [0.71722739],\n",
       "       [0.71514902],\n",
       "       [0.71277775],\n",
       "       [0.71199525],\n",
       "       [0.71197445],\n",
       "       [0.71116991],\n",
       "       [0.7098492 ],\n",
       "       [0.70850615],\n",
       "       [0.70719517],\n",
       "       [0.70588796],\n",
       "       [0.70457894],\n",
       "       [0.70297183],\n",
       "       [0.70135373],\n",
       "       [0.69820977],\n",
       "       [0.69482245],\n",
       "       [0.69219149],\n",
       "       [0.69061201],\n",
       "       [0.68985739],\n",
       "       [0.68851485],\n",
       "       [0.68718975],\n",
       "       [0.68559442],\n",
       "       [0.68430467],\n",
       "       [0.68327804],\n",
       "       [0.68221815],\n",
       "       [0.68090219],\n",
       "       [0.67961498],\n",
       "       [0.6777911 ],\n",
       "       [0.67518586],\n",
       "       [0.67312558],\n",
       "       [0.67104499],\n",
       "       [0.66923734],\n",
       "       [0.66742858],\n",
       "       [0.66560804],\n",
       "       [0.66433591],\n",
       "       [0.66513253],\n",
       "       [0.6651595 ],\n",
       "       [0.6646652 ],\n",
       "       [0.66414858],\n",
       "       [0.66364805],\n",
       "       [0.66316326],\n",
       "       [0.66291491],\n",
       "       [0.66238138],\n",
       "       [0.66161838],\n",
       "       [0.66059263],\n",
       "       [0.65775704],\n",
       "       [0.65567486],\n",
       "       [0.65412711],\n",
       "       [0.65261658],\n",
       "       [0.65108506],\n",
       "       [0.64978392],\n",
       "       [0.64957459],\n",
       "       [0.65043876],\n",
       "       [0.65054171],\n",
       "       [0.68514529],\n",
       "       [0.71924637],\n",
       "       [0.75304449],\n",
       "       [0.78683124],\n",
       "       [0.82022317],\n",
       "       [0.85454354],\n",
       "       [0.88885234],\n",
       "       [0.91991088],\n",
       "       [0.95013565],\n",
       "       [0.98082373],\n",
       "       [0.97642479],\n",
       "       [0.97199392],\n",
       "       [0.96757988],\n",
       "       [0.96260955],\n",
       "       [0.95773398],\n",
       "       [0.95162123],\n",
       "       [0.94501228],\n",
       "       [0.94005051],\n",
       "       [0.93512026],\n",
       "       [0.9362181 ],\n",
       "       [0.93680392],\n",
       "       [0.93734629],\n",
       "       [0.93739366],\n",
       "       [0.93906479],\n",
       "       [0.93908152],\n",
       "       [0.9385656 ],\n",
       "       [0.93807676],\n",
       "       [0.93751082],\n",
       "       [0.93641329],\n",
       "       [0.93041341],\n",
       "       [0.92880685],\n",
       "       [0.92569002],\n",
       "       [0.92230917],\n",
       "       [0.91606203],\n",
       "       [0.9117517 ],\n",
       "       [0.90775305],\n",
       "       [0.90347356],\n",
       "       [0.89930634],\n",
       "       [0.89515298],\n",
       "       [0.88991095],\n",
       "       [0.88082842],\n",
       "       [0.87457572],\n",
       "       [0.87019642],\n",
       "       [0.86604197],\n",
       "       [0.8611326 ],\n",
       "       [0.85649073],\n",
       "       [0.8585846 ],\n",
       "       [0.86040398],\n",
       "       [0.86115348],\n",
       "       [0.8608814 ],\n",
       "       [0.86037721],\n",
       "       [0.85809447],\n",
       "       [0.85474429],\n",
       "       [0.85220874],\n",
       "       [0.85015731],\n",
       "       [0.84811571],\n",
       "       [0.839655  ],\n",
       "       [0.83142003],\n",
       "       [0.82423566],\n",
       "       [0.81757432],\n",
       "       [0.81141341],\n",
       "       [0.80606353],\n",
       "       [0.80067294],\n",
       "       [0.79581551],\n",
       "       [0.79070085],\n",
       "       [0.78582759],\n",
       "       [0.78092808],\n",
       "       [0.77605256],\n",
       "       [0.7709601 ],\n",
       "       [0.76710262],\n",
       "       [0.76323655],\n",
       "       [0.75909822],\n",
       "       [0.75526314],\n",
       "       [0.75139183],\n",
       "       [0.74778314],\n",
       "       [0.74416979],\n",
       "       [0.74314608],\n",
       "       [0.74135206],\n",
       "       [0.73956017],\n",
       "       [0.73701708],\n",
       "       [0.73475253],\n",
       "       [0.73272633],\n",
       "       [0.73067364],\n",
       "       [0.72810657],\n",
       "       [0.72606753],\n",
       "       [0.72408303],\n",
       "       [0.71999313],\n",
       "       [0.71693422],\n",
       "       [0.72207281],\n",
       "       [0.72541165],\n",
       "       [0.7271884 ],\n",
       "       [0.72845133],\n",
       "       [0.72921577],\n",
       "       [0.73026171],\n",
       "       [0.73079292],\n",
       "       [0.73102272],\n",
       "       [0.73102337],\n",
       "       [0.73100897],\n",
       "       [0.72304937],\n",
       "       [0.7171491 ],\n",
       "       [0.71253057],\n",
       "       [0.70869341],\n",
       "       [0.7071809 ],\n",
       "       [0.70515106],\n",
       "       [0.70281063],\n",
       "       [0.70074664],\n",
       "       [0.69869028],\n",
       "       [0.69642479],\n",
       "       [0.69462693],\n",
       "       [0.69282754],\n",
       "       [0.69103098],\n",
       "       [0.68872612],\n",
       "       [0.68511583],\n",
       "       [0.68228262],\n",
       "       [0.67999057],\n",
       "       [0.67771466],\n",
       "       [0.67541952],\n",
       "       [0.67336584],\n",
       "       [0.67285732],\n",
       "       [0.67363328],\n",
       "       [0.67338235],\n",
       "       [0.67311688],\n",
       "       [0.67207321],\n",
       "       [0.67103073],\n",
       "       [0.67000876],\n",
       "       [0.6687198 ],\n",
       "       [0.66740307],\n",
       "       [0.66606293],\n",
       "       [0.6629952 ],\n",
       "       [0.65888139],\n",
       "       [0.6557897 ],\n",
       "       [0.65346797],\n",
       "       [0.65298355],\n",
       "       [0.65168548],\n",
       "       [0.64985747],\n",
       "       [0.64829908],\n",
       "       [0.64678785],\n",
       "       [0.6455283 ],\n",
       "       [0.64395614],\n",
       "       [0.64189869],\n",
       "       [0.64011238],\n",
       "       [0.63781504],\n",
       "       [0.63422163],\n",
       "       [0.63117022],\n",
       "       [0.62862211],\n",
       "       [0.62607524],\n",
       "       [0.62376274],\n",
       "       [0.62120646],\n",
       "       [0.61943826],\n",
       "       [0.6199555 ],\n",
       "       [0.61918748],\n",
       "       [0.61791   ],\n",
       "       [0.61585083],\n",
       "       [0.61405425],\n",
       "       [0.61227006],\n",
       "       [0.61020353],\n",
       "       [0.60786944],\n",
       "       [0.60555602],\n",
       "       [0.60247538],\n",
       "       [0.59734667],\n",
       "       [0.59323542],\n",
       "       [0.58963832],\n",
       "       [0.58579999],\n",
       "       [0.58272583],\n",
       "       [0.57964043],\n",
       "       [0.57786945],\n",
       "       [0.57689197],\n",
       "       [0.57612913],\n",
       "       [0.61231947],\n",
       "       [0.6482543 ],\n",
       "       [0.68446044],\n",
       "       [0.72092079],\n",
       "       [0.75833361],\n",
       "       [0.79529015],\n",
       "       [0.83248311],\n",
       "       [0.86896174],\n",
       "       [0.90432495],\n",
       "       [0.93972307],\n",
       "       [0.93867266],\n",
       "       [0.93762341],\n",
       "       [0.93654401],\n",
       "       [0.93545589],\n",
       "       [0.93445145],\n",
       "       [0.93335321],\n",
       "       [0.93174732],\n",
       "       [0.93009814],\n",
       "       [0.92903255],\n",
       "       [0.92956896],\n",
       "       [0.93014035],\n",
       "       [0.93121253],\n",
       "       [0.93180924],\n",
       "       [0.9323688 ],\n",
       "       [0.93293426],\n",
       "       [0.93297811],\n",
       "       [0.93358894],\n",
       "       [0.93412094],\n",
       "       [0.93410898],\n",
       "       [0.93253004],\n",
       "       [0.93262982],\n",
       "       [0.9317161 ],\n",
       "       [0.93051318],\n",
       "       [0.92884462],\n",
       "       [0.92716915],\n",
       "       [0.92577214],\n",
       "       [0.92382779],\n",
       "       [0.92169483],\n",
       "       [0.91985692],\n",
       "       [0.91797712],\n",
       "       [0.91410648],\n",
       "       [0.91162563],\n",
       "       [0.90959132],\n",
       "       [0.90754144],\n",
       "       [0.90497761],\n",
       "       [0.90241034],\n",
       "       [0.90210677],\n",
       "       [0.90206659],\n",
       "       [0.90150967],\n",
       "       [0.90045177],\n",
       "       [0.89916618],\n",
       "       [0.89727241],\n",
       "       [0.89547235],\n",
       "       [0.89368485],\n",
       "       [0.89187297],\n",
       "       [0.89033913],\n",
       "       [0.88683678],\n",
       "       [0.88303394],\n",
       "       [0.87944999],\n",
       "       [0.87612263],\n",
       "       [0.87280442],\n",
       "       [0.86973649],\n",
       "       [0.86640595],\n",
       "       [0.86360258],\n",
       "       [0.86079878],\n",
       "       [0.85769917],\n",
       "       [0.85460145],\n",
       "       [0.85151551],\n",
       "       [0.8487476 ],\n",
       "       [0.84592442],\n",
       "       [0.84333879],\n",
       "       [0.8405115 ],\n",
       "       [0.83795583],\n",
       "       [0.83511601],\n",
       "       [0.83225812],\n",
       "       [0.829688  ],\n",
       "       [0.82759024],\n",
       "       [0.82527239],\n",
       "       [0.82267275],\n",
       "       [0.82012228],\n",
       "       [0.81780015],\n",
       "       [0.81576514],\n",
       "       [0.81368149],\n",
       "       [0.81135363],\n",
       "       [0.80932882],\n",
       "       [0.80732694],\n",
       "       [0.80506131],\n",
       "       [0.80301535],\n",
       "       [0.80639574],\n",
       "       [0.80687406],\n",
       "       [0.80687006],\n",
       "       [0.80631698],\n",
       "       [0.80552244],\n",
       "       [0.80500993],\n",
       "       [0.80448164],\n",
       "       [0.80366943],\n",
       "       [0.80264003],\n",
       "       [0.80159742],\n",
       "       [0.79566919],\n",
       "       [0.79263199],\n",
       "       [0.78982652],\n",
       "       [0.78779249],\n",
       "       [0.78679273],\n",
       "       [0.78553627],\n",
       "       [0.78425646],\n",
       "       [0.78275266],\n",
       "       [0.78118559],\n",
       "       [0.77994661],\n",
       "       [0.77866348],\n",
       "       [0.77711642],\n",
       "       [0.77557274],\n",
       "       [0.77376994],\n",
       "       [0.77147555],\n",
       "       [0.76940679],\n",
       "       [0.76735239],\n",
       "       [0.76553992],\n",
       "       [0.76402631],\n",
       "       [0.76247273],\n",
       "       [0.76194102],\n",
       "       [0.76218245],\n",
       "       [0.76192567],\n",
       "       [0.76115844],\n",
       "       [0.76009311],\n",
       "       [0.75905761],\n",
       "       [0.75801534],\n",
       "       [0.75697536],\n",
       "       [0.75591582],\n",
       "       [0.75459261],\n",
       "       [0.75202137],\n",
       "       [0.74920388],\n",
       "       [0.7468712 ],\n",
       "       [0.74528721],\n",
       "       [0.74480479],\n",
       "       [0.74374886],\n",
       "       [0.74271353],\n",
       "       [0.74167497],\n",
       "       [0.74066665],\n",
       "       [0.73964305],\n",
       "       [0.73860465],\n",
       "       [0.73730004],\n",
       "       [0.73601923],\n",
       "       [0.73450495],\n",
       "       [0.73193893],\n",
       "       [0.73017291],\n",
       "       [0.72838612],\n",
       "       [0.72659453],\n",
       "       [0.7248229 ],\n",
       "       [0.7232871 ],\n",
       "       [0.72229161],\n",
       "       [0.72281716],\n",
       "       [0.72284262],\n",
       "       [0.72261872],\n",
       "       [0.72236744],\n",
       "       [0.72161114],\n",
       "       [0.72113257],\n",
       "       [0.7206331 ],\n",
       "       [0.72009672],\n",
       "       [0.71934516],\n",
       "       [0.71806865],\n",
       "       [0.71553724],\n",
       "       [0.71348605],\n",
       "       [0.7116789 ],\n",
       "       [0.70989794],\n",
       "       [0.70863318],\n",
       "       [0.70706552],\n",
       "       [0.70684204],\n",
       "       [0.70716041],\n",
       "       [0.70764404],\n",
       "       [0.72957791],\n",
       "       [0.75090877],\n",
       "       [0.77234686],\n",
       "       [0.79333079],\n",
       "       [0.81465723],\n",
       "       [0.83576688],\n",
       "       [0.85680418],\n",
       "       [0.87647335],\n",
       "       [0.89506549],\n",
       "       [0.9146737 ],\n",
       "       [0.91252975],\n",
       "       [0.91060455],\n",
       "       [0.90816668],\n",
       "       [0.90580653],\n",
       "       [0.90321845],\n",
       "       [0.90035246],\n",
       "       [0.89772392],\n",
       "       [0.89464694],\n",
       "       [0.89174303],\n",
       "       [0.88747125],\n",
       "       [0.88344082],\n",
       "       [0.87863599],\n",
       "       [0.87466727],\n",
       "       [0.87086884],\n",
       "       [0.86928382],\n",
       "       [0.86736185],\n",
       "       [0.8650419 ],\n",
       "       [0.86295269],\n",
       "       [0.86060509],\n",
       "       [0.85842369],\n",
       "       [0.85594299],\n",
       "       [0.85436209],\n",
       "       [0.85206474],\n",
       "       [0.84954926],\n",
       "       [0.84449856],\n",
       "       [0.83979858],\n",
       "       [0.83506945],\n",
       "       [0.83058482],\n",
       "       [0.82632176],\n",
       "       [0.82542251],\n",
       "       [0.8237924 ],\n",
       "       [0.8215627 ],\n",
       "       [0.81910735],\n",
       "       [0.81679287],\n",
       "       [0.81415486],\n",
       "       [0.81855172],\n",
       "       [0.82196046],\n",
       "       [0.82474169],\n",
       "       [0.8270743 ],\n",
       "       [0.82659226],\n",
       "       [0.82646891],\n",
       "       [0.82613796],\n",
       "       [0.82592505],\n",
       "       [0.82566674],\n",
       "       [0.82957581],\n",
       "       [0.82526219],\n",
       "       [0.82113427],\n",
       "       [0.81657542],\n",
       "       [0.81254631],\n",
       "       [0.80743443],\n",
       "       [0.80287367],\n",
       "       [0.79859569],\n",
       "       [0.79459587],\n",
       "       [0.7908902 ],\n",
       "       [0.78332091],\n",
       "       [0.77662551],\n",
       "       [0.77103334],\n",
       "       [0.76652095],\n",
       "       [0.76418843],\n",
       "       [0.76217202],\n",
       "       [0.75945072],\n",
       "       [0.75706137],\n",
       "       [0.7546195 ],\n",
       "       [0.75207522],\n",
       "       [0.74963763],\n",
       "       [0.74771226],\n",
       "       [0.74554578],\n",
       "       [0.74312141],\n",
       "       [0.73908915],\n",
       "       [0.73502367],\n",
       "       [0.73192763],\n",
       "       [0.72873912],\n",
       "       [0.72581806],\n",
       "       [0.72527175],\n",
       "       [0.72422546],\n",
       "       [0.72296621],\n",
       "       [0.72148039],\n",
       "       [0.71985983],\n",
       "       [0.71994962],\n",
       "       [0.71923873],\n",
       "       [0.7182603 ],\n",
       "       [0.71760596],\n",
       "       [0.71664483],\n",
       "       [0.71357656],\n",
       "       [0.7107902 ],\n",
       "       [0.70832684],\n",
       "       [0.70637626],\n",
       "       [0.70453178],\n",
       "       [0.701048  ],\n",
       "       [0.69814836],\n",
       "       [0.69583055],\n",
       "       [0.69344995],\n",
       "       [0.69100165],\n",
       "       [0.6936009 ],\n",
       "       [0.69626315],\n",
       "       [0.69849184],\n",
       "       [0.70044203],\n",
       "       [0.70225314],\n",
       "       [0.70370254],\n",
       "       [0.70513294],\n",
       "       [0.70623223],\n",
       "       [0.7073371 ],\n",
       "       [0.70880276],\n",
       "       [0.70519197],\n",
       "       [0.70149611],\n",
       "       [0.69782492],\n",
       "       [0.69435578],\n",
       "       [0.69092795],\n",
       "       [0.69157563],\n",
       "       [0.69195138],\n",
       "       [0.69185931],\n",
       "       [0.69176947],\n",
       "       [0.6909775 ],\n",
       "       [0.6905515 ],\n",
       "       [0.6901753 ],\n",
       "       [0.69007631],\n",
       "       [0.69029729],\n",
       "       [0.69057898],\n",
       "       [0.68697669],\n",
       "       [0.68370685],\n",
       "       [0.68067881],\n",
       "       [0.67781505],\n",
       "       [0.67576426]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_setY_scaled = sc.fit_transform(dataset_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc6a260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84402423],\n",
       "       [0.84008695],\n",
       "       [0.83611787],\n",
       "       [0.83344956],\n",
       "       [0.83075345],\n",
       "       [0.82679398],\n",
       "       [0.82264829],\n",
       "       [0.81862468],\n",
       "       [0.81582152],\n",
       "       [0.81310389],\n",
       "       [0.81587298],\n",
       "       [0.81868964],\n",
       "       [0.82140471],\n",
       "       [0.82289084],\n",
       "       [0.82433306],\n",
       "       [0.82717267],\n",
       "       [0.82864591],\n",
       "       [0.83015195],\n",
       "       [0.83149877],\n",
       "       [0.8314973 ],\n",
       "       [0.82619095],\n",
       "       [0.82673275],\n",
       "       [0.82605649],\n",
       "       [0.82402128],\n",
       "       [0.82148804],\n",
       "       [0.81825049],\n",
       "       [0.8150891 ],\n",
       "       [0.81115451],\n",
       "       [0.80609691],\n",
       "       [0.80242403],\n",
       "       [0.79795091],\n",
       "       [0.78689474],\n",
       "       [0.7791004 ],\n",
       "       [0.77333808],\n",
       "       [0.76680483],\n",
       "       [0.75969731],\n",
       "       [0.75322924],\n",
       "       [0.75455134],\n",
       "       [0.75580603],\n",
       "       [0.75510506],\n",
       "       [0.75376401],\n",
       "       [0.75185585],\n",
       "       [0.7486559 ],\n",
       "       [0.74541323],\n",
       "       [0.74227398],\n",
       "       [0.73905636],\n",
       "       [0.73589867],\n",
       "       [0.72507452],\n",
       "       [0.71483494],\n",
       "       [0.70584244],\n",
       "       [0.69693265],\n",
       "       [0.68798807],\n",
       "       [0.67969194],\n",
       "       [0.6707091 ],\n",
       "       [0.66239322],\n",
       "       [0.65473899],\n",
       "       [0.64635247],\n",
       "       [0.63793172],\n",
       "       [0.62958271],\n",
       "       [0.62132624],\n",
       "       [0.61357009],\n",
       "       [0.6057681 ],\n",
       "       [0.59736595],\n",
       "       [0.58968087],\n",
       "       [0.58119983],\n",
       "       [0.5727904 ],\n",
       "       [0.56566024],\n",
       "       [0.56043019],\n",
       "       [0.55326369],\n",
       "       [0.54549847],\n",
       "       [0.53779395],\n",
       "       [0.53138862],\n",
       "       [0.52497961],\n",
       "       [0.51847593],\n",
       "       [0.51203494],\n",
       "       [0.50488452],\n",
       "       [0.4979141 ],\n",
       "       [0.4889099 ],\n",
       "       [0.48183738],\n",
       "       [0.48689266],\n",
       "       [0.48739714],\n",
       "       [0.4859899 ],\n",
       "       [0.48323304],\n",
       "       [0.48052466],\n",
       "       [0.47789561],\n",
       "       [0.47591675],\n",
       "       [0.47320342],\n",
       "       [0.47059627],\n",
       "       [0.46730471],\n",
       "       [0.45248483],\n",
       "       [0.44217638],\n",
       "       [0.43317182],\n",
       "       [0.42743021],\n",
       "       [0.42361733],\n",
       "       [0.41915017],\n",
       "       [0.41394338],\n",
       "       [0.40743691],\n",
       "       [0.40158074],\n",
       "       [0.3971551 ],\n",
       "       [0.39260523],\n",
       "       [0.38744791],\n",
       "       [0.38228795],\n",
       "       [0.37580063],\n",
       "       [0.3673959 ],\n",
       "       [0.36024479],\n",
       "       [0.35378001],\n",
       "       [0.34865367],\n",
       "       [0.34351802],\n",
       "       [0.33765862],\n",
       "       [0.33572505],\n",
       "       [0.33567366],\n",
       "       [0.33368565],\n",
       "       [0.33042217],\n",
       "       [0.32710349],\n",
       "       [0.32386407],\n",
       "       [0.32063395],\n",
       "       [0.31739936],\n",
       "       [0.3134282 ],\n",
       "       [0.30942988],\n",
       "       [0.30166115],\n",
       "       [0.29329108],\n",
       "       [0.28678998],\n",
       "       [0.28288708],\n",
       "       [0.28102243],\n",
       "       [0.27770501],\n",
       "       [0.27443069],\n",
       "       [0.27048862],\n",
       "       [0.26730165],\n",
       "       [0.26476486],\n",
       "       [0.26214587],\n",
       "       [0.25889412],\n",
       "       [0.25571343],\n",
       "       [0.25120664],\n",
       "       [0.24476909],\n",
       "       [0.23967814],\n",
       "       [0.23453699],\n",
       "       [0.23007031],\n",
       "       [0.22560086],\n",
       "       [0.22110229],\n",
       "       [0.21795886],\n",
       "       [0.21992732],\n",
       "       [0.21999395],\n",
       "       [0.21877255],\n",
       "       [0.21749597],\n",
       "       [0.21625917],\n",
       "       [0.21506126],\n",
       "       [0.21444757],\n",
       "       [0.21312924],\n",
       "       [0.21124385],\n",
       "       [0.20870921],\n",
       "       [0.20170249],\n",
       "       [0.19655743],\n",
       "       [0.19273292],\n",
       "       [0.18900041],\n",
       "       [0.18521602],\n",
       "       [0.18200092],\n",
       "       [0.18148366],\n",
       "       [0.18361901],\n",
       "       [0.18387341],\n",
       "       [0.26937883],\n",
       "       [0.35364257],\n",
       "       [0.43715768],\n",
       "       [0.52064471],\n",
       "       [0.60315615],\n",
       "       [0.68796176],\n",
       "       [0.77273878],\n",
       "       [0.84948439],\n",
       "       [0.92416977],\n",
       "       [1.        ],\n",
       "       [0.98913022],\n",
       "       [0.97818154],\n",
       "       [0.96727445],\n",
       "       [0.95499277],\n",
       "       [0.94294524],\n",
       "       [0.92784064],\n",
       "       [0.91150992],\n",
       "       [0.89924939],\n",
       "       [0.88706677],\n",
       "       [0.88977951],\n",
       "       [0.89122707],\n",
       "       [0.89256729],\n",
       "       [0.89268431],\n",
       "       [0.89681369],\n",
       "       [0.89685502],\n",
       "       [0.89558018],\n",
       "       [0.89437227],\n",
       "       [0.89297382],\n",
       "       [0.89026184],\n",
       "       [0.87543613],\n",
       "       [0.87146632],\n",
       "       [0.86376465],\n",
       "       [0.85541056],\n",
       "       [0.8399739 ],\n",
       "       [0.82932305],\n",
       "       [0.8194424 ],\n",
       "       [0.8088678 ],\n",
       "       [0.79857059],\n",
       "       [0.78830764],\n",
       "       [0.77535458],\n",
       "       [0.75291166],\n",
       "       [0.73746124],\n",
       "       [0.72664001],\n",
       "       [0.71637436],\n",
       "       [0.70424331],\n",
       "       [0.69277327],\n",
       "       [0.6979472 ],\n",
       "       [0.70244289],\n",
       "       [0.70429491],\n",
       "       [0.70362261],\n",
       "       [0.70237675],\n",
       "       [0.69673609],\n",
       "       [0.6884578 ],\n",
       "       [0.68219245],\n",
       "       [0.67712338],\n",
       "       [0.67207859],\n",
       "       [0.65117219],\n",
       "       [0.63082357],\n",
       "       [0.613071  ],\n",
       "       [0.59661083],\n",
       "       [0.58138723],\n",
       "       [0.5681677 ],\n",
       "       [0.55484754],\n",
       "       [0.54284485],\n",
       "       [0.53020651],\n",
       "       [0.51816469],\n",
       "       [0.50605803],\n",
       "       [0.4940106 ],\n",
       "       [0.48142715],\n",
       "       [0.47189532],\n",
       "       [0.46234227],\n",
       "       [0.45211646],\n",
       "       [0.44263996],\n",
       "       [0.43307398],\n",
       "       [0.42415689],\n",
       "       [0.41522831],\n",
       "       [0.41269874],\n",
       "       [0.4082657 ],\n",
       "       [0.40383794],\n",
       "       [0.39755396],\n",
       "       [0.39195828],\n",
       "       [0.38695154],\n",
       "       [0.38187933],\n",
       "       [0.37553611],\n",
       "       [0.37049764],\n",
       "       [0.36559394],\n",
       "       [0.35548782],\n",
       "       [0.34792925],\n",
       "       [0.36062671],\n",
       "       [0.36887697],\n",
       "       [0.37326731],\n",
       "       [0.37638801],\n",
       "       [0.37827694],\n",
       "       [0.38086146],\n",
       "       [0.38217408],\n",
       "       [0.38274192],\n",
       "       [0.38274353],\n",
       "       [0.38270794],\n",
       "       [0.36303977],\n",
       "       [0.34846021],\n",
       "       [0.33704783],\n",
       "       [0.32756622],\n",
       "       [0.3238288 ],\n",
       "       [0.31881306],\n",
       "       [0.31302987],\n",
       "       [0.30792976],\n",
       "       [0.30284849],\n",
       "       [0.29725046],\n",
       "       [0.29280795],\n",
       "       [0.28836165],\n",
       "       [0.28392237],\n",
       "       [0.27822705],\n",
       "       [0.26930604],\n",
       "       [0.26230517],\n",
       "       [0.25664153],\n",
       "       [0.25101774],\n",
       "       [0.24534646],\n",
       "       [0.24027181],\n",
       "       [0.23901525],\n",
       "       [0.24093266],\n",
       "       [0.24031262],\n",
       "       [0.23965664],\n",
       "       [0.23707773],\n",
       "       [0.23450176],\n",
       "       [0.23197648],\n",
       "       [0.22879145],\n",
       "       [0.22553781],\n",
       "       [0.22222634],\n",
       "       [0.21464597],\n",
       "       [0.20448075],\n",
       "       [0.19684118],\n",
       "       [0.1911042 ],\n",
       "       [0.18990719],\n",
       "       [0.18669966],\n",
       "       [0.18218267],\n",
       "       [0.17833187],\n",
       "       [0.17459762],\n",
       "       [0.17148529],\n",
       "       [0.16760048],\n",
       "       [0.16251652],\n",
       "       [0.15810255],\n",
       "       [0.15242582],\n",
       "       [0.14354652],\n",
       "       [0.13600647],\n",
       "       [0.12971011],\n",
       "       [0.12341678],\n",
       "       [0.11770261],\n",
       "       [0.11138603],\n",
       "       [0.10701681],\n",
       "       [0.10829492],\n",
       "       [0.10639715],\n",
       "       [0.10324049],\n",
       "       [0.09815228],\n",
       "       [0.09371294],\n",
       "       [0.08930419],\n",
       "       [0.0841978 ],\n",
       "       [0.07843028],\n",
       "       [0.07271381],\n",
       "       [0.06510155],\n",
       "       [0.05242852],\n",
       "       [0.04226962],\n",
       "       [0.03338119],\n",
       "       [0.02389667],\n",
       "       [0.01630043],\n",
       "       [0.0086764 ],\n",
       "       [0.00430033],\n",
       "       [0.00188496],\n",
       "       [0.        ],\n",
       "       [0.0894263 ],\n",
       "       [0.17822123],\n",
       "       [0.26768657],\n",
       "       [0.35778005],\n",
       "       [0.4502271 ],\n",
       "       [0.54154667],\n",
       "       [0.63345045],\n",
       "       [0.72358912],\n",
       "       [0.81097157],\n",
       "       [0.89844029],\n",
       "       [0.89584474],\n",
       "       [0.89325203],\n",
       "       [0.89058483],\n",
       "       [0.88789609],\n",
       "       [0.88541414],\n",
       "       [0.88270039],\n",
       "       [0.87873221],\n",
       "       [0.8746571 ],\n",
       "       [0.87202403],\n",
       "       [0.87334949],\n",
       "       [0.87476141],\n",
       "       [0.87741076],\n",
       "       [0.87888524],\n",
       "       [0.88026789],\n",
       "       [0.88166516],\n",
       "       [0.8817735 ],\n",
       "       [0.88328286],\n",
       "       [0.88459743],\n",
       "       [0.88456789],\n",
       "       [0.88066633],\n",
       "       [0.88091288],\n",
       "       [0.87865509],\n",
       "       [0.87568266],\n",
       "       [0.87155967],\n",
       "       [0.86741956],\n",
       "       [0.86396755],\n",
       "       [0.85916308],\n",
       "       [0.85389254],\n",
       "       [0.84935106],\n",
       "       [0.84470607],\n",
       "       [0.83514171],\n",
       "       [0.82901154],\n",
       "       [0.82398476],\n",
       "       [0.81891953],\n",
       "       [0.81258429],\n",
       "       [0.80624057],\n",
       "       [0.80549045],\n",
       "       [0.80539117],\n",
       "       [0.80401503],\n",
       "       [0.80140095],\n",
       "       [0.79822425],\n",
       "       [0.79354475],\n",
       "       [0.7890968 ],\n",
       "       [0.78467989],\n",
       "       [0.78020273],\n",
       "       [0.77641262],\n",
       "       [0.76775832],\n",
       "       [0.75836151],\n",
       "       [0.74950557],\n",
       "       [0.74128366],\n",
       "       [0.73308437],\n",
       "       [0.72550352],\n",
       "       [0.71727375],\n",
       "       [0.71034664],\n",
       "       [0.70341845],\n",
       "       [0.6957593 ],\n",
       "       [0.68810485],\n",
       "       [0.6804795 ],\n",
       "       [0.67364   ],\n",
       "       [0.66666393],\n",
       "       [0.66027483],\n",
       "       [0.65328859],\n",
       "       [0.64697353],\n",
       "       [0.63995635],\n",
       "       [0.63289449],\n",
       "       [0.62654374],\n",
       "       [0.62136017],\n",
       "       [0.61563277],\n",
       "       [0.60920907],\n",
       "       [0.60290686],\n",
       "       [0.59716886],\n",
       "       [0.59214036],\n",
       "       [0.58699165],\n",
       "       [0.58123952],\n",
       "       [0.57623621],\n",
       "       [0.57128958],\n",
       "       [0.56569121],\n",
       "       [0.56063563],\n",
       "       [0.56898857],\n",
       "       [0.57017052],\n",
       "       [0.57016062],\n",
       "       [0.56879397],\n",
       "       [0.56683065],\n",
       "       [0.56556425],\n",
       "       [0.56425885],\n",
       "       [0.56225188],\n",
       "       [0.55970824],\n",
       "       [0.55713194],\n",
       "       [0.54248329],\n",
       "       [0.53497837],\n",
       "       [0.52804605],\n",
       "       [0.52301996],\n",
       "       [0.52054956],\n",
       "       [0.51744486],\n",
       "       [0.51428245],\n",
       "       [0.51056655],\n",
       "       [0.50669433],\n",
       "       [0.50363279],\n",
       "       [0.50046219],\n",
       "       [0.4966394 ],\n",
       "       [0.49282498],\n",
       "       [0.48837026],\n",
       "       [0.48270082],\n",
       "       [0.47758892],\n",
       "       [0.4725125 ],\n",
       "       [0.46803388],\n",
       "       [0.46429376],\n",
       "       [0.46045485],\n",
       "       [0.45914101],\n",
       "       [0.45973759],\n",
       "       [0.45910308],\n",
       "       [0.45720724],\n",
       "       [0.45457482],\n",
       "       [0.45201612],\n",
       "       [0.44944066],\n",
       "       [0.44687086],\n",
       "       [0.44425275],\n",
       "       [0.44098309],\n",
       "       [0.43462957],\n",
       "       [0.42766754],\n",
       "       [0.42190349],\n",
       "       [0.41798946],\n",
       "       [0.41679739],\n",
       "       [0.4141882 ],\n",
       "       [0.41162991],\n",
       "       [0.40906362],\n",
       "       [0.40657207],\n",
       "       [0.40404274],\n",
       "       [0.40147686],\n",
       "       [0.39825318],\n",
       "       [0.3950883 ],\n",
       "       [0.39134651],\n",
       "       [0.38500587],\n",
       "       [0.38064202],\n",
       "       [0.37622687],\n",
       "       [0.37179987],\n",
       "       [0.36742217],\n",
       "       [0.36362719],\n",
       "       [0.36116735],\n",
       "       [0.36246599],\n",
       "       [0.36252889],\n",
       "       [0.36197564],\n",
       "       [0.36135473],\n",
       "       [0.3594859 ],\n",
       "       [0.35830336],\n",
       "       [0.35706918],\n",
       "       [0.35574378],\n",
       "       [0.35388668],\n",
       "       [0.35073241],\n",
       "       [0.34447731],\n",
       "       [0.33940881],\n",
       "       [0.33494334],\n",
       "       [0.3305426 ],\n",
       "       [0.32741739],\n",
       "       [0.3235437 ],\n",
       "       [0.32299147],\n",
       "       [0.32377817],\n",
       "       [0.32497323],\n",
       "       [0.37917178],\n",
       "       [0.43188034],\n",
       "       [0.48485382],\n",
       "       [0.5367051 ],\n",
       "       [0.58940271],\n",
       "       [0.64156464],\n",
       "       [0.69354779],\n",
       "       [0.7421503 ],\n",
       "       [0.78809146],\n",
       "       [0.83654333],\n",
       "       [0.83124561],\n",
       "       [0.82648846],\n",
       "       [0.82046447],\n",
       "       [0.81463256],\n",
       "       [0.80823742],\n",
       "       [0.80115555],\n",
       "       [0.79466043],\n",
       "       [0.78705723],\n",
       "       [0.77988165],\n",
       "       [0.7693261 ],\n",
       "       [0.7593669 ],\n",
       "       [0.74749417],\n",
       "       [0.73768746],\n",
       "       [0.72830155],\n",
       "       [0.72438497],\n",
       "       [0.71963579],\n",
       "       [0.71390319],\n",
       "       [0.70874075],\n",
       "       [0.70293985],\n",
       "       [0.6975496 ],\n",
       "       [0.69141979],\n",
       "       [0.6875134 ],\n",
       "       [0.68183665],\n",
       "       [0.67562089],\n",
       "       [0.66314061],\n",
       "       [0.65152697],\n",
       "       [0.63984128],\n",
       "       [0.62875977],\n",
       "       [0.61822575],\n",
       "       [0.6160037 ],\n",
       "       [0.61197572],\n",
       "       [0.60646612],\n",
       "       [0.60039896],\n",
       "       [0.59467988],\n",
       "       [0.58816135],\n",
       "       [0.599026  ],\n",
       "       [0.607449  ],\n",
       "       [0.61432142],\n",
       "       [0.62008528],\n",
       "       [0.61889417],\n",
       "       [0.61858937],\n",
       "       [0.61777159],\n",
       "       [0.61724549],\n",
       "       [0.61660721],\n",
       "       [0.62626652],\n",
       "       [0.61560755],\n",
       "       [0.60540748],\n",
       "       [0.59414255],\n",
       "       [0.58418665],\n",
       "       [0.57155519],\n",
       "       [0.56028554],\n",
       "       [0.54971467],\n",
       "       [0.53983111],\n",
       "       [0.5306744 ],\n",
       "       [0.5119707 ],\n",
       "       [0.49542636],\n",
       "       [0.48160811],\n",
       "       [0.47045801],\n",
       "       [0.46469434],\n",
       "       [0.45971182],\n",
       "       [0.45298747],\n",
       "       [0.4470834 ],\n",
       "       [0.44104954],\n",
       "       [0.43476263],\n",
       "       [0.42873935],\n",
       "       [0.42398175],\n",
       "       [0.41862838],\n",
       "       [0.41263778],\n",
       "       [0.40267405],\n",
       "       [0.39262825],\n",
       "       [0.38497794],\n",
       "       [0.37709914],\n",
       "       [0.36988121],\n",
       "       [0.36853129],\n",
       "       [0.3659459 ],\n",
       "       [0.36283429],\n",
       "       [0.35916284],\n",
       "       [0.35515842],\n",
       "       [0.35538029],\n",
       "       [0.3536237 ],\n",
       "       [0.351206  ],\n",
       "       [0.34958911],\n",
       "       [0.34721416],\n",
       "       [0.33963246],\n",
       "       [0.33274737],\n",
       "       [0.32666041],\n",
       "       [0.32184053],\n",
       "       [0.31728282],\n",
       "       [0.3086744 ],\n",
       "       [0.3015094 ],\n",
       "       [0.29578209],\n",
       "       [0.28989963],\n",
       "       [0.2838499 ],\n",
       "       [0.29027263],\n",
       "       [0.29685106],\n",
       "       [0.30235813],\n",
       "       [0.30717705],\n",
       "       [0.31165231],\n",
       "       [0.31523378],\n",
       "       [0.3187683 ],\n",
       "       [0.32148465],\n",
       "       [0.32421478],\n",
       "       [0.3278364 ],\n",
       "       [0.31891415],\n",
       "       [0.30978168],\n",
       "       [0.30071017],\n",
       "       [0.29213794],\n",
       "       [0.28366778],\n",
       "       [0.2852682 ],\n",
       "       [0.28619667],\n",
       "       [0.28596915],\n",
       "       [0.28574716],\n",
       "       [0.28379022],\n",
       "       [0.28273756],\n",
       "       [0.28180797],\n",
       "       [0.28156337],\n",
       "       [0.28210942],\n",
       "       [0.28280547],\n",
       "       [0.27390421],\n",
       "       [0.26582445],\n",
       "       [0.25834217],\n",
       "       [0.2512658 ],\n",
       "       [0.2461983 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_setY_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5df2b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and remaining data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(dataset_train_scaled, training_setY_scaled, test_size=0.3,shuffle=False, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4c4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the remaining data into validation and testing sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5,shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79d9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96737777, 0.90778795, 0.80694798, 0.37373319],\n",
       "       [0.97863714, 0.91125169, 0.79699429, 0.35879472],\n",
       "       [0.98014568, 0.91078349, 0.78313496, 0.3376471 ],\n",
       "       ...,\n",
       "       [0.46714587, 0.62600255, 0.70547366, 0.35846986],\n",
       "       [0.4637791 , 0.62283866, 0.70320174, 0.36007351],\n",
       "       [0.45968124, 0.61891729, 0.70050831, 0.36243047]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c995b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439, 4)\n",
      "(439, 1)\n",
      "(94, 4)\n",
      "(94, 1)\n",
      "(95, 4)\n",
      "(95, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape),print(X_val.shape), print(y_val.shape),print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3049b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[:, 0:1]  \n",
    "X_train2 = X_train[:, 1:2]  \n",
    "X_train3 = X_train[:, 2:3]  \n",
    "X_train4 = X_train[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587ba546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test[:, 0:1]  \n",
    "X_test2 = X_test[:, 1:2]  \n",
    "X_test3 = X_test[:, 2:3]  \n",
    "X_test4 = X_test[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val1 = X_val[:, 0:1]  \n",
    "X_val2 = X_val[:, 1:2]  \n",
    "X_val3 = X_val[:, 2:3]  \n",
    "X_val4 = X_val[:, 3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8dc2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e1f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU,LSTM,SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add, concatenate\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70a93138",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_1 =(X_train1.shape[1], 1)\n",
    "input_shape_2 = (X_train2.shape[1], 1)\n",
    "input_shape_3 =(X_train3.shape[1], 1)\n",
    "input_shape_4 = (X_train4.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "227c1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e1985e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=input_shape_1)\n",
    "input_2 = Input(shape=input_shape_2)\n",
    "input_3 = Input(shape=input_shape_3)\n",
    "input_4 = Input(shape=input_shape_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d65e875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "print(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "280d7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92d31ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.01\n",
    "decay_rate = 0.99\n",
    "decay_steps = 10000\n",
    "\n",
    "class LearningRateUpdater(Callback):\n",
    "    def __init__(self, initial_lr, decay_rate, decay_steps):\n",
    "        super(LearningRateUpdater, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.initial_lr * math.pow(self.decay_rate, (epoch + 1) // self.decay_steps)\n",
    "        self.model.optimizer.lr.assign(lr)\n",
    "        print(\"Learning rate updated to:\", lr)\n",
    "\n",
    "\n",
    "# Create the optimizer with the initial learning rate\n",
    "optimizer = Adam(learning_rate=initial_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the learning rate updater callback\n",
    "lr_updater_callback = LearningRateUpdater(initial_lr, decay_rate, decay_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2172067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_scheduler(epoch, lr):\n",
    "#     if epoch % 10000 == 0 and epoch > 0:\n",
    "#         lr *= 0.99\n",
    "#     return lr\n",
    "# def lr_scheduler(epoch, lr):\n",
    "        \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_lr, decay_steps=decay_steps, decay_rate=decay_rate, staircase=False)\n",
    "\n",
    "\n",
    "#lr_scheduler_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "173facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dc576e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        print(f'\\nLearning rate after epoch {epoch} is {lr:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "466e2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5ce23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/18 [>.............................] - ETA: 46s - loss: 0.1151 - mae: 0.2658\n",
      "Learning rate after epoch 0 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 4s 51ms/step - loss: 0.0138 - mae: 0.0808 - val_loss: 0.0260 - val_mae: 0.1526\n",
      "Epoch 2/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0497\n",
      "Learning rate after epoch 1 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0594 - val_loss: 0.0277 - val_mae: 0.1574\n",
      "Epoch 3/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0253\n",
      "Learning rate after epoch 2 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0530 - val_loss: 0.0276 - val_mae: 0.1555\n",
      "Epoch 4/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0274\n",
      "Learning rate after epoch 3 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0468 - val_loss: 0.0278 - val_mae: 0.1535\n",
      "Epoch 5/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0536\n",
      "Learning rate after epoch 4 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 0.0271 - val_mae: 0.1437\n",
      "Epoch 6/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0458\n",
      "Learning rate after epoch 5 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0465 - val_loss: 0.0271 - val_mae: 0.1421\n",
      "Epoch 7/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0780\n",
      "Learning rate after epoch 6 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0456 - val_loss: 0.0290 - val_mae: 0.1326\n",
      "Epoch 8/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0502\n",
      "Learning rate after epoch 7 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0610 - val_loss: 0.0311 - val_mae: 0.1302\n",
      "Epoch 9/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0366\n",
      "Learning rate after epoch 8 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0244 - val_mae: 0.1427\n",
      "Epoch 10/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0413\n",
      "Learning rate after epoch 9 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0579 - val_loss: 0.0300 - val_mae: 0.1335\n",
      "Epoch 11/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0629\n",
      "Learning rate after epoch 10 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0539 - val_loss: 0.0311 - val_mae: 0.1326\n",
      "Epoch 12/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0376\n",
      "Learning rate after epoch 11 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0525 - val_loss: 0.0256 - val_mae: 0.1315\n",
      "Epoch 13/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0610\n",
      "Learning rate after epoch 12 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0535 - val_loss: 0.0272 - val_mae: 0.1330\n",
      "Epoch 14/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0410\n",
      "Learning rate after epoch 13 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0455 - val_loss: 0.0258 - val_mae: 0.1503\n",
      "Epoch 15/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0394\n",
      "Learning rate after epoch 14 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0495 - val_loss: 0.0281 - val_mae: 0.1344\n",
      "Epoch 16/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0323\n",
      "Learning rate after epoch 15 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0593 - val_loss: 0.0276 - val_mae: 0.1258\n",
      "Epoch 17/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0676\n",
      "Learning rate after epoch 16 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0558 - val_loss: 0.0239 - val_mae: 0.1378\n",
      "Epoch 18/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0322\n",
      "Learning rate after epoch 17 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0573 - val_loss: 0.0197 - val_mae: 0.1149\n",
      "Epoch 19/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0630\n",
      "Learning rate after epoch 18 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0581 - val_loss: 0.0274 - val_mae: 0.1201\n",
      "Epoch 20/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0482\n",
      "Learning rate after epoch 19 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0190 - val_mae: 0.1033\n",
      "Epoch 21/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0432\n",
      "Learning rate after epoch 20 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0566 - val_loss: 0.0280 - val_mae: 0.1186\n",
      "Epoch 22/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0336\n",
      "Learning rate after epoch 21 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0436 - val_loss: 0.0154 - val_mae: 0.0974\n",
      "Epoch 23/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0348\n",
      "Learning rate after epoch 22 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0513 - val_loss: 0.0155 - val_mae: 0.0910\n",
      "Epoch 24/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0798\n",
      "Learning rate after epoch 23 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0566 - val_loss: 0.0321 - val_mae: 0.1454\n",
      "Epoch 25/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0449\n",
      "Learning rate after epoch 24 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0497 - val_loss: 0.0337 - val_mae: 0.1628\n",
      "Epoch 26/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0413\n",
      "Learning rate after epoch 25 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0511 - val_loss: 0.0191 - val_mae: 0.1124\n",
      "Epoch 27/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0093 - mae: 0.0938\n",
      "Learning rate after epoch 26 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0517 - val_loss: 0.0133 - val_mae: 0.0842\n",
      "Epoch 28/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0266\n",
      "Learning rate after epoch 27 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0053 - val_mae: 0.0570\n",
      "Epoch 29/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0408\n",
      "Learning rate after epoch 28 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0504 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 30/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0285\n",
      "Learning rate after epoch 29 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0230 - val_mae: 0.1232\n",
      "Epoch 31/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0424\n",
      "Learning rate after epoch 30 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0458 - val_loss: 0.0145 - val_mae: 0.0823\n",
      "Epoch 32/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0324\n",
      "Learning rate after epoch 31 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 0.0200 - val_mae: 0.1179\n",
      "Epoch 33/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0366\n",
      "Learning rate after epoch 32 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0542 - val_loss: 0.0158 - val_mae: 0.1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0602\n",
      "Learning rate after epoch 33 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0499 - val_loss: 0.0163 - val_mae: 0.1232\n",
      "Epoch 35/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0399\n",
      "Learning rate after epoch 34 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0463 - val_loss: 0.0078 - val_mae: 0.0620\n",
      "Epoch 36/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.0979\n",
      "Learning rate after epoch 35 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0446 - val_loss: 0.0267 - val_mae: 0.1377\n",
      "Epoch 37/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.9543e-04 - mae: 0.0267\n",
      "Learning rate after epoch 36 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0560 - val_loss: 0.0129 - val_mae: 0.1094\n",
      "Epoch 38/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0635\n",
      "Learning rate after epoch 37 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0540 - val_loss: 0.0130 - val_mae: 0.0981\n",
      "Epoch 39/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0305\n",
      "Learning rate after epoch 38 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.0174 - val_mae: 0.1036\n",
      "Epoch 40/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0481\n",
      "Learning rate after epoch 39 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0275 - val_mae: 0.1121\n",
      "Epoch 41/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0547\n",
      "Learning rate after epoch 40 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0517 - val_loss: 0.0332 - val_mae: 0.1681\n",
      "Epoch 42/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0616\n",
      "Learning rate after epoch 41 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.1139\n",
      "Epoch 43/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0510\n",
      "Learning rate after epoch 42 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0537 - val_loss: 0.0492 - val_mae: 0.2115\n",
      "Epoch 44/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0265\n",
      "Learning rate after epoch 43 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0222 - val_mae: 0.1189\n",
      "Epoch 45/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0677\n",
      "Learning rate after epoch 44 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0483 - val_loss: 0.0127 - val_mae: 0.0742\n",
      "Epoch 46/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0339\n",
      "Learning rate after epoch 45 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0074 - val_mae: 0.0808\n",
      "Epoch 47/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0336\n",
      "Learning rate after epoch 46 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0152 - val_mae: 0.0912\n",
      "Epoch 48/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0110 - mae: 0.1005\n",
      "Learning rate after epoch 47 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0112 - val_mae: 0.0775\n",
      "Epoch 49/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0396\n",
      "Learning rate after epoch 48 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0523 - val_loss: 0.0365 - val_mae: 0.1872\n",
      "Epoch 50/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0383\n",
      "Learning rate after epoch 49 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0549 - val_loss: 0.0442 - val_mae: 0.2080\n",
      "Epoch 51/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0807\n",
      "Learning rate after epoch 50 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0540 - val_loss: 0.0395 - val_mae: 0.1949\n",
      "Epoch 52/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0658\n",
      "Learning rate after epoch 51 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0383 - val_mae: 0.1855\n",
      "Epoch 53/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0707\n",
      "Learning rate after epoch 52 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0405 - val_loss: 0.0125 - val_mae: 0.1006\n",
      "Epoch 54/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0552\n",
      "Learning rate after epoch 53 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0086 - val_mae: 0.0859\n",
      "Epoch 55/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.7871e-04 - mae: 0.0160\n",
      "Learning rate after epoch 54 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0509 - val_loss: 0.0232 - val_mae: 0.1502\n",
      "Epoch 56/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0325\n",
      "Learning rate after epoch 55 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0489 - val_loss: 0.1140 - val_mae: 0.3338\n",
      "Epoch 57/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0827\n",
      "Learning rate after epoch 56 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0541 - val_mae: 0.2306\n",
      "Epoch 58/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0274\n",
      "Learning rate after epoch 57 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0465 - val_loss: 0.0706 - val_mae: 0.2633\n",
      "Epoch 59/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.7031e-04 - mae: 0.0247\n",
      "Learning rate after epoch 58 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0383 - val_loss: 0.0767 - val_mae: 0.2752\n",
      "Epoch 60/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0370\n",
      "Learning rate after epoch 59 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0322 - val_mae: 0.1706\n",
      "Epoch 61/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3549e-04 - mae: 0.0225\n",
      "Learning rate after epoch 60 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0836 - val_mae: 0.2872\n",
      "Epoch 62/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0433\n",
      "Learning rate after epoch 61 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0470 - val_loss: 0.0683 - val_mae: 0.2570\n",
      "Epoch 63/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0375\n",
      "Learning rate after epoch 62 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0304 - val_mae: 0.1715\n",
      "Epoch 64/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0540\n",
      "Learning rate after epoch 63 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0507 - val_loss: 0.0060 - val_mae: 0.0635\n",
      "Epoch 65/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0402\n",
      "Learning rate after epoch 64 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0034 - val_mae: 0.0534\n",
      "Epoch 66/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0722\n",
      "Learning rate after epoch 65 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 0.0237 - val_mae: 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0290\n",
      "Learning rate after epoch 66 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0832 - val_mae: 0.2865\n",
      "Epoch 68/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0629\n",
      "Learning rate after epoch 67 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0606 - val_loss: 0.1174 - val_mae: 0.3331\n",
      "Epoch 69/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0605\n",
      "Learning rate after epoch 68 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0707 - val_mae: 0.2587\n",
      "Epoch 70/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0266\n",
      "Learning rate after epoch 69 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0051 - val_mae: 0.0472\n",
      "Epoch 71/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0374\n",
      "Learning rate after epoch 70 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0056 - val_mae: 0.0462\n",
      "Epoch 72/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0323\n",
      "Learning rate after epoch 71 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0432 - val_loss: 0.0100 - val_mae: 0.0761\n",
      "Epoch 73/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0533\n",
      "Learning rate after epoch 72 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0448 - val_loss: 0.0061 - val_mae: 0.0569\n",
      "Epoch 74/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0292\n",
      "Learning rate after epoch 73 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 75/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0348\n",
      "Learning rate after epoch 74 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0477 - val_loss: 0.0054 - val_mae: 0.0477\n",
      "Epoch 76/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0448\n",
      "Learning rate after epoch 75 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0439 - val_loss: 0.0077 - val_mae: 0.0784\n",
      "Epoch 77/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0684\n",
      "Learning rate after epoch 76 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0546 - val_loss: 0.0065 - val_mae: 0.0758\n",
      "Epoch 78/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0509\n",
      "Learning rate after epoch 77 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0020 - val_mae: 0.0365\n",
      "Epoch 79/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.3288e-04 - mae: 0.0164\n",
      "Learning rate after epoch 78 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0099 - val_mae: 0.0745\n",
      "Epoch 80/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0364\n",
      "Learning rate after epoch 79 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0564 - val_loss: 0.0065 - val_mae: 0.0748\n",
      "Epoch 81/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2642e-04 - mae: 0.0170\n",
      "Learning rate after epoch 80 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0050 - val_mae: 0.0621\n",
      "Epoch 82/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0473\n",
      "Learning rate after epoch 81 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0496 - val_loss: 0.0050 - val_mae: 0.0630\n",
      "Epoch 83/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0668\n",
      "Learning rate after epoch 82 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 84/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0756\n",
      "Learning rate after epoch 83 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0438 - val_loss: 0.0148 - val_mae: 0.1075\n",
      "Epoch 85/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0435\n",
      "Learning rate after epoch 84 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0451 - val_loss: 0.0175 - val_mae: 0.1256\n",
      "Epoch 86/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0327\n",
      "Learning rate after epoch 85 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0455 - val_loss: 0.0107 - val_mae: 0.0977\n",
      "Epoch 87/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0259\n",
      "Learning rate after epoch 86 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0508 - val_loss: 0.0202 - val_mae: 0.1377\n",
      "Epoch 88/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0400\n",
      "Learning rate after epoch 87 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 0.0031 - val_mae: 0.0472\n",
      "Epoch 89/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0293\n",
      "Learning rate after epoch 88 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0593 - val_loss: 0.0372 - val_mae: 0.1843\n",
      "Epoch 90/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0583\n",
      "Learning rate after epoch 89 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0484 - val_loss: 0.0563 - val_mae: 0.2357\n",
      "Epoch 91/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0311\n",
      "Learning rate after epoch 90 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0596 - val_mae: 0.2428\n",
      "Epoch 92/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0800\n",
      "Learning rate after epoch 91 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0726 - val_mae: 0.2665\n",
      "Epoch 93/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0647\n",
      "Learning rate after epoch 92 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0618 - val_mae: 0.2374\n",
      "Epoch 94/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.6936e-04 - mae: 0.0212\n",
      "Learning rate after epoch 93 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0565 - val_loss: 0.0477 - val_mae: 0.2109\n",
      "Epoch 95/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0423\n",
      "Learning rate after epoch 94 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0439 - val_loss: 0.0304 - val_mae: 0.1617\n",
      "Epoch 96/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0292\n",
      "Learning rate after epoch 95 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0450 - val_loss: 0.0428 - val_mae: 0.1975\n",
      "Epoch 97/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0870\n",
      "Learning rate after epoch 96 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0399 - val_mae: 0.1910\n",
      "Epoch 98/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0347\n",
      "Learning rate after epoch 97 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0414 - val_loss: 0.0488 - val_mae: 0.2138\n",
      "Epoch 99/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0244\n",
      "Learning rate after epoch 98 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0550 - val_loss: 0.0202 - val_mae: 0.1377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0533\n",
      "Learning rate after epoch 99 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0398 - val_loss: 0.0275 - val_mae: 0.1587\n",
      "Epoch 101/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0144 - mae: 0.1148\n",
      "Learning rate after epoch 100 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "Epoch 102/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0394\n",
      "Learning rate after epoch 101 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0461 - val_loss: 0.0194 - val_mae: 0.1334\n",
      "Epoch 103/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0585\n",
      "Learning rate after epoch 102 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0165 - val_mae: 0.1200\n",
      "Epoch 104/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0271\n",
      "Learning rate after epoch 103 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0465 - val_loss: 0.0054 - val_mae: 0.0679\n",
      "Epoch 105/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0272\n",
      "Learning rate after epoch 104 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0450 - val_loss: 0.0038 - val_mae: 0.0560\n",
      "Epoch 106/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0514\n",
      "Learning rate after epoch 105 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0056 - val_mae: 0.0628\n",
      "Epoch 107/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9945e-04 - mae: 0.0232\n",
      "Learning rate after epoch 106 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0494 - val_loss: 0.0106 - val_mae: 0.0972\n",
      "Epoch 108/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0340\n",
      "Learning rate after epoch 107 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0423 - val_loss: 0.0045 - val_mae: 0.0604\n",
      "Epoch 109/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0916\n",
      "Learning rate after epoch 108 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 7.7006e-04 - val_mae: 0.0234\n",
      "Epoch 110/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0411\n",
      "Learning rate after epoch 109 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0467 - val_loss: 0.0064 - val_mae: 0.0655\n",
      "Epoch 111/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0313\n",
      "Learning rate after epoch 110 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.0125 - val_mae: 0.0861\n",
      "Epoch 112/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0269\n",
      "Learning rate after epoch 111 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0088 - val_mae: 0.0766\n",
      "Epoch 113/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0378\n",
      "Learning rate after epoch 112 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0545 - val_loss: 0.0044 - val_mae: 0.0559\n",
      "Epoch 114/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0825\n",
      "Learning rate after epoch 113 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0335\n",
      "Epoch 115/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0276\n",
      "Learning rate after epoch 114 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0032 - val_mae: 0.0523\n",
      "Epoch 116/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.8287e-04 - mae: 0.0195\n",
      "Learning rate after epoch 115 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0416 - val_loss: 0.0012 - val_mae: 0.0309\n",
      "Epoch 117/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0601\n",
      "Learning rate after epoch 116 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0516 - val_loss: 0.0119 - val_mae: 0.0788\n",
      "Epoch 118/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0527\n",
      "Learning rate after epoch 117 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0107 - val_mae: 0.0800\n",
      "Epoch 119/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0377\n",
      "Learning rate after epoch 118 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0091 - val_mae: 0.0882\n",
      "Epoch 120/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0537\n",
      "Learning rate after epoch 119 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0538 - val_loss: 0.0054 - val_mae: 0.0640\n",
      "Epoch 121/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0781\n",
      "Learning rate after epoch 120 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0013 - val_mae: 0.0266\n",
      "Epoch 122/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.1024e-04 - mae: 0.0208\n",
      "Learning rate after epoch 121 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0411 - val_loss: 0.0019 - val_mae: 0.0398\n",
      "Epoch 123/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0285\n",
      "Learning rate after epoch 122 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0446 - val_loss: 0.0060 - val_mae: 0.0692\n",
      "Epoch 124/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0226\n",
      "Learning rate after epoch 123 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0350 - val_loss: 0.0030 - val_mae: 0.0505\n",
      "Epoch 125/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.9994e-04 - mae: 0.0184\n",
      "Learning rate after epoch 124 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0022 - val_mae: 0.0312\n",
      "Epoch 126/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0768\n",
      "Learning rate after epoch 125 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0543 - val_loss: 0.0190 - val_mae: 0.1338\n",
      "Epoch 127/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0360\n",
      "Learning rate after epoch 126 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0252 - val_mae: 0.1208\n",
      "Epoch 128/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0443\n",
      "Learning rate after epoch 127 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0502 - val_loss: 0.0101 - val_mae: 0.0781\n",
      "Epoch 129/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0429\n",
      "Learning rate after epoch 128 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0043 - val_mae: 0.0473\n",
      "Epoch 130/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5375e-04 - mae: 0.0252\n",
      "Learning rate after epoch 129 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0026 - val_mae: 0.0309\n",
      "Epoch 131/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0323\n",
      "Learning rate after epoch 130 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0528 - val_loss: 0.0064 - val_mae: 0.0781\n",
      "Epoch 132/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0453\n",
      "Learning rate after epoch 131 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0460 - val_loss: 0.0163 - val_mae: 0.1127\n",
      "Epoch 133/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0481\n",
      "Learning rate after epoch 132 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0485 - val_loss: 0.0034 - val_mae: 0.0411\n",
      "Epoch 134/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0501\n",
      "Learning rate after epoch 133 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 135/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0502\n",
      "Learning rate after epoch 134 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0474 - val_loss: 9.9933e-04 - val_mae: 0.0213\n",
      "Epoch 136/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7718e-04 - mae: 0.0225\n",
      "Learning rate after epoch 135 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 137/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0325\n",
      "Learning rate after epoch 136 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0857 - val_mae: 0.2849\n",
      "Epoch 138/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0279\n",
      "Learning rate after epoch 137 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0468 - val_loss: 0.0519 - val_mae: 0.2226\n",
      "Epoch 139/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0418\n",
      "Learning rate after epoch 138 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0381 - val_loss: 0.0452 - val_mae: 0.2092\n",
      "Epoch 140/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0472\n",
      "Learning rate after epoch 139 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0450 - val_loss: 0.0299 - val_mae: 0.1658\n",
      "Epoch 141/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0418\n",
      "Learning rate after epoch 140 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0233 - val_mae: 0.1505\n",
      "Epoch 142/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0686\n",
      "Learning rate after epoch 141 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0340 - val_mae: 0.1818\n",
      "Epoch 143/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0277\n",
      "Learning rate after epoch 142 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 6.2516e-04 - val_mae: 0.0200\n",
      "Epoch 144/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0939\n",
      "Learning rate after epoch 143 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0529 - val_loss: 0.0077 - val_mae: 0.0774\n",
      "Epoch 145/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0067e-04 - mae: 0.0195\n",
      "Learning rate after epoch 144 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0460 - val_loss: 0.0017 - val_mae: 0.0365\n",
      "Epoch 146/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0310\n",
      "Learning rate after epoch 145 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0497 - val_loss: 0.0087 - val_mae: 0.0827\n",
      "Epoch 147/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0439\n",
      "Learning rate after epoch 146 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0672 - val_mae: 0.2565\n",
      "Epoch 148/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0415\n",
      "Learning rate after epoch 147 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0522 - val_loss: 0.0446 - val_mae: 0.2064\n",
      "Epoch 149/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0375\n",
      "Learning rate after epoch 148 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0448 - val_loss: 0.0601 - val_mae: 0.2349\n",
      "Epoch 150/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0491\n",
      "Learning rate after epoch 149 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0450 - val_loss: 0.0671 - val_mae: 0.2502\n",
      "Epoch 151/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0397\n",
      "Learning rate after epoch 150 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0538 - val_loss: 0.0276 - val_mae: 0.1630\n",
      "Epoch 152/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0422\n",
      "Learning rate after epoch 151 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0483 - val_loss: 0.0030 - val_mae: 0.0494\n",
      "Epoch 153/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0332\n",
      "Learning rate after epoch 152 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0507 - val_loss: 0.0029 - val_mae: 0.0487\n",
      "Epoch 154/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0651\n",
      "Learning rate after epoch 153 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0538 - val_loss: 0.0029 - val_mae: 0.0343\n",
      "Epoch 155/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0073 - mae: 0.0726\n",
      "Learning rate after epoch 154 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0330\n",
      "Epoch 156/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0306\n",
      "Learning rate after epoch 155 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0371 - val_loss: 0.0089 - val_mae: 0.0811\n",
      "Epoch 157/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0363\n",
      "Learning rate after epoch 156 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0040 - val_mae: 0.0589\n",
      "Epoch 158/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.3257e-04 - mae: 0.0270\n",
      "Learning rate after epoch 157 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0372 - val_loss: 0.0118 - val_mae: 0.0967\n",
      "Epoch 159/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0372\n",
      "Learning rate after epoch 158 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0521 - val_loss: 0.0086 - val_mae: 0.0893\n",
      "Epoch 160/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0425\n",
      "Learning rate after epoch 159 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0019 - val_mae: 0.0286\n",
      "Epoch 161/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0466\n",
      "Learning rate after epoch 160 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0516 - val_loss: 0.0110 - val_mae: 0.1027\n",
      "Epoch 162/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0347\n",
      "Learning rate after epoch 161 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0541 - val_loss: 6.8756e-04 - val_mae: 0.0192\n",
      "Epoch 163/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0301\n",
      "Learning rate after epoch 162 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0469 - val_loss: 0.0171 - val_mae: 0.1205\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0376\n",
      "Learning rate after epoch 163 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0515 - val_loss: 0.0017 - val_mae: 0.0392\n",
      "Epoch 165/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0504\n",
      "Learning rate after epoch 164 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0238 - val_mae: 0.1506\n",
      "Epoch 166/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0722\n",
      "Learning rate after epoch 165 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0442 - val_loss: 0.0236 - val_mae: 0.1507\n",
      "Epoch 167/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0378\n",
      "Learning rate after epoch 166 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0170 - val_mae: 0.1280\n",
      "Epoch 168/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4407e-04 - mae: 0.0249\n",
      "Learning rate after epoch 167 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0259 - val_mae: 0.1588\n",
      "Epoch 169/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0463\n",
      "Learning rate after epoch 168 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0470 - val_loss: 0.0119 - val_mae: 0.1028\n",
      "Epoch 170/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.1479e-04 - mae: 0.0203\n",
      "Learning rate after epoch 169 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0503 - val_loss: 0.0075 - val_mae: 0.0575\n",
      "Epoch 171/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0313\n",
      "Learning rate after epoch 170 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0448 - val_loss: 0.0086 - val_mae: 0.0709\n",
      "Epoch 172/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0377\n",
      "Learning rate after epoch 171 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0046 - val_mae: 0.0437\n",
      "Epoch 173/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0251\n",
      "Learning rate after epoch 172 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0425 - val_loss: 0.0088 - val_mae: 0.0844\n",
      "Epoch 174/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.7383e-04 - mae: 0.0252\n",
      "Learning rate after epoch 173 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0455 - val_loss: 0.0274 - val_mae: 0.1499\n",
      "Epoch 175/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.2741e-04 - mae: 0.0141\n",
      "Learning rate after epoch 174 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0133 - val_mae: 0.1031\n",
      "Epoch 176/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0722\n",
      "Learning rate after epoch 175 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0510 - val_loss: 0.0160 - val_mae: 0.1145\n",
      "Epoch 177/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0369\n",
      "Learning rate after epoch 176 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0381 - val_loss: 0.0045 - val_mae: 0.0553\n",
      "Epoch 178/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0343\n",
      "Learning rate after epoch 177 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0162 - val_mae: 0.1220\n",
      "Epoch 179/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.0858e-04 - mae: 0.0214\n",
      "Learning rate after epoch 178 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 0.0145 - val_mae: 0.1011\n",
      "Epoch 180/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0298\n",
      "Learning rate after epoch 179 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0420 - val_loss: 0.0093 - val_mae: 0.0868\n",
      "Epoch 181/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0279\n",
      "Learning rate after epoch 180 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 182/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0808\n",
      "Learning rate after epoch 181 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 0.0070 - val_mae: 0.0764\n",
      "Epoch 183/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0152 - mae: 0.1164\n",
      "Learning rate after epoch 182 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0550 - val_loss: 0.0212 - val_mae: 0.1302\n",
      "Epoch 184/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0296\n",
      "Learning rate after epoch 183 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0372 - val_loss: 0.0046 - val_mae: 0.0563\n",
      "Epoch 185/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0054 - mae: 0.0675\n",
      "Learning rate after epoch 184 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0105 - val_mae: 0.0953\n",
      "Epoch 186/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0734\n",
      "Learning rate after epoch 185 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0543 - val_loss: 0.0352 - val_mae: 0.1491\n",
      "Epoch 187/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.3076e-04 - mae: 0.0209\n",
      "Learning rate after epoch 186 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0521 - val_loss: 0.0411 - val_mae: 0.1619\n",
      "Epoch 188/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9449e-04 - mae: 0.0234\n",
      "Learning rate after epoch 187 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0511 - val_loss: 0.0389 - val_mae: 0.1765\n",
      "Epoch 189/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0390\n",
      "Learning rate after epoch 188 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0411 - val_mae: 0.1916\n",
      "Epoch 190/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0293\n",
      "Learning rate after epoch 189 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0528 - val_loss: 0.0538 - val_mae: 0.2212\n",
      "Epoch 191/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.4686e-04 - mae: 0.0192\n",
      "Learning rate after epoch 190 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0117 - val_mae: 0.0831\n",
      "Epoch 192/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0668\n",
      "Learning rate after epoch 191 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0594 - val_loss: 0.0401 - val_mae: 0.1989\n",
      "Epoch 193/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0383\n",
      "Learning rate after epoch 192 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0436 - val_loss: 0.0045 - val_mae: 0.0602\n",
      "Epoch 194/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0425\n",
      "Learning rate after epoch 193 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 9.7513e-04 - val_mae: 0.0257\n",
      "Epoch 195/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0268\n",
      "Learning rate after epoch 194 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0504 - val_loss: 0.0102 - val_mae: 0.0946\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0393\n",
      "Learning rate after epoch 195 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0508 - val_loss: 9.9375e-04 - val_mae: 0.0255\n",
      "Epoch 197/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0339\n",
      "Learning rate after epoch 196 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0482 - val_loss: 0.0052 - val_mae: 0.0703\n",
      "Epoch 198/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0343\n",
      "Learning rate after epoch 197 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0068 - val_mae: 0.0798\n",
      "Epoch 199/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.0250e-04 - mae: 0.0142\n",
      "Learning rate after epoch 198 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0379 - val_loss: 0.0048 - val_mae: 0.0458\n",
      "Epoch 200/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0559\n",
      "Learning rate after epoch 199 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0468 - val_loss: 0.0142 - val_mae: 0.1070\n",
      "Epoch 201/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0679\n",
      "Learning rate after epoch 200 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0166 - val_mae: 0.1117\n",
      "Epoch 202/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0621\n",
      "Learning rate after epoch 201 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0414 - val_loss: 0.0124 - val_mae: 0.0961\n",
      "Epoch 203/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0851\n",
      "Learning rate after epoch 202 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0503 - val_loss: 0.0025 - val_mae: 0.0394\n",
      "Epoch 204/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0808\n",
      "Learning rate after epoch 203 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0405 - val_loss: 0.0021 - val_mae: 0.0386\n",
      "Epoch 205/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0370\n",
      "Learning rate after epoch 204 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 9.7452e-04 - val_mae: 0.0258\n",
      "Epoch 206/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0283\n",
      "Learning rate after epoch 205 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0457 - val_loss: 0.0090 - val_mae: 0.0836\n",
      "Epoch 207/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0154 - mae: 0.1191\n",
      "Learning rate after epoch 206 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0061 - val_mae: 0.0716\n",
      "Epoch 208/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0704\n",
      "Learning rate after epoch 207 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0615 - val_loss: 0.0056 - val_mae: 0.0717\n",
      "Epoch 209/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0119 - mae: 0.1022\n",
      "Learning rate after epoch 208 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0046 - val_mae: 0.0614\n",
      "Epoch 210/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.2182e-04 - mae: 0.0156\n",
      "Learning rate after epoch 209 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0427 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 211/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0364\n",
      "Learning rate after epoch 210 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0075 - val_mae: 0.0762\n",
      "Epoch 212/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0277\n",
      "Learning rate after epoch 211 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 5.8083e-04 - val_mae: 0.0205\n",
      "Epoch 213/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0401\n",
      "Learning rate after epoch 212 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0037 - val_mae: 0.0578\n",
      "Epoch 214/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0394\n",
      "Learning rate after epoch 213 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0224 - val_mae: 0.1476\n",
      "Epoch 215/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0125 - mae: 0.1030\n",
      "Learning rate after epoch 214 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0493 - val_loss: 0.0226 - val_mae: 0.1482\n",
      "Epoch 216/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8281e-04 - mae: 0.0226\n",
      "Learning rate after epoch 215 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0168 - val_mae: 0.1288\n",
      "Epoch 217/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0600\n",
      "Learning rate after epoch 216 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0429 - val_loss: 0.0028 - val_mae: 0.0508\n",
      "Epoch 218/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0272\n",
      "Learning rate after epoch 217 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0377 - val_loss: 0.0051 - val_mae: 0.0681\n",
      "Epoch 219/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0431\n",
      "Learning rate after epoch 218 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0053 - val_mae: 0.0525\n",
      "Epoch 220/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0435\n",
      "Learning rate after epoch 219 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0448 - val_loss: 0.0155 - val_mae: 0.1191\n",
      "Epoch 221/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0684\n",
      "Learning rate after epoch 220 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0458 - val_loss: 0.0091 - val_mae: 0.0906\n",
      "Epoch 222/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0524\n",
      "Learning rate after epoch 221 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0428 - val_loss: 4.9501e-04 - val_mae: 0.0150\n",
      "Epoch 223/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0629\n",
      "Learning rate after epoch 222 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 224/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0435\n",
      "Learning rate after epoch 223 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0433 - val_loss: 0.0049 - val_mae: 0.0480\n",
      "Epoch 225/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0336\n",
      "Learning rate after epoch 224 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0454 - val_loss: 0.0041 - val_mae: 0.0452\n",
      "Epoch 226/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0588\n",
      "Learning rate after epoch 225 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 9.7786e-04 - val_mae: 0.0189\n",
      "Epoch 227/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.1704e-04 - mae: 0.0221\n",
      "Learning rate after epoch 226 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0494 - val_loss: 0.0024 - val_mae: 0.0346\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0396\n",
      "Learning rate after epoch 227 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0412\n",
      "Epoch 229/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0483\n",
      "Learning rate after epoch 228 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0448 - val_loss: 0.0048 - val_mae: 0.0608\n",
      "Epoch 230/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0426\n",
      "Learning rate after epoch 229 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0120 - val_mae: 0.1031\n",
      "Epoch 231/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0364\n",
      "Learning rate after epoch 230 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 0.0079 - val_mae: 0.0788\n",
      "Epoch 232/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0339\n",
      "Learning rate after epoch 231 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0015 - val_mae: 0.0247\n",
      "Epoch 233/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0746\n",
      "Learning rate after epoch 232 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0549 - val_loss: 0.0029 - val_mae: 0.0493\n",
      "Epoch 234/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0527\n",
      "Learning rate after epoch 233 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0556 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 235/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0948\n",
      "Learning rate after epoch 234 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0047 - val_mae: 0.0660\n",
      "Epoch 236/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0267\n",
      "Learning rate after epoch 235 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0034 - val_mae: 0.0520\n",
      "Epoch 237/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4503e-04 - mae: 0.0239\n",
      "Learning rate after epoch 236 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0482 - val_loss: 0.0015 - val_mae: 0.0341\n",
      "Epoch 238/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0284\n",
      "Learning rate after epoch 237 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0411 - val_loss: 5.1312e-04 - val_mae: 0.0149\n",
      "Epoch 239/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0649\n",
      "Learning rate after epoch 238 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0437 - val_loss: 0.0012 - val_mae: 0.0313\n",
      "Epoch 240/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0356\n",
      "Learning rate after epoch 239 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0013 - val_mae: 0.0340\n",
      "Epoch 241/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0302\n",
      "Learning rate after epoch 240 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0427 - val_loss: 0.0013 - val_mae: 0.0262\n",
      "Epoch 242/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0894\n",
      "Learning rate after epoch 241 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0084 - val_mae: 0.0833\n",
      "Epoch 243/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0329\n",
      "Learning rate after epoch 242 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0024 - val_mae: 0.0469\n",
      "Epoch 244/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.0464e-04 - mae: 0.0223\n",
      "Learning rate after epoch 243 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0444 - val_loss: 4.9271e-04 - val_mae: 0.0160\n",
      "Epoch 245/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0124 - mae: 0.1077\n",
      "Learning rate after epoch 244 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0535 - val_loss: 0.0014 - val_mae: 0.0331\n",
      "Epoch 246/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0887\n",
      "Learning rate after epoch 245 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 9.3292e-04 - val_mae: 0.0268\n",
      "Epoch 247/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0488\n",
      "Learning rate after epoch 246 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0471 - val_loss: 0.0023 - val_mae: 0.0313\n",
      "Epoch 248/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0514\n",
      "Learning rate after epoch 247 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0082 - val_mae: 0.0813\n",
      "Epoch 249/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0343\n",
      "Learning rate after epoch 248 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.0011 - val_mae: 0.0279\n",
      "Epoch 250/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.8140e-04 - mae: 0.0204\n",
      "Learning rate after epoch 249 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0074 - val_mae: 0.0746\n",
      "Epoch 251/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0280\n",
      "Learning rate after epoch 250 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0037 - val_mae: 0.0505\n",
      "Epoch 252/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0260\n",
      "Learning rate after epoch 251 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0376 - val_loss: 0.0059 - val_mae: 0.0669\n",
      "Epoch 253/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0584\n",
      "Learning rate after epoch 252 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0394 - val_loss: 0.0025 - val_mae: 0.0427\n",
      "Epoch 254/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0635\n",
      "Learning rate after epoch 253 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0382 - val_mae: 0.1814\n",
      "Epoch 255/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0717\n",
      "Learning rate after epoch 254 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0084 - val_mae: 0.0717\n",
      "Epoch 256/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0310\n",
      "Learning rate after epoch 255 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0359 - val_loss: 0.0039 - val_mae: 0.0598\n",
      "Epoch 257/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0262\n",
      "Learning rate after epoch 256 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0018 - val_mae: 0.0405\n",
      "Epoch 258/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0515\n",
      "Learning rate after epoch 257 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0383 - val_loss: 0.0079 - val_mae: 0.0859\n",
      "Epoch 259/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0273\n",
      "Learning rate after epoch 258 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0490 - val_loss: 0.0059 - val_mae: 0.0715\n",
      "Epoch 260/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.1007\n",
      "Learning rate after epoch 259 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0500 - val_loss: 0.0039 - val_mae: 0.0425\n",
      "Epoch 261/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.7949e-04 - mae: 0.0160\n",
      "Learning rate after epoch 260 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0074 - val_mae: 0.0724\n",
      "Epoch 262/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.8260e-04 - mae: 0.0213\n",
      "Learning rate after epoch 261 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0050 - val_mae: 0.0560\n",
      "Epoch 263/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0637\n",
      "Learning rate after epoch 262 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 0.0033 - val_mae: 0.0546\n",
      "Epoch 264/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0708\n",
      "Learning rate after epoch 263 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0513 - val_loss: 0.0025 - val_mae: 0.0381\n",
      "Epoch 265/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0369\n",
      "Learning rate after epoch 264 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0502 - val_loss: 0.0051 - val_mae: 0.0511\n",
      "Epoch 266/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0349\n",
      "Learning rate after epoch 265 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0429 - val_loss: 0.0038 - val_mae: 0.0585\n",
      "Epoch 267/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0491\n",
      "Learning rate after epoch 266 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0580 - val_loss: 0.0030 - val_mae: 0.0443\n",
      "Epoch 268/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0460\n",
      "Learning rate after epoch 267 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 269/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0374\n",
      "Learning rate after epoch 268 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0565 - val_loss: 0.0017 - val_mae: 0.0384\n",
      "Epoch 270/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0370\n",
      "Learning rate after epoch 269 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 271/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0071 - mae: 0.0781\n",
      "Learning rate after epoch 270 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0489 - val_loss: 8.5987e-04 - val_mae: 0.0263\n",
      "Epoch 272/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0606\n",
      "Learning rate after epoch 271 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0476 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 273/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0772\n",
      "Learning rate after epoch 272 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0353 - val_loss: 3.2405e-04 - val_mae: 0.0156\n",
      "Epoch 274/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0463\n",
      "Learning rate after epoch 273 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0396 - val_loss: 0.0025 - val_mae: 0.0465\n",
      "Epoch 275/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0247\n",
      "Learning rate after epoch 274 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0452 - val_loss: 0.0012 - val_mae: 0.0320\n",
      "Epoch 276/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0511\n",
      "Learning rate after epoch 275 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0386\n",
      "Epoch 277/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0375\n",
      "Learning rate after epoch 276 is 0.0100\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0459 - val_loss: 0.0010 - val_mae: 0.0224\n",
      "Epoch 278/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0746\n",
      "Learning rate after epoch 277 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0481 - val_loss: 0.0013 - val_mae: 0.0342\n",
      "Epoch 279/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0322\n",
      "Learning rate after epoch 278 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0020 - val_mae: 0.0286\n",
      "Epoch 280/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0515\n",
      "Learning rate after epoch 279 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0357 - val_loss: 0.0017 - val_mae: 0.0285\n",
      "Epoch 281/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0353\n",
      "Learning rate after epoch 280 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0375\n",
      "Epoch 282/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0721\n",
      "Learning rate after epoch 281 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0521 - val_loss: 0.0023 - val_mae: 0.0453\n",
      "Epoch 283/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0268\n",
      "Learning rate after epoch 282 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 5.0126e-04 - val_mae: 0.0196\n",
      "Epoch 284/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0439\n",
      "Learning rate after epoch 283 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0427 - val_loss: 0.0029 - val_mae: 0.0377\n",
      "Epoch 285/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0396\n",
      "Learning rate after epoch 284 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0435 - val_loss: 0.0024 - val_mae: 0.0426\n",
      "Epoch 286/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0376\n",
      "Learning rate after epoch 285 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0380 - val_loss: 0.0053 - val_mae: 0.0626\n",
      "Epoch 287/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0424\n",
      "Learning rate after epoch 286 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0495 - val_loss: 0.0060 - val_mae: 0.0725\n",
      "Epoch 288/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9807e-04 - mae: 0.0243\n",
      "Learning rate after epoch 287 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0338 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 289/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0554\n",
      "Learning rate after epoch 288 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0472 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 290/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0298\n",
      "Learning rate after epoch 289 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0381\n",
      "Epoch 291/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.3485e-04 - mae: 0.0150\n",
      "Learning rate after epoch 290 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0015 - val_mae: 0.0278\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0339\n",
      "Learning rate after epoch 291 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0015 - val_mae: 0.0332\n",
      "Epoch 293/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0364\n",
      "Learning rate after epoch 292 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0380 - val_loss: 0.0026 - val_mae: 0.0346\n",
      "Epoch 294/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0482\n",
      "Learning rate after epoch 293 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0427 - val_loss: 0.0014 - val_mae: 0.0244\n",
      "Epoch 295/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0414\n",
      "Learning rate after epoch 294 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0460 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 296/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0322\n",
      "Learning rate after epoch 295 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0508 - val_loss: 0.0066 - val_mae: 0.0751\n",
      "Epoch 297/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3705e-04 - mae: 0.0164\n",
      "Learning rate after epoch 296 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0099 - val_mae: 0.0887\n",
      "Epoch 298/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0732\n",
      "Learning rate after epoch 297 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0142 - val_mae: 0.1113\n",
      "Epoch 299/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0494\n",
      "Learning rate after epoch 298 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0412 - val_loss: 0.0077 - val_mae: 0.0845\n",
      "Epoch 300/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0284\n",
      "Learning rate after epoch 299 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 301/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0099 - mae: 0.0946\n",
      "Learning rate after epoch 300 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0057 - val_mae: 0.0703\n",
      "Epoch 302/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6658e-04 - mae: 0.0226\n",
      "Learning rate after epoch 301 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0410 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 303/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0331\n",
      "Learning rate after epoch 302 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0038 - val_mae: 0.0597\n",
      "Epoch 304/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5726e-04 - mae: 0.0266\n",
      "Learning rate after epoch 303 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0044 - val_mae: 0.0642\n",
      "Epoch 305/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0386\n",
      "Learning rate after epoch 304 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0059 - val_mae: 0.0742\n",
      "Epoch 306/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0460\n",
      "Learning rate after epoch 305 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0065 - val_mae: 0.0742\n",
      "Epoch 307/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0314\n",
      "Learning rate after epoch 306 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0382 - val_loss: 0.0084 - val_mae: 0.0887\n",
      "Epoch 308/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0429\n",
      "Learning rate after epoch 307 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0444 - val_loss: 0.0069 - val_mae: 0.0799\n",
      "Epoch 309/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.3185e-04 - mae: 0.0204\n",
      "Learning rate after epoch 308 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0416 - val_loss: 0.0067 - val_mae: 0.0724\n",
      "Epoch 310/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0280\n",
      "Learning rate after epoch 309 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0464 - val_loss: 0.0125 - val_mae: 0.1092\n",
      "Epoch 311/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0356\n",
      "Learning rate after epoch 310 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0054 - val_mae: 0.0699\n",
      "Epoch 312/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0264\n",
      "Learning rate after epoch 311 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0075 - val_mae: 0.0852\n",
      "Epoch 313/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0258\n",
      "Learning rate after epoch 312 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0441 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 314/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0287\n",
      "Learning rate after epoch 313 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0447 - val_loss: 0.0032 - val_mae: 0.0519\n",
      "Epoch 315/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0294\n",
      "Learning rate after epoch 314 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0375 - val_loss: 0.0040 - val_mae: 0.0557\n",
      "Epoch 316/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0401\n",
      "Learning rate after epoch 315 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0370 - val_loss: 0.0042 - val_mae: 0.0579\n",
      "Epoch 317/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0543\n",
      "Learning rate after epoch 316 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0357 - val_loss: 0.0021 - val_mae: 0.0341\n",
      "Epoch 318/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0264\n",
      "Learning rate after epoch 317 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0420 - val_loss: 0.0040 - val_mae: 0.0603\n",
      "Epoch 319/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0365\n",
      "Learning rate after epoch 318 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0419 - val_loss: 0.0021 - val_mae: 0.0369\n",
      "Epoch 320/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0731\n",
      "Learning rate after epoch 319 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0240\n",
      "Epoch 321/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0973e-04 - mae: 0.0242\n",
      "Learning rate after epoch 320 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 9.6458e-04 - val_mae: 0.0202\n",
      "Epoch 322/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.4908e-04 - mae: 0.0231\n",
      "Learning rate after epoch 321 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 7.1532e-04 - val_mae: 0.0187\n",
      "Epoch 323/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.9350e-04 - mae: 0.0155\n",
      "Learning rate after epoch 322 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0398 - val_loss: 0.0015 - val_mae: 0.0270\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0304\n",
      "Learning rate after epoch 323 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 325/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0573\n",
      "Learning rate after epoch 324 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0033 - val_mae: 0.0394\n",
      "Epoch 326/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0491\n",
      "Learning rate after epoch 325 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0386 - val_loss: 7.6465e-04 - val_mae: 0.0199\n",
      "Epoch 327/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0383\n",
      "Learning rate after epoch 326 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0416 - val_loss: 0.0032 - val_mae: 0.0475\n",
      "Epoch 328/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0321\n",
      "Learning rate after epoch 327 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0366 - val_loss: 0.0022 - val_mae: 0.0416\n",
      "Epoch 329/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0273\n",
      "Learning rate after epoch 328 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0406 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 330/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.0883e-04 - mae: 0.0154\n",
      "Learning rate after epoch 329 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0475 - val_loss: 8.1059e-04 - val_mae: 0.0247\n",
      "Epoch 331/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0345\n",
      "Learning rate after epoch 330 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0418 - val_loss: 0.0025 - val_mae: 0.0390\n",
      "Epoch 332/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.0350e-04 - mae: 0.0187\n",
      "Learning rate after epoch 331 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0525 - val_loss: 0.0011 - val_mae: 0.0280\n",
      "Epoch 333/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0675\n",
      "Learning rate after epoch 332 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0404 - val_loss: 0.0048 - val_mae: 0.0669\n",
      "Epoch 334/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0463\n",
      "Learning rate after epoch 333 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0445 - val_loss: 0.0025 - val_mae: 0.0458\n",
      "Epoch 335/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0739\n",
      "Learning rate after epoch 334 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0434 - val_loss: 0.0020 - val_mae: 0.0389\n",
      "Epoch 336/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.8631e-04 - mae: 0.0250\n",
      "Learning rate after epoch 335 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0452 - val_loss: 0.0031 - val_mae: 0.0454\n",
      "Epoch 337/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0720\n",
      "Learning rate after epoch 336 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0510 - val_loss: 7.4341e-04 - val_mae: 0.0164\n",
      "Epoch 338/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0293\n",
      "Learning rate after epoch 337 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0010 - val_mae: 0.0292\n",
      "Epoch 339/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0451\n",
      "Learning rate after epoch 338 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0484 - val_loss: 4.5936e-04 - val_mae: 0.0183\n",
      "Epoch 340/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0345\n",
      "Learning rate after epoch 339 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0387 - val_loss: 5.0627e-04 - val_mae: 0.0195\n",
      "Epoch 341/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0534\n",
      "Learning rate after epoch 340 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0015 - val_mae: 0.0363\n",
      "Epoch 342/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0295\n",
      "Learning rate after epoch 341 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0085 - val_mae: 0.0908\n",
      "Epoch 343/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8689e-04 - mae: 0.0229\n",
      "Learning rate after epoch 342 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0056 - val_mae: 0.0642\n",
      "Epoch 344/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.5439e-04 - mae: 0.0179\n",
      "Learning rate after epoch 343 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0490 - val_loss: 0.0045 - val_mae: 0.0638\n",
      "Epoch 345/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0426\n",
      "Learning rate after epoch 344 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0377 - val_loss: 0.0032 - val_mae: 0.0511\n",
      "Epoch 346/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.4314e-04 - mae: 0.0210\n",
      "Learning rate after epoch 345 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0042 - val_mae: 0.0584\n",
      "Epoch 347/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0771\n",
      "Learning rate after epoch 346 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0384 - val_loss: 0.0020 - val_mae: 0.0416\n",
      "Epoch 348/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.0943e-04 - mae: 0.0147\n",
      "Learning rate after epoch 347 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 8.3356e-04 - val_mae: 0.0258\n",
      "Epoch 349/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0387\n",
      "Learning rate after epoch 348 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 4.1029e-04 - val_mae: 0.0152\n",
      "Epoch 350/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0701\n",
      "Learning rate after epoch 349 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0016 - val_mae: 0.0366\n",
      "Epoch 351/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0272\n",
      "Learning rate after epoch 350 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0019 - val_mae: 0.0396\n",
      "Epoch 352/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0518\n",
      "Learning rate after epoch 351 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0535 - val_loss: 0.0157 - val_mae: 0.1183\n",
      "Epoch 353/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0678\n",
      "Learning rate after epoch 352 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0424 - val_loss: 0.0099 - val_mae: 0.0977\n",
      "Epoch 354/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0596\n",
      "Learning rate after epoch 353 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0153 - val_mae: 0.1211\n",
      "Epoch 355/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0533\n",
      "Learning rate after epoch 354 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0368 - val_loss: 0.0096 - val_mae: 0.0968\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 6.9929e-04 - mae: 0.0235\n",
      "Learning rate after epoch 355 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0062 - val_mae: 0.0739\n",
      "Epoch 357/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0618\n",
      "Learning rate after epoch 356 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0527 - val_loss: 0.0045 - val_mae: 0.0639\n",
      "Epoch 358/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0247\n",
      "Learning rate after epoch 357 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0031 - val_mae: 0.0527\n",
      "Epoch 359/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0292\n",
      "Learning rate after epoch 358 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0473 - val_loss: 8.1706e-04 - val_mae: 0.0196\n",
      "Epoch 360/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0308\n",
      "Learning rate after epoch 359 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0489 - val_loss: 4.2383e-04 - val_mae: 0.0155\n",
      "Epoch 361/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0369\n",
      "Learning rate after epoch 360 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0457 - val_loss: 0.0015 - val_mae: 0.0351\n",
      "Epoch 362/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0348\n",
      "Learning rate after epoch 361 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0433 - val_loss: 6.2511e-04 - val_mae: 0.0178\n",
      "Epoch 363/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3664e-04 - mae: 0.0219\n",
      "Learning rate after epoch 362 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0298 - val_loss: 8.4484e-04 - val_mae: 0.0203\n",
      "Epoch 364/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0453\n",
      "Learning rate after epoch 363 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0427 - val_loss: 0.0032 - val_mae: 0.0526\n",
      "Epoch 365/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0271\n",
      "Learning rate after epoch 364 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0463 - val_loss: 0.0041 - val_mae: 0.0605\n",
      "Epoch 366/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0741\n",
      "Learning rate after epoch 365 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0523 - val_loss: 0.0037 - val_mae: 0.0581\n",
      "Epoch 367/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0513\n",
      "Learning rate after epoch 366 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0568 - val_loss: 0.0059 - val_mae: 0.0727\n",
      "Epoch 368/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.7429e-04 - mae: 0.0245\n",
      "Learning rate after epoch 367 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0442 - val_loss: 0.0017 - val_mae: 0.0353\n",
      "Epoch 369/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0360\n",
      "Learning rate after epoch 368 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0029 - val_mae: 0.0364\n",
      "Epoch 370/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0364\n",
      "Learning rate after epoch 369 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0021 - val_mae: 0.0304\n",
      "Epoch 371/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0632\n",
      "Learning rate after epoch 370 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0499 - val_loss: 6.1096e-04 - val_mae: 0.0155\n",
      "Epoch 372/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0453\n",
      "Learning rate after epoch 371 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0409 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 373/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.2800e-04 - mae: 0.0217\n",
      "Learning rate after epoch 372 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 7.9300e-04 - val_mae: 0.0178\n",
      "Epoch 374/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0358\n",
      "Learning rate after epoch 373 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0461 - val_loss: 8.9170e-04 - val_mae: 0.0224\n",
      "Epoch 375/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.8843e-04 - mae: 0.0246\n",
      "Learning rate after epoch 374 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 9.9953e-04 - val_mae: 0.0254\n",
      "Epoch 376/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0442\n",
      "Learning rate after epoch 375 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0500 - val_loss: 0.0011 - val_mae: 0.0313\n",
      "Epoch 377/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.3986e-04 - mae: 0.0257\n",
      "Learning rate after epoch 376 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0521 - val_loss: 5.3699e-04 - val_mae: 0.0178\n",
      "Epoch 378/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.6973e-04 - mae: 0.0245\n",
      "Learning rate after epoch 377 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 0.0013 - val_mae: 0.0331\n",
      "Epoch 379/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0400\n",
      "Learning rate after epoch 378 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0028 - val_mae: 0.0489\n",
      "Epoch 380/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0606\n",
      "Learning rate after epoch 379 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0435 - val_loss: 5.7200e-04 - val_mae: 0.0176\n",
      "Epoch 381/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0385\n",
      "Learning rate after epoch 380 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 6.1786e-04 - val_mae: 0.0165\n",
      "Epoch 382/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0506\n",
      "Learning rate after epoch 381 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0451 - val_loss: 0.0032 - val_mae: 0.0460\n",
      "Epoch 383/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0177e-04 - mae: 0.0240\n",
      "Learning rate after epoch 382 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0386 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 384/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9026e-04 - mae: 0.0231\n",
      "Learning rate after epoch 383 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0329 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 385/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6097e-04 - mae: 0.0197\n",
      "Learning rate after epoch 384 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 386/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0352\n",
      "Learning rate after epoch 385 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0018 - val_mae: 0.0369\n",
      "Epoch 387/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0684\n",
      "Learning rate after epoch 386 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0470 - val_loss: 0.0071 - val_mae: 0.0820\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0390\n",
      "Learning rate after epoch 387 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0413 - val_loss: 4.8149e-04 - val_mae: 0.0173\n",
      "Epoch 389/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0263\n",
      "Learning rate after epoch 388 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0357 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 390/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0512\n",
      "Learning rate after epoch 389 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0463 - val_loss: 0.0032 - val_mae: 0.0520\n",
      "Epoch 391/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0391\n",
      "Learning rate after epoch 390 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0551\n",
      "Epoch 392/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0315\n",
      "Learning rate after epoch 391 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 9.7057e-04 - val_mae: 0.0194\n",
      "Epoch 393/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0305\n",
      "Learning rate after epoch 392 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0396 - val_loss: 2.0746e-04 - val_mae: 0.0087\n",
      "Epoch 394/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0293\n",
      "Learning rate after epoch 393 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0359 - val_loss: 0.0014 - val_mae: 0.0314\n",
      "Epoch 395/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0406\n",
      "Learning rate after epoch 394 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 396/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0386\n",
      "Learning rate after epoch 395 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 0.0016 - val_mae: 0.0328\n",
      "Epoch 397/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0560\n",
      "Learning rate after epoch 396 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 9.7101e-04 - val_mae: 0.0269\n",
      "Epoch 398/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0282\n",
      "Learning rate after epoch 397 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0471 - val_loss: 0.0021 - val_mae: 0.0406\n",
      "Epoch 399/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7538e-04 - mae: 0.0197\n",
      "Learning rate after epoch 398 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0485 - val_loss: 0.0015 - val_mae: 0.0285\n",
      "Epoch 400/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5830e-04 - mae: 0.0274\n",
      "Learning rate after epoch 399 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0455 - val_loss: 0.0037 - val_mae: 0.0562\n",
      "Epoch 401/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3142e-04 - mae: 0.0224\n",
      "Learning rate after epoch 400 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0520 - val_loss: 0.0048 - val_mae: 0.0582\n",
      "Epoch 402/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0360\n",
      "Learning rate after epoch 401 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0087 - val_mae: 0.0864\n",
      "Epoch 403/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0913\n",
      "Learning rate after epoch 402 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0411 - val_loss: 0.0044 - val_mae: 0.0630\n",
      "Epoch 404/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0511\n",
      "Learning rate after epoch 403 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0494 - val_loss: 0.0034 - val_mae: 0.0493\n",
      "Epoch 405/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0661\n",
      "Learning rate after epoch 404 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0486 - val_loss: 0.0015 - val_mae: 0.0324\n",
      "Epoch 406/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2298e-04 - mae: 0.0175\n",
      "Learning rate after epoch 405 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0408 - val_loss: 9.4946e-04 - val_mae: 0.0258\n",
      "Epoch 407/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0283\n",
      "Learning rate after epoch 406 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0391\n",
      "Epoch 408/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0336\n",
      "Learning rate after epoch 407 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0340 - val_loss: 0.0019 - val_mae: 0.0400\n",
      "Epoch 409/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0158 - mae: 0.1216\n",
      "Learning rate after epoch 408 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 6.3412e-04 - val_mae: 0.0207\n",
      "Epoch 410/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6045e-04 - mae: 0.0198\n",
      "Learning rate after epoch 409 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0337 - val_loss: 7.6873e-04 - val_mae: 0.0234\n",
      "Epoch 411/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0342\n",
      "Learning rate after epoch 410 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0038 - val_mae: 0.0551\n",
      "Epoch 412/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0562\n",
      "Learning rate after epoch 411 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0429 - val_loss: 0.0018 - val_mae: 0.0374\n",
      "Epoch 413/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.2476e-04 - mae: 0.0139\n",
      "Learning rate after epoch 412 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 9.0761e-04 - val_mae: 0.0234\n",
      "Epoch 414/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0657\n",
      "Learning rate after epoch 413 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0424 - val_loss: 8.1983e-04 - val_mae: 0.0197\n",
      "Epoch 415/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0390\n",
      "Learning rate after epoch 414 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0481 - val_loss: 0.0023 - val_mae: 0.0440\n",
      "Epoch 416/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0646\n",
      "Learning rate after epoch 415 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0016 - val_mae: 0.0340\n",
      "Epoch 417/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0646\n",
      "Learning rate after epoch 416 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0485 - val_loss: 7.3541e-04 - val_mae: 0.0248\n",
      "Epoch 418/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5723e-04 - mae: 0.0220\n",
      "Learning rate after epoch 417 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0015 - val_mae: 0.0233\n",
      "Epoch 419/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0280\n",
      "Learning rate after epoch 418 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0015 - val_mae: 0.0287\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0429\n",
      "Learning rate after epoch 419 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0023 - val_mae: 0.0316\n",
      "Epoch 421/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.7614e-04 - mae: 0.0283\n",
      "Learning rate after epoch 420 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0030 - val_mae: 0.0506\n",
      "Epoch 422/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0113 - mae: 0.1039\n",
      "Learning rate after epoch 421 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0048 - val_mae: 0.0626\n",
      "Epoch 423/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.6895e-04 - mae: 0.0201\n",
      "Learning rate after epoch 422 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0403 - val_loss: 0.0064 - val_mae: 0.0736\n",
      "Epoch 424/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0316\n",
      "Learning rate after epoch 423 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0358 - val_loss: 0.0064 - val_mae: 0.0724\n",
      "Epoch 425/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.2382e-04 - mae: 0.0226\n",
      "Learning rate after epoch 424 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0049 - val_mae: 0.0654\n",
      "Epoch 426/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0462\n",
      "Learning rate after epoch 425 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0055 - val_mae: 0.0696\n",
      "Epoch 427/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0578\n",
      "Learning rate after epoch 426 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0058 - val_mae: 0.0740\n",
      "Epoch 428/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0390\n",
      "Learning rate after epoch 427 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0440 - val_loss: 8.5642e-04 - val_mae: 0.0181\n",
      "Epoch 429/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0271\n",
      "Learning rate after epoch 428 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0327 - val_loss: 0.0014 - val_mae: 0.0260\n",
      "Epoch 430/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0289\n",
      "Learning rate after epoch 429 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0036 - val_mae: 0.0567\n",
      "Epoch 431/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.1535e-04 - mae: 0.0244\n",
      "Learning rate after epoch 430 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 0.0016 - val_mae: 0.0338\n",
      "Epoch 432/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0448\n",
      "Learning rate after epoch 431 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0013 - val_mae: 0.0213\n",
      "Epoch 433/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0351\n",
      "Learning rate after epoch 432 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0443 - val_loss: 0.0011 - val_mae: 0.0282\n",
      "Epoch 434/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0330\n",
      "Learning rate after epoch 433 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 8.2060e-04 - val_mae: 0.0191\n",
      "Epoch 435/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0369\n",
      "Learning rate after epoch 434 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 8.2043e-04 - val_mae: 0.0202\n",
      "Epoch 436/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0529\n",
      "Learning rate after epoch 435 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0416 - val_loss: 0.0037 - val_mae: 0.0562\n",
      "Epoch 437/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5588e-04 - mae: 0.0177\n",
      "Learning rate after epoch 436 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0466 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 438/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8035e-04 - mae: 0.0219\n",
      "Learning rate after epoch 437 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 6.5227e-04 - val_mae: 0.0149\n",
      "Epoch 439/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.8867e-04 - mae: 0.0203\n",
      "Learning rate after epoch 438 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0367 - val_loss: 6.3307e-04 - val_mae: 0.0138\n",
      "Epoch 440/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0520\n",
      "Learning rate after epoch 439 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0389 - val_loss: 0.0012 - val_mae: 0.0291\n",
      "Epoch 441/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0287\n",
      "Learning rate after epoch 440 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0012 - val_mae: 0.0299\n",
      "Epoch 442/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.2591e-04 - mae: 0.0243\n",
      "Learning rate after epoch 441 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0352 - val_loss: 0.0016 - val_mae: 0.0363\n",
      "Epoch 443/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0280\n",
      "Learning rate after epoch 442 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0525 - val_loss: 0.0025 - val_mae: 0.0364\n",
      "Epoch 444/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0310\n",
      "Learning rate after epoch 443 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0367 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 445/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0338\n",
      "Learning rate after epoch 444 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 6.6588e-04 - val_mae: 0.0193\n",
      "Epoch 446/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0515e-04 - mae: 0.0231\n",
      "Learning rate after epoch 445 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0347 - val_loss: 6.8745e-04 - val_mae: 0.0161\n",
      "Epoch 447/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0275\n",
      "Learning rate after epoch 446 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 448/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0578\n",
      "Learning rate after epoch 447 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 0.0014 - val_mae: 0.0246\n",
      "Epoch 449/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7036e-04 - mae: 0.0186\n",
      "Learning rate after epoch 448 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0437 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 450/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0401\n",
      "Learning rate after epoch 449 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0348 - val_loss: 8.1562e-04 - val_mae: 0.0231\n",
      "Epoch 451/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0619\n",
      "Learning rate after epoch 450 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0405\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0364\n",
      "Learning rate after epoch 451 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 9.9092e-04 - val_mae: 0.0262\n",
      "Epoch 453/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0411\n",
      "Learning rate after epoch 452 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0418 - val_loss: 4.6616e-04 - val_mae: 0.0174\n",
      "Epoch 454/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0389\n",
      "Learning rate after epoch 453 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0369 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 455/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0284\n",
      "Learning rate after epoch 454 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0030 - val_mae: 0.0513\n",
      "Epoch 456/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0319\n",
      "Learning rate after epoch 455 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0339\n",
      "Epoch 457/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.0171e-04 - mae: 0.0244\n",
      "Learning rate after epoch 456 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0045 - val_mae: 0.0610\n",
      "Epoch 458/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0339\n",
      "Learning rate after epoch 457 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0020 - val_mae: 0.0293\n",
      "Epoch 459/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0096 - mae: 0.0926\n",
      "Learning rate after epoch 458 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0527 - val_loss: 0.0056 - val_mae: 0.0698\n",
      "Epoch 460/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0443\n",
      "Learning rate after epoch 459 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0564 - val_loss: 0.0019 - val_mae: 0.0380\n",
      "Epoch 461/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2976e-04 - mae: 0.0197\n",
      "Learning rate after epoch 460 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 8.7545e-04 - val_mae: 0.0216\n",
      "Epoch 462/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0425\n",
      "Learning rate after epoch 461 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0417 - val_loss: 3.7014e-04 - val_mae: 0.0114\n",
      "Epoch 463/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0351\n",
      "Learning rate after epoch 462 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0405 - val_loss: 5.3234e-04 - val_mae: 0.0139\n",
      "Epoch 464/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0361\n",
      "Learning rate after epoch 463 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0540 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 465/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.5087e-04 - mae: 0.0194\n",
      "Learning rate after epoch 464 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 5.5746e-04 - val_mae: 0.0191\n",
      "Epoch 466/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0306\n",
      "Learning rate after epoch 465 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 5.6654e-04 - val_mae: 0.0128\n",
      "Epoch 467/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0340\n",
      "Learning rate after epoch 466 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 468/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0677\n",
      "Learning rate after epoch 467 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0375 - val_loss: 4.6611e-04 - val_mae: 0.0160\n",
      "Epoch 469/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.9018e-04 - mae: 0.0168\n",
      "Learning rate after epoch 468 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0423 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 470/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6974e-04 - mae: 0.0263\n",
      "Learning rate after epoch 469 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0478 - val_loss: 0.0072 - val_mae: 0.0765\n",
      "Epoch 471/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0091 - mae: 0.0815\n",
      "Learning rate after epoch 470 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0026 - val_mae: 0.0468\n",
      "Epoch 472/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0341\n",
      "Learning rate after epoch 471 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0484 - val_loss: 0.0018 - val_mae: 0.0297\n",
      "Epoch 473/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0292\n",
      "Learning rate after epoch 472 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 0.0014 - val_mae: 0.0315\n",
      "Epoch 474/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5944e-04 - mae: 0.0244\n",
      "Learning rate after epoch 473 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0340 - val_loss: 0.0015 - val_mae: 0.0259\n",
      "Epoch 475/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0318\n",
      "Learning rate after epoch 474 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0512 - val_loss: 0.0029 - val_mae: 0.0477\n",
      "Epoch 476/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0527\n",
      "Learning rate after epoch 475 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0431 - val_loss: 0.0022 - val_mae: 0.0292\n",
      "Epoch 477/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0643\n",
      "Learning rate after epoch 476 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0395 - val_loss: 4.8771e-04 - val_mae: 0.0179\n",
      "Epoch 478/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.6194e-04 - mae: 0.0179\n",
      "Learning rate after epoch 477 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0015 - val_mae: 0.0246\n",
      "Epoch 479/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0482\n",
      "Learning rate after epoch 478 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0022 - val_mae: 0.0417\n",
      "Epoch 480/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3192e-04 - mae: 0.0173\n",
      "Learning rate after epoch 479 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0464 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "Epoch 481/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0062 - mae: 0.0740\n",
      "Learning rate after epoch 480 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0013 - val_mae: 0.0299\n",
      "Epoch 482/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0432\n",
      "Learning rate after epoch 481 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0028 - val_mae: 0.0489\n",
      "Epoch 483/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0447\n",
      "Learning rate after epoch 482 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0374 - val_loss: 0.0015 - val_mae: 0.0349\n",
      "Epoch 484/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0867\n",
      "Learning rate after epoch 483 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0013 - val_mae: 0.0314\n",
      "Epoch 485/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0396\n",
      "Learning rate after epoch 484 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0478 - val_loss: 0.0024 - val_mae: 0.0437\n",
      "Epoch 486/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0621\n",
      "Learning rate after epoch 485 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0037 - val_mae: 0.0528\n",
      "Epoch 487/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0544\n",
      "Learning rate after epoch 486 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0334 - val_loss: 0.0019 - val_mae: 0.0300\n",
      "Epoch 488/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0161 - mae: 0.1185\n",
      "Learning rate after epoch 487 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0594 - val_loss: 0.0051 - val_mae: 0.0567\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0290\n",
      "Learning rate after epoch 488 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0022 - val_mae: 0.0306\n",
      "Epoch 490/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0440\n",
      "Learning rate after epoch 489 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0447 - val_loss: 0.0057 - val_mae: 0.0728\n",
      "Epoch 491/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0474\n",
      "Learning rate after epoch 490 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0514 - val_loss: 0.0050 - val_mae: 0.0661\n",
      "Epoch 492/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5710e-04 - mae: 0.0230\n",
      "Learning rate after epoch 491 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0405 - val_loss: 5.7158e-04 - val_mae: 0.0154\n",
      "Epoch 493/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4554e-04 - mae: 0.0230\n",
      "Learning rate after epoch 492 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0320 - val_loss: 0.0021 - val_mae: 0.0401\n",
      "Epoch 494/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5314e-04 - mae: 0.0182\n",
      "Learning rate after epoch 493 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0531 - val_loss: 8.5932e-04 - val_mae: 0.0204\n",
      "Epoch 495/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0676\n",
      "Learning rate after epoch 494 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0426 - val_loss: 6.7927e-04 - val_mae: 0.0201\n",
      "Epoch 496/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0518\n",
      "Learning rate after epoch 495 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0566 - val_loss: 5.1457e-04 - val_mae: 0.0189\n",
      "Epoch 497/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0268\n",
      "Learning rate after epoch 496 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0016 - val_mae: 0.0313\n",
      "Epoch 498/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0475\n",
      "Learning rate after epoch 497 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0385 - val_loss: 7.4259e-04 - val_mae: 0.0166\n",
      "Epoch 499/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.2521e-04 - mae: 0.0150\n",
      "Learning rate after epoch 498 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0024 - val_mae: 0.0450\n",
      "Epoch 500/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.7409e-04 - mae: 0.0174\n",
      "Learning rate after epoch 499 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0378 - val_loss: 3.5088e-04 - val_mae: 0.0134\n",
      "Epoch 501/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.9794e-04 - mae: 0.0201\n",
      "Learning rate after epoch 500 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0414 - val_loss: 6.5065e-04 - val_mae: 0.0156\n",
      "Epoch 502/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0263\n",
      "Learning rate after epoch 501 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0039 - val_mae: 0.0569\n",
      "Epoch 503/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0275\n",
      "Learning rate after epoch 502 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0453 - val_loss: 0.0046 - val_mae: 0.0582\n",
      "Epoch 504/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0321\n",
      "Learning rate after epoch 503 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0374\n",
      "Epoch 505/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0321\n",
      "Learning rate after epoch 504 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0411 - val_loss: 6.4267e-04 - val_mae: 0.0210\n",
      "Epoch 506/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0747\n",
      "Learning rate after epoch 505 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0028 - val_mae: 0.0438\n",
      "Epoch 507/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0758\n",
      "Learning rate after epoch 506 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0011 - val_mae: 0.0288\n",
      "Epoch 508/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0303\n",
      "Learning rate after epoch 507 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0012 - val_mae: 0.0212\n",
      "Epoch 509/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0595\n",
      "Learning rate after epoch 508 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 510/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0627\n",
      "Learning rate after epoch 509 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 511/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0266\n",
      "Learning rate after epoch 510 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0587 - val_loss: 0.0041 - val_mae: 0.0582\n",
      "Epoch 512/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0345\n",
      "Learning rate after epoch 511 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 513/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0761\n",
      "Learning rate after epoch 512 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0375 - val_loss: 0.0022 - val_mae: 0.0297\n",
      "Epoch 514/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0540\n",
      "Learning rate after epoch 513 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0358 - val_loss: 0.0014 - val_mae: 0.0244\n",
      "Epoch 515/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0070 - mae: 0.0804\n",
      "Learning rate after epoch 514 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0016 - val_mae: 0.0246\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 4.0280e-04 - mae: 0.0160\n",
      "Learning rate after epoch 515 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 517/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.1844e-04 - mae: 0.0233\n",
      "Learning rate after epoch 516 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0475 - val_loss: 7.3422e-04 - val_mae: 0.0182\n",
      "Epoch 518/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0446\n",
      "Learning rate after epoch 517 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0407 - val_loss: 0.0030 - val_mae: 0.0464\n",
      "Epoch 519/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.3407e-04 - mae: 0.0215\n",
      "Learning rate after epoch 518 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0373 - val_loss: 0.0044 - val_mae: 0.0543\n",
      "Epoch 520/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0466\n",
      "Learning rate after epoch 519 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0418 - val_loss: 0.0046 - val_mae: 0.0612\n",
      "Epoch 521/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2975e-04 - mae: 0.0185\n",
      "Learning rate after epoch 520 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0333 - val_loss: 0.0022 - val_mae: 0.0414\n",
      "Epoch 522/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0383\n",
      "Learning rate after epoch 521 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0410 - val_loss: 0.0015 - val_mae: 0.0333\n",
      "Epoch 523/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0344\n",
      "Learning rate after epoch 522 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0373 - val_loss: 0.0037 - val_mae: 0.0461\n",
      "Epoch 524/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8683e-04 - mae: 0.0248\n",
      "Learning rate after epoch 523 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0416 - val_loss: 0.0021 - val_mae: 0.0353\n",
      "Epoch 525/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0534\n",
      "Learning rate after epoch 524 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.0041 - val_mae: 0.0606\n",
      "Epoch 526/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0302\n",
      "Learning rate after epoch 525 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0033 - val_mae: 0.0478\n",
      "Epoch 527/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0766\n",
      "Learning rate after epoch 526 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0059 - val_mae: 0.0634\n",
      "Epoch 528/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0252 - mae: 0.1512\n",
      "Learning rate after epoch 527 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0601 - val_loss: 0.0037 - val_mae: 0.0537\n",
      "Epoch 529/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0439\n",
      "Learning rate after epoch 528 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0430 - val_loss: 8.9055e-04 - val_mae: 0.0199\n",
      "Epoch 530/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5079e-04 - mae: 0.0154\n",
      "Learning rate after epoch 529 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 531/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0542\n",
      "Learning rate after epoch 530 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0017 - val_mae: 0.0367\n",
      "Epoch 532/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0439\n",
      "Learning rate after epoch 531 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0444 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 533/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0395\n",
      "Learning rate after epoch 532 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0408 - val_loss: 9.8306e-04 - val_mae: 0.0241\n",
      "Epoch 534/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0359\n",
      "Learning rate after epoch 533 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0372 - val_loss: 0.0016 - val_mae: 0.0324\n",
      "Epoch 535/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0915\n",
      "Learning rate after epoch 534 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 3.6723e-04 - val_mae: 0.0135\n",
      "Epoch 536/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0186 - mae: 0.1315\n",
      "Learning rate after epoch 535 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0406 - val_loss: 4.8258e-04 - val_mae: 0.0136\n",
      "Epoch 537/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0322\n",
      "Learning rate after epoch 536 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0388 - val_loss: 6.6457e-04 - val_mae: 0.0163\n",
      "Epoch 538/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0270\n",
      "Learning rate after epoch 537 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0029 - val_mae: 0.0496\n",
      "Epoch 539/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0386\n",
      "Learning rate after epoch 538 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0498 - val_loss: 5.5023e-04 - val_mae: 0.0186\n",
      "Epoch 540/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0750\n",
      "Learning rate after epoch 539 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0457 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 541/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.1089\n",
      "Learning rate after epoch 540 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0432 - val_loss: 0.0048 - val_mae: 0.0623\n",
      "Epoch 542/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0357\n",
      "Learning rate after epoch 541 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0546\n",
      "Epoch 543/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0040 - mae: 0.0565\n",
      "Learning rate after epoch 542 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 9.2423e-04 - val_mae: 0.0278\n",
      "Epoch 544/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0780\n",
      "Learning rate after epoch 543 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0534 - val_loss: 8.7472e-04 - val_mae: 0.0212\n",
      "Epoch 545/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0578\n",
      "Learning rate after epoch 544 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0408 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 546/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0438\n",
      "Learning rate after epoch 545 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0359 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 547/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0352\n",
      "Learning rate after epoch 546 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0384 - val_loss: 0.0013 - val_mae: 0.0224\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0325\n",
      "Learning rate after epoch 547 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0393 - val_loss: 0.0031 - val_mae: 0.0513\n",
      "Epoch 549/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.3616e-04 - mae: 0.0156\n",
      "Learning rate after epoch 548 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0393 - val_loss: 0.0021 - val_mae: 0.0288\n",
      "Epoch 550/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0562\n",
      "Learning rate after epoch 549 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0362 - val_loss: 0.0027 - val_mae: 0.0442\n",
      "Epoch 551/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6903e-04 - mae: 0.0206\n",
      "Learning rate after epoch 550 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0021 - val_mae: 0.0416\n",
      "Epoch 552/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0292\n",
      "Learning rate after epoch 551 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0036 - val_mae: 0.0544\n",
      "Epoch 553/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0464\n",
      "Learning rate after epoch 552 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0482 - val_loss: 8.4474e-04 - val_mae: 0.0194\n",
      "Epoch 554/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0273\n",
      "Learning rate after epoch 553 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0363 - val_loss: 4.0956e-04 - val_mae: 0.0158\n",
      "Epoch 555/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.8623e-04 - mae: 0.0115\n",
      "Learning rate after epoch 554 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0294\n",
      "Epoch 556/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2753e-04 - mae: 0.0185\n",
      "Learning rate after epoch 555 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0434 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 557/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0817\n",
      "Learning rate after epoch 556 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 9.7614e-04 - val_mae: 0.0212\n",
      "Epoch 558/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0120 - mae: 0.1068\n",
      "Learning rate after epoch 557 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 559/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.0754e-04 - mae: 0.0165\n",
      "Learning rate after epoch 558 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0026 - val_mae: 0.0497\n",
      "Epoch 560/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0336\n",
      "Learning rate after epoch 559 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0378 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 561/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0324\n",
      "Learning rate after epoch 560 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0370 - val_loss: 0.0027 - val_mae: 0.0351\n",
      "Epoch 562/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0524\n",
      "Learning rate after epoch 561 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0360 - val_loss: 0.0021 - val_mae: 0.0397\n",
      "Epoch 563/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0258\n",
      "Learning rate after epoch 562 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0339 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 564/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0297\n",
      "Learning rate after epoch 563 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0447 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 565/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0286\n",
      "Learning rate after epoch 564 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 7.9724e-04 - val_mae: 0.0238\n",
      "Epoch 566/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0841\n",
      "Learning rate after epoch 565 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0478 - val_loss: 0.0042 - val_mae: 0.0637\n",
      "Epoch 567/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0438\n",
      "Learning rate after epoch 566 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0021 - val_mae: 0.0431\n",
      "Epoch 568/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0370\n",
      "Learning rate after epoch 567 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0377 - val_loss: 0.0016 - val_mae: 0.0368\n",
      "Epoch 569/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0336\n",
      "Learning rate after epoch 568 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0382 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 570/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0516\n",
      "Learning rate after epoch 569 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0351 - val_loss: 0.0043 - val_mae: 0.0563\n",
      "Epoch 571/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.4688e-04 - mae: 0.0241\n",
      "Learning rate after epoch 570 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0327 - val_loss: 0.0012 - val_mae: 0.0210\n",
      "Epoch 572/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0316\n",
      "Learning rate after epoch 571 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0033 - val_mae: 0.0523\n",
      "Epoch 573/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0725\n",
      "Learning rate after epoch 572 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0370 - val_loss: 0.0021 - val_mae: 0.0396\n",
      "Epoch 574/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0612\n",
      "Learning rate after epoch 573 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0416 - val_loss: 0.0037 - val_mae: 0.0549\n",
      "Epoch 575/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0253\n",
      "Learning rate after epoch 574 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0022 - val_mae: 0.0407\n",
      "Epoch 576/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0111 - mae: 0.1000\n",
      "Learning rate after epoch 575 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 0.0030 - val_mae: 0.0461\n",
      "Epoch 577/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.7098e-04 - mae: 0.0168\n",
      "Learning rate after epoch 576 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0377 - val_loss: 0.0016 - val_mae: 0.0311\n",
      "Epoch 578/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.8433e-04 - mae: 0.0222\n",
      "Learning rate after epoch 577 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 7.5240e-04 - val_mae: 0.0200\n",
      "Epoch 579/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0794e-04 - mae: 0.0173\n",
      "Learning rate after epoch 578 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 7.8920e-04 - val_mae: 0.0169\n",
      "Epoch 580/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3348e-04 - mae: 0.0236\n",
      "Learning rate after epoch 579 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0350 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 581/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.2527e-04 - mae: 0.0181\n",
      "Learning rate after epoch 580 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0336 - val_loss: 0.0031 - val_mae: 0.0521\n",
      "Epoch 582/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0701\n",
      "Learning rate after epoch 581 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 583/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0307\n",
      "Learning rate after epoch 582 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0413 - val_loss: 5.5985e-04 - val_mae: 0.0145\n",
      "Epoch 584/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4939e-04 - mae: 0.0263\n",
      "Learning rate after epoch 583 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0013 - val_mae: 0.0328\n",
      "Epoch 585/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0381\n",
      "Learning rate after epoch 584 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0011 - val_mae: 0.0305\n",
      "Epoch 586/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0131 - mae: 0.1125\n",
      "Learning rate after epoch 585 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 8.5083e-04 - val_mae: 0.0198\n",
      "Epoch 587/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.9226e-04 - mae: 0.0178\n",
      "Learning rate after epoch 586 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0360 - val_loss: 0.0013 - val_mae: 0.0233\n",
      "Epoch 588/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.6964e-04 - mae: 0.0211\n",
      "Learning rate after epoch 587 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0374 - val_loss: 0.0020 - val_mae: 0.0406\n",
      "Epoch 589/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0392\n",
      "Learning rate after epoch 588 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 8.9372e-04 - val_mae: 0.0242\n",
      "Epoch 590/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0423\n",
      "Learning rate after epoch 589 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0013 - val_mae: 0.0322\n",
      "Epoch 591/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0382\n",
      "Learning rate after epoch 590 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0357 - val_loss: 0.0021 - val_mae: 0.0427\n",
      "Epoch 592/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0523\n",
      "Learning rate after epoch 591 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0016 - val_mae: 0.0355\n",
      "Epoch 593/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.1187e-04 - mae: 0.0221\n",
      "Learning rate after epoch 592 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0441 - val_loss: 0.0028 - val_mae: 0.0408\n",
      "Epoch 594/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0283\n",
      "Learning rate after epoch 593 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0370 - val_loss: 6.8082e-04 - val_mae: 0.0196\n",
      "Epoch 595/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0271\n",
      "Learning rate after epoch 594 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 596/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0452\n",
      "Learning rate after epoch 595 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0023 - val_mae: 0.0368\n",
      "Epoch 597/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0484\n",
      "Learning rate after epoch 596 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0418 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 598/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.5275e-04 - mae: 0.0194\n",
      "Learning rate after epoch 597 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0354 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 599/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0304\n",
      "Learning rate after epoch 598 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0335 - val_loss: 0.0022 - val_mae: 0.0342\n",
      "Epoch 600/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8923e-04 - mae: 0.0222\n",
      "Learning rate after epoch 599 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0367 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 601/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0653\n",
      "Learning rate after epoch 600 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 4.7363e-04 - val_mae: 0.0141\n",
      "Epoch 602/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0302\n",
      "Learning rate after epoch 601 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0022 - val_mae: 0.0332\n",
      "Epoch 603/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0897\n",
      "Learning rate after epoch 602 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0527 - val_loss: 7.1630e-04 - val_mae: 0.0181\n",
      "Epoch 604/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3915e-04 - mae: 0.0218\n",
      "Learning rate after epoch 603 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0414 - val_loss: 6.2579e-04 - val_mae: 0.0184\n",
      "Epoch 605/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.8253e-04 - mae: 0.0231\n",
      "Learning rate after epoch 604 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0292\n",
      "Epoch 606/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0429\n",
      "Learning rate after epoch 605 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0404 - val_loss: 8.3537e-04 - val_mae: 0.0198\n",
      "Epoch 607/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0643\n",
      "Learning rate after epoch 606 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0416 - val_loss: 0.0019 - val_mae: 0.0291\n",
      "Epoch 608/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.1987e-04 - mae: 0.0172\n",
      "Learning rate after epoch 607 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0356 - val_loss: 0.0022 - val_mae: 0.0306\n",
      "Epoch 609/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0439\n",
      "Learning rate after epoch 608 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0021 - val_mae: 0.0421\n",
      "Epoch 610/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0427\n",
      "Learning rate after epoch 609 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0381 - val_loss: 0.0023 - val_mae: 0.0412\n",
      "Epoch 611/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0575\n",
      "Learning rate after epoch 610 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0420 - val_loss: 0.0018 - val_mae: 0.0386\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0295\n",
      "Learning rate after epoch 611 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0489 - val_loss: 0.0020 - val_mae: 0.0393\n",
      "Epoch 613/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0377\n",
      "Learning rate after epoch 612 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0446 - val_loss: 6.5294e-04 - val_mae: 0.0189\n",
      "Epoch 614/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0134 - mae: 0.1118\n",
      "Learning rate after epoch 613 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0518 - val_loss: 6.8997e-04 - val_mae: 0.0161\n",
      "Epoch 615/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.0246e-04 - mae: 0.0178\n",
      "Learning rate after epoch 614 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0029 - val_mae: 0.0452\n",
      "Epoch 616/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0444\n",
      "Learning rate after epoch 615 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0358 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 617/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.3796e-04 - mae: 0.0200\n",
      "Learning rate after epoch 616 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0023 - val_mae: 0.0435\n",
      "Epoch 618/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7653e-04 - mae: 0.0222\n",
      "Learning rate after epoch 617 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 8.3322e-04 - val_mae: 0.0207\n",
      "Epoch 619/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0376\n",
      "Learning rate after epoch 618 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 6.6747e-04 - val_mae: 0.0165\n",
      "Epoch 620/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0092 - mae: 0.0912\n",
      "Learning rate after epoch 619 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0505 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 621/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0222\n",
      "Learning rate after epoch 620 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 0.0039 - val_mae: 0.0539\n",
      "Epoch 622/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.1339e-04 - mae: 0.0242\n",
      "Learning rate after epoch 621 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0514 - val_loss: 5.3369e-04 - val_mae: 0.0157\n",
      "Epoch 623/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.0216e-04 - mae: 0.0234\n",
      "Learning rate after epoch 622 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0016 - val_mae: 0.0364\n",
      "Epoch 624/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.0463e-04 - mae: 0.0181\n",
      "Learning rate after epoch 623 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 5.8692e-04 - val_mae: 0.0151\n",
      "Epoch 625/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.8846e-04 - mae: 0.0154\n",
      "Learning rate after epoch 624 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0331 - val_loss: 0.0040 - val_mae: 0.0560\n",
      "Epoch 626/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0388\n",
      "Learning rate after epoch 625 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0017 - val_mae: 0.0252\n",
      "Epoch 627/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4762e-04 - mae: 0.0243\n",
      "Learning rate after epoch 626 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0361 - val_loss: 0.0020 - val_mae: 0.0274\n",
      "Epoch 628/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.1655e-04 - mae: 0.0141\n",
      "Learning rate after epoch 627 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 629/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.1444e-04 - mae: 0.0189\n",
      "Learning rate after epoch 628 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0424 - val_loss: 0.0031 - val_mae: 0.0519\n",
      "Epoch 630/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0457\n",
      "Learning rate after epoch 629 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0491 - val_loss: 0.0023 - val_mae: 0.0335\n",
      "Epoch 631/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.1045e-04 - mae: 0.0230\n",
      "Learning rate after epoch 630 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0371\n",
      "Epoch 632/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0345\n",
      "Learning rate after epoch 631 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0426 - val_loss: 7.6200e-04 - val_mae: 0.0189\n",
      "Epoch 633/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0060 - mae: 0.0705\n",
      "Learning rate after epoch 632 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0459 - val_loss: 2.5435e-04 - val_mae: 0.0093\n",
      "Epoch 634/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.1601e-04 - mae: 0.0246\n",
      "Learning rate after epoch 633 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0360 - val_loss: 0.0012 - val_mae: 0.0305\n",
      "Epoch 635/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0268\n",
      "Learning rate after epoch 634 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0440 - val_loss: 6.4642e-04 - val_mae: 0.0221\n",
      "Epoch 636/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0310\n",
      "Learning rate after epoch 635 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0029 - val_mae: 0.0460\n",
      "Epoch 637/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0379\n",
      "Learning rate after epoch 636 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0080 - val_mae: 0.0864\n",
      "Epoch 638/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0504\n",
      "Learning rate after epoch 637 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0021 - val_mae: 0.0400\n",
      "Epoch 639/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0330\n",
      "Learning rate after epoch 638 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0012 - val_mae: 0.0315\n",
      "Epoch 640/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0258\n",
      "Learning rate after epoch 639 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 641/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0285\n",
      "Learning rate after epoch 640 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0428 - val_loss: 0.0028 - val_mae: 0.0439\n",
      "Epoch 642/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0396\n",
      "Learning rate after epoch 641 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 6.1193e-04 - val_mae: 0.0177\n",
      "Epoch 643/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0518\n",
      "Learning rate after epoch 642 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 644/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0584\n",
      "Learning rate after epoch 643 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0347 - val_loss: 0.0011 - val_mae: 0.0278\n",
      "Epoch 645/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0441\n",
      "Learning rate after epoch 644 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 646/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6184e-04 - mae: 0.0207\n",
      "Learning rate after epoch 645 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0383 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 647/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0369\n",
      "Learning rate after epoch 646 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0362 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 648/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0348e-04 - mae: 0.0177\n",
      "Learning rate after epoch 647 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 0.0018 - val_mae: 0.0393\n",
      "Epoch 649/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0514\n",
      "Learning rate after epoch 648 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0439 - val_loss: 5.9633e-04 - val_mae: 0.0161\n",
      "Epoch 650/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0507e-04 - mae: 0.0187\n",
      "Learning rate after epoch 649 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0354 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 651/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0609\n",
      "Learning rate after epoch 650 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0010 - val_mae: 0.0253\n",
      "Epoch 652/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.5424e-04 - mae: 0.0172\n",
      "Learning rate after epoch 651 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 7.4338e-04 - val_mae: 0.0244\n",
      "Epoch 653/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0309\n",
      "Learning rate after epoch 652 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 6.3266e-04 - val_mae: 0.0157\n",
      "Epoch 654/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.5867e-04 - mae: 0.0197\n",
      "Learning rate after epoch 653 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0457 - val_loss: 9.6820e-04 - val_mae: 0.0264\n",
      "Epoch 655/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0339\n",
      "Learning rate after epoch 654 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0014 - val_mae: 0.0271\n",
      "Epoch 656/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0265\n",
      "Learning rate after epoch 655 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0369 - val_loss: 0.0013 - val_mae: 0.0278\n",
      "Epoch 657/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0280\n",
      "Learning rate after epoch 656 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0432 - val_loss: 0.0028 - val_mae: 0.0360\n",
      "Epoch 658/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.6656e-04 - mae: 0.0267\n",
      "Learning rate after epoch 657 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0417 - val_loss: 0.0079 - val_mae: 0.0833\n",
      "Epoch 659/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0534\n",
      "Learning rate after epoch 658 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0462 - val_loss: 0.0028 - val_mae: 0.0475\n",
      "Epoch 660/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0509\n",
      "Learning rate after epoch 659 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0465 - val_loss: 8.3675e-04 - val_mae: 0.0184\n",
      "Epoch 661/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0573\n",
      "Learning rate after epoch 660 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 662/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2181e-04 - mae: 0.0267\n",
      "Learning rate after epoch 661 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0358 - val_loss: 6.8648e-04 - val_mae: 0.0193\n",
      "Epoch 663/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.2223e-04 - mae: 0.0210\n",
      "Learning rate after epoch 662 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0350 - val_loss: 0.0022 - val_mae: 0.0294\n",
      "Epoch 664/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0065 - mae: 0.0774\n",
      "Learning rate after epoch 663 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0491 - val_loss: 0.0027 - val_mae: 0.0421\n",
      "Epoch 665/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0432\n",
      "Learning rate after epoch 664 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0034 - val_mae: 0.0440\n",
      "Epoch 666/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.4490e-04 - mae: 0.0155\n",
      "Learning rate after epoch 665 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0388 - val_loss: 0.0024 - val_mae: 0.0450\n",
      "Epoch 667/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8812e-04 - mae: 0.0239\n",
      "Learning rate after epoch 666 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0453 - val_loss: 0.0022 - val_mae: 0.0336\n",
      "Epoch 668/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5081e-04 - mae: 0.0217\n",
      "Learning rate after epoch 667 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0428 - val_loss: 0.0013 - val_mae: 0.0228\n",
      "Epoch 669/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.4473e-04 - mae: 0.0132\n",
      "Learning rate after epoch 668 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0486 - val_loss: 0.0043 - val_mae: 0.0609\n",
      "Epoch 670/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.4563e-04 - mae: 0.0277\n",
      "Learning rate after epoch 669 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0367 - val_loss: 8.3790e-04 - val_mae: 0.0206\n",
      "Epoch 671/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0502\n",
      "Learning rate after epoch 670 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0466 - val_loss: 0.0010 - val_mae: 0.0213\n",
      "Epoch 672/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0052 - mae: 0.0679\n",
      "Learning rate after epoch 671 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0351 - val_loss: 0.0022 - val_mae: 0.0445\n",
      "Epoch 673/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.7579e-04 - mae: 0.0208\n",
      "Learning rate after epoch 672 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0011 - val_mae: 0.0203\n",
      "Epoch 674/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0434\n",
      "Learning rate after epoch 673 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 675/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.2299e-04 - mae: 0.0133\n",
      "Learning rate after epoch 674 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 0.0014 - val_mae: 0.0312\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0506\n",
      "Learning rate after epoch 675 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0374 - val_loss: 0.0033 - val_mae: 0.0369\n",
      "Epoch 677/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0633\n",
      "Learning rate after epoch 676 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 678/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0337\n",
      "Learning rate after epoch 677 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 7.7171e-04 - val_mae: 0.0190\n",
      "Epoch 679/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0525\n",
      "Learning rate after epoch 678 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0441 - val_loss: 0.0019 - val_mae: 0.0400\n",
      "Epoch 680/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0319\n",
      "Learning rate after epoch 679 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 5.0082e-04 - val_mae: 0.0171\n",
      "Epoch 681/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0314\n",
      "Learning rate after epoch 680 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 682/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0538\n",
      "Learning rate after epoch 681 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0359 - val_loss: 0.0015 - val_mae: 0.0337\n",
      "Epoch 683/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0269\n",
      "Learning rate after epoch 682 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0360 - val_loss: 8.0703e-04 - val_mae: 0.0188\n",
      "Epoch 684/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2016e-04 - mae: 0.0234\n",
      "Learning rate after epoch 683 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0030 - val_mae: 0.0427\n",
      "Epoch 685/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0455\n",
      "Learning rate after epoch 684 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0020 - val_mae: 0.0282\n",
      "Epoch 686/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.6475e-04 - mae: 0.0170\n",
      "Learning rate after epoch 685 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0015 - val_mae: 0.0355\n",
      "Epoch 687/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.3806e-04 - mae: 0.0111\n",
      "Learning rate after epoch 686 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0462 - val_loss: 0.0030 - val_mae: 0.0513\n",
      "Epoch 688/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.5798e-04 - mae: 0.0198\n",
      "Learning rate after epoch 687 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0014 - val_mae: 0.0216\n",
      "Epoch 689/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7922e-04 - mae: 0.0229\n",
      "Learning rate after epoch 688 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0019 - val_mae: 0.0272\n",
      "Epoch 690/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.6868e-04 - mae: 0.0157\n",
      "Learning rate after epoch 689 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 691/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0542\n",
      "Learning rate after epoch 690 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0427 - val_loss: 3.1959e-04 - val_mae: 0.0149\n",
      "Epoch 692/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0377\n",
      "Learning rate after epoch 691 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0409 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 693/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.2193e-04 - mae: 0.0199\n",
      "Learning rate after epoch 692 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0427 - val_loss: 7.7314e-04 - val_mae: 0.0178\n",
      "Epoch 694/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0308\n",
      "Learning rate after epoch 693 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0362 - val_loss: 6.5111e-04 - val_mae: 0.0208\n",
      "Epoch 695/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0344\n",
      "Learning rate after epoch 694 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 7.3378e-04 - val_mae: 0.0220\n",
      "Epoch 696/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.4063e-04 - mae: 0.0121\n",
      "Learning rate after epoch 695 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0200\n",
      "Epoch 697/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.2237e-04 - mae: 0.0222\n",
      "Learning rate after epoch 696 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0301 - val_loss: 0.0014 - val_mae: 0.0335\n",
      "Epoch 698/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.3192e-04 - mae: 0.0212\n",
      "Learning rate after epoch 697 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0011 - val_mae: 0.0279\n",
      "Epoch 699/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.9973e-04 - mae: 0.0234\n",
      "Learning rate after epoch 698 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 0.0018 - val_mae: 0.0400\n",
      "Epoch 700/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0267\n",
      "Learning rate after epoch 699 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0352 - val_loss: 0.0013 - val_mae: 0.0329\n",
      "Epoch 701/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0055 - mae: 0.0696\n",
      "Learning rate after epoch 700 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 0.0017 - val_mae: 0.0372\n",
      "Epoch 702/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.3130e-04 - mae: 0.0254\n",
      "Learning rate after epoch 701 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0328 - val_loss: 0.0017 - val_mae: 0.0378\n",
      "Epoch 703/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0255\n",
      "Learning rate after epoch 702 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0025 - val_mae: 0.0433\n",
      "Epoch 704/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0449\n",
      "Learning rate after epoch 703 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0522 - val_loss: 0.0027 - val_mae: 0.0481\n",
      "Epoch 705/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0404\n",
      "Learning rate after epoch 704 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0351 - val_loss: 8.3720e-04 - val_mae: 0.0237\n",
      "Epoch 706/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8570e-04 - mae: 0.0228\n",
      "Learning rate after epoch 705 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0013 - val_mae: 0.0334\n",
      "Epoch 707/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5511e-04 - mae: 0.0171\n",
      "Learning rate after epoch 706 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 6.4023e-04 - val_mae: 0.0210\n",
      "Epoch 708/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0428\n",
      "Learning rate after epoch 707 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 709/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0050 - mae: 0.0636\n",
      "Learning rate after epoch 708 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0406 - val_loss: 8.6352e-04 - val_mae: 0.0195\n",
      "Epoch 710/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0253\n",
      "Learning rate after epoch 709 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0020 - val_mae: 0.0388\n",
      "Epoch 711/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0309\n",
      "Learning rate after epoch 710 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.0010 - val_mae: 0.0251\n",
      "Epoch 712/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.1876e-04 - mae: 0.0168\n",
      "Learning rate after epoch 711 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 713/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0307\n",
      "Learning rate after epoch 712 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0016 - val_mae: 0.0350\n",
      "Epoch 714/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0562\n",
      "Learning rate after epoch 713 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0395\n",
      "Epoch 715/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0397\n",
      "Learning rate after epoch 714 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0376 - val_loss: 0.0013 - val_mae: 0.0337\n",
      "Epoch 716/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0408\n",
      "Learning rate after epoch 715 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0614 - val_loss: 0.0100 - val_mae: 0.0950\n",
      "Epoch 717/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0606\n",
      "Learning rate after epoch 716 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0444 - val_loss: 0.0071 - val_mae: 0.0815\n",
      "Epoch 718/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0078 - mae: 0.0827\n",
      "Learning rate after epoch 717 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0443 - val_loss: 0.0035 - val_mae: 0.0536\n",
      "Epoch 719/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0368\n",
      "Learning rate after epoch 718 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0499 - val_loss: 0.0064 - val_mae: 0.0726\n",
      "Epoch 720/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0706\n",
      "Learning rate after epoch 719 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0027 - val_mae: 0.0362\n",
      "Epoch 721/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0415\n",
      "Learning rate after epoch 720 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0446 - val_loss: 0.0079 - val_mae: 0.0849\n",
      "Epoch 722/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0416\n",
      "Learning rate after epoch 721 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0148 - val_mae: 0.1148\n",
      "Epoch 723/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0252\n",
      "Learning rate after epoch 722 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0056 - val_mae: 0.0655\n",
      "Epoch 724/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.0912e-04 - mae: 0.0152\n",
      "Learning rate after epoch 723 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0443\n",
      "Epoch 725/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.9014e-04 - mae: 0.0194\n",
      "Learning rate after epoch 724 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0377 - val_loss: 8.6665e-04 - val_mae: 0.0249\n",
      "Epoch 726/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0403\n",
      "Learning rate after epoch 725 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0393 - val_loss: 0.0023 - val_mae: 0.0376\n",
      "Epoch 727/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0242\n",
      "Learning rate after epoch 726 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0015 - val_mae: 0.0243\n",
      "Epoch 728/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.3472e-04 - mae: 0.0226\n",
      "Learning rate after epoch 727 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0438 - val_loss: 0.0013 - val_mae: 0.0241\n",
      "Epoch 729/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0284\n",
      "Learning rate after epoch 728 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0347 - val_loss: 0.0019 - val_mae: 0.0269\n",
      "Epoch 730/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.6210e-04 - mae: 0.0218\n",
      "Learning rate after epoch 729 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0465 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 731/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0518\n",
      "Learning rate after epoch 730 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0011 - val_mae: 0.0277\n",
      "Epoch 732/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0336\n",
      "Learning rate after epoch 731 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0420 - val_loss: 0.0017 - val_mae: 0.0265\n",
      "Epoch 733/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.1759e-04 - mae: 0.0202\n",
      "Learning rate after epoch 732 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0506 - val_loss: 0.0013 - val_mae: 0.0206\n",
      "Epoch 734/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0346\n",
      "Learning rate after epoch 733 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0369 - val_loss: 0.0032 - val_mae: 0.0508\n",
      "Epoch 735/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0360\n",
      "Learning rate after epoch 734 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 0.0027 - val_mae: 0.0477\n",
      "Epoch 736/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5325e-04 - mae: 0.0232\n",
      "Learning rate after epoch 735 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0017 - val_mae: 0.0372\n",
      "Epoch 737/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.9365e-04 - mae: 0.0188\n",
      "Learning rate after epoch 736 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 738/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0322\n",
      "Learning rate after epoch 737 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0453 - val_loss: 0.0087 - val_mae: 0.0873\n",
      "Epoch 739/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0273\n",
      "Learning rate after epoch 738 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0446 - val_loss: 0.0069 - val_mae: 0.0794\n",
      "Epoch 740/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0396\n",
      "Learning rate after epoch 739 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0021 - val_mae: 0.0348\n",
      "Epoch 741/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0267\n",
      "Learning rate after epoch 740 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 742/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0292\n",
      "Learning rate after epoch 741 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0440 - val_loss: 6.1447e-04 - val_mae: 0.0188\n",
      "Epoch 743/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5787e-04 - mae: 0.0197\n",
      "Learning rate after epoch 742 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0422 - val_loss: 5.4184e-04 - val_mae: 0.0197\n",
      "Epoch 744/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0515\n",
      "Learning rate after epoch 743 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0021 - val_mae: 0.0404\n",
      "Epoch 745/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7904e-04 - mae: 0.0181\n",
      "Learning rate after epoch 744 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0327 - val_loss: 0.0015 - val_mae: 0.0355\n",
      "Epoch 746/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3744e-04 - mae: 0.0178\n",
      "Learning rate after epoch 745 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0333 - val_loss: 9.2649e-04 - val_mae: 0.0172\n",
      "Epoch 747/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.8965e-04 - mae: 0.0245\n",
      "Learning rate after epoch 746 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 748/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0435\n",
      "Learning rate after epoch 747 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0425 - val_loss: 8.2752e-04 - val_mae: 0.0226\n",
      "Epoch 749/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.0073e-04 - mae: 0.0138\n",
      "Learning rate after epoch 748 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0302\n",
      "Epoch 750/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0480\n",
      "Learning rate after epoch 749 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0021 - val_mae: 0.0424\n",
      "Epoch 751/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5656e-04 - mae: 0.0278\n",
      "Learning rate after epoch 750 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 752/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0432\n",
      "Learning rate after epoch 751 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0428 - val_loss: 0.0016 - val_mae: 0.0361\n",
      "Epoch 753/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5843e-04 - mae: 0.0201\n",
      "Learning rate after epoch 752 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0374 - val_loss: 5.7497e-04 - val_mae: 0.0160\n",
      "Epoch 754/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0274\n",
      "Learning rate after epoch 753 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0355 - val_loss: 0.0016 - val_mae: 0.0347\n",
      "Epoch 755/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0292\n",
      "Learning rate after epoch 754 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 7.4640e-04 - val_mae: 0.0230\n",
      "Epoch 756/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0145 - mae: 0.0885\n",
      "Learning rate after epoch 755 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0010 - val_mae: 0.0267\n",
      "Epoch 757/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0130 - mae: 0.1118\n",
      "Learning rate after epoch 756 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0499 - val_loss: 0.0024 - val_mae: 0.0403\n",
      "Epoch 758/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0517\n",
      "Learning rate after epoch 757 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0419 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 759/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9889e-04 - mae: 0.0239\n",
      "Learning rate after epoch 758 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0013 - val_mae: 0.0261\n",
      "Epoch 760/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0358\n",
      "Learning rate after epoch 759 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0374 - val_loss: 0.0021 - val_mae: 0.0422\n",
      "Epoch 761/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0770\n",
      "Learning rate after epoch 760 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0591 - val_loss: 0.0029 - val_mae: 0.0495\n",
      "Epoch 762/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0253\n",
      "Learning rate after epoch 761 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 7.4776e-04 - val_mae: 0.0206\n",
      "Epoch 763/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0878\n",
      "Learning rate after epoch 762 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0443 - val_loss: 0.0032 - val_mae: 0.0523\n",
      "Epoch 764/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9654e-04 - mae: 0.0248\n",
      "Learning rate after epoch 763 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0015 - val_mae: 0.0248\n",
      "Epoch 765/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0474\n",
      "Learning rate after epoch 764 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 0.0021 - val_mae: 0.0406\n",
      "Epoch 766/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.3464e-04 - mae: 0.0161\n",
      "Learning rate after epoch 765 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0017 - val_mae: 0.0368\n",
      "Epoch 767/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0599\n",
      "Learning rate after epoch 766 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0564 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 768/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0441\n",
      "Learning rate after epoch 767 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0428 - val_loss: 0.0018 - val_mae: 0.0383\n",
      "Epoch 769/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0579\n",
      "Learning rate after epoch 768 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0476 - val_loss: 8.6251e-04 - val_mae: 0.0224\n",
      "Epoch 770/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0464\n",
      "Learning rate after epoch 769 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0359 - val_loss: 6.8403e-04 - val_mae: 0.0173\n",
      "Epoch 771/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7387e-04 - mae: 0.0219\n",
      "Learning rate after epoch 770 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0409 - val_loss: 0.0017 - val_mae: 0.0375\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0457\n",
      "Learning rate after epoch 771 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0395 - val_loss: 0.0013 - val_mae: 0.0300\n",
      "Epoch 773/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0572\n",
      "Learning rate after epoch 772 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 0.0013 - val_mae: 0.0328\n",
      "Epoch 774/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0289\n",
      "Learning rate after epoch 773 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0340 - val_loss: 0.0027 - val_mae: 0.0488\n",
      "Epoch 775/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0811\n",
      "Learning rate after epoch 774 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0483 - val_loss: 0.0016 - val_mae: 0.0302\n",
      "Epoch 776/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6371e-04 - mae: 0.0208\n",
      "Learning rate after epoch 775 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0471 - val_loss: 0.0032 - val_mae: 0.0523\n",
      "Epoch 777/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0459\n",
      "Learning rate after epoch 776 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0418 - val_loss: 0.0029 - val_mae: 0.0451\n",
      "Epoch 778/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0379\n",
      "Learning rate after epoch 777 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0024 - val_mae: 0.0323\n",
      "Epoch 779/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0173 - mae: 0.1271\n",
      "Learning rate after epoch 778 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 6.7469e-04 - val_mae: 0.0155\n",
      "Epoch 780/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0292\n",
      "Learning rate after epoch 779 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0347 - val_loss: 0.0014 - val_mae: 0.0243\n",
      "Epoch 781/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0399\n",
      "Learning rate after epoch 780 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0041 - val_mae: 0.0544\n",
      "Epoch 782/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0624\n",
      "Learning rate after epoch 781 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0021 - val_mae: 0.0293\n",
      "Epoch 783/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.9398e-04 - mae: 0.0193\n",
      "Learning rate after epoch 782 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0031 - val_mae: 0.0387\n",
      "Epoch 784/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.2520e-04 - mae: 0.0225\n",
      "Learning rate after epoch 783 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0025 - val_mae: 0.0337\n",
      "Epoch 785/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0310\n",
      "Learning rate after epoch 784 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0018 - val_mae: 0.0279\n",
      "Epoch 786/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0269\n",
      "Learning rate after epoch 785 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0030 - val_mae: 0.0415\n",
      "Epoch 787/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0061 - mae: 0.0754\n",
      "Learning rate after epoch 786 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0018 - val_mae: 0.0383\n",
      "Epoch 788/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0392\n",
      "Learning rate after epoch 787 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0406 - val_loss: 8.1439e-04 - val_mae: 0.0221\n",
      "Epoch 789/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0348\n",
      "Learning rate after epoch 788 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0443 - val_loss: 9.2449e-04 - val_mae: 0.0235\n",
      "Epoch 790/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0346\n",
      "Learning rate after epoch 789 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0348 - val_loss: 5.5449e-04 - val_mae: 0.0180\n",
      "Epoch 791/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.9575e-04 - mae: 0.0223\n",
      "Learning rate after epoch 790 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0384 - val_loss: 9.7121e-04 - val_mae: 0.0248\n",
      "Epoch 792/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0090 - mae: 0.0928\n",
      "Learning rate after epoch 791 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0021 - val_mae: 0.0412\n",
      "Epoch 793/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.6499e-04 - mae: 0.0200\n",
      "Learning rate after epoch 792 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0022 - val_mae: 0.0417\n",
      "Epoch 794/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0557\n",
      "Learning rate after epoch 793 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0418 - val_loss: 0.0010 - val_mae: 0.0255\n",
      "Epoch 795/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0349\n",
      "Learning rate after epoch 794 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0018 - val_mae: 0.0272\n",
      "Epoch 796/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.9714e-04 - mae: 0.0267\n",
      "Learning rate after epoch 795 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0358 - val_loss: 0.0010 - val_mae: 0.0272\n",
      "Epoch 797/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5874e-04 - mae: 0.0162\n",
      "Learning rate after epoch 796 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 798/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0416\n",
      "Learning rate after epoch 797 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 799/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.9884e-04 - mae: 0.0145\n",
      "Learning rate after epoch 798 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0382 - val_loss: 0.0011 - val_mae: 0.0294\n",
      "Epoch 800/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0542\n",
      "Learning rate after epoch 799 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0016 - val_mae: 0.0259\n",
      "Epoch 801/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0278\n",
      "Learning rate after epoch 800 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0468 - val_loss: 6.8801e-04 - val_mae: 0.0174\n",
      "Epoch 802/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.8237e-04 - mae: 0.0285\n",
      "Learning rate after epoch 801 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 803/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0521\n",
      "Learning rate after epoch 802 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0359 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 804/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 7.8846e-04 - mae: 0.0240\n",
      "Learning rate after epoch 803 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0440 - val_loss: 0.0018 - val_mae: 0.0377\n",
      "Epoch 805/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0633\n",
      "Learning rate after epoch 804 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 806/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0504\n",
      "Learning rate after epoch 805 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0414 - val_loss: 0.0029 - val_mae: 0.0337\n",
      "Epoch 807/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0310\n",
      "Learning rate after epoch 806 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 808/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0293\n",
      "Learning rate after epoch 807 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0021 - val_mae: 0.0339\n",
      "Epoch 809/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.4405e-04 - mae: 0.0168\n",
      "Learning rate after epoch 808 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0020 - val_mae: 0.0344\n",
      "Epoch 810/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.2279e-04 - mae: 0.0218\n",
      "Learning rate after epoch 809 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0373 - val_loss: 0.0053 - val_mae: 0.0610\n",
      "Epoch 811/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0328\n",
      "Learning rate after epoch 810 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0022 - val_mae: 0.0338\n",
      "Epoch 812/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0497\n",
      "Learning rate after epoch 811 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0522 - val_loss: 8.9172e-04 - val_mae: 0.0250\n",
      "Epoch 813/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.1313e-04 - mae: 0.0186\n",
      "Learning rate after epoch 812 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0029 - val_mae: 0.0331\n",
      "Epoch 814/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0360\n",
      "Learning rate after epoch 813 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0407 - val_loss: 0.0011 - val_mae: 0.0281\n",
      "Epoch 815/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0307\n",
      "Learning rate after epoch 814 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0015 - val_mae: 0.0325\n",
      "Epoch 816/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0300\n",
      "Learning rate after epoch 815 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0283\n",
      "Epoch 817/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0360\n",
      "Learning rate after epoch 816 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 0.0015 - val_mae: 0.0226\n",
      "Epoch 818/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0483\n",
      "Learning rate after epoch 817 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0013 - val_mae: 0.0295\n",
      "Epoch 819/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0390\n",
      "Learning rate after epoch 818 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0383 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 820/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.1511e-04 - mae: 0.0214\n",
      "Learning rate after epoch 819 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0494 - val_loss: 0.0018 - val_mae: 0.0377\n",
      "Epoch 821/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0622\n",
      "Learning rate after epoch 820 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0426 - val_loss: 0.0022 - val_mae: 0.0426\n",
      "Epoch 822/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0290\n",
      "Learning rate after epoch 821 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0036 - val_mae: 0.0544\n",
      "Epoch 823/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3115e-04 - mae: 0.0176\n",
      "Learning rate after epoch 822 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0023 - val_mae: 0.0426\n",
      "Epoch 824/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0301\n",
      "Learning rate after epoch 823 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0342 - val_loss: 0.0020 - val_mae: 0.0397\n",
      "Epoch 825/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0313\n",
      "Learning rate after epoch 824 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0342 - val_loss: 8.5791e-04 - val_mae: 0.0222\n",
      "Epoch 826/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0558\n",
      "Learning rate after epoch 825 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0361 - val_loss: 0.0057 - val_mae: 0.0674\n",
      "Epoch 827/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0271\n",
      "Learning rate after epoch 826 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0040 - val_mae: 0.0511\n",
      "Epoch 828/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0043 - mae: 0.0585\n",
      "Learning rate after epoch 827 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0183\n",
      "Epoch 829/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0441\n",
      "Learning rate after epoch 828 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0271\n",
      "Epoch 830/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0435\n",
      "Learning rate after epoch 829 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0393 - val_loss: 0.0026 - val_mae: 0.0333\n",
      "Epoch 831/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.4969e-04 - mae: 0.0214\n",
      "Learning rate after epoch 830 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0339 - val_loss: 0.0011 - val_mae: 0.0268\n",
      "Epoch 832/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0355\n",
      "Learning rate after epoch 831 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0019 - val_mae: 0.0382\n",
      "Epoch 833/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0320\n",
      "Learning rate after epoch 832 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0015 - val_mae: 0.0336\n",
      "Epoch 834/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0341\n",
      "Learning rate after epoch 833 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0333 - val_loss: 0.0021 - val_mae: 0.0275\n",
      "Epoch 835/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.9464e-04 - mae: 0.0183\n",
      "Learning rate after epoch 834 is 0.0099\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0438 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0444\n",
      "Learning rate after epoch 835 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0018 - val_mae: 0.0363\n",
      "Epoch 837/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0284\n",
      "Learning rate after epoch 836 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0418 - val_loss: 0.0021 - val_mae: 0.0271\n",
      "Epoch 838/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.4021e-04 - mae: 0.0176\n",
      "Learning rate after epoch 837 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 839/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0036 - mae: 0.0502\n",
      "Learning rate after epoch 838 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0033 - val_mae: 0.0412\n",
      "Epoch 840/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7695e-04 - mae: 0.0226\n",
      "Learning rate after epoch 839 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0363 - val_loss: 0.0027 - val_mae: 0.0481\n",
      "Epoch 841/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0904e-04 - mae: 0.0238\n",
      "Learning rate after epoch 840 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 842/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0512\n",
      "Learning rate after epoch 841 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0399 - val_loss: 0.0020 - val_mae: 0.0402\n",
      "Epoch 843/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.8515e-04 - mae: 0.0211\n",
      "Learning rate after epoch 842 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0345 - val_loss: 0.0017 - val_mae: 0.0349\n",
      "Epoch 844/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6113e-04 - mae: 0.0215\n",
      "Learning rate after epoch 843 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0390 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 845/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0080 - mae: 0.0880\n",
      "Learning rate after epoch 844 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0011 - val_mae: 0.0302\n",
      "Epoch 846/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.1434e-04 - mae: 0.0219\n",
      "Learning rate after epoch 845 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0370 - val_loss: 8.2515e-04 - val_mae: 0.0250\n",
      "Epoch 847/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0253\n",
      "Learning rate after epoch 846 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0020 - val_mae: 0.0267\n",
      "Epoch 848/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0776\n",
      "Learning rate after epoch 847 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0020 - val_mae: 0.0307\n",
      "Epoch 849/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3844e-04 - mae: 0.0175\n",
      "Learning rate after epoch 848 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0017 - val_mae: 0.0356\n",
      "Epoch 850/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0577\n",
      "Learning rate after epoch 849 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0380 - val_loss: 0.0027 - val_mae: 0.0474\n",
      "Epoch 851/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0295\n",
      "Learning rate after epoch 850 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0373 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 852/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.4135e-04 - mae: 0.0191\n",
      "Learning rate after epoch 851 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0324 - val_loss: 0.0017 - val_mae: 0.0379\n",
      "Epoch 853/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0135 - mae: 0.1124\n",
      "Learning rate after epoch 852 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0501 - val_loss: 0.0017 - val_mae: 0.0276\n",
      "Epoch 854/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.6890e-04 - mae: 0.0275\n",
      "Learning rate after epoch 853 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 855/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0034 - mae: 0.0465\n",
      "Learning rate after epoch 854 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0371 - val_loss: 9.6305e-04 - val_mae: 0.0236\n",
      "Epoch 856/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0346\n",
      "Learning rate after epoch 855 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0298\n",
      "Epoch 857/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0037 - mae: 0.0563\n",
      "Learning rate after epoch 856 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0503 - val_loss: 0.0014 - val_mae: 0.0306\n",
      "Epoch 858/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0231e-04 - mae: 0.0194\n",
      "Learning rate after epoch 857 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0022 - val_mae: 0.0400\n",
      "Epoch 859/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0049 - mae: 0.0578\n",
      "Learning rate after epoch 858 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 7.0964e-04 - val_mae: 0.0187\n",
      "Epoch 860/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.7536e-04 - mae: 0.0194\n",
      "Learning rate after epoch 859 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 0.0021 - val_mae: 0.0381\n",
      "Epoch 861/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.7888e-04 - mae: 0.0145\n",
      "Learning rate after epoch 860 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0025 - val_mae: 0.0355\n",
      "Epoch 862/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0435\n",
      "Learning rate after epoch 861 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0379 - val_loss: 0.0024 - val_mae: 0.0411\n",
      "Epoch 863/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.1086e-04 - mae: 0.0186\n",
      "Learning rate after epoch 862 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0039 - val_mae: 0.0531\n",
      "Epoch 864/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.5563e-04 - mae: 0.0206\n",
      "Learning rate after epoch 863 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0109 - val_mae: 0.1013\n",
      "Epoch 865/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0572\n",
      "Learning rate after epoch 864 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0373 - val_loss: 0.0056 - val_mae: 0.0683\n",
      "Epoch 866/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0408\n",
      "Learning rate after epoch 865 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0429 - val_loss: 0.0026 - val_mae: 0.0393\n",
      "Epoch 867/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - mae: 0.0490\n",
      "Learning rate after epoch 866 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.0011 - val_mae: 0.0204\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 8.5024e-04 - mae: 0.0234\n",
      "Learning rate after epoch 867 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0371 - val_loss: 0.0020 - val_mae: 0.0275\n",
      "Epoch 869/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0385\n",
      "Learning rate after epoch 868 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0440 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 870/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.5919e-04 - mae: 0.0148\n",
      "Learning rate after epoch 869 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0352 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 871/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.6513e-04 - mae: 0.0165\n",
      "Learning rate after epoch 870 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0462 - val_loss: 0.0032 - val_mae: 0.0374\n",
      "Epoch 872/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0285\n",
      "Learning rate after epoch 871 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0416 - val_loss: 0.0029 - val_mae: 0.0478\n",
      "Epoch 873/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5770e-04 - mae: 0.0238\n",
      "Learning rate after epoch 872 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0472 - val_loss: 8.7412e-04 - val_mae: 0.0201\n",
      "Epoch 874/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0340\n",
      "Learning rate after epoch 873 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0195\n",
      "Epoch 875/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.3192e-04 - mae: 0.0198\n",
      "Learning rate after epoch 874 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 8.2837e-04 - val_mae: 0.0179\n",
      "Epoch 876/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0076 - mae: 0.0834\n",
      "Learning rate after epoch 875 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0415 - val_loss: 9.8847e-04 - val_mae: 0.0186\n",
      "Epoch 877/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.4430e-04 - mae: 0.0240\n",
      "Learning rate after epoch 876 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0418 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 878/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0320\n",
      "Learning rate after epoch 877 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0358 - val_loss: 0.0018 - val_mae: 0.0376\n",
      "Epoch 879/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.6563e-04 - mae: 0.0218\n",
      "Learning rate after epoch 878 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 7.0098e-04 - val_mae: 0.0177\n",
      "Epoch 880/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0477\n",
      "Learning rate after epoch 879 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0359 - val_loss: 0.0022 - val_mae: 0.0429\n",
      "Epoch 881/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0298\n",
      "Learning rate after epoch 880 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0010 - val_mae: 0.0180\n",
      "Epoch 882/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.6901e-04 - mae: 0.0188\n",
      "Learning rate after epoch 881 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0491 - val_loss: 0.0012 - val_mae: 0.0275\n",
      "Epoch 883/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0386\n",
      "Learning rate after epoch 882 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0365\n",
      "Epoch 884/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0323\n",
      "Learning rate after epoch 883 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 885/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0136 - mae: 0.1148\n",
      "Learning rate after epoch 884 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0461 - val_loss: 0.0016 - val_mae: 0.0326\n",
      "Epoch 886/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0366\n",
      "Learning rate after epoch 885 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0345 - val_loss: 0.0011 - val_mae: 0.0276\n",
      "Epoch 887/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.7279e-04 - mae: 0.0238\n",
      "Learning rate after epoch 886 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0463 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 888/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0314\n",
      "Learning rate after epoch 887 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 6.5087e-04 - val_mae: 0.0211\n",
      "Epoch 889/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0364\n",
      "Learning rate after epoch 888 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0343 - val_loss: 0.0010 - val_mae: 0.0265\n",
      "Epoch 890/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.6218e-04 - mae: 0.0205\n",
      "Learning rate after epoch 889 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0284 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 891/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0337\n",
      "Learning rate after epoch 890 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0271 - val_loss: 9.3718e-04 - val_mae: 0.0242\n",
      "Epoch 892/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0460\n",
      "Learning rate after epoch 891 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 6.8273e-04 - val_mae: 0.0206\n",
      "Epoch 893/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0255\n",
      "Learning rate after epoch 892 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 894/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0349\n",
      "Learning rate after epoch 893 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0467 - val_loss: 0.0016 - val_mae: 0.0367\n",
      "Epoch 895/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7619e-04 - mae: 0.0229\n",
      "Learning rate after epoch 894 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0015 - val_mae: 0.0351\n",
      "Epoch 896/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.7410e-04 - mae: 0.0192\n",
      "Learning rate after epoch 895 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0340\n",
      "Epoch 897/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.2681e-04 - mae: 0.0195\n",
      "Learning rate after epoch 896 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0370 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 898/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.6731e-04 - mae: 0.0219\n",
      "Learning rate after epoch 897 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0382 - val_loss: 0.0010 - val_mae: 0.0257\n",
      "Epoch 899/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0388e-04 - mae: 0.0252\n",
      "Learning rate after epoch 898 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0446 - val_loss: 0.0014 - val_mae: 0.0219\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 4.1243e-04 - mae: 0.0177\n",
      "Learning rate after epoch 899 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0012 - val_mae: 0.0224\n",
      "Epoch 901/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.1633e-04 - mae: 0.0261\n",
      "Learning rate after epoch 900 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 0.0021 - val_mae: 0.0429\n",
      "Epoch 902/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0398\n",
      "Learning rate after epoch 901 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0021 - val_mae: 0.0405\n",
      "Epoch 903/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0588\n",
      "Learning rate after epoch 902 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0433 - val_loss: 0.0016 - val_mae: 0.0355\n",
      "Epoch 904/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0432\n",
      "Learning rate after epoch 903 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0480 - val_loss: 0.0021 - val_mae: 0.0421\n",
      "Epoch 905/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0776\n",
      "Learning rate after epoch 904 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0360 - val_loss: 0.0011 - val_mae: 0.0293\n",
      "Epoch 906/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0743\n",
      "Learning rate after epoch 905 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 907/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0743\n",
      "Learning rate after epoch 906 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0019 - val_mae: 0.0407\n",
      "Epoch 908/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5548e-04 - mae: 0.0151\n",
      "Learning rate after epoch 907 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0012 - val_mae: 0.0197\n",
      "Epoch 909/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7352e-04 - mae: 0.0216\n",
      "Learning rate after epoch 908 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0347 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 910/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0026 - mae: 0.0479\n",
      "Learning rate after epoch 909 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0030 - val_mae: 0.0468\n",
      "Epoch 911/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.6526e-04 - mae: 0.0204\n",
      "Learning rate after epoch 910 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0358 - val_loss: 0.0032 - val_mae: 0.0490\n",
      "Epoch 912/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0340\n",
      "Learning rate after epoch 911 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0348 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 913/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0399\n",
      "Learning rate after epoch 912 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0427 - val_loss: 0.0029 - val_mae: 0.0438\n",
      "Epoch 914/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0502\n",
      "Learning rate after epoch 913 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0447 - val_loss: 0.0025 - val_mae: 0.0422\n",
      "Epoch 915/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0318\n",
      "Learning rate after epoch 914 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0510 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 916/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0379\n",
      "Learning rate after epoch 915 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0367 - val_loss: 0.0012 - val_mae: 0.0191\n",
      "Epoch 917/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.9113e-04 - mae: 0.0233\n",
      "Learning rate after epoch 916 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0016 - val_mae: 0.0248\n",
      "Epoch 918/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0053 - mae: 0.0697\n",
      "Learning rate after epoch 917 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0011 - val_mae: 0.0205\n",
      "Epoch 919/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.7691e-04 - mae: 0.0219\n",
      "Learning rate after epoch 918 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0370 - val_loss: 0.0017 - val_mae: 0.0355\n",
      "Epoch 920/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0345\n",
      "Learning rate after epoch 919 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0448 - val_loss: 0.0014 - val_mae: 0.0223\n",
      "Epoch 921/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.5606e-04 - mae: 0.0148\n",
      "Learning rate after epoch 920 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0016 - val_mae: 0.0373\n",
      "Epoch 922/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.5017e-04 - mae: 0.0212\n",
      "Learning rate after epoch 921 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 9.9361e-04 - val_mae: 0.0192\n",
      "Epoch 923/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0306\n",
      "Learning rate after epoch 922 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0017 - val_mae: 0.0382\n",
      "Epoch 924/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.6423e-04 - mae: 0.0185\n",
      "Learning rate after epoch 923 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0013 - val_mae: 0.0239\n",
      "Epoch 925/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0279\n",
      "Learning rate after epoch 924 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0376 - val_loss: 0.0010 - val_mae: 0.0247\n",
      "Epoch 926/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.3545e-04 - mae: 0.0120\n",
      "Learning rate after epoch 925 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0318 - val_loss: 0.0017 - val_mae: 0.0372\n",
      "Epoch 927/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0458\n",
      "Learning rate after epoch 926 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0425 - val_loss: 0.0014 - val_mae: 0.0325\n",
      "Epoch 928/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0652\n",
      "Learning rate after epoch 927 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0422 - val_loss: 0.0015 - val_mae: 0.0321\n",
      "Epoch 929/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.3846e-04 - mae: 0.0149\n",
      "Learning rate after epoch 928 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0017 - val_mae: 0.0371\n",
      "Epoch 930/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0380\n",
      "Learning rate after epoch 929 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.0016 - val_mae: 0.0354\n",
      "Epoch 931/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.1563e-04 - mae: 0.0117\n",
      "Learning rate after epoch 930 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0068 - val_mae: 0.0750\n",
      "Epoch 932/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0305\n",
      "Learning rate after epoch 931 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0047 - val_mae: 0.0639\n",
      "Epoch 933/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0374\n",
      "Learning rate after epoch 932 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0027 - val_mae: 0.0478\n",
      "Epoch 934/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0273\n",
      "Learning rate after epoch 933 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0354 - val_loss: 0.0016 - val_mae: 0.0369\n",
      "Epoch 935/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.9017e-04 - mae: 0.0238\n",
      "Learning rate after epoch 934 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0323 - val_loss: 0.0023 - val_mae: 0.0429\n",
      "Epoch 936/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.5327e-04 - mae: 0.0211\n",
      "Learning rate after epoch 935 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0036 - val_mae: 0.0557\n",
      "Epoch 937/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.0931e-04 - mae: 0.0231\n",
      "Learning rate after epoch 936 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0360 - val_loss: 0.0018 - val_mae: 0.0384\n",
      "Epoch 938/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0112 - mae: 0.1003\n",
      "Learning rate after epoch 937 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0019 - val_mae: 0.0259\n",
      "Epoch 939/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0473\n",
      "Learning rate after epoch 938 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 0.0025 - val_mae: 0.0448\n",
      "Epoch 940/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0314\n",
      "Learning rate after epoch 939 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0019 - val_mae: 0.0395\n",
      "Epoch 941/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0269\n",
      "Learning rate after epoch 940 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0364 - val_loss: 0.0015 - val_mae: 0.0352\n",
      "Epoch 942/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0285\n",
      "Learning rate after epoch 941 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0410 - val_loss: 0.0040 - val_mae: 0.0578\n",
      "Epoch 943/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0057 - mae: 0.0726\n",
      "Learning rate after epoch 942 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0483 - val_loss: 0.0015 - val_mae: 0.0319\n",
      "Epoch 944/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0039 - mae: 0.0548\n",
      "Learning rate after epoch 943 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0021 - val_mae: 0.0396\n",
      "Epoch 945/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0294\n",
      "Learning rate after epoch 944 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0351 - val_loss: 0.0018 - val_mae: 0.0370\n",
      "Epoch 946/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0623\n",
      "Learning rate after epoch 945 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0457 - val_loss: 0.0028 - val_mae: 0.0476\n",
      "Epoch 947/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0075 - mae: 0.0823\n",
      "Learning rate after epoch 946 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0015 - val_mae: 0.0303\n",
      "Epoch 948/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.8955e-04 - mae: 0.0286\n",
      "Learning rate after epoch 947 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 949/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.6751e-04 - mae: 0.0232\n",
      "Learning rate after epoch 948 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 8.9123e-04 - val_mae: 0.0243\n",
      "Epoch 950/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0271\n",
      "Learning rate after epoch 949 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0012 - val_mae: 0.0216\n",
      "Epoch 951/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7.2404e-04 - mae: 0.0214\n",
      "Learning rate after epoch 950 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0462 - val_loss: 0.0015 - val_mae: 0.0329\n",
      "Epoch 952/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.1056e-04 - mae: 0.0140\n",
      "Learning rate after epoch 951 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0381 - val_loss: 0.0030 - val_mae: 0.0505\n",
      "Epoch 953/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0321\n",
      "Learning rate after epoch 952 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0361 - val_loss: 0.0013 - val_mae: 0.0266\n",
      "Epoch 954/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0289\n",
      "Learning rate after epoch 953 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 8.9462e-04 - val_mae: 0.0164\n",
      "Epoch 955/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.3696e-04 - mae: 0.0163\n",
      "Learning rate after epoch 954 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0354 - val_loss: 0.0023 - val_mae: 0.0444\n",
      "Epoch 956/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0089 - mae: 0.0895\n",
      "Learning rate after epoch 955 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0496 - val_loss: 0.0017 - val_mae: 0.0250\n",
      "Epoch 957/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0139 - mae: 0.1160\n",
      "Learning rate after epoch 956 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0446 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 958/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7058e-04 - mae: 0.0211\n",
      "Learning rate after epoch 957 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0400 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 959/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.7454e-04 - mae: 0.0178\n",
      "Learning rate after epoch 958 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0337 - val_loss: 0.0024 - val_mae: 0.0384\n",
      "Epoch 960/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0286\n",
      "Learning rate after epoch 959 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 0.0046 - val_mae: 0.0575\n",
      "Epoch 961/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0507\n",
      "Learning rate after epoch 960 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0056 - val_mae: 0.0696\n",
      "Epoch 962/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0279\n",
      "Learning rate after epoch 961 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0306 - val_loss: 0.0029 - val_mae: 0.0428\n",
      "Epoch 963/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6.7416e-04 - mae: 0.0183\n",
      "Learning rate after epoch 962 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0348 - val_loss: 0.0064 - val_mae: 0.0738\n",
      "Epoch 964/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0072 - mae: 0.0819\n",
      "Learning rate after epoch 963 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0054 - val_mae: 0.0619\n",
      "Epoch 965/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0416\n",
      "Learning rate after epoch 964 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0023 - val_mae: 0.0370\n",
      "Epoch 966/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0429\n",
      "Learning rate after epoch 965 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0374 - val_loss: 0.0021 - val_mae: 0.0288\n",
      "Epoch 967/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0326\n",
      "Learning rate after epoch 966 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0363 - val_loss: 0.0021 - val_mae: 0.0373\n",
      "Epoch 968/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0377\n",
      "Learning rate after epoch 967 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0426 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 969/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0380\n",
      "Learning rate after epoch 968 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 970/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0310\n",
      "Learning rate after epoch 969 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0365 - val_loss: 0.0011 - val_mae: 0.0185\n",
      "Epoch 971/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0398\n",
      "Learning rate after epoch 970 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0034 - val_mae: 0.0452\n",
      "Epoch 972/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.2110e-04 - mae: 0.0169\n",
      "Learning rate after epoch 971 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0377 - val_loss: 0.0018 - val_mae: 0.0372\n",
      "Epoch 973/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0294\n",
      "Learning rate after epoch 972 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 974/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0786\n",
      "Learning rate after epoch 973 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 975/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.8893e-04 - mae: 0.0151\n",
      "Learning rate after epoch 974 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0013 - val_mae: 0.0326\n",
      "Epoch 976/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.3032e-04 - mae: 0.0189\n",
      "Learning rate after epoch 975 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0469 - val_loss: 0.0012 - val_mae: 0.0292\n",
      "Epoch 977/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0572\n",
      "Learning rate after epoch 976 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0012 - val_mae: 0.0300\n",
      "Epoch 978/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0628\n",
      "Learning rate after epoch 977 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 8.5710e-04 - val_mae: 0.0240\n",
      "Epoch 979/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0279\n",
      "Learning rate after epoch 978 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 9.7543e-04 - val_mae: 0.0254\n",
      "Epoch 980/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8.0917e-04 - mae: 0.0247\n",
      "Learning rate after epoch 979 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0292 - val_loss: 0.0015 - val_mae: 0.0248\n",
      "Epoch 981/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.0540e-04 - mae: 0.0185\n",
      "Learning rate after epoch 980 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0390 - val_loss: 0.0037 - val_mae: 0.0537\n",
      "Epoch 982/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0432\n",
      "Learning rate after epoch 981 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0371 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 983/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0388\n",
      "Learning rate after epoch 982 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0396\n",
      "Epoch 984/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0379\n",
      "Learning rate after epoch 983 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0478 - val_loss: 0.0018 - val_mae: 0.0386\n",
      "Epoch 985/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0568\n",
      "Learning rate after epoch 984 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 986/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0329\n",
      "Learning rate after epoch 985 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0337 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 987/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0596\n",
      "Learning rate after epoch 986 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 9.0520e-04 - val_mae: 0.0231\n",
      "Epoch 988/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - mae: 0.0331\n",
      "Learning rate after epoch 987 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0013 - val_mae: 0.0185\n",
      "Epoch 989/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - mae: 0.0328\n",
      "Learning rate after epoch 988 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 990/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.5002e-04 - mae: 0.0181\n",
      "Learning rate after epoch 989 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0196\n",
      "Epoch 991/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - mae: 0.0301\n",
      "Learning rate after epoch 990 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 992/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0058 - mae: 0.0705\n",
      "Learning rate after epoch 991 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0018 - val_mae: 0.0283\n",
      "Epoch 993/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0288\n",
      "Learning rate after epoch 992 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0333 - val_loss: 0.0046 - val_mae: 0.0474\n",
      "Epoch 994/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5.2842e-04 - mae: 0.0198\n",
      "Learning rate after epoch 993 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0379 - val_loss: 0.0029 - val_mae: 0.0421\n",
      "Epoch 995/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0536\n",
      "Learning rate after epoch 994 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0349 - val_loss: 0.0014 - val_mae: 0.0246\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0064 - mae: 0.0735\n",
      "Learning rate after epoch 995 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0370 - val_loss: 0.0020 - val_mae: 0.0368\n",
      "Epoch 997/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9.9098e-04 - mae: 0.0271\n",
      "Learning rate after epoch 996 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0260\n",
      "Epoch 998/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0392\n",
      "Learning rate after epoch 997 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0025 - val_mae: 0.0462\n",
      "Epoch 999/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0111 - mae: 0.0989\n",
      "Learning rate after epoch 998 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 1000/1000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4.1900e-04 - mae: 0.0161\n",
      "Learning rate after epoch 999 is 0.0098\n",
      "\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0034 - val_mae: 0.0504\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense,add,Lambda,Flatten\n",
    "\n",
    "# Define the first parallel recurrent layer with return_sequences=True\n",
    "rnn_1 =LSTM(units=11)(input_1)\n",
    "dropout1 = Dropout(rate=0.01)(rnn_1)\n",
    "\n",
    "# Define the second parallel recurrent layer\n",
    "rnn_2 = LSTM(units=11)(input_2)\n",
    "dropout2 = Dropout(rate=0.01)(rnn_2)\n",
    "\n",
    "# Define the third parallel recurrent layer\n",
    "rnn_3 =LSTM(units=11)(input_3)\n",
    "dropout3 = Dropout(rate=0.01)(rnn_3)\n",
    "\n",
    "# Define the fourth parallel recurrent layer\n",
    "rnn_4 = LSTM(units=11)(input_4)\n",
    "dropout4 = Dropout(rate=0.01)(rnn_4)\n",
    "\n",
    "# Concatenate the outputs of the recurrent layers\n",
    "merged = concatenate([dropout1, dropout2, dropout3, dropout4], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the merged output\n",
    "flatten = Flatten()(merged)\n",
    "\n",
    "# ...\n",
    "activation_layer = Activation('tanh')(flatten)\n",
    "dense1 = Dense(units=50, activation='tanh')(activation_layer)#,kernel_regularizer=regularizers.l1(0.001))(activation_layer)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(units=25, activation='relu')(dense1)# kernel_regularizer=regularizers.l1(0.001))(dense1)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the output layer\n",
    "output = Dense(units=1, activation='sigmoid')(dense2)\n",
    "\n",
    "\n",
    "# Create the model with the inputs and output\n",
    "regressor = Model(inputs=[input_1, input_2,input_3, input_4], outputs=output)\n",
    "\n",
    "# Compile the model with the desired optimizer, loss function, and metrics\n",
    "regressor.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model with the training data\n",
    "result=regressor.fit([X_train1, X_train2,X_train3, X_train4], y_train, epochs=1000, batch_size=25,validation_data=([X_val1, X_val2,X_val3, X_val4], y_val),callbacks=[LearningRateLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "852f54fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 11)           572         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 11)           572         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 11)           572         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 11)           572         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 11)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 11)           0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 11)           0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 11)           0           ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 44)           0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 44)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 44)           0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           2250        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50)          200         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           1275        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 25)          100         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            26          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,139\n",
      "Trainable params: 5,989\n",
      "Non-trainable params: 150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e751d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data\n",
    "trainPredict = regressor.predict([X_train1, X_train2, X_train3, X_train4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bb6ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8d54155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81651974],\n",
       "       [0.81724775],\n",
       "       [0.8079433 ],\n",
       "       [0.80818784],\n",
       "       [0.80835575],\n",
       "       [0.8091604 ],\n",
       "       [0.8082965 ],\n",
       "       [0.80469614],\n",
       "       [0.8042378 ],\n",
       "       [0.80304825],\n",
       "       [0.800899  ],\n",
       "       [0.8011679 ],\n",
       "       [0.81075865],\n",
       "       [0.81204015],\n",
       "       [0.8124488 ],\n",
       "       [0.81210047],\n",
       "       [0.8120559 ],\n",
       "       [0.81452227],\n",
       "       [0.8161372 ],\n",
       "       [0.81916964],\n",
       "       [0.81064546],\n",
       "       [0.807464  ],\n",
       "       [0.8062767 ],\n",
       "       [0.8024349 ],\n",
       "       [0.7985146 ],\n",
       "       [0.79530483],\n",
       "       [0.7900655 ],\n",
       "       [0.7855473 ],\n",
       "       [0.78171843],\n",
       "       [0.7755735 ],\n",
       "       [0.76733273],\n",
       "       [0.75715667],\n",
       "       [0.75566506],\n",
       "       [0.7472379 ],\n",
       "       [0.73800117],\n",
       "       [0.7306415 ],\n",
       "       [0.7241267 ],\n",
       "       [0.7165184 ],\n",
       "       [0.7070882 ],\n",
       "       [0.6928078 ],\n",
       "       [0.70091206],\n",
       "       [0.7050605 ],\n",
       "       [0.7055526 ],\n",
       "       [0.70496476],\n",
       "       [0.70301205],\n",
       "       [0.70310104],\n",
       "       [0.69923747],\n",
       "       [0.69618833],\n",
       "       [0.6942079 ],\n",
       "       [0.69526577],\n",
       "       [0.67647606],\n",
       "       [0.659998  ],\n",
       "       [0.64675087],\n",
       "       [0.6340661 ],\n",
       "       [0.6220094 ],\n",
       "       [0.6159494 ],\n",
       "       [0.60765195],\n",
       "       [0.5963615 ],\n",
       "       [0.587544  ],\n",
       "       [0.5795542 ],\n",
       "       [0.57107717],\n",
       "       [0.5635435 ],\n",
       "       [0.55572486],\n",
       "       [0.55130225],\n",
       "       [0.5441744 ],\n",
       "       [0.5311821 ],\n",
       "       [0.52312464],\n",
       "       [0.51654893],\n",
       "       [0.50809485],\n",
       "       [0.4965519 ],\n",
       "       [0.49135485],\n",
       "       [0.48430526],\n",
       "       [0.4758977 ],\n",
       "       [0.46550354],\n",
       "       [0.4599342 ],\n",
       "       [0.4530064 ],\n",
       "       [0.4465281 ],\n",
       "       [0.43867397],\n",
       "       [0.4316369 ],\n",
       "       [0.42812964],\n",
       "       [0.41893807],\n",
       "       [0.41288903],\n",
       "       [0.41472587],\n",
       "       [0.41534853],\n",
       "       [0.41256517],\n",
       "       [0.41028112],\n",
       "       [0.40593722],\n",
       "       [0.40337887],\n",
       "       [0.40134886],\n",
       "       [0.39897504],\n",
       "       [0.3960349 ],\n",
       "       [0.39096224],\n",
       "       [0.37937468],\n",
       "       [0.36732253],\n",
       "       [0.35765618],\n",
       "       [0.35506582],\n",
       "       [0.35206598],\n",
       "       [0.3478739 ],\n",
       "       [0.34188595],\n",
       "       [0.33520842],\n",
       "       [0.33038846],\n",
       "       [0.32707462],\n",
       "       [0.32262525],\n",
       "       [0.32566103],\n",
       "       [0.3207913 ],\n",
       "       [0.31159037],\n",
       "       [0.3051573 ],\n",
       "       [0.29767612],\n",
       "       [0.29272482],\n",
       "       [0.28714007],\n",
       "       [0.280937  ],\n",
       "       [0.27961934],\n",
       "       [0.27967402],\n",
       "       [0.26949525],\n",
       "       [0.26915136],\n",
       "       [0.2657567 ],\n",
       "       [0.2613869 ],\n",
       "       [0.25805023],\n",
       "       [0.25365192],\n",
       "       [0.24970788],\n",
       "       [0.24430415],\n",
       "       [0.23490006],\n",
       "       [0.22559722],\n",
       "       [0.21814276],\n",
       "       [0.21109639],\n",
       "       [0.21111451],\n",
       "       [0.20711718],\n",
       "       [0.20430219],\n",
       "       [0.20206814],\n",
       "       [0.19793533],\n",
       "       [0.19541784],\n",
       "       [0.19241321],\n",
       "       [0.18915163],\n",
       "       [0.18708655],\n",
       "       [0.18325539],\n",
       "       [0.17671643],\n",
       "       [0.17314664],\n",
       "       [0.17274064],\n",
       "       [0.16673444],\n",
       "       [0.16611587],\n",
       "       [0.16426478],\n",
       "       [0.16966358],\n",
       "       [0.17245872],\n",
       "       [0.17223077],\n",
       "       [0.1723207 ],\n",
       "       [0.16965199],\n",
       "       [0.16848843],\n",
       "       [0.16590479],\n",
       "       [0.16799183],\n",
       "       [0.16762117],\n",
       "       [0.16754058],\n",
       "       [0.16103512],\n",
       "       [0.15744288],\n",
       "       [0.15498488],\n",
       "       [0.15314801],\n",
       "       [0.15311538],\n",
       "       [0.15214708],\n",
       "       [0.15039316],\n",
       "       [0.1555785 ],\n",
       "       [0.21033013],\n",
       "       [0.2917674 ],\n",
       "       [0.3713484 ],\n",
       "       [0.45563817],\n",
       "       [0.53185517],\n",
       "       [0.5850863 ],\n",
       "       [0.64307946],\n",
       "       [0.74467087],\n",
       "       [0.87391555],\n",
       "       [0.9590314 ],\n",
       "       [0.9556693 ],\n",
       "       [0.9214467 ],\n",
       "       [0.9147262 ],\n",
       "       [0.9063963 ],\n",
       "       [0.89560413],\n",
       "       [0.8858381 ],\n",
       "       [0.87765497],\n",
       "       [0.8669974 ],\n",
       "       [0.8577092 ],\n",
       "       [0.85026735],\n",
       "       [0.84965396],\n",
       "       [0.89381075],\n",
       "       [0.8940017 ],\n",
       "       [0.893011  ],\n",
       "       [0.89257   ],\n",
       "       [0.89023197],\n",
       "       [0.88582426],\n",
       "       [0.8850594 ],\n",
       "       [0.8809679 ],\n",
       "       [0.87611127],\n",
       "       [0.8589332 ],\n",
       "       [0.8294621 ],\n",
       "       [0.8222352 ],\n",
       "       [0.8152609 ],\n",
       "       [0.8069525 ],\n",
       "       [0.796723  ],\n",
       "       [0.78670347],\n",
       "       [0.77221733],\n",
       "       [0.7588819 ],\n",
       "       [0.746851  ],\n",
       "       [0.73378533],\n",
       "       [0.7416847 ],\n",
       "       [0.721628  ],\n",
       "       [0.70118815],\n",
       "       [0.68779445],\n",
       "       [0.6859952 ],\n",
       "       [0.6765302 ],\n",
       "       [0.6650631 ],\n",
       "       [0.6611541 ],\n",
       "       [0.66512567],\n",
       "       [0.66636425],\n",
       "       [0.6665795 ],\n",
       "       [0.66770935],\n",
       "       [0.6656998 ],\n",
       "       [0.65655625],\n",
       "       [0.64667064],\n",
       "       [0.6365737 ],\n",
       "       [0.6284861 ],\n",
       "       [0.6163245 ],\n",
       "       [0.58893967],\n",
       "       [0.5614712 ],\n",
       "       [0.5294436 ],\n",
       "       [0.50247097],\n",
       "       [0.4964584 ],\n",
       "       [0.48848632],\n",
       "       [0.4739085 ],\n",
       "       [0.46652195],\n",
       "       [0.4615047 ],\n",
       "       [0.4509641 ],\n",
       "       [0.4436013 ],\n",
       "       [0.4302742 ],\n",
       "       [0.4244248 ],\n",
       "       [0.41588834],\n",
       "       [0.40799552],\n",
       "       [0.4002571 ],\n",
       "       [0.39275026],\n",
       "       [0.38632923],\n",
       "       [0.3782189 ],\n",
       "       [0.3735131 ],\n",
       "       [0.36842522],\n",
       "       [0.36358917],\n",
       "       [0.34843004],\n",
       "       [0.34250438],\n",
       "       [0.34252524],\n",
       "       [0.33696598],\n",
       "       [0.33162633],\n",
       "       [0.31928053],\n",
       "       [0.310922  ],\n",
       "       [0.29386437],\n",
       "       [0.2889426 ],\n",
       "       [0.3041023 ],\n",
       "       [0.30982754],\n",
       "       [0.30597508],\n",
       "       [0.29418206],\n",
       "       [0.2990702 ],\n",
       "       [0.30683976],\n",
       "       [0.30579102],\n",
       "       [0.319815  ],\n",
       "       [0.32487684],\n",
       "       [0.31335732],\n",
       "       [0.29120657],\n",
       "       [0.2765629 ],\n",
       "       [0.2651056 ],\n",
       "       [0.26423064],\n",
       "       [0.2577166 ],\n",
       "       [0.2520998 ],\n",
       "       [0.24667753],\n",
       "       [0.24136701],\n",
       "       [0.23697713],\n",
       "       [0.24029233],\n",
       "       [0.23582347],\n",
       "       [0.23459041],\n",
       "       [0.23327148],\n",
       "       [0.22122082],\n",
       "       [0.21476926],\n",
       "       [0.20814687],\n",
       "       [0.20257926],\n",
       "       [0.1950558 ],\n",
       "       [0.19098291],\n",
       "       [0.18456349],\n",
       "       [0.18833548],\n",
       "       [0.19035764],\n",
       "       [0.18848401],\n",
       "       [0.18537828],\n",
       "       [0.18638761],\n",
       "       [0.1836566 ],\n",
       "       [0.18471707],\n",
       "       [0.18171684],\n",
       "       [0.17615078],\n",
       "       [0.17081113],\n",
       "       [0.158716  ],\n",
       "       [0.14754777],\n",
       "       [0.13983603],\n",
       "       [0.13699527],\n",
       "       [0.13372558],\n",
       "       [0.13209303],\n",
       "       [0.1301106 ],\n",
       "       [0.12733105],\n",
       "       [0.12630536],\n",
       "       [0.12495991],\n",
       "       [0.12372811],\n",
       "       [0.12194299],\n",
       "       [0.11899494],\n",
       "       [0.114828  ],\n",
       "       [0.10825794],\n",
       "       [0.10215797],\n",
       "       [0.09620318],\n",
       "       [0.09146003],\n",
       "       [0.08637542],\n",
       "       [0.0814449 ],\n",
       "       [0.07496599],\n",
       "       [0.077162  ],\n",
       "       [0.07781988],\n",
       "       [0.07602216],\n",
       "       [0.07387665],\n",
       "       [0.07185138],\n",
       "       [0.07039923],\n",
       "       [0.06834513],\n",
       "       [0.06520576],\n",
       "       [0.06208353],\n",
       "       [0.06129275],\n",
       "       [0.05185422],\n",
       "       [0.04422268],\n",
       "       [0.03797367],\n",
       "       [0.03307437],\n",
       "       [0.02854466],\n",
       "       [0.02476804],\n",
       "       [0.02303153],\n",
       "       [0.07945254],\n",
       "       [0.12987703],\n",
       "       [0.20614831],\n",
       "       [0.30790353],\n",
       "       [0.41026658],\n",
       "       [0.50527686],\n",
       "       [0.5755593 ],\n",
       "       [0.624581  ],\n",
       "       [0.706857  ],\n",
       "       [0.8722904 ],\n",
       "       [0.88448095],\n",
       "       [0.8467437 ],\n",
       "       [0.849638  ],\n",
       "       [0.8548755 ],\n",
       "       [0.8547484 ],\n",
       "       [0.8559235 ],\n",
       "       [0.8567771 ],\n",
       "       [0.85713524],\n",
       "       [0.85661656],\n",
       "       [0.8531058 ],\n",
       "       [0.8523503 ],\n",
       "       [0.89108753],\n",
       "       [0.8891793 ],\n",
       "       [0.8889049 ],\n",
       "       [0.88748497],\n",
       "       [0.8867155 ],\n",
       "       [0.886241  ],\n",
       "       [0.8818417 ],\n",
       "       [0.88095325],\n",
       "       [0.880832  ],\n",
       "       [0.87920934],\n",
       "       [0.8771369 ],\n",
       "       [0.8742095 ],\n",
       "       [0.8694241 ],\n",
       "       [0.86697185],\n",
       "       [0.86097777],\n",
       "       [0.85407495],\n",
       "       [0.8495657 ],\n",
       "       [0.8427273 ],\n",
       "       [0.83234566],\n",
       "       [0.8251102 ],\n",
       "       [0.8149636 ],\n",
       "       [0.8065186 ],\n",
       "       [0.79869086],\n",
       "       [0.7875516 ],\n",
       "       [0.7810948 ],\n",
       "       [0.77310485],\n",
       "       [0.7631085 ],\n",
       "       [0.7543486 ],\n",
       "       [0.7597491 ],\n",
       "       [0.7638749 ],\n",
       "       [0.76364857],\n",
       "       [0.7605337 ],\n",
       "       [0.7561587 ],\n",
       "       [0.75576675],\n",
       "       [0.75335634],\n",
       "       [0.74989223],\n",
       "       [0.7459508 ],\n",
       "       [0.74154997],\n",
       "       [0.72477984],\n",
       "       [0.71002734],\n",
       "       [0.6990478 ],\n",
       "       [0.6892897 ],\n",
       "       [0.67994726],\n",
       "       [0.66943234],\n",
       "       [0.6608244 ],\n",
       "       [0.6523869 ],\n",
       "       [0.641526  ],\n",
       "       [0.6339811 ],\n",
       "       [0.62710094],\n",
       "       [0.61907345],\n",
       "       [0.61162084],\n",
       "       [0.60489213],\n",
       "       [0.5986002 ],\n",
       "       [0.592366  ],\n",
       "       [0.5842992 ],\n",
       "       [0.5778801 ],\n",
       "       [0.57243794],\n",
       "       [0.562062  ],\n",
       "       [0.5576012 ],\n",
       "       [0.5514342 ],\n",
       "       [0.54493725],\n",
       "       [0.53942007],\n",
       "       [0.5352635 ],\n",
       "       [0.53146535],\n",
       "       [0.52735096],\n",
       "       [0.52260846],\n",
       "       [0.51753545],\n",
       "       [0.51773405],\n",
       "       [0.51263636],\n",
       "       [0.5080596 ],\n",
       "       [0.50940543],\n",
       "       [0.5094299 ],\n",
       "       [0.50830513],\n",
       "       [0.50629216],\n",
       "       [0.504477  ],\n",
       "       [0.5032606 ],\n",
       "       [0.50269836],\n",
       "       [0.50086105],\n",
       "       [0.49854606],\n",
       "       [0.49734113],\n",
       "       [0.49060047],\n",
       "       [0.4842117 ],\n",
       "       [0.47647417],\n",
       "       [0.4745751 ],\n",
       "       [0.4720394 ],\n",
       "       [0.46911788],\n",
       "       [0.46621004],\n",
       "       [0.46246824],\n",
       "       [0.4600104 ],\n",
       "       [0.45758066],\n",
       "       [0.4546016 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76b50669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "testPredict = regressor.predict([X_test1, X_test2, X_test3, X_test4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a8bdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "valPredict = regressor.predict([X_val1, X_val2,X_val3, X_val4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b6f7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bb9e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_val,valPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3056cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.22\n"
     ]
    }
   ],
   "source": [
    "MAE = math.sqrt(mean_absolute_error(y_val,valPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c58d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.605636 0.618226]\n",
      " [0.604435 0.616004]\n",
      " [0.603605 0.611976]\n",
      " [0.599896 0.606466]\n",
      " [0.596128 0.600399]\n",
      " [0.590567 0.59468 ]\n",
      " [0.579034 0.588161]\n",
      " [0.574894 0.599026]\n",
      " [0.581178 0.607449]\n",
      " [0.584488 0.614321]\n",
      " [0.597768 0.620085]\n",
      " [0.596359 0.618894]\n",
      " [0.588659 0.618589]\n",
      " [0.588739 0.617772]\n",
      " [0.589541 0.617245]\n",
      " [0.59412  0.616607]\n",
      " [0.620929 0.626267]\n",
      " [0.616271 0.615608]\n",
      " [0.593275 0.605407]\n",
      " [0.591555 0.594143]\n",
      " [0.589065 0.584187]\n",
      " [0.587929 0.571555]\n",
      " [0.59435  0.560286]\n",
      " [0.584024 0.549715]\n",
      " [0.580357 0.539831]\n",
      " [0.57565  0.530674]\n",
      " [0.571978 0.511971]\n",
      " [0.584137 0.495426]\n",
      " [0.576259 0.481608]\n",
      " [0.565805 0.470458]\n",
      " [0.554103 0.464694]\n",
      " [0.544673 0.459712]\n",
      " [0.533169 0.452987]\n",
      " [0.514337 0.447083]\n",
      " [0.509257 0.44105 ]\n",
      " [0.502948 0.434763]\n",
      " [0.497674 0.428739]\n",
      " [0.490656 0.423982]\n",
      " [0.483082 0.418628]\n",
      " [0.477648 0.412638]\n",
      " [0.472955 0.402674]\n",
      " [0.467015 0.392628]\n",
      " [0.461861 0.384978]\n",
      " [0.464106 0.377099]\n",
      " [0.454679 0.369881]\n",
      " [0.443395 0.368531]\n",
      " [0.434544 0.365946]\n",
      " [0.428486 0.362834]\n",
      " [0.402617 0.359163]\n",
      " [0.401228 0.355158]\n",
      " [0.39975  0.35538 ]\n",
      " [0.394624 0.353624]\n",
      " [0.390925 0.351206]\n",
      " [0.371527 0.349589]\n",
      " [0.370678 0.347214]\n",
      " [0.371509 0.339632]\n",
      " [0.368527 0.332747]\n",
      " [0.365818 0.32666 ]\n",
      " [0.383176 0.321841]\n",
      " [0.371618 0.317283]\n",
      " [0.364335 0.308674]\n",
      " [0.358574 0.301509]\n",
      " [0.352236 0.295782]\n",
      " [0.370699 0.2899  ]\n",
      " [0.360607 0.28385 ]\n",
      " [0.352837 0.290273]\n",
      " [0.348415 0.296851]\n",
      " [0.342008 0.302358]\n",
      " [0.310451 0.307177]\n",
      " [0.318713 0.311652]\n",
      " [0.326671 0.315234]\n",
      " [0.335179 0.318768]\n",
      " [0.34325  0.321485]\n",
      " [0.349696 0.324215]\n",
      " [0.354499 0.327836]\n",
      " [0.358952 0.318914]\n",
      " [0.364367 0.309782]\n",
      " [0.371205 0.30071 ]\n",
      " [0.399444 0.292138]\n",
      " [0.392201 0.283668]\n",
      " [0.37921  0.285268]\n",
      " [0.368247 0.286197]\n",
      " [0.357521 0.285969]\n",
      " [0.325082 0.285747]\n",
      " [0.327568 0.28379 ]\n",
      " [0.328193 0.282738]\n",
      " [0.327283 0.281808]\n",
      " [0.322858 0.281563]\n",
      " [0.322483 0.282109]\n",
      " [0.321085 0.282805]\n",
      " [0.324744 0.273904]\n",
      " [0.324391 0.265824]\n",
      " [0.326297 0.258342]\n",
      " [0.352456 0.251266]\n",
      " [0.345078 0.246198]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "print(np.concatenate((testPredict.reshape(len(testPredict),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c431e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.04\n",
      "Test RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "RMSE = math.sqrt(mean_squared_error(y_train,trainPredict))\n",
    "print('Train RMSE: %.2f' % (RMSE))\n",
    "\n",
    "RMSE = math.sqrt(mean_squared_error(y_test,testPredict))\n",
    "print('Test RMSE: %.2f' % (RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca612703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017641701568284244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0030662866305011995"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse=mean_squared_error(y_train,trainPredict)\n",
    "print(mse)\n",
    "\n",
    "mse=mean_squared_error(y_test,testPredict)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "835f6cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003428717039426336"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse=mean_squared_error(y_val,valPredict)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1ddd352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_train,trainPredict))\n",
    "print('Train MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0f7067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = math.sqrt(mean_absolute_error(y_test,testPredict))\n",
    "print('Test MAE: %.2f' % (MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77df0e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733800979123399"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, trainPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd26b337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791742142785777"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, valPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e65e48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8102707968443119"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c16b02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(combined_datap, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd6b7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.arange(439, 628)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ef48b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_datap = np.concatenate((trainPredict,valPredict, testPredict), axis=0)\n",
    "combined_data = np.concatenate((y_train,y_val,y_test), axis=0)\n",
    "plt.plot(trainPredict,color = 'blue', label = 'Predicted SOH(Training)')\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "plt.plot( X_data,z,color = 'darkgreen', label = 'Predicted SOH(Testing )')\n",
    "plt.plot(combined_data, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f582902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_train, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c97df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4911dcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valPredict, color = 'blue', label = 'Predicted SOH')\n",
    "plt.plot(y_val, color = 'red', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8517e995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testPredict, color = 'darkgreen', label = 'Predicted SOH(Testing)')\n",
    "plt.plot(y_test, color = 'blue', label = 'Actual SOH')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba2d2629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(combined_data-combined_datap, color = 'blue', label = 'Predicted SOH')\n",
    "yticks_positions = [-0.3, -0.2,-0.1,0.0 ,0.1,0.2,0.3]\n",
    "#yticks_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "\n",
    "# Apply the yticks\n",
    "#plt.yticks(yticks_positions, yticks_labels)\n",
    "plt.yticks(yticks_positions)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5691222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597483634001194"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(combined_data, combined_datap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9979038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGiCAYAAAAvEibfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjBklEQVR4nO3deVxU5eIG8GfYF2EQEHABxSWX3CEVzbJS1DLz182lxRZTszIz61bmTckWvZVl3VLLFss262plZRre1DTDFCUtldy3QFwHFNnf3x9vZ+bMBgzMwpl5vp8PH2bOnDnzzmE5z7yrTgghQERERKQRfp4uABEREZEjGF6IiIhIUxheiIiISFMYXoiIiEhTGF6IiIhIUxheiIiISFMYXoiIiEhTGF6IiIhIUxheiIiISFMYXoiIiEhT3BJeFixYgOTkZISEhCAlJQUbN260u++mTZvQr18/xMTEIDQ0FB06dMCrr77qjmISERGRBgS4+gWWLVuGqVOnYsGCBejXrx/eeustDB06FLt370ZSUpLV/uHh4Zg8eTK6du2K8PBwbNq0Cffddx/Cw8MxceJEVxeXiIiIGjidqxdm7N27N3r27ImFCxcat3Xs2BEjRozAnDlzanWMm2++GeHh4Vi6dKmriklEREQa4dKal7KyMmRnZ+PJJ580256eno7NmzfX6hg7duzA5s2b8dxzz9l8vLS0FKWlpcb7VVVVOHv2LGJiYqDT6epeeCIiInIbIQSKiorQrFkz+PlV36vFpeHl9OnTqKysRHx8vNn2+Ph45OfnV/vcFi1a4NSpU6ioqEBGRgbGjx9vc785c+bgmWeecVqZiYiIyHOOHTuGFi1aVLuPy/u8ALCqARFC1FgrsnHjRly4cAFZWVl48skn0bZtW9x6661W+02fPh3Tpk0z3jcYDEhKSsKxY8cQGRnpnDdARERELlVYWIjExERERETUuK9Lw0tsbCz8/f2talkKCgqsamMsJScnAwC6dOmCkydPIiMjw2Z4CQ4ORnBwsNX2yMhIhhciIiKNqU2XD5cOlQ4KCkJKSgoyMzPNtmdmZqJv3761Po4QwqxfCxEREfkulzcbTZs2DWPHjkVqairS0tLw9ttv4+jRo5g0aRIA2exz4sQJfPjhhwCAN998E0lJSejQoQMAOe/Lyy+/jIceesjVRSUiIiINcHl4GT16NM6cOYPZs2cjLy8PnTt3xqpVq9CyZUsAQF5eHo4ePWrcv6qqCtOnT8ehQ4cQEBCANm3aYO7cubjvvvtcXVQiIiLSAJfP8+JuhYWF0Ov1MBgM7PNCRORCQghUVFSgsrLS00UhjfD390dAQIDNfi2OXL/dMtqIiIi8S1lZGfLy8lBcXOzpopDGhIWFoWnTpggKCqrzMRheiIjIIVVVVTh06BD8/f3RrFkzBAUFcVJQqpEQAmVlZTh16hQOHTqEdu3a1TgZnT0ML0RE5JCysjJUVVUhMTERYWFhni4OaUhoaCgCAwNx5MgRlJWVISQkpE7Hccuq0kRE5H3q+qmZfJszfm/4m0dERESawvBCREREmsLwQkREVEcDBgzA1KlTa73/4cOHodPpkJOT47Iy+QKGFyIi8no6na7ar7vvvrtOx12xYgWeffbZWu+fmJhonLDVlZSQZOsrKyvLpa/tDhxtREREXi8vL894e9myZZg5cyZyc3ON20JDQ832Ly8vR2BgYI3HjY6Odqgc/v7+SEhIcOg59bF27VpcfvnlZttiYmJs7mvvPdf2XDjrebXBmhciIqo3IYCLF93/Vds54hMSEoxfer0eOp3OeL+kpARRUVH4/PPPMWDAAISEhOCjjz7CmTNncOutt6JFixYICwtDly5d8Omnn5od17LZqFWrVnjhhRcwbtw4REREICkpCW+//bbxcctmo/Xr10On0+F///sfUlNTERYWhr59+5oFKwB47rnnEBcXh4iICIwfPx5PPvkkunfvXuP7jomJMXvvCQkJxkCRkZGB7t2747333kPr1q0RHBwMIQR0Oh0WLVqEm266CeHh4XjuuecAAAsXLkSbNm0QFBSE9u3bY+nSpWavZe95rsDwQkRE9VZcDDRq5P4vZ07w+8QTT2DKlCnYs2cPBg8ejJKSEqSkpODbb7/F77//jokTJ2Ls2LHYsmVLtceZN28eUlNTsWPHDjzwwAO4//77sXfv3mqfM2PGDMybNw/btm1DQEAAxo0bZ3zs448/xvPPP49///vfyM7ORlJSEhYuXOiU97x//358/vnnWL58uVk/nFmzZuGmm27Crl27MG7cOHz55Zd4+OGH8eijj+L333/Hfffdh3vuuQfr1q0zO57l81xGeBmDwSAACIPB4OmiEBF5pUuXLondu3eLS5cuGbdduCCErAdx79eFC46X//333xd6vd54/9ChQwKAmD9/fo3Pvf7668Wjjz5qvH/11VeLhx9+2Hi/ZcuW4o477jDer6qqEnFxcWLhwoVmr7Vjxw4hhBDr1q0TAMTatWuNz/nuu+8EAOP57d27t3jwwQfNytGvXz/RrVs3u+VUXic0NFSEh4ebfVVUVAghhJg1a5YIDAwUBQUFZs8FIKZOnWq2rW/fvmLChAlm20aOHCmuv/76ap9ni63fHyEcu36zzwsREdVbWBhw4YJnXtdZUlNTze5XVlZi7ty5WLZsGU6cOIHS0lKUlpYiPDy82uN07drVeFtpniooKKj1c5o2bQoAKCgoQFJSEnJzc/HAAw+Y7d+rVy/8+OOPNb6nZcuWoWPHjmbb/P39jbdbtmyJJk2aWD3P8lzs2bMHEydONNvWr18/vPbaa9U+z1UYXoiIqN50OqCGa3qDZxlK5s2bh1dffRXz589Hly5dEB4ejqlTp6KsrKza41h2UtXpdKiqqqr1c5R1otTPsVw7StSys09iYiLatm1r93F7QczWdltlsNxWU7BzFvZ5ISIismHjxo246aabcMcdd6Bbt25o3bo19u3b5/ZytG/fHr/++qvZtm3btrm1DB07dsSmTZvMtm3evNmqVsddWPNCRERkQ9u2bbF8+XJs3rwZjRs3xiuvvIL8/Hy3X7AfeughTJgwAampqejbty+WLVuGnTt3onXr1jU+98yZM8jPzzfbFhUV5fCCiP/85z8xatQo9OzZE9dddx2++eYbrFixAmvXrnXoOM7C8EJERGTD008/jUOHDmHw4MEICwvDxIkTMWLECBgMBreW4/bbb8fBgwfx2GOPoaSkBKNGjcLdd99tVRtjy8CBA622ffrppxgzZoxDZRgxYgRee+01vPTSS5gyZQqSk5Px/vvvY8CAAQ4dx1l0orYNZxpRWFgIvV4Pg8GAyMhITxeHiMjrlJSU4NChQ0hOTnb4Ezw5x6BBg5CQkGA114oW2Pv9ceT6zZoXIiKiBqy4uBiLFi3C4MGD4e/vj08//RRr165FZmamp4vmMQwvREREDZhOp8OqVavw3HPPobS0FO3bt8fy5cttNgn5CoYXIiKiBiw0NNRjHWMbKg6VJiIiIk1heCEiIiJNYXghIiIiTWF4ISIiIk1heCEiIiJNYXghIiIiTWF4ISIicrIlS5YgKirK08XwWgwvRETk9XQ6XbVfd999d52P3apVK8yfP99s2+jRo/Hnn3/Wr9C1sGTJEpvvx9uXbeAkdURE5PXy8vKMt5ctW4aZM2ciNzfXuC00NNSprxcaGur0Y9oTGRlp9l4AGdbsKSsrQ1BQkNk2IQQqKysREOBYLKjr8+qLNS9ERFRvQghcLL3o9q/ari2ckJBg/NLr9dDpdGbbfvrpJ6SkpCAkJAStW7fGM888g4qKCuPzMzIykJSUhODgYDRr1gxTpkwBAAwYMABHjhzBI488Yqz1AKybjTIyMtC9e3csXboUrVq1gl6vx5gxY1BUVGTcp6ioCLfffjvCw8PRtGlTvPrqqxgwYACmTp1a7XuzfC8JCQmIj483Pj5gwABMnjwZ06ZNQ2xsLAYNGoT169dDp9NhzZo1SE1NRXBwMDZu3IjS0lJMmTIFcXFxCAkJwZVXXomtW7caj2Xvee7GmhciIqq34rJiNJrcyO2ve+GNCwgPDq/XMdasWYM77rgDr7/+Ovr3748DBw5g4sSJAIBZs2bhv//9L1599VV89tlnuPzyy5Gfn4/ffvsNALBixQp069YNEydOxIQJE6p9nQMHDuCrr77Ct99+i3PnzmHUqFGYO3cunn/+eQDAtGnT8PPPP2PlypWIj4/HzJkzsX37dnTv3r1e7w8APvjgA9x///34+eefIYRAfn4+AODxxx/Hyy+/jNatWyMqKgqPP/44li9fjg8++AAtW7bEiy++iMGDB2P//v2Ijo42Hs/yee7G8EJERD7t+eefx5NPPom77roLANC6dWs8++yzePzxxzFr1iwcPXoUCQkJGDhwIAIDA5GUlIRevXoBAKKjo+Hv74+IiAgkJCRU+zpVVVVYsmQJIiIiAABjx47F//73Pzz//PMoKirCBx98gE8++QTXXXcdAOD9999Hs2bNaiy/wWBAo0bmwbFv37744YcfjPfbtm2LF1980XhfCS+zZ8/GoEGDAAAXL17EwoULsWTJEgwdOhQAsHjxYmRmZuLdd9/FP//5T+Pz1c/zBIYXIiKqt7CgMFx444JHXre+srOzsXXrVmMNCABUVlaipKQExcXFGDlyJObPn4/WrVtjyJAhuP7663HjjTc63M+jVatWxuACAE2bNkVBQQEA4ODBgygvLzeGIgDQ6/Vo3759jceNiIjA9u3bzbZZ9rdJTU21+Vz19gMHDqC8vBz9+vUzbgsMDESvXr2wZ8+eWh3PXRheiIio3nQ6Xb2bbzylqqoKzzzzDG6++Warx0JCQpCYmIjc3FxkZmZi7dq1eOCBB/DSSy9hw4YNCAwMrPXrWO6r0+lQVVUFAMa+O5YdbWvTp8fPzw9t27atdp/wcNs/G/X26spguc3e8dyFHXaJiMin9ezZE7m5uWjbtq3Vl5+fvEyGhoZi+PDheP3117F+/Xr88ssv2LVrFwAgKCgIlZWV9SpDmzZtEBgYiF9//dW4rbCwEPv27avXcR3Rtm1bBAUFYdOmTcZt5eXl2LZtGzp27Oi2ctQGa16IiMinzZw5E8OGDUNiYiJGjhwJPz8/7Ny5E7t27cJzzz2HJUuWoLKyEr1790ZYWBiWLl2K0NBQtGzZEoBsDvrpp58wZswYBAcHIzY21uEyRERE4K677sI///lPREdHIy4uDrNmzYKfn1+1w54BmHXAVYuLizOGr9oIDw/H/fffbyxDUlISXnzxRRQXF+Pee+91+D25EsMLERH5tMGDB+Pbb7/F7Nmz8eKLLyIwMBAdOnTA+PHjAQBRUVGYO3cupk2bhsrKSnTp0gXffPMNYmJiAMjOq/fddx/atGmD0tLSWg/ftvTKK69g0qRJGDZsGCIjI/H444/j2LFjNU44V1hYiKZNm1ptz8vLq7ETsaW5c+eiqqoKY8eORVFREVJTU7FmzRo0btzYoeO4mk7U9Sw3UIWFhdDr9TAYDIiMjPR0cYiIvE5JSQkOHTqE5ORkr5/J1ZMuXryI5s2bY968eQ2u5qM+7P3+OHL9Zs0LERFRA7Bjxw7s3bsXvXr1gsFgwOzZswEAN910k4dL1vAwvBARETUQL7/8MnJzcxEUFISUlBRs3LixTn1ovB3DCxERUQPQo0cPZGdne7oYmsCh0kRERKQpDC9ERFQnXjbeg9zEGb83DC9EROQQZabY4uJiD5eEtEj5vXFkdmJL7PNCREQO8ff3R1RUlHFdnrCwsBonUiMSQqC4uBgFBQWIioqCv79/nY/F8EJERA5TJj9TAgxRbUVFRTk8eZ4lhhciInKYTqdD06ZNERcXh/Lyck8XhzQiMDCwXjUuCoYXIiKqM39/f6dcjIgcwQ67REREpCkML0RERKQpbgkvCxYsMC7ApEx3bM+KFSswaNAgNGnSBJGRkUhLS8OaNWvcUUwiIiLSAJeHl2XLlmHq1KmYMWMGduzYgf79+2Po0KE4evSozf1/+uknDBo0CKtWrUJ2djauueYa3HjjjdixY4eri0pEREQaoBMuniKxd+/e6NmzJxYuXGjc1rFjR4wYMQJz5syp1TEuv/xyjB49GjNnzrR6rLS0FKWlpcb7hYWFSExMrNWS2kRERNQwFBYWQq/X1+r67dKal7KyMmRnZyM9Pd1se3p6OjZv3lyrY1RVVaGoqAjR0dE2H58zZw70er3xKzExsd7lJiIioobLpeHl9OnTqKysRHx8vNn2+Ph45Ofn1+oY8+bNw8WLFzFq1Cibj0+fPh0Gg8H4dezYsXqXm4iIiBout8zzYjlttBCiVlNJf/rpp8jIyMDXX3+NuLg4m/sEBwcjODjYKeUkIiKihs+l4SU2Nhb+/v5WtSwFBQVWtTGWli1bhnvvvRdffPEFBg4c6MpiEhERkYa4tNkoKCgIKSkpyMzMNNuemZmJvn372n3ep59+irvvvhuffPIJbrjhBlcWkYiIiDTG5c1G06ZNw9ixY5Gamoq0tDS8/fbbOHr0KCZNmgRA9lk5ceIEPvzwQwAyuNx555147bXX0KdPH2OtTWhoKPR6vauLS0RERA2cy8PL6NGjcebMGcyePRt5eXno3LkzVq1ahZYtWwIA8vLyzOZ8eeutt1BRUYEHH3wQDz74oHH7XXfdhSVLlri6uERERNTAuXyeF3dzZJw4ERERNQwNZp4XIiIiImdjeCEiIiJNYXghIiIiTWF4ISIiIk1heCEiIiJNYXghIiIiTWF4ISIiIk1heCEiIiJNYXghIiIiTWF4ISIiIk1heCEiIiJNYXghIiKvUVJeAi9bso9sYHghIiKvcKDgABo/3BgPfvKgp4tCLsbwQkREXmHu6rkoKS/BwvULPV0UcjGGFyIi8grFpcWeLgK5CcMLERF5hUvllzxdBHIThhciIvIKDC++g+GFiIi8wqUyU3jhiCPvxvBCREReQV3zUlJe4sGSkKsxvBARkVdQ17xcLL3owZKQqzG8EBGRVzh78azx9sUyhhdvxvBCRESaJ4TA6QunjfdZ8+LdGF6IiEjz8gx5KK0oNd5nePFuDC9ERKR5O4/vNLvPZiPvxvBCRESaZxVeWPPi1RheiIhI8xhefAvDCxERad7hM4fN7rPZyLsxvBARkeaduXAGABDTKAYAa168HcMLERFp3pmLMrwkRScBYHjxdgwvRESkaUII4wR1xvDCZiOvxvBCRESaZrhkQGVVJQAgsXEiAKC4rNiTRSIXY3ghIiJNU/q7hAWFsc+Lj2B4ISIiTVP6u8Q0ikF4cDgAhhdvx/BCRESaZhxpFB6D8KC/wwv7vHg1hhfyeZWVwPLlQF6ep0tCRHXBmhffw/BCPm/hQuCWW4CePT1dEiKqC7OaF4YXn8DwQj5v5Ur5PT/fs+Ugoroxq3lhs5FPYHghn+fHvwIiTWPNi+/hv23yeTqdp0tARPWhTFDHPi++g+GFfB5rXoi0zdhsxNFGPoP/tsnnMbwQaZt6UUbWvPgG/tsmn6cOL1VVnisHEdWNWc3L3+GlvLIc5RXlniwWuRDDC/k8dZ+XS5c8Vw4iqhul5iU6PNrYbASw6cibMbyQzxPCdPvCBc+Vg4gcV1ZRhgul8g83plEMggKC4O/nD4BNR96M4YV8XkmJ6TbDC5G2KLUufjo/RIVGQafTsd+LD2B4IZ9XXGy6zfBCpC1Kf5fG4Y3h93cHNo448n4ML+TzGF6ItEs9QZ2iUXAjAEBRSZFHykSux/BCPu+i6sMZwwuRtqiXBlAot5VgQ96H4YV8HmteiLTLVs1Lk4gmAIDTF057pEzkegwv5PMYXoi0Sz3HiyK2USwA4FTRKY+UiVzPLeFlwYIFSE5ORkhICFJSUrBx40a7++bl5eG2225D+/bt4efnh6lTp7qjiOTD1OGliE3kXksI4Nlngbfe8nRJyJnUs+sqlPDCmhfv5fLwsmzZMkydOhUzZszAjh070L9/fwwdOhRHjx61uX9paSmaNGmCGTNmoFu3bq4uHvm4qirzielKSz1XFnKtTZuAmTOBSZM8XRJyJuOijGw28ikuDy+vvPIK7r33XowfPx4dO3bE/PnzkZiYiIULF9rcv1WrVnjttddw5513Qq/Xu7p45OMsZ9QtK/NMOcj1fvzR0yUgV7DVYZc1L97PpeGlrKwM2dnZSE9PN9uenp6OzZs3O+U1SktLUVhYaPZFVFvqJiMAKOdSKF7r119Nt7mGlfdgs5Fvcml4OX36NCorKxEfH2+2PT4+Hvn5+U55jTlz5kCv1xu/EhMTnXJc8g2W4YU1L97r999NtysqPFcOcq7qOuwyvHgvt3TY1alXvgMghLDaVlfTp0+HwWAwfh07dswpxyXfcNFiAk7WvHgv9TIQDC/eQ+nzEh0ebdym9HkpKCrwSJnI9QJcefDY2Fj4+/tb1bIUFBRY1cbUVXBwMIKDg51yLPI9rHnxHerAUlnpuXKQcxWWyK4C+lBTH8mEyAQAcm2jCyUX0CikkUfKRq7j0pqXoKAgpKSkIDMz02x7ZmYm+vbt68qXJqoV9nnxHerAwpoX71BeUY5LZbLXfWRopHF7o5BGxsUZ8wud00WBGhaX1rwAwLRp0zB27FikpqYiLS0Nb7/9No4ePYpJf49XnD59Ok6cOIEPP/zQ+JycnBwAwIULF3Dq1Cnk5OQgKCgInTp1cnVxycew5sV3MLx4H6XWBQAiQyLNHmuqb4r9BfuRdz4PbePaurto5GIuDy+jR4/GmTNnMHv2bOTl5aFz585YtWoVWrZsCUBOSmc550uPHj2Mt7Ozs/HJJ5+gZcuWOHz4sKuLSz6GNS++Qx1MGV68g+GSAQAQFhSGAH/zy1lCZIIML4Y8TxSNXMzl4QUAHnjgATzwwAM2H1uyZInVNiGEi0tEJLHDrm+oqmJ48UZKeFH3d1E01TcFAIYXL8W1jcin+Xqz0bx5wBVXAE6auaDBsvy5Mrx4h8JLstlI3d9FkaCXnXbZ58U7MbyQT/P1ZqPHHgO2bQMefNDTJXEty2UfONrIO9Sm5uWv83+5tUzkHgwv5NOU8BLwdwOqr9W8KL791tMlcC31HC8Aa168hdJh17KzLgB0bNoRALDhzw3siuCFGF7Ipyl9XpRltHyp5kVd+1BWBhgMniuLq1nWvDC8eIfqal7SO6UjLCgMR84cwdbDW91dNHIxhhfyaUrNS1SU/O4LNS8//AAMGwbs2mW+fe9ez5THHRhevFN1fV7CgsMwvNtwAMAjyx5BFRe08ioML+TTlPDiSzUvgwcD330HjBxpvn33bs+Uxx0YXrxTdTUvAPDvf/wb4cHh2HxgM7IOZrmzaORiDC/k03yx5kWxf7/5/XHjgO3bPVMWV2OfF++khBdbfV4AICkmCTd1uwkAsGLHCreVi1yP4YV8mtLnRQkvvlDzUh1v7bjL0UbeSZnDJT7S/lp5/0j5BwBgefZydtz1IgwvZCUnB3jlFd/4B+9rNS+2/nf372+6feaM+8riTmw28k7Hzh4DACRGJ9rdZ8jlQxAWFIbDZw5jx9Ed7ioauRjDC1np0QN49FFg0SJPl8T1fK3PS2Gh9bb27eVkdQBw6pR7y+MuDC/e6di5v8NLY/vhJSw4DEM7DwUAfPDLB24pF7kewwuZUV+8fvjBc+Vwl/Pn5ffoaPnd22teTp603pacDDRpIm97a3hhnxfvU1JeglNF8he2upoXALjv6vsAAIs2LMLxs8ddXjZyPYYXMvPTT6bblkNpvU1ZGZCbK2936SK/e3vNS0GB9bYrrgDi4uw/7g1Y8+J9jp+TISQsKAzR4dHV7juw40D0SOqBsooybD6w2R3FIxdjeCEz27aZbh86BKxZA7RpA0REAPPnu/71N20C/vMf230znG3HDhlW9HqgbVu5zRdrXlJSvL/mheHF+6j7u+h0umr31el0uLzZ5QCAA6cOuLxs5HpuWVWatOPQIfP7N95oqo145BEgLQ3o3ds1r11Zaeo8GhMD3HYbcOkSEBIC1PC/yWFHjgB9+sjbXbsCQUHytrfXvJw+bX4/Lk42mSmjrk6flsHR2efb0yybjXyhM7q3M4aXavq7qLVp0gYAw4u3YM0LmVHCy9ix8nt5ufxUHhEh7+9wYWf9LNUcUrffLucdiYgAOnQAXnzRubUiX3xhut2njym8eHvNi9JB+dZbgU8+MfVrUmpeysu9c5kA1rx4n6NnjwKoub+Lom2crF5lePEODC8N2D33AOnp7v2UqISXRx4BMjOBjRuBw4dlmACA/L9Xl6+sBJYtA86dc95rf/ON+f3335ev8+efwBNPABMmOO+1lPlMunYFnnwSCAyU97295kUJL+HhMsB06ybvh4QAjRrJ297SdFRSAixZAuTl+V54qawEJk4Enn3W0yVxndqMNFJjzYt3YXhpoMrK5D/ezEzzfiiudPGi6cKVnAwMHAhceSUQFgYkJMjtSnh57z1gzBhg0CDnvf7mv/vRDR0KPP440LevbKJ67DG5/cMPTa9fH0ePylAGAF99JZtNlJqXykrAm5dAUcJLWJj1Y8pcN7aGU2vRCy/IDwDXXed74WXjRmDxYmDmTO9d9qE2c7yoXRZ/mfF5Zy546YRGPoThpYFS902w7KfgKocPy+9RUaYLmcIyvLzzjvyenQ388Uf9X7uiQh4LAF5+Gfj3v4Gff5ZNSS+9BPTsKR/77rv6X1wXL5YB5dprZUgDTDUvgHfXvqhrXiwpNS8XLsi+RpMmyfCsVZ9/Lr/v2eN7Q6XXrzfdfvlleQ7+/NNjxXEJpeYlKTqpVvvHNIpBx6YdAQA//flTDXtTQ8fw0kCph6wePeqe11SajFq1sn7MMryoa0CWLgWefhro2LHmEUmzZgHx8fLToPoCsnu3vLAqfVwsKTU848cDsbHAf/9bm3dkW06O/P6Pf5i2KTUvALBzJ/DWW95ZA1NdzYs6vPznP/IcpKfLDrwnTtQc6o4ftz2ayVPUgdTXal7WrTPdfv99oFMnORnh9OmeK5OzOVrzAgDXtL8GAPDj3h9dUiZyH4aXBkodXo4ccc9rKuFFqY1QU4eXvDzzQPXvfwPPPQfs3Sv7yqj/cSpOnZKPz54t39vllwPBwTLIPPIIsGWL3O+KKwA/G7+Vt95qGgFTXi5rBf76SzYxLVvm2Pu0XBIAML/QDRggj6/MOutNahtejh0zbQ8NBVq0kN8HDbLdB6uwUP5M27dvOMFAHUgta+u8ebRRZaWpFvOaa8wfmzvXum+ZFhWVFBkXZaxtnxcAGHz5YADAR1s+wvni8zhddBovrXkJK7Zz0UatYXhpoNThRWnOcTYh5EVKmVNFeZ2awsuePfJ2s2a2mx8efND6U/qAAbJmRq2qSr7P114DVq6U23r1sl3Wbt2AVauAkSPl/TNngObNgdWrZd8bR1y6JL+rL+D+/qZwpFzgX33VseNqQW3DS16eabtSa1FZCaxdCxyw0d/x999lQDAYTBdOT1OHYMsyN5SA5QoHDsj+a6Ghstlv505ZK/bPf8rHH3/cs+VzBqXWJSosCo1CGtX6ecO6DsPlzS7H+eLzWLBuAQa+MhCP//dx3LLoFmQdyKr5ANRgMLw0UOrwYjn3irMsWgQkJQFXXSU7B+/dK7fbCi/xfy/aWlpqqiXp1g2YM8f0+J49sklnzx7zZp1Tp6w7DV59texMCMjwpIz+qW4OmSFDZD+G9HTrx5Rp/mtDuYCHhpq26XTmtS+AvIA3hKYjIWRz2ZNP1v9YtQ0vyszDgAxx586ZAqytvhPq39GG0k9GvcikErgV3hxelGbRLl1kKO/SRQZ9JbTs3WsK8Frl6BwvCj8/PzyWLkcAzPhqBn47/hsAQAiBf339L+cWklyK4aWBUoeX3btdcxH98EP5fdMmOSpj1Sp531afl5AQGXQA2WkWANq1AyZPBr78Uh6jQwfg5pvlY+oLnPLPVG39euCZZ6yHctqreVGbMcN629atNT9PYe8Crm5mULhrpFd1Dh0C3n1XNs+dPVu/Y9UmvBgMwL598vb+/cDUqbKJTZlAUB1sFPv3m25/8YX9GZLz8+XviztWr1b/Df31l/weEiK/uzO8nDvnnhmjFb/J67FxGLwiJkY21QINq2+SosqBf3LKHC+17ayrNip1FCJCIoz3x/UbBwBYn7sep4vcNDqC6o3hpYFS/+O9cMH84lAfZ8/KT/Fff22qQbnnHtOqygBw2WW2n6t0pP35Z/m9bVtZYzFihGl6/WbN5HflYgFYh5fnnzfdVuaPAYDWrU3Pr85VV8mLwWefmS7CGzbU/DyFrWYjwPSPXU0Jap6kvtDXd5LA6sKLMhHh1q2yhi083DzItm8vv3/3nfXFWP37uXOnrL174w3r15g4UQbc5GTZ1OQqFy+aZg1Wa9xYfndXeMnOlrWRkye75/UAUw3q5Zebb9fpTDWozphywFmqqqqQNicNHZ7uAENx7WZIVGpMHOmsqwgLDsNLt7wEAIhtFIv5Y+aje2J3VFZV4pudXtAhyEcwvDRQlv9cnDWzbUaG/BQ/YoS8AF1xhZyzJStLdpx980374cWyz4oSWNRshZdffpHfn39efmpXt7knJwPDhsnbc+c69l5GjwYWLJC3v/9efjcY5IR21YUZexfwFi2s933tNecFx7pSB9nt2+t3LOWCXl3NizLrbu/estlBofxerFsnf2fUlGZBpcnxyBHZx+LCBdM+QpiCb1GR7Kvkqo6z9haYVFYPP3/ePVMQZGTIWlPl99RZtm6V89hs2wZcf71sUlVq5ZRas3btrJ+nNP01pJqXdbnrkHUwC/sK9uG1/71W4/7/zf4v3lz3JgDHm40UE6+aiGUTl+F/j/4PESER+L8e/wcAWJ69vE7HI/djeGmgTpyQ35WLQZaT+pIpTUMKpRakQwfglVeABx6w/1zLIcyWn+wA8/BSVSVH7Xz5pdw2ZIi8AAZYrKj10UfyoqZ0xnXE0KHy+/btcj6Y7t3lUgLjx9t/jq0+L4B1c1nnzjIMvf224+VyJvWFuL6dYWvTbKQskdC3r/njyrkGzPs07dghz39AgAyNS5bI7SUlcgi9Ukvz11+mC2xYmJwfSNnX2ZT3aUkJLy++KJdEcPUq2uqO686cP+jWW2Xz6RVXyOC+Zg1w113yNZSwbevDhVLz0pDCy9JflhpvP/vds/h+1/e13r954+Z1ek2dTodRV4xC1xZdAQA395Tt3d/t+g7/9+b/1emY5F4MLw3UcbnaO+6+W35fubL+7eaffWYaddGihZzHw5EZcpWJ4gDZzJRo40OPOrysWCFfA5D79uhh+7h6vfWFsrbi4kzztTz+uGnE1P79tjuWVlWZJiyzvICrw0tIiKyJAkzNa65QXl5zE4b6ArtsmVzzqa7NHrUJL4rUVPP7sbGm/hQ//WQKOcqorJEj5c/5rrtMnbHnzwf+9z95e9cu+b1TJzlkHpAh88036/ZeqmM5KZ1CCS8KJVi7inqI9sGDzjnmp5/aHvH17bfyb+zSJVljVl3H+4bSbFRZVYnvdsm22cToRFRUVuD616/Hjf+5ETuO2q5uzj1p6nQ1rOswp5Tj8maXo3PzzgCAr3K+4gy8GsDw0gAVF5s+oY4fLy+kBw/a7vhq6cwZWaU/ZQowapS8XVEh/7Hdeafc57HH5BDpiRMdK5f6Ynbpku2Vh5v//UEoP1+WQTF3rutWKv7oI9MIpG7dTH0z1IsvKtQXNcsLuPqffUSEXEEbkFX0Slg4f955nS/PnZOdoIcMqX4/y9qB99+X4aEuHAkvLVta79O5s6yxKC6WF/7+/eUkhQAwbZppv3/9S+4LmPoNqUfBPPywHHEGyN8TZ0/EaC+8KH1eFDt3Ovd11YQw9T8BbHd0ro3CQtm5/rvvZPPTbbeZHnvhBTmab+VKWZOozHbdqpX16Dmg4TUbbTu8DacvnEZkaCT2zt5rbL75due36PlsT9y75F5UVpnaFgsvFSI3X57IglcKENMoxinl0Ol02DJ9CyJDIwHIpixq4ISXMRgMAoAwGAyeLkqd/fmnEIAQjRoJUVUlxKhR8v4999h/zurVQmzbJkRystxX/XXDDUL4+cnbt9wiRGVl3cs2YIA8zkMP2X68slKIwEDTa7dvL8T583V/vdoqLhZi2TIhzp0T4oMP5GtHRVm/9qlTprJVVJg/9tVXpsdat5bvRa+X93NyhPjxRyFCQoS4917nlHnZMtPrHTtmf7877rD+mc6a5fjrVVUJodPJ5+flWT++fLn5a5w6Zfs4Awdal2fwYOv9Pv/c9Pi+fUL83//J2y+9JB8vLxeiWze57emnHX8/1Vm7Vh43JMS8nI88Yn6/f3/nvq6a+ncNEOLFFx0/xsqVQoSFWZ/voCAhvvvOfN/du4VIS5Pv+bnnbB/vP/+Rzx8xQt5fulTePnLE8bLZU1JWIu7/6H7x3qb3atx3yqdTBMZDjFw4UgghRFVVldj9125x29u3CYyHwHiIxT8tNu7/9Y6vBcZDJD+Z7LwC2yjPHe/c4ZLjU/UcuX4zvDRAP/4o/8F06CDv//yzvK/TyQuMpexs639uQ4fK0KLe1quXEKWl9SvbuXNCvPGGEBcu2N9n0CDTa27aVL/Xq4uKCiFatZKvv2qV+WNHjpj++Vv67TdTubt2ldv69JH31RdiZ0X+p582He+jj+zvl54u91GHmAEDaj5+VZUQr7wig8WJE0JcumR6vq0/jzVrTI8HB8vn2zJ5smm/Ll2EWL/e9u/VmTPyOEoYjImRt3/6ybTPJ5/Ibe3a2X+9uvjuO3ncyy83/7lNn25+Py7Oea9pyfLv0pHQu3ev/HtVntumjRABAaYPIHU9V5mZpp9HVZUQERHyfmSk7UBbFwvXLTQGj8OnD4vX174unv3mWXHsjCmhn794Xjz7zbPG/X744wer48xbM09gPESLf7YQWw5uEUPmDzHu//CnDzunsBa2HNwiMB7Cf6K/2H9yv0teg+xz5PrNZqMGSOnvoox+6dtXNh8JIft1qEdwANbr/MyZIzvmfv010LSpafudd9qey8QRUVFyBl1bM+sq/v1v2dR11VV178tSH/7+siMjYL1opL1h0oD56Ayl2UHZpp7vJcY5NdVmx6xuSLay0vett5qaObZvr7n56quvZFPOmjWyv5O6E6tlZ2XAvNmoRQv7zXxKsxxgav6x9XsVHS37u0REyGbPM2fkzyYlxbTPsGFyiPq+fc4dOq38/CwXGLXsLF5QIEc+uYJlU5gjzUb33Qf8+qu83a+fnGQvO1suWfHee3VvglWafg8elIMAlPdeWCib89q0kc1S9vpUfbD5A1z78rXYesj+xEofbfnIeLvVk60w5bMpePrrp3HZ05dh+orpKC4txvA3h+Ppr58GAPRI6oGBHQdaHefBax5Ek4gmOH7uOHq/0Burf19tfOyWlFscfOe10yu5F9I7paOyqhL3f3y/S16DnIPhpQFS1jJSd4idN0/+4z1wQF4M1B0Bv/pKfm/SRI7uUeaU8Pc3TQkOWK9z4io9esiJ1b7/3nX9XGqijIT65z/lhHjKhb66Ph/qC7oy2ksJL0qnU8B8Tpz6UF+sv/jCfr+Pc+fk9+hoGRwCAuTPXymjPeqJ+377Ta4/Bcj3bqs/hDq8VXdBb93adLtfv+rL0K+f+dD47t3Nz31EhKm/0gonLi+jhJeQEFPfGsA6vACuGwqv/B23aSO/1za8HDxoGur/ww9yaHpgINC1qwyjynw8dREVZRo1+OKL8nvz5vJnevq0fO1PP7W9hMAvB37B3e/fjXW563D3+3ejotI64RSXFuOXA7+YbWvdpDW6tuiKS2WXMPf7ueic0dm4qnO3Ft3w9YNfQ2fjH0VwYDAmXT3JeL9ZVDP8+x//xqI7FqFf2xp+8erhzdtlD/LM3ZnsuNuAMbw0QMqoBHUH0shI+clboYz6yM2Vn8oCA+Wn14ULzT9BT51qWjixUyeXF90oIcF2QHAX9TDua64xzcpbXXhRU+ZDUYabqocoW65QrDh3Tg41X7u2dmVUalSSkuQn3a+/tr2fsvRBVJSs4VBChmWtkiV1GPrwQzlnDSBX9ralSRPTbVs1Mwrl03ujRua1MPaow8N111k/rowWW+7EKTbU4eWNN+TPe+xY2+HF1qg0Z1DO/8C/KxVOnTIFUXuyskwzGV97rRwNaCto1oeyBIfyoWfCBFmT9+67phmyX31V3lf7Osf0C7o7bzfe+/k9HCg4gMOnDxu37zy+E1WiCnERcXhr7FuYeNVEZE3PQs7MHLxxm5y18NDpQwCARwY+gpxZOdVONPfIwEeMt/91w7/w+JDHcd/V99kMO87SNq4tosKiAAAFRS4eS091xvDSACnrxKg/4QIymCiThikTUSn/gK691naNgE4nP0XZmlLfm/XsaV7rozSlXXmlvG/v4qw0MyjPtXVxVoYIW/rqK/kzGjSo5vlYiotNF9hb/q4Bt/WcqipTLZtSNiWE7t4tR/BYrpisUK8MrRzrxhurX5hvxw55cbOchE4tLs40FL021xClCQ8A+vSxfnz4cBkqdu0y/V7Xlzq8dO4s16lassR80j2FekSQMynhpVMn09Ia1f1eCCGbbP76S9aOLFzomnJZLsExbJj83zFunAyQGRly+/33mzdtZu6Wi1altpTp9b6l96HtjLZInp6MHrN7YG/eXmw/KmdRTGmZgolXTcRbY99Ck4gm0Ol0mHT1JDSPMs3LckPXG2osa+Pwxtj4+EY8P+J5jL+ymsmbnKxJI5nkTxWdcttrkmMYXjysrEz2R1APh7VV8wLIfiaT/q5FVT4tKp/yb7zRteXUmtatgW++kU0nyjm7QfW/0t4aQZmZcri1MmNv9+7W/Xbs1byop/G3nAzQkjK7a1CQqWbC1oXtwgXTulZKeOkq59XCtGmyic5yQr7CQhlqlGYLQF60b7655gn3uneXn/6vvbb6/dq0Me9PVZ2QELkI6OTJtn9PGzc2vZ6t2pd582TodGRdJ+VnpCz5EBkpV5m2VfOydKlrlgtQ5hxKSjL9jNXNj5ays+UHl/BwObeQvZmu60u9+GnTptbzL82cCdw4+i+k3LEAe8uWAZA1KtuPbodOp8OKB1agfztZPeSn84Ofzg85x3Lw2BePIfuI/CXukWQ9qZO/nz/evP1NxDaKRbcW3YzHqMmV7a7EUzc8hcAAJ1dBVaNJBMNLg+eGDsRupbXRRvPmyd7+TZoIcfCgEB9/bBphYKv3//z58rGbb5ZDTcPD5f1du9xfdq04edI0UqMuI4ZycsyfFxxse7+ZM0373Hmn3Hb+vBATJwqxYoX5vtu3y/2aNRPi+HF5289PiIsXzfdTRkepX/PYMSFCQ83LdOmSfGz3buuhtbm57hmuXh9vvSXLmpZmvr2iwvQ+nn229sd74QX5nHHjzLcrfz+AEG3bChEbK29//XX934NaVZWc6gCQPxNl+H7r1vZH9Tz8sNxn5EjnlsVSWZnpHPznP7b3WfDj2wLjIfq80EecKjwles7uKTAeYvRbo4UQcjj0F9u+EMfOHBO7ju8SGA/hN8FPBNwXIDAeYtXOVbYPrBEj3hghMB5iwboF1e53uui06De3n8j4OkP0fr636PNCH45SqgeONnIBg0FW43bpIj+ZO2vWVWUitVOn5KRoykKFERGm2TDVlP4O+/bJT9cXL8pP5O7sz6I1cXHmU9s7qls3ObusorTU9kgfdfONMgPqG2/I2o6bbzatGQSYal5iYuSsxHq9rGFRPq0rlP4u6ibBFi3MJ4QDZI0RICfss5wav3Vr53UydhWlM/n27ebT6Ct9uwDzmqSaqJuN1NQ1L7GxpgnfVq6s/bFr4/hxWWsWECD7TQ0ZIvsIHTwoazssa9ny84HFi+XtceOcWxZLgYGyVvLNN+XIQVuGd78eAJB1MAupz6di+9HtiAqLwjPDnwEgO9PeknILWkS3QOfmndE7uTeqRBUqKisQFhSGazq4aXSAi9S25uW5757Dz/t/RsY3GdhyaAuyDmbhmnnX4GRhA5kF0IsxvNRSRYXsjPn773K4ak2jLGpiMMjqavWaRcqsl1dfDXz8se3+BEpV8r59ptEkvXvLKnGy76WXZDCcPFk21cyZ49jzLdfhsbVOjXqEzv79MuC8/75p248/mm4rTUyxsfLnrCxNcPiwDLLKsdSdddWeeMJ8ram775bPVTr9jh4tQ9FNN9luKmlo2rSRTTulpbIDumL9etNtRxalrE14CQkxLQr67bc1Dz13hLJQZbt2MizExZk3iX36qfn+d98tQ2dqKjB4sPPKYc+wYfL/mb0+S80bN0e3Ft0AAEfOHEF0eDR+fuJntE+w3UP7zrQ7jbeHdh6KkMAQm/tphRJeauqwu+FP6xVgj509hnc3vmtjb3ImXvJqKSZG1rooKivrPsRyzx75z/rOO60f69hRDo2014elVSv5D7ikxNR+bmuBRDLXvr2slfjPf2QwePJJx54fF2e+cKStfi/qmpeTJ4HNm83XoFHXqqhrXgBTeNm2TQ6RV5YmsBdeIiJkkM7Lk31gzp6VvzN//CH7tyxcKD/9u3rtHmfx8zP1vVCHFHWH0Z07TfP01MSyz4tCPR9NaKj8oBAWJn9eNY3eqq2zZ01LPqhXYk9Pl2tTAbJPlBKW/vhDzsUTGAh88IHnphewdP8AOc/J4MsHI2t6Fjo1s1+9O6bXGMQ0ikGCPgGvjHrFXUV0mbiIOADV17xs3r/Z7vpLmw9sdkm5yIThxQGWa73UZbXh776TTTzqzp1vvGG6PXVq9f+8AgJMHXm//VZ+r81wVTKp60R96gthTeEFMI1sUqjDi7rmBTCFl9dfl8f+4w95obYXXgAZUhISZECJjDTNG3P11bITrE7XcC6EtaGMSlJ3at2hujZUVNRufS/Afs2LeoLBkBD5u6DUoq5bJ5vu1q0zDZWvC6WzN2AaBq5Qhj7v2SPXKQJMgWbIkIbV/DvxqokoW1iG1VNXo118u2r3jQ6PRu6zudgzew+SYpLcVELXqU3Nyxvr3rDa9o+e8gf+y8FfIJxZlUdWGF4cYFlT8sEHjlU1b9oEjBghbwcHy6ahTz6R1bdpabIG5Y47aj6O0nSkXEDVzQfkOv7+pqG21YUXy9CirAxeXc2LEozVoTYvr/rwomjdWg7TVkLZTTfZ37ch+z+5Jh8++kgGin79TMOYlbll1BPvVcdeeFH3XVKGyyv9bdavB+65R458UiZwqwtlgrkHHjBfRBGQofL55+VtZTVuJaxZBh1P0+l0Do3wiWkUY5wfRetax8p5Kvbm2x9Hf/ycnApdqaUBgNt7347ggGCcvXjWOJ8NuQbDiwNGjpQd3Q4ckFXNBQWmtu2a7Nwp+yFUVMh5FjZvlv/Ybr1VfjrevFnuU5uJ3dpZfAhieHEfpfbFVnhR+qk8+aQcnn3NNfLTtDLHzsmTpmYPezUvan/9VbvwAsjX+u474KGHrIdOa0Vammluo82b5RcgO64PHy5v//xz7Y5Vm/CiPDZggPy+YoWczA8wfXeUEKZ+OvZWC58wQf7NHzggO+ru2iW3q1dtJ8/q0qILdDod8g35KCi0Xfty+oL8BDLrxlkY3m04pg2ahhu63oAEvVy6m8OsXYvhxUHDhsl/sEqfhA2q/lq7d1uPFgFk5870dHkxatFCjjrp2dN6v9p2ulXP/xIebj4zKrlWdeFFqXmJi5N9Tn78UTYhtGljmvVYmTjOsuZFPZGbIi/PFHKio2su28CBstnJkzMb14dOJ5tCFy2SM0LrdLKmKyNDNrcAskNyQfV9KAHYDy/qvxXl7y011XqtrroGiZ9/lp3pQ0Pl2l62REXJifMAWfNaVCRrzVw1rws5Ljw4HG2byOm1fzv+m819lPByZbsr8fXkrzFv1DwEBQShcVhjAMDZiw5MTEQOY3ipI2XSKWX46969stmnf3/Zbr59uxweu2KFHMZ68qRs6964sf7DVpNUTcotW2qrX4PW1Sa8REaab9fpTOHj7Flg7lzT0GalJkBZhFPtr7/kFyBHDvmCjh3looQzZsiAd+yYrMXq3VsGvNJS4K23aj6OvQ676r89pV9LYKB1U5+9iQhrovSDu/326v/OlX42yiy6HTs6fxkAqp9uiXK01bbD26weq6qqMoaT2EaxZo9Fh8s/9nPFNawFQfXC8FJHSr+Cr7+Ws2K+/LK8f/y4rAa+8UbZkfIf/zDN7Dpxou3mAUdZhhdyH3vhRQhTeLG1cJ6y7amngOnTTdvVHUjV2wHz8FLb2Wy9SXS06X3rdLIzOyA7utYULuzVvKhrN9Wdcu+913y/2o5qUisrM80Xo/RzskcJL8qIRaUmhhqO6zrIhbiWbV1m9ZjhkgGVVZUAgJhw82XmWfPiHgwvddS1q+kfTq9e5mvBTJ9uuuiojRrlnNdWrzZtayI7ch174eXSJdM0/pY1L4ApvKxbZ75d3QcjI0Mu96DMQeOLNS/VGTlSnof8fNMIHXvshRe1CxdMt2+5xdSZXv382qqokJ2mDQb5N2lrDSc1y3milAVAqeEYdcUoBAUE4bfjvyHrQBayDmQZRxApTUYRIREIDjSv3lPXvFQp/xTI6Rhe6uG99+RF6fRp81FHylDJ+fPN19Op78R2CvUFTwsTkHkTe+HFYJDfdTrr/hOA7doYwLzmJShIrrqshNMTJ2S/F4DhBZDNKpMny9tvWI9SNeNoeNHpZE2pMv2Ao+Hljjtkh3xAdi62tQCkWqtW5j/TNm0cez1yvejwaGPtS9rcNKTNTcM9798DIYQxvFg2GQGmmpeZX89E3KNxOHSKo45cgeGlHq64wv6ohEaN5Eii11+XnXPffrvmf2i1pe7jonQEJfewFV6qqkx9WGJibPdBshdebNXSKBe1P/4wvY4vNhvZMm6cPL9bt5qCnS3KebMVXpTAeN111o8pw6cdCS8VFeY1QeoaHHt0OvMPMwwvDdPQzubrinzwywfYdnhbteFFqXkBgDMXzmD2t7NdW0gfxfBSTzfdZPrEde+9ciRQSorsyBsXJ0cmZWfL4ZHONGuW7OT52GPOPS5VzzK8/OtfMpTedZe8b68Zz17ItBV0lPCijKqJibHueOqr4uPl3xdgvlaUJaXPiq3ztn27XNfnX/+yfkwJO470edmrmgokNtZ2KLJFPcKM4aVhGtrFelG0D375wDh8OqZRjNXjjcMbm903XDK4pnA+juGlnnQ6Odncxo1y5MDBg3JKc2UotatkZABHjwLNm7v2dciccnErLZUXLWXCMUVcnPVzAPs1L7ZYNhGx1sWcMn/K6tX291HCh1KTopaUJCeQszWkXPn5OlLzoixhEB8va4RqGzTV/WLs/d6QZ7WNs+6M9M7Gd/DpVrk4Vft46+nNlWYjxaXyOvT+phoxvDiBv78caunuoY4cIu1+6pqXefOsH7dX86IOL8qIl65d7e+rrqlhfxdzSnj54Qe5xpgt1YWX6jgaXt56S87KCwBjxzo2mrB/f9mc/P33/FtuyLondjfeHtJ5CEorSvG/PXJa5CvbXWm1v7rZCAAulFyw2ofqzy3hZcGCBUhOTkZISAhSUlKwcePGavffsGEDUlJSEBISgtatW2PRokXuKCZRjZTwMm4c8M478vbjj5ser014efBBuVSEesVkS+rAwvBirndvOYfK2bPmCzeq1TW8KPurm42EkAt6Dh9uWvkdkCvCT5okb/v7m247YsIE+zPxUsPwxaQvcGXbK7Fqyiq8OupVs8f6tbEehdFUb15VqiwjQM7l8vCybNkyTJ06FTNmzMCOHTvQv39/DB06FEePHrW5/6FDh3D99dejf//+2LFjB5566ilMmTIFy9XryRN5iGWTwPz5phEwgPlIMDV1eGnZUnbWbNzY9r4Aw0t1AgJMM+7aajqqrJSzWgP1q3lRRhB+/jkwZYpcGiQhAXj4YdmvRd00PG8e+614q7ZxbbHxiY0Y2mUoOjTtgJnDZqJxWGOMvmI0mkZZt+leFm8+VfKxc8dQUVnhruL6DJeHl1deeQX33nsvxo8fj44dO2L+/PlITEzEQmVqSQuLFi1CUlIS5s+fj44dO2L8+PEYN24cXlZmgbNQWlqKwsJCsy8iV1GHl1tukRcydZ8Uewt1qpuBajOxoLLGD8DwYkt1/V7UtSZ1DS9VVXIUEWDdMfj11+XSD4rDh+XvAfmGZ256BmdfO4vPJn5m8/EAf/P5KyqrKnH4zGE3lMy3uDS8lJWVITs7G+np6Wbb09PTsVlZdc3CL7/8YrX/4MGDsW3bNpQrH6dU5syZA71eb/xKVM/gRuRk6vDSv7/8rp5rx15nTcual5qoR6IwvFhT/kX8+itQXGz+WH3Ci3p/pd+LZdPUXXeZhluPH89ZrsmaPtR8bYi9efZXp6a6cWl4OX36NCorKxFv0REgPj4e+fn5Np+Tn59vc/+KigqcVlazU5k+fToMBoPx65iy8h2RC6hrRNRDYp97DujRw/6QeHWocTS8JCQ4VkZf0KKFDIRVVXLUnZp6mHRtFztVqH9Oly7JYPTHH/L+vHly0cglS+TElH/+KYdcE1la/fBqdGzaEREh8lPL3nzPh5fsI9l448c3vGbWX7fMz6qz6EovhLDaVtP+trYDQHBwMII5CQa5yWOPyRWH9Xq5EKdixgz5ZU9Rkel2bVYB79LFdNvWoo2+TqeTI3t27ZLNNh06mB6ra2dd5bjBwXI0WUmJnEW7slIOr542zXzfdu3qWnrydn3a9MHu2buRsTIDz3zzTIMIL2lz0lBeWQ4hBB667iFPF6feXFrzEhsbC39/f6taloKCAqvaFUVCQoLN/QMCAhATYz0hEJE7+fvLGpfUVMeeN2SI7KA7dGjthsUGBcl+FZ9/br6WFZkoNVhHjphvr094AUz9Xt5+27RY5qxZdTsW+TZlHph9Bfs8XBKgvFJ2u1i4wXZ/U61xaXgJCgpCSkoKMpW50/+WmZmJvn372nxOWlqa1f4//PADUlNTEcg140mjoqPlWkXK2jm1cc01cjFCsk2ZU+XwYfPt9Q0vyvOUCQjHjat5lWgiW1o0ltWmf523sVKvh+zJ22NszdAyl482mjZtGt555x2899572LNnDx555BEcPXoUk/6eFGH69Om48847jftPmjQJR44cwbRp07Bnzx689957ePfdd/EY58EnjQsNdbwPBtmnhBdX1bwAQFSUnOOFPzeqi2ZRsrf9X+f/8nhgaBRsGvL4x19/eLAkzuHyPi+jR4/GmTNnMHv2bOTl5aFz585YtWoVWv5d55uXl2c250tycjJWrVqFRx55BG+++SaaNWuG119/Hf/4xz9cXVQi0hCl2cjZNS/qWXunTbO9jABRbSgT1hWXFaPwUiH0YfoanuE66j6j3//+PTo37+yxsjiDTng6DjpZYWEh9Ho9DAYDIm0t2UtEXmHbNjkqq1kz2SSn+O9/ZXNb//7ATz85flx1n6TycvOh8ESOavxwY5wvPo/ds3ejY9OOHitH0KQgY7+XQZ0G4YdHqlnZ1EMcuX6zMpSINEmpefnrL9Mq30D9a14UvXoxuFD9NY+Sq+d6st9LZVWlMbgAQNbBLFRW2VkYTCMYXohIk2JjTU066rlelEnr6hpeFi2So8n++9/6lY8IMO/34ikl5aaVRnU6HYpKijTf74XhhYg0SZnrBQB27DBtr2/Ny333AVu3cog6OYfS7yXPkOexMqjDy9WXXQ0A2Lzf9iz3WsHwQkSapTQdjR4tJ6wDnNdsROQM0eHRAICzF896rAxKeAnwD8BV7a4CAGw+wPBCROQRvXqZbo8bJ4MLwws1JI3D5PLx54rPueT4tZnuXwkvIQEh6NtGzrHG8EJE5CEzZ8pVn6Oi5OijJ54AlAXrGV6oITCGl4vODy8fZX2E6KnR+GTLJ9XuZwwvgSHo3bo3AODAqQPIO++5pqz6YnghIs3y8wMGDQKWLpX3//MfuWgiAHCmBGoIGoe7ruZl8cbFMFwy4PZ3bsfJwpN297tULqsjQ4NCERUWhZSWKQCAVbtWOb1M7sLwQkSad8MN5gtlXncdp/SnhsGVzUbhQeHG29lHsu3up242AoD/6/F/AIAlm5dodpVphhci0jydDvjsM7mA4o8/AmvXypWgiTzNleHFcMlgvL2/YL/d/dTNRgAwKnUU/P38sWn/JixYv8Dp5XIHhhci8gqdOwMZGXJBS6KGwths5II+L+pAdODUAbv7WYaXdvHtMPmayQCALYe2OL1c7sDwQkRE5CJKzcv5S+ed3kSjDi/V1bwofV6U8AIAPZJ6AAAKCgucWiZ3YXghIiJyESW8CCFQWFLo1GOra3Nq02wUGmgagtckogkA4NSFU04tk7swvBAREblIcGAwQoNkaPjpzzqsFGpHSXkJSitMi3r9efJPu0sQWDYbAUBcRBwA1rwQERGRDfER8QCAe5bc47RjKrUufjo/9E6Wc7d8teMrm/vaCi/qmhchhNPK5S4ML0RERC707l3vApBLBOQb8p1yTKW/S1RYFG5JuQUAsGLHCpv7llTYCC+NZHgpqyhDUUmRU8rkTgwvRERELnRtx2vRIaEDAOC3Y7855ZhKeGkc1hg397wZALA+dz3OXDhjte+lMusOu2HBYQgPlvPEFBSZNx3tL9iPP/P/NN5/5YdXkPxkMg4U2B/R5G4ML0RERC7WPbE7ACDnWI5Tjrf18FYAMry0btIaXVt0RWVVJX7c+6PVvraajQBT7cupIlOn3cqqSrSb0Q7tn26PsxfPIudoDh794lEcPnMYy7Yuc0rZnYHhhYiIyMWUocnOmFel8FIhnv7qaQDAoE6DAABtmrQBAJy+cNpqf2VbdFi02fa4yL877apqXi6UXDDe/m/2f3HdK9cZ7yvNTw1BgKcLQERE5O2uvuxqALJpp7KqEv5+/g4fo7KqEpM+moRdx3fhQukFXBZ/GWbfNBsAEBESAQA2+68oo5CaRTUz226r5kWZEwYAZnw5A2cvnjXed1Z/HWdgzQsREZGLpbRMQWRoJM4Vn8OOozvqdIyth7binY3vGGtvbut1GwL8ZR1EZIhcibTwkvVcMn8ZbIcXpebFLLyUmcKLUmOjzFWTX8jwQkRE5DMC/APQq1UvAMDvJ36v0zEulF4wuz/uynHG28aal1LHa17UzUbqmhfL12lINS9sNiIiInKD+Eg538uZi9YjgmpDPUPv8vuXIzE60Xg/MtR2zUt5RbkxnDSPam72mK2al+KyYgBy/pinhz2N5lHN0bVFV8z7YV6DqnlheCEiInKD2EaxAGx3qq0NpT/L4MsHG4dHK+z1eTlZeBJCCAT4BxhfX2Gz5uXvZqO2cW2RMTwDAHD0zFEAsuZFCAGdTlen8jsTm42IiIjcoL7hRalVUfq3qCnbLMOL0t+lqb4p/PzML/k2+7z83WykXgdJqTEqryw368DrSQwvREREbmAML0X1q3lRalnUlG1nLp4xm+7f2N9F38zqOcYlAmw0GynrMQFyfaam+qYAgAOnGsZEdQwvREREbhAbUc+al7/7vCj9W9SU8JJ9JBsj3hyB8opyAPY76wKqxRmLCoyBR2k2CgsKM9v3svjLAMgFIBsChhciIiI3UGpe6tpht7qaF3VT0srfViLo/iC88N0L1YYXpTzlleXGY9tqNgKA9gntAQC5+bl1KruzMbwQERG5Qb37vJTY7/NiK9A8+92zpjlebDQbhQaFGpuHlDWRjOElyCK8xDO8EBER+ZyY8BgAMihUVVU5/Pxqa15UTUlXtLoCgFzT6OhZOVLIVs2LWZn+rg1S+rzYazbaV7DP4XK7AsMLERGRG8Q0kkGhSlTBcMng8POV0UbVddgFgGeGP2O8rfRRsRdeosPlekfKKCKlz4tls1HrJq0BAIfPHHa43K7A8EJEROQGQQFBCPQPBGCq4XCEUvNiq9koPCjceDutTRqCAoIAAMfOHgNQi5qXGpqNWsa0BACcLz6P88XnHS67szG8EBERuYnSHHOx9KLNx/cX7MeAlwZg2rJpqKisMHtM6fNiq+bFz88Px/59DAdfOIiosCg0Cm5k9nhCZILN11NqgyybjSxrXsKDw41Dq4+cOWL/DboJwwsREZGbhAfLGhJ1zUt5RTlKyksAAI9+/ig2/LkBr659FYs3LjbuI4TAueJzAGyHFwBoEd0CyU2SAcAsvPjp/IzNQ5aU7caaFztDpQGgZbSsfWkITUcML0RERG5irHkpM9W89JnTBwmPJqDPC32w8reVxu0b/txgvP3LgV9wqugUQoNC0S6+XY2vow4vMY1irGbXNT5m0WHXXrMRALSKbQUAOHz6cI2v72oML0RERG6ihBel5uVCyQVsP7odhksGbDm0BQCQFJ0EAMg6mGV83tKspQCA0amj7da8qKn3UdYwssXYbGRR82LZbAQALRq3AGCa+M6TGF6IiIjcRGk2Uvq8nCw8aXxsYMeB6Ny8M75/+Hv46fxw5MwRnDh3AgCw9fBWAMANXW+o1es0CjHVvCh9VWyp7VBpwNQpuC6djZ2N4YWIiMhNLGtelPDSKqYVMqdlYlfGLnRq1gmprVIBAGv+WIPyinL8fuJ3AECPxB61eh11s5GyDIAtSg2NEqaU5ixb4UVpSlKaljyJ4YWIiMhNlNoLy5oXZeVmxZDLhwAAvv/9e+SezEVpRSkiQiKQHJtcq9dRh5fqal5CAkMAwNhhOO98HgAgQW89OklpSlKaljyJ4YWIiMhN7NW8WIaFYV2HAQC+3fkt/rfnfwCALs272O14a8msz0ttwktFCYQQOHFeNlPZmheGNS9EREQ+yF54sax5SW2Vit7JvVFSXoIZX80AALSNa1vr16lLzYvhksFYruZRza32Nda8MLwQERH5DqsOu0W2w4tOp8PI1JFm+yqjkGpDCSUA0DOpZ437lZSXGEcRNQ5rbHOotLHmhc1GREREvsOy5kXpY2IZXgDTlPwKR8LL7rzdxtu9knvZ3S8kwBReqmsyAljzQkRE5JOMNS9lFyGEMM7t0qlpJ6t9Exsnmt13JLzcmXYnAOCGLjfA38/f7n5KbUpJeYlxWLatJiP1vg2h5iXA0wUgIiLyFeqalz9P/ok8Qx6CA4KR1ibNal/LsJIUU/vwMrzbcGx/ejs6JHSodj+l2ehS+SVjs1HzxnbCSwOqeWF4ISIichP1UOl1e9cBkKtAq/uoKCybkixrYqqj0+nQI6nmOWGU162sqsSRs3LBxWZ6O81GDajmhc1GREREbqKueVmXK8PLNe2vsbmveli0PlRvNmuusyh9XgDgwKkDALRR88LwQkRE5CZhwTK8XCi9gPW56wEAA9oPsLv/AwMeQGRoJNY9ts4l5QkODDbePlDwd3ix1+eF4YWIiMj3KFP1/7z/ZxQUFSAkMAS9k3vb3f/N299EwbyCWjUB1YW/nz8C/QMBAIfPHAZQTc2LqtlICOGS8tQWwwsREZGbdGvRzex+j6QeZrUfttT0eH1Z9rex2+dFtdJ0aUWpS8tUE4YXIiIiN9GH6dEurp3xfnUTyLmLOrz4+/kjLtL2Qo7qies83WnXpeHl3LlzGDt2LPR6PfR6PcaOHYvz589X+5wVK1Zg8ODBiI2NhU6nQ05OjiuLSERE5FY9W5oCS0MIL+oalfjIeLvzwgT6B8JPJ2ODp/u9uDS83HbbbcjJycHq1auxevVq5OTkYOzYsdU+5+LFi+jXrx/mzp3ryqIRERF5xCMDH4E+VA8/nR+uvuxqTxfHrOZF6ZNji06nazDDpV02z8uePXuwevVqZGVloXdv2Rlp8eLFSEtLQ25uLtq3b2/zeUq4OXz4sKuKRkRE5DG9W/fG4bmHce7iOSQ3SfZ0cczCS2yj2Br3vVh6EdNXTMe7d79rtnq1O7ms5uWXX36BXq83BhcA6NOnD/R6PTZv3uy01yktLUVhYaHZFxERUUMWFRbVIIILYB5eqluBGgDOXDgDAPgi+wuUlJe4tFzVcVl4yc/PR1ycdfVTXFwc8vPznfY6c+bMMfap0ev1SEys/QyEREREvs6RmhfF9V2urzHouJLD4SUjIwM6na7ar23btgGQ7WOWhBA2t9fV9OnTYTAYjF/Hjh1z2rGJiIi8nXqW3ZrCy1tj38KI7iPw0b0fubpY1XK4z8vkyZMxZsyYavdp1aoVdu7ciZMnT1o9durUKcTHWy/9XVfBwcEIDnbtGHgiIiJv5Uiz0cSrJmLiVRNdXaQaORxeYmNjERtbc7VSWloaDAYDfv31V/Tq1QsAsGXLFhgMBvTt29fxkhIREZHT1aXZyNNc1uelY8eOGDJkCCZMmICsrCxkZWVhwoQJGDZsmNlIow4dOuDLL7803j979ixycnKwe/duAEBubi5ycnKc2k+GiIiIpKiwKONtT/ZjcYRL53n5+OOP0aVLF6SnpyM9PR1du3bF0qVLzfbJzc2FwWAw3l+5ciV69OiBG264AQAwZswY9OjRA4sWLXJlUYmIiHzSg9c8CADw0/mhTZM2Hi5N7eiEp1dXcrLCwkLo9XoYDAZERkZ6ujhEREQN3pEzR5B3Pg992vTxWBkcuX67bJI6IiIi0oaWMS3RMqalp4tRa1yYkYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0heGFiIiINIXhhYiIiDSF4YWIiIg0xaXh5dy5cxg7diz0ej30ej3Gjh2L8+fP292/vLwcTzzxBLp06YLw8HA0a9YMd955J/766y9XFpOIiIg0xKXh5bbbbkNOTg5Wr16N1atXIycnB2PHjrW7f3FxMbZv346nn34a27dvx4oVK/Dnn39i+PDhriwmERERaYhOCCFcceA9e/agU6dOyMrKQu/evQEAWVlZSEtLw969e9G+fftaHWfr1q3o1asXjhw5gqSkpBr3LywshF6vh8FgQGRkZL3eAxEREbmHI9dvl9W8/PLLL9Dr9cbgAgB9+vSBXq/H5s2ba30cg8EAnU6HqKgom4+XlpaisLDQ7IuIiIi8l8vCS35+PuLi4qy2x8XFIT8/v1bHKCkpwZNPPonbbrvNbgqbM2eOsU+NXq9HYmJivcpNREREDZvD4SUjIwM6na7ar23btgEAdDqd1fOFEDa3WyovL8eYMWNQVVWFBQsW2N1v+vTpMBgMxq9jx445+paIiIhIQwIcfcLkyZMxZsyYavdp1aoVdu7ciZMnT1o9durUKcTHx1f7/PLycowaNQqHDh3Cjz/+WG3bV3BwMIKDg2tXeCIiItI8h8NLbGwsYmNja9wvLS0NBoMBv/76K3r16gUA2LJlCwwGA/r27Wv3eUpw2bdvH9atW4eYmBhHi0hERERezGV9Xjp27IghQ4ZgwoQJyMrKQlZWFiZMmIBhw4aZjTTq0KEDvvzySwBARUUFbrnlFmzbtg0ff/wxKisrkZ+fj/z8fJSVlbmqqERERKQhLp3n5eOPP0aXLl2Qnp6O9PR0dO3aFUuXLjXbJzc3FwaDAQBw/PhxrFy5EsePH0f37t3RtGlT45cjI5SIiIjIe7lsnhdP4TwvRERE2tMg5nkhIiIicgWGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFIYXIiIi0hSGFyIiItIUhhciIiLSFJeGl3PnzmHs2LHQ6/XQ6/UYO3Yszp8/X+1zMjIy0KFDB4SHh6Nx48YYOHAgtmzZ4spiEhERkYa4NLzcdtttyMnJwerVq7F69Wrk5ORg7Nix1T7nsssuwxtvvIFdu3Zh06ZNaNWqFdLT03Hq1ClXFpWIiIg0QieEEK448J49e9CpUydkZWWhd+/eAICsrCykpaVh7969aN++fa2OU1hYCL1ej7Vr1+K6666zery0tBSlpaXG+waDAUlJSTh27BgiIyOd82aIiIjIpQoLC5GYmIjz589Dr9dXu2+Aqwrxyy+/QK/XG4MLAPTp0wd6vR6bN2+uVXgpKyvD22+/Db1ej27dutncZ86cOXjmmWesticmJta98EREROQRRUVFngsv+fn5iIuLs9oeFxeH/Pz8ap/77bffYsyYMSguLkbTpk2RmZmJ2NhYm/tOnz4d06ZNM96vqqrC2bNnERMTA51OV783YUFJhazVsY3np3o8P9Xj+akez0/1eH6qp4XzI4RAUVERmjVrVuO+DoeXjIwMmzUdalu3bgUAm+FBCFFjqLjmmmuQk5OD06dPY/HixRg1ahS2bNliMwwFBwcjODjYbFtUVFQN76J+IiMjG+wPvyHg+akez0/1eH6qx/NTPZ6f6jX081NTjYvC4fAyefJkjBkzptp9WrVqhZ07d+LkyZNWj506dQrx8fHVPj88PBxt27ZF27Zt0adPH7Rr1w7vvvsupk+f7mhxiYiIyMs4HF5iY2PtNuGopaWlwWAw4Ndff0WvXr0AAFu2bIHBYEDfvn0dek0hhFmnXCIiIvJdLhsq3bFjRwwZMgQTJkxAVlYWsrKyMGHCBAwbNsyss26HDh3w5ZdfAgAuXryIp556CllZWThy5Ai2b9+O8ePH4/jx4xg5cqSrilprwcHBmDVrllUzFUk8P9Xj+akez0/1eH6qx/NTPW87Py4bKg0AZ8+exZQpU7By5UoAwPDhw/HGG2+Y9UnR6XR4//33cffdd6OkpAS33XYbtmzZgtOnTyMmJgZXXHEF/vWvf+GKK65wVTGJiIhIQ1waXoiIiIicjWsbERERkaYwvBAREZGmMLwQERGRpjC8EBERkaYwvNTSggULkJycjJCQEKSkpGDjxo2eLpJb/PTTT7jxxhvRrFkz6HQ6fPXVV2aPCyGQkZGBZs2aITQ0FAMGDMAff/xhtk9paSkeeughxMbGIjw8HMOHD8fx48fd+C5cZ86cObjiiisQERGBuLg4jBgxArm5uWb7+PI5WrhwIbp27Wqc1TMtLQ3ff/+98XFfPjeW5syZA51Oh6lTpxq3+fL5ycjIgE6nM/tKSEgwPu7L50Zx4sQJ3HHHHYiJiUFYWBi6d++O7Oxs4+NefY4E1eizzz4TgYGBYvHixWL37t3i4YcfFuHh4eLIkSOeLprLrVq1SsyYMUMsX75cABBffvml2eNz584VERERYvny5WLXrl1i9OjRomnTpqKwsNC4z6RJk0Tz5s1FZmam2L59u7jmmmtEt27dREVFhZvfjfMNHjxYvP/+++L3338XOTk54oYbbhBJSUniwoULxn18+RytXLlSfPfddyI3N1fk5uaKp556SgQGBorff/9dCOHb50bt119/Fa1atRJdu3YVDz/8sHG7L5+fWbNmicsvv1zk5eUZvwoKCoyP+/K5EUKIs2fPipYtW4q7775bbNmyRRw6dEisXbtW7N+/37iPN58jhpda6NWrl5g0aZLZtg4dOognn3zSQyXyDMvwUlVVJRISEsTcuXON20pKSoRerxeLFi0SQghx/vx5ERgYKD777DPjPidOnBB+fn5i9erVbiu7uxQUFAgAYsOGDUIIniNbGjduLN555x2em78VFRWJdu3aiczMTHH11Vcbw4uvn59Zs2aJbt262XzM18+NEEI88cQT4sorr7T7uLefIzYb1aCsrAzZ2dlIT083256eno7Nmzd7qFQNw6FDh5Cfn292boKDg3H11Vcbz012djbKy8vN9mnWrBk6d+7slefPYDAAAKKjowHwHKlVVlbis88+w8WLF5GWlsZz87cHH3wQN9xwAwYOHGi2necH2LdvH5o1a4bk5GSMGTMGBw8eBMBzAwArV65EamoqRo4cibi4OPTo0QOLFy82Pu7t54jhpQanT59GZWWl1WKS8fHxyM/P91CpGgbl/Vd3bvLz8xEUFITGjRvb3cdbCCEwbdo0XHnllejcuTMAniMA2LVrFxo1aoTg4GBMmjQJX375JTp16sRzA+Czzz7D9u3bMWfOHKvHfP389O7dGx9++CHWrFmDxYsXIz8/H3379sWZM2d8/twAwMGDB7Fw4UK0a9cOa9aswaRJkzBlyhR8+OGHALz/98fhhRl9lU6nM7svhLDa5qvqcm688fxNnjwZO3fuxKZNm6we8+Vz1L59e+Tk5OD8+fNYvnw57rrrLmzYsMH4uK+em2PHjuHhhx/GDz/8gJCQELv7+er5GTp0qPF2ly5dkJaWhjZt2uCDDz5Anz59APjuuQGAqqoqpKam4oUXXgAA9OjRA3/88QcWLlyIO++807ift54j1rzUIDY2Fv7+/lYptKCgwCrR+hql53915yYhIQFlZWU4d+6c3X28wUMPPYSVK1di3bp1aNGihXE7zxEQFBSEtm3bIjU1FXPmzEG3bt3w2muv+fy5yc7ORkFBAVJSUhAQEICAgABs2LABr7/+OgICAozvz1fPj6Xw8HB06dIF+/bt8/nfHQBo2rQpOnXqZLatY8eOOHr0KADv/9/D8FKDoKAgpKSkIDMz02x7ZmYm+vbt66FSNQzJyclISEgwOzdlZWXYsGGD8dykpKQgMDDQbJ+8vDz8/vvvXnH+hBCYPHkyVqxYgR9//BHJyclmj/McWRNCoLS01OfPzXXXXYddu3YhJyfH+JWamorbb78dOTk5aN26tU+fH0ulpaXYs2cPmjZt6vO/OwDQr18/q2kZ/vzzT7Rs2RKAD/zvcX8fYe1Rhkq/++67Yvfu3WLq1KkiPDxcHD582NNFc7mioiKxY8cOsWPHDgFAvPLKK2LHjh3GYeJz584Ver1erFixQuzatUvceuutNofitWjRQqxdu1Zs375dXHvttZoYilcb999/v9Dr9WL9+vVmQzqLi4uN+/jyOZo+fbr46aefxKFDh8TOnTvFU089Jfz8/MQPP/wghPDtc2OLerSREL59fh599FGxfv16cfDgQZGVlSWGDRsmIiIijP93ffncCCGH1wcEBIjnn39e7Nu3T3z88cciLCxMfPTRR8Z9vPkcMbzU0ptvvilatmwpgoKCRM+ePY1DYb3dunXrBACrr7vuuksIIYfjzZo1SyQkJIjg4GBx1VVXiV27dpkd49KlS2Ly5MkiOjpahIaGimHDhomjR4964N04n61zA0C8//77xn18+RyNGzfO+HfTpEkTcd111xmDixC+fW5ssQwvvnx+lDlJAgMDRbNmzcTNN98s/vjjD+PjvnxuFN98843o3LmzCA4OFh06dBBvv/222ePefI50QgjhmTofIiIiIsexzwsRERFpCsMLERERaQrDCxEREWkKwwsRERFpCsMLERERaQrDCxEREWkKwwsRERFpCsMLERERaQrDCxEREWkKwwsRERFpCsMLERERacr/A6tGNlVdQL9gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(y_train-trainPredict, color = 'blue', label = 'Training Error')\n",
    "#plt.plot(combined_data-combined_datap, color = 'blue', label = 'Error')\n",
    "X_data = np.arange(439, 628)\n",
    "z=np.concatenate((valPredict,testPredict), axis=0)\n",
    "p=np.concatenate((y_val,y_test), axis=0)\n",
    "plt.plot(X_data,p-z, color = 'darkgreen', label = 'Testing Error')\n",
    "yticks_positions = [-0.3, -0.2,-0.1,0.0 ,0.1,0.2,0.3]\n",
    "#yticks_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "\n",
    "# Apply the yticks\n",
    "#plt.yticks(yticks_positions, yticks_labels)\n",
    "plt.yticks(yticks_positions)\n",
    "plt.legend()\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "824ddb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model =  regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd819012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model_best\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./saved_model_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02f123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
